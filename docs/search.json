[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html#thomas-h.-simm",
    "href": "index.html#thomas-h.-simm",
    "title": "TH Simm Python Pages",
    "section": "Thomas H. Simm",
    "text": "Thomas H. Simm\nData Scientist / Materials Scientist / Physicist"
  },
  {
    "objectID": "index.html#links",
    "href": "index.html#links",
    "title": "TH Simm Python Pages",
    "section": "Links",
    "text": "Links\nWebsite built with Quarto visit for more info https://quarto.org/docs/websites."
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/FastaiCheatSheets.html#misc.",
    "href": "posts/MACHINELEARNING/neural_networks/FastaiCheatSheets.html#misc.",
    "title": "FastAI CheatSheet",
    "section": "Misc.",
    "text": "Misc.\n\nCreating a path\nWhere the data is\n\n# current directory\npath=Path()\n\nPath.BASE_PATH = path\n\n# another folder off cwd\npath = Path('bears')\n#if doesn't exist can do\npath.mkdir()\n\n# as part of downloading inbuilt data\npath = untar_data(URLs.IMDB)\n\n\n# When using path to select a subfolder\n`trains = path/'train'`\nOr to view\n`(path/'train').ls()"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/FastaiCheatSheets.html#loading-the-data",
    "href": "posts/MACHINELEARNING/neural_networks/FastaiCheatSheets.html#loading-the-data",
    "title": "FastAI CheatSheet",
    "section": "Loading the data",
    "text": "Loading the data\nDataLoaders is a thin class that just stores whatever DataLoader objects you pass to it, and makes them available as train and valid. Although it’s a very simple class, it’s very important in fastai: it provides the data for your model. The key functionality in DataLoaders is provided with just these four lines of code (it has some other minor functionality we’ll skip over for now):\nclass DataLoaders(GetAttr):\n    def __init__(self, *loaders): self.loaders = loaders\n    def __getitem__(self, i): return self.loaders[i]\n    train,valid = add_props(lambda i,self: self[i])\nTo turn our downloaded data into a DataLoaders object we need to tell fastai at least four things:\n\nWhat kinds of data we are working with\nHow to get the list of items\nHow to label these items\nHow to create the validation set\n\n\nDataBlocks\n\ndBlock = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\nblocks what format is the data? - ImageBlock - CategoryBlock - TextBlock\nget_items takes a function that that gives the list of all data (images/text etc) - get_image_files - partial(get_text_files, folders=['train', 'test', 'unsup'])\nsplitter how data is plit into test and validation sets - RandomSplitter(valid_pct=0.2, seed=42) randomly - def splitter(df):     train = df.index[~df['is_valid']].tolist()     valid = df.index[df['is_valid']].tolist()     return train,valid use a function this one uses data frame\nget_x and get_y get the independent (x) and dependent variables (y) takes a function that provides labels for the data - parent_label gets the name of the parent folder e.g. when doing categorical data put rabbits in ‘rabbits’ folder and horses in ‘horses’ folder - def get_y(r): return r['labels'].split(' ')\nitem_tfms runs on individual items- allows for data augmentation, making images the same size etc - Resize(128) resize all images to 128 - Resize(128, ResizeMethod.Pad, pad_mode='zeros' resize with zeros\nbatch_tfms similar to the above but apply to all batch - [*aug_transforms(size=size, min_scale=0.75), Normalize.from_stats(*imagenet_stats)]\n\n\nDataLoaders\nThe data block is like a template for creating a DataLoaders. We still need to tell fastai the actual source of our data—in this case, the path where the images can be found along with some other details.\nA DataLoaders includes validation and training DataLoaders. DataLoader is a class that provides batches of a few items at a time to the GPU. When you loop through a DataLoader fastai will give you 64 (by default) items at a time, all stacked up into a single tensor.\n\ndls = dBlock.dataloaders(path, \n            path=path, \n            bs=128, \n            seq_len=80)\n\nafter_item applied after each item equivalent of item_tfms\nbefore_batch applied on list of items before they’re collated\nafter_batch applied on the batch as a whole after construction- equivalent to batch_tfms\nbs batch size\nseq_len\npath path to data"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/FastaiCheatSheets.html#the-model",
    "href": "posts/MACHINELEARNING/neural_networks/FastaiCheatSheets.html#the-model",
    "title": "FastAI CheatSheet",
    "section": "The model",
    "text": "The model\n\nDifferent models\n\nVision\nfrom fastai.vision import models\nlearn = cnn_learner(data, models.resnet18, metrics=accuracy)\nTorchvision models\n\nresnet18, resnet34, resnet50, resnet101, resnet152\nsqueezenet1_0, squeezenet1_1\ndensenet121, densenet169, densenet201, densenet161\nvgg16_bn, vgg19_bn\nalexnet Others\nDarknet\nunet\n\n\n\nText\nfrom fastai.text import *\nlearn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\nOr for classification\nlearn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n\n\nTabular\nfrom fastai.tabular import *\nlearn = tabular_learner(data, layers=[200,100], emb_szs={'native-country': 10}, metrics=accuracy)\n\n\n\nLearning\nTo fit the model we have a few options:\n\nlearn.fit(10,lr=4e-3)\nlearn.fit_one_cycle()\nlearn.fine_tune(10, base_lr=1e-3, freeze_epochs=7)\nlearn.fine_tune(15, lr)\n\nFastAI adds an extra 2 layers on the end of neural network when doing transfer learning, these can then be fitted using fine_tune. It is recommended to do a few fits frozen before unfreezing. This is normally the best option for transfer learning.\nBut the other ones can be used. In general fit can be more unstable and lead to bigger losses, but can be useful if fine_tune is not bringing losses down.\nhttps://forums.fast.ai/t/fine-tune-vs-fit-one-cycle/66029/6\nfit_one_cycle = New Model\n\nfine_tuning = with Transfer Learning?\n\nI’d say yes but with a very strong but, only because it’s easy to fall into a trap that way. fine_tuning is geared towards transfer learning specifically, but you can also just do fit_one_cycle as well! (Or flat_cos).\n\nFor beginners it’s a great starting fit function (and advanced too), but also don’t forget that you can then\nAn alternative to fine_tuning with transfer learning is to specify which layers are frozen:\nUnfreeze layers, to freeze all except the last two parameter groups use freeze_to:\nlearn.freeze_to(-2)\nlearn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))\nAnd unfreeze a bit more\nlearn.freeze_to(-3)\nOr unfreeze the whole model\nlearn.unfreeze\nCan see the difference between fine_tune and fit_one_cycle from the fine_tune function:\n\ndef fine_tune(self:Learner, epochs, base_lr=2e-3, freeze_epochs=1, lr_mult=100,\n              pct_start=0.3, div=5.0, **kwargs):\n    \"Fine tune with `freeze` for `freeze_epochs` then with `unfreeze` from `epochs` using discriminative LR\"\n    self.freeze()\n    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n    base_lr /= 2\n    self.unfreeze()\n    self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)\n\n\n\nSome other useful bits\nFind the best learing rate:\nlearn.lr_find()"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#general",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#general",
    "title": "TensorFlow cheat sheet",
    "section": "General",
    "text": "General\nLibrary websites:\nkeras.io\ntensorflow.org"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#courses",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#courses",
    "title": "TensorFlow cheat sheet",
    "section": "Courses",
    "text": "Courses\nI have tried both of the following courses: DeepLearning.AI TensorFlow Developer Professional Certificate and TensorFlow 2 for Deep Learning Specialization.\n\nDeepLearning.AI TensorFlow Developer Professional Certificate\nTensorFlow 2 for Deep Learning Specialization\n\nThe Tensorflow2 course is a bit longer and goes into more depth, although there are additional extended courses for the deeplearning one. The deeplearning one can be done within the current 7 days trail period of coursera. The Tensorflow2 course is tricky to do in this timeframe. This is due to more material, the harder coursework, and waiting for capstone projects to be marked.\nIn the end I only did the first course of Tensorflow2 as I found the tests had material that wasn’t explained within the course and I found the lectures lacking in detail and the instructors became increasingly boring. I gave up after getting to the capstone in course 2 (of 3) when they asked a question about an NLP network that was never explained anywhere. However, the coursework is a good challenge, so it may be worth doing the course for this alone and learning from other sources in addition to this one.\nI prefered the DeepLearning courses as they were more in depth and didn’t assume as much prior knowledge, and the presentation was better. I am currently working through the follow-up course TensorFlow: Advanced Techniques Specialization and given time will do the NLP and MLOps courses.\nSome Others:\nOne by Udacity Intro to TensorFlow for Deep Learning is being offered for free and looks okay too.\nTensorFlow example tutorials written as Jupyter notebooks and run directly in Google Colab—a hosted notebook environment that requires no setup. Click the Run in Google Colab button. Part of the TensorFlow resources."
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#resources",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#resources",
    "title": "TensorFlow cheat sheet",
    "section": "Resources",
    "text": "Resources\n\nTensorFlow’s website recommendations\nFrançois Chollet\n\nHis book Deep Learning with Python, Second Edition can be read online.\n\nDeep learning book by Ian Goodfellow and Yoshua Bengio and Aaron Courville\n\navailable free online\n\nProbabilistic Programming & Bayesian Methods for Hackers\n\navailable online"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#model-creations",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#model-creations",
    "title": "TensorFlow cheat sheet",
    "section": "Model creations",
    "text": "Model creations\nThe easiest way to create a model in Keras is through keras.Sequential, which creates a neural network as a stack of layers.\nSo in the examplel below - the 1st layer has units = 4 and input_shape=2 with a relu activation function - the 2nd layer has units = 3 with a relu activation function - the 3rd layer has units = 1\nThe 3rd layer is the output layer. Since there is no activation function this would be a regression problem to predict one value.\n\nFor non sequential models or with multiple inputs/outputs see functional API\n\nTabular Data\nhttps://www.kaggle.com/code/thomassimm/premier-league-predictions-using-tensorflow\n\nmodel = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(512//8,activation='relu'),\n        tf.keras.layers.Dense(1,activation='sigmoid')        \n    ])\n\n\n\nImage Data\n\nmodel = tf.keras.models.Sequential([ \n          tf.keras.layers.Convolution2D( 64,(3,3),activation='relu',input_shape=(28,28,1) ),\n          tf.keras.layers.MaxPool2D(2,2),\n          tf.keras.layers.Flatten(),\n          tf.keras.layers.Dense(256//2,activation='relu'),\n          tf.keras.layers.Dense(1,activation='sigmoid') ])\n\n\n\nLanguage Data\nThe standard language model starts with an embedding layer, this then needs to be flattened to a vector, then we can add a dense layer before an output layer.\nThe Embedding layer creates a vector-space for the text data. So for example, the words beautiful and ugly may be in opposite directions. And words such as cat and kitten may be close together in vector space.\nGlobalAveragePooling1Dcan be replaced by Flatten()\n\nmodel = tf.keras.Sequential([ \n    tf.keras.layers.Embedding(num_words,embedding_dim,input_length=maxlen),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(5,'softmax')\n])\n\nThe model above does not take account for the order of words,\nIf we want to do this we can insert an additional layer after the embedding layer. For example, by using the LSTM model as below\n\nmodel_lstm= tf.keras.Sequential([\n    tf.keras.layers.Embedding(VOCAB_SIZE,EMBEDDING_DIM,input_length=MAXLEN),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')   \n])\n\nWe can even insert a conolution layer after the embedding instead\ntf.keras.layers.Conv1D(128,5,activation='relu')\nFor two consecutive layers of RNNs use return_sequences=True\n\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#compile-the-model",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#compile-the-model",
    "title": "TensorFlow cheat sheet",
    "section": "Compile the model",
    "text": "Compile the model\nTo compile the model, need to define the following:\n\nthe optimizer to use, i.e. how to update the parameters to improve model during fitting\nthe loss, i.e. what defines the goodness of the fit\nany metrics to record\n\n\nopt = keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(\n    optimizer=opt,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#evaluate-predict-the-model",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#evaluate-predict-the-model",
    "title": "TensorFlow cheat sheet",
    "section": "Evaluate / Predict the model",
    "text": "Evaluate / Predict the model\ntest_loss, test_accuracy = model.evaluate(scaled_test_images,\ntf.keras.utils.to_categorical(test_labels),\nverbose=0)\nand more or less outputs depending on metrics used\npred = model.predict(X_sample)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#saving-and-loading",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#saving-and-loading",
    "title": "TensorFlow cheat sheet",
    "section": "Saving and Loading",
    "text": "Saving and Loading\n\nSaving / Loading weights\n\nmodel_weights_file='my_file'\n\nmodel.save_weights(model_weights_file)\n\nmodel.load_weights(model_weights_file)\n\n\n# All the model\n\nmodel.save('saved_model/my_model')\n\nnew_model = tf.keras.models.load_model('saved_model/my_model')"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#callbacks",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#callbacks",
    "title": "TensorFlow cheat sheet",
    "section": "Callbacks",
    "text": "Callbacks\nwithin model.fit(....)\ncallbacks=[callback_function]\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n\nEarlyStopping\n\nto stop the model early if some conditions are met\n\nModelCheckpoint\n\nsave the model/model weights (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)\nmain data stored similar to ‘.data-00000-of-00001’\nhttps://www.tensorflow.org/tutorials/keras/save_and_load#what_are_these_files\nCan give file names with variables using {}\n\nval_loss\nval_accuracy\nbatch\nepoch\n\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    min_delta=0.0001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n    monitor='val_binary_accuracy',\n)\n\nfilepath = os.path.join(cwd,'checkpoints_every_epoch/checkpoint.{epoch}.{batch}')\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n        save_weights_only=True,\n        save_best_only=True,\n        filepath=filepath,\n    )"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#overfitting-strategies",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#overfitting-strategies",
    "title": "TensorFlow cheat sheet",
    "section": "Overfitting strategies",
    "text": "Overfitting strategies\n\nDropout\nThe idea behind dropout is to randomly drop out some fraction of a layer’s input units every step of training, making it much harder for the network to learn those spurious patterns in the training data that leads to overfitting.\nInstead, it has to search for broad, general patterns, whose weight patterns tend to be more robust.\nYou could also think about dropout as creating a kind of ensemble of networks like with RandomForests.\nExample useage, apply 30% dropout to the next layer\nlayers.Dropout(rate=0.3),\nlayers.Dense(16)\nExample taken from kaggle https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization\n\n\n\nBatch Normalization\nNormalization is important in neural networks, it can really significantly improve the results of the values of the input and output are between 0 and 1.\nIn contrast, it is not important in other models such as random forests. Hence, the input data is often normalised such as train_datagen = ImageDataGenerator(rescale=1./255.) in image models.\nSo if it is good to normalize the input data it can also be good to normalize the layers of the network. This can be done with a BatchNormalization layer.A batch normalization layer looks at each batch as it comes in, first normalizing the batch with its own mean and standard deviation, and then also putting the data on a new scale with two trainable rescaling parameters. Batchnorm, in effect, performs a kind of coordinated rescaling of its inputs.\nAs stated in kaggle-dropout-and-batch-normalization batchnorm: - batchnorm is most often added as an aid to the optimization process - but it can sometimes also help prediction performance - Models with batchnorm tend to need fewer epochs to complete training. - And can fix various problems that can cause the training to get “stuck”. - it can be used at almost any point in a network.\nlayers.Dense(16, activation='relu'),\nlayers.BatchNormalization(),\n… or between a layer and its activation function:\nlayers.Dense(16),\nlayers.BatchNormalization(),\nlayers.Activation('relu'),\n… Or if you add it as the first layer of your network it can act as a kind of adaptive preprocessor like Sci-Kit Learn’s StandardScaler."
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#multiple-inputs-and-outputs",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#multiple-inputs-and-outputs",
    "title": "TensorFlow cheat sheet",
    "section": "Multiple inputs and outputs",
    "text": "Multiple inputs and outputs\n3 inputs and 2 outputs. Simple model\nInputs: - temp_train - nocc_train - lumbp_train\nOutputs: - out1_train - out2_train\nThings to note: - inputs in the model is a list of the Input() parts - concatentate is used with the input list to provide input to the next layers of the model - outputs in the model is a list of the output layers - When compiling use dictionary to set loss and metrics to each output - or lists ['binary_crossentropy','binary_crossentropy'] - When fitting, for the inputs/outputs either: - provide a list of the inputs [temp_train,nocc_train, lumbp_train] - give as a dict {'layer_name':variable_name}\n\n## Functional: multiple inputs\n# N.B. lowercase 'c' concatenate\nimport tensorflow as tf \nfrom tensorflow.keras.layers import Input, Dense, concatenate\ninput_shape=(1,)\n\n# get individual inputs\ninputs_temp = Input(shape=input_shape,name='temp')\ninputs_nocc = Input(shape=input_shape,name='nocc')\ninputs_lumbp = Input(shape=input_shape,name='lumbp')\n\n# combine them\ninput_list = [inputs_temp,inputs_nocc,inputs_lumbp]\ninput_layer =concatenate(input_list)\n\n# add inputs to the model for two outputs\noutput_pred1  = Dense(2,activation='sigmoid',name='out_1')(input_layer)\noutput_pred2 = Dense(2,activation='sigmoid',name='out_2')(input_layer)\n\n# output layer\noutput_list = [output_pred1, output_pred2]\n\n# create the model object\nmodel = tf.keras.Model(inputs=input_list, outputs=output_list )\n\n# show the model\nmodel.summary()\n\n# Compile\nmodel.compile(\n        optimizer='SGD',\n        loss={'out_1':'binary_crossentropy',\n              'out_2':'binary_crossentropy'},\n        metrics={'out_1':['accuracy'],\n                 'out_2':['accuracy']},\n        loss_weights=[1,0.2]\n        )\n\ntf.keras.utils.plot_model(model)\n\n\n# Define training inputs and outputs\ninputs_train = {'temp': temp_train, 'nocc': nocc_train, 'lumbp': lumbp_train}\noutputs_train = {'out_1': out1_train, 'out_2': out2_train}\n\n# fit the model\nmodel.fit(inputs_train,outputs_train)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#inception-images",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#inception-images",
    "title": "TensorFlow cheat sheet",
    "section": "Inception (images)",
    "text": "Inception (images)\n\nLoad the model pre-trained weights\nImport the model architecture\nGive the model the input shape for data\nLoad the weights into the model\nFreeze all the layers\nPick out the front part of the model, as the layers to the end are more specialized\nAdd extra layers to the model that can be fitted to\n\n\n# 1- Download the inception v3 weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n# 2- Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# 3- create the model and load in the weights\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n                                  include_top = False, \n                                  weights = None) \n\n# 4- load weights into the model\npre_trained_model.load_weights(local_weights_file)\n\n# 5- Make all the layers in the pre-trained model non-trainable\nfor layers in pre_trained_model.layers:\n    layers.trainable = False\n    \n# 6- Pick out part of the model\nlast_desired_layer = pre_trained_model.get_layer('mixed7')    \nlast_output = last_desired_layer.output\n\n# 7- Add extra layers to the model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)  \n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024,activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1,activation='sigmoid')(x) \n\n# Create the complete model by using the Model class\nmodel = Model(inputs=pre_trained_model.input, outputs=x)\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001), \n            loss = 'binary_crossentropy',\n            metrics = ['accuracy'])"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#summary-info-of-model",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#summary-info-of-model",
    "title": "TensorFlow cheat sheet",
    "section": "Summary / info of model",
    "text": "Summary / info of model\nmodel.summary()\nGet summary of the model"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#class-or-function---metrics-and-losses",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#class-or-function---metrics-and-losses",
    "title": "TensorFlow cheat sheet",
    "section": "Class or Function - Metrics and Losses",
    "text": "Class or Function - Metrics and Losses\nIn general, classes use camel formatting CategoricalAccuracy whereas function use underscores and lower case categorical_accuracy and sometimes initials MAE\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#low-level-handling-of-metrics",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#low-level-handling-of-metrics",
    "title": "TensorFlow cheat sheet",
    "section": "Low level handling of metrics",
    "text": "Low level handling of metrics\n\nmetric.update_state() to accumulate metric stats after each batch\nmetric.result get current value of metric to display\nmetric.reset_state() to reset metric value typically at the end of epoch"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#categorical-binary-versus-multiple",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#categorical-binary-versus-multiple",
    "title": "TensorFlow cheat sheet",
    "section": "Categorical: Binary versus Multiple",
    "text": "Categorical: Binary versus Multiple\nFor categorical data there is a slight difference between if there are only 2 categories or more.\nGoing from binary to multiple: - We need to change activation in model from sigmoid to softmax in final Dense layer - Change loss function from binary_crossentropy to categorical_crossentropy in compile - Making data one-hot encoded, i.e. columns for each outcome - Or use SparseCategoricalCrossentropy\n\nmodel_binary = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(1,activation='sigmoid')        \n    ])\n\nmodel_multi = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(4,activation='softmax')        \n    ])\n\n\nmodel_binary.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n\nmodel_multi.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n\n\n# One-hot encoding method\n\ny_binary =[1,0,0,0,0,0,1,1,1,1,0,1,0,1]\n\ny_multi=[1,2,4,6,1,3,4,2,4,2,5,2,1,4,2,1]\ny_multi=tf.keras.utils.to_categorical(y_multi)\ny_multi\n\narray([[0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)\n\n\nAlternatively, with output data like [0, 1, 4, 0, 2, 3, 3, 0, …]\nuse: - SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(\n                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer='adam',\n                 metrics=['accuracy'])"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#learning-rate",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#learning-rate",
    "title": "TensorFlow cheat sheet",
    "section": "Learning rate",
    "text": "Learning rate\nFind the best learning rate by using callbacks\nThe learning rate to use on the data below would be where the loss is low (y-axis) but not too close to where it increases or is unstable.\nSo for this on the downward part of the curve between 10E-6 and 10E-5\n\n# Set the learning rate scheduler\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch / 20) )\n    \n# Set the training parameters\nmodel_tune.compile(loss=\"mse\", optimizer=optimizer)\n    \n# train the model\nhistory = model_tune.fit(dataset, epochs=100, callbacks=[lr_schedule])\n\n# plot the results\n# Define the learning rate array\nlrs = 1e-8 * (10 ** (np.arange(100) / 20))\n\n# Plot the loss in log scale\nplt.semilogx(lrs, history.history[\"loss\"])"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#lambda-functions",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#lambda-functions",
    "title": "TensorFlow cheat sheet",
    "section": "lambda functions",
    "text": "lambda functions\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda\ntf.keras.layers.Lambda(     function, output_shape=None, mask=None, arguments=None, **kwargs )\nAdd a function that works on the data within the model\n\n# expand the dimensions\ntf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n                      input_shape=[window_size])\n\n# make the output larger (can be useful if predicting to large values, but previous layer have activation function so values are close to 1)\ntf.keras.layers.Lambda(lambda x: x * 100.0)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#force-cpugpu",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/1_Tensorflow.html#force-cpugpu",
    "title": "TensorFlow cheat sheet",
    "section": "Force CPU/GPU",
    "text": "Force CPU/GPU\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\n\n# Check available CPU/GPU devices\n\nprint(tf.config.list_physical_devices('CPU'))\n\nprint(tf.config.list_physical_devices('GPU'))\n\nwith tf.device(\"CPU:0\"):\n    model.fit(....)\n    \nwith tf.device(\"GPU:0\"):\n    model.fit(....)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#dataset-generators",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#dataset-generators",
    "title": "TensorFlow cheat sheet 2",
    "section": "Dataset generators",
    "text": "Dataset generators\nHave you ever had to work with a dataset so large that it overwhelmed your machine’s memory? Or maybe you have a complex function that needs to maintain an internal state every time it’s called, but the function is too small to justify creating its own class. In these cases and more, generators and the Python yield statement are here to help\nhttps://realpython.com/introduction-to-python-generators/\nHow yield works:\n\ndef do_yield():\n    for i in range(20):\n        yield i\n        \ngot_yield =  do_yield()\n\nprint(got_yield)\nprint(next(got_yield))\nprint(next(got_yield))\n\nnext(got_yield)\n\nprint(next(got_yield))\ngot_yield\nprint(next(got_yield))\n\nWhen datasets are large and won’t fit into memory, a way to handle this is to use detaset generators. Where data is fed into the model without loading it into memory at once.Each time we iterate the generator, it yields the next value in the series.\nAn example is below. The function takes a path to a file but returns a yield statement, or a data generator, and not a line of the data.\nAs above x,y = next(text_datagen) gets the next line of the text.\nThis can be used when fitting to the model using model.fit_generator(text_datagen)\nSee also load images.\n\ndef get_data(filepath):\n    with open(filepath,'r') as f:\n        for row in f:\n            x=row[0]\n            y=row[1]\n            yield (x,y)\n            \ntext_datagen = get_data('file.txt')\n\nmodel.fit_generator(text_datagen, steps_per_epoch=1000, epochs=5)\n\n\n# or something more practical:\ndef get_generator(features, labels, batch_size=1):\n    for n in range(int(len(features)/batch_size)):\n        x = features[n*batch_size: (n+1)*batch_size]\n        y = labels[n*batch_size: (n+1)*batch_size]\n        yield (x,y)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#the-dataset-class",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#the-dataset-class",
    "title": "TensorFlow cheat sheet 2",
    "section": "The dataset Class",
    "text": "The dataset Class\n\nx=np.random.randint(0,255,(100,20,2,2))\ny=np.random.randint(0,4,size=(100,1))\n\ndataset_1 = tf.data.Dataset.from_tensor_slices(x)\n\nprint(\">>\",dataset_1.element_spec)\nprint('>> N.B. first dimension inetrpreted as batch size')\n\ndataset_2 = tf.data.Dataset.from_tensor_slices(y)\nprint(\">>\",dataset_2.element_spec)\n\ndataset_zipped = tf.data.Dataset.zip((dataset_1,dataset_2))\nprint(\">>\",dataset_zipped.element_spec)\n\ndataset_comb = tf.data.Dataset.from_tensor_slices((x,y))\nprint(\">>\",dataset_comb.element_spec)\n\n>> TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None)\n>> N.B. first dimension inetrpreted as batch size\n>> TensorSpec(shape=(1,), dtype=tf.int32, name=None)\n>> (TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(1,), dtype=tf.int32, name=None))\n>> (TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(1,), dtype=tf.int32, name=None))\n\n\nCan access the values by iterating\n\ndef check3s(dataset_comb):\n    dataset_iter = iter(dataset_comb)\n    for i,x in enumerate(dataset_iter):\n        if tf.squeeze(x[1])==3:\n            print('Has 3s')\n            return\n    return 'no 3s'\ncheck3s(dataset_comb)\n\nHas 3s\n\n\n\nFilter\nFilter certain values\n\ndef label_func(image,label):\n    return tf.squeeze(label) != 3\n\ndataset_comb = dataset_comb.filter(label_func)\n\ncheck3s(dataset_comb)\n\n'no 3s'\n\n\n\n\nMap\nModify values. Below creates one-hot encoding\n\ndef map_func(image, x):\n    return (image,tf.one_hot(x,depth=3) )\ndataset_comb_2=dataset_comb.map(map_func)\n\nfor i,x in enumerate(dataset_comb):\n    if i<5:\n        print(i,x[1].numpy())    \n    else:\n        break\n        \nfor i,x in enumerate(dataset_comb_2):\n    if i<5:\n        print(i,x[1].numpy())    \n    else:\n        break\n\n0 [0]\n1 [1]\n2 [2]\n3 [2]\n4 [2]\n0 [[1. 0. 0.]]\n1 [[0. 1. 0.]]\n2 [[0. 0. 1.]]\n3 [[0. 0. 1.]]\n4 [[0. 0. 1.]]\n\n\n\ndataset.batch(20), drop_remainder=True set batch size to 16 and remove any remaining samples if not divisible\ndataset.repeat(10) set the number of epochs. No value inside is indefinitely\ndataset.shuffle(100) shuffle the data, no of sample in the buffer\ndataset.filter(function_name) filter the values use lambda or a function that returns a boolean\ndataset.map(func_name) transform the values\n\ne.g. dataset.map(lambda x:x*2) doubles all values\n\ndataset.take(1) take a value from the dataset"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#tensor-math",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#tensor-math",
    "title": "TensorFlow cheat sheet 2",
    "section": "Tensor Math",
    "text": "Tensor Math\n\nimport tensorflow.keras.backend as K\n\nx = K.arange(0,10)\ny = K.square(x)\ny_mean = K.mean(y)\n\nprint(f\"x = {x},\\ny = {y},\\ny_mean = {y_mean}\")\n\nx = [0 1 2 3 4 5 6 7 8 9],\ny = [ 0  1  4  9 16 25 36 49 64 81],\ny_mean = 28\n\n\n\n#hide-input\nprint(f\"tf.add([1,2],[3,4]) = {tf.add([1,2],[3,4])}\\n\")\nprint(\"Or with operator overloading\")\nprint(f\"tf.Variable([1,2])+tf.Variable([3,4]) = {tf.Variable([1,2])+tf.Variable([3,4])}\\n\")\nprint(f\"x = tf.Variable([[1,2],[3,4]])\\n\")\nx=tf.Variable([[1,2],[3,4]])\nprint(f\"tf.square(x) = {tf.square(x)}\\n\")\nprint(\"Reduces dimension by adding up components\")\nprint(f\"tf.reduce_sum(x) = {tf.reduce_sum(x)}\\n\")\n      \n\ntf.add([1,2],[3,4]) = [4 6]\n\nOr with operator overloading\ntf.Variable([1,2])+tf.Variable([3,4]) = [4 6]\n\nx = tf.Variable([[1,2],[3,4]])\n\ntf.square(x) = [[ 1  4]\n [ 9 16]]\n\nReduces dimension by adding up components\ntf.reduce_sum(x) = 10"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#tensor-operations",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#tensor-operations",
    "title": "TensorFlow cheat sheet 2",
    "section": "Tensor Operations",
    "text": "Tensor Operations\n\nEvaluated immediately\nTensorFlow supports two types of code execution, graph-based where all of the data and ops are loaded into a graph before evaluating them within a session, or eager based where all of the code is executed line by line.\nIf eager mode was off, tensor would not be evaluated so\nx_sq = tf.square(2)\nprint(x_sq)\nthe print statement would just show details of the tensor object, such as its name, shape, data type and all that but it would not yet store the number 4 as a value.\nOtherwise values are evaluated immediately in custom eager mode = On\n\n\nBroadcasting\nBroadcasting is where adding or subtracting two tensors of different dimensions is handled in a way where the tensor with fewer dimensions is replicated to match the dimensions of the tensor with more dimensions.\na = tf.constant([[1,2],[3,4]])\n>>tf.add(a,1)\n=tf.Tensor([[2,3],[4,5]])\nOr overloading can utilise Python syntax such as\n>>a ** 2\n=tf.Tensor([[1,4],[9,16]])\nOr using numpy math operations. TensorFlow will convert the tensor objects a and b into ndarrays, and then pass those ndarrays to the np.cos function.\n>>np.cos(a)\n=array([[ 0.54030231, -0.41614684],        [-0.9899925 , -0.65364362]])\nDon’t need to preconvert from the ndarray data type into a tensor data type. TensorFlow handles this automatically.\nndarray = np.ones([3,3])\n=[[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]]\ntf.multiply(ndarray,3)\n=tf.Tensor( [[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]], shape=(3,3), dtype=float64)\nTensors can be easily converted back to numpy arrays using tensor.numpy()"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#simple-example-of-using-gradient-tape-to-calculate-gradient-of-a-function",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#simple-example-of-using-gradient-tape-to-calculate-gradient-of-a-function",
    "title": "TensorFlow cheat sheet 2",
    "section": "Simple example of using gradient tape to calculate gradient of a function",
    "text": "Simple example of using gradient tape to calculate gradient of a function\n\ndef myfunc(x):\n    return tf.math.sin(x) + tf.math.exp(x/3)\n\nw = tf.Variable(np.arange(0, np.pi*2,.2))\nwith tf.GradientTape() as tape:\n    loss = myfunc(w)\ngradient = tape.gradient(loss, w).numpy()\n\nplt.plot(w.numpy(), loss,'.-')\nplt.grid(True)\nplt.plot(w.numpy(), gradient,'x--');\nplt.legend(['Loss','Gradient of Loss']);"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#using-watch",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/2_Tensorflow.html#using-watch",
    "title": "TensorFlow cheat sheet 2",
    "section": "Using watch",
    "text": "Using watch\nIf use watch on a variable the following variables referencing that variable are also watched\nBut the calls to new functions need to be within the with statement, but the gradient getting doesn’t\n\nx = tf.Variable(np.arange(0, np.pi*2,.2))\n\nwith tf.GradientTape() as t:\n    t.watch(x)\n    \n    y = tf.sin(x)\n    z = tf.exp(y)\ndz_dx = t.gradient(z,x)\n\nplt.plot(x.numpy(),z.numpy())\nplt.plot(x.numpy(),dz_dx.numpy(),'--')\nplt.legend(['z','dz/dx'])\nplt.grid(True)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#coding-custom-layer",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#coding-custom-layer",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Coding custom layer",
    "text": "Coding custom layer\nA layer class is inherited from Kera’s Layer class. Hence, MyLayer(Layer):\n\ndef __init__(self, units=32):\n\nInitializes the class, accepts parameters and sets up internal variables.\nsuper().__init__() returns a temporary object of the superclass (proxy object) the Layer class. This allows us to acces methods of the base class. - make sure to pass class name and self in super() - or **kwargs\nThen build and call functions can be added to create the layer and when it is called. N.B. build can often be moved to __init__.\n\ndef build(self, input_shape):\n\nruns when instance is created\ncreates state of layers (weights)\n\ndef call(self, inputs):\n\ncall does the computation\n\n\nThe values for the parameters can be explicitly set using functions like tf.random_normal_initializer() and sepcifying a shape.\nThe key to call is defining how the parts in build and __init__ are put together to create the computation of the layer.\nAlso note that in the call the format is the same as for the functional API, where the previous layer is added at the end of the next layer.\nAll the variables (weights and biases) can also be accesed with layer_class.variables.\n\n# Create a custom layer\nfrom tensorflow.keras.layers import Layer\nimport tensorflow as tf\n\nclass SimpleDense(Layer):\n    \n    def __init__(self,units=32):\n        super(SimpleDense, self).__init__()\n        self.units = units\n        \n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.w = tf.Variable(\n                initial_value=w_init(shape=(input_shape[-1], self.units), dtype='float32'),\n                trainable=True,name='kernel',\n                                )\n        b_init = tf.zeros_initializer()\n        self.b = tf.Variable(\n                initial_value=b_init(shape=(self.units), dtype='float32'),\n                trainable=True, name='bias',\n                                )\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w)+self.b\n    \ndense_layer = SimpleDense(units=32)\n\nx = tf.ones((1,1))\n\nprint(dense_layer(x) )\nprint()\nprint(f\"Weights = {dense_layer.weights[0].numpy()} \\n\\nand biases {dense_layer.weights[1].numpy()}\")\nprint()\nprint([ var.numpy() for var in dense_layer.variables])\n\ntf.Tensor(\n[[-0.07436698 -0.02011585  0.05582675  0.05404044  0.02519816  0.02855827\n   0.00046192  0.01360966  0.04663334  0.04556176  0.04592257  0.04647708\n  -0.03950281 -0.00014847 -0.03248019  0.08354251  0.07218082 -0.01156685\n   0.04577427 -0.06801199 -0.02725383 -0.02071865  0.08600459 -0.00035707\n  -0.03410981  0.00493511 -0.05133317 -0.12937713 -0.13792662 -0.01709494\n  -0.05110807 -0.01718794]], shape=(1, 32), dtype=float32)\n\nWeights = [[-0.07436698 -0.02011585  0.05582675  0.05404044  0.02519816  0.02855827\n   0.00046192  0.01360966  0.04663334  0.04556176  0.04592257  0.04647708\n  -0.03950281 -0.00014847 -0.03248019  0.08354251  0.07218082 -0.01156685\n   0.04577427 -0.06801199 -0.02725383 -0.02071865  0.08600459 -0.00035707\n  -0.03410981  0.00493511 -0.05133317 -0.12937713 -0.13792662 -0.01709494\n  -0.05110807 -0.01718794]] \n\nand biases [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0.]\n\n[array([[-0.07436698, -0.02011585,  0.05582675,  0.05404044,  0.02519816,\n         0.02855827,  0.00046192,  0.01360966,  0.04663334,  0.04556176,\n         0.04592257,  0.04647708, -0.03950281, -0.00014847, -0.03248019,\n         0.08354251,  0.07218082, -0.01156685,  0.04577427, -0.06801199,\n        -0.02725383, -0.02071865,  0.08600459, -0.00035707, -0.03410981,\n         0.00493511, -0.05133317, -0.12937713, -0.13792662, -0.01709494,\n        -0.05110807, -0.01718794]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)]\n\n\nOr equivalently…\n\n# Create a custom layer\nfrom tensorflow.keras.layers import Layer\nimport tensorflow as tf\n\nclass MyLayer(Layer):\n    \n    def __init__(self,units,input_dim):\n        super(MyLayer, self).__init__()\n        self.w = self.add_weight(shape=(input_dim,units),\n                                initializer='random_normal',\n                                trainable=True)\n        self.b = self.add_weight(shape=(units,),\n                                 initializer='zeros',\n                                trainable=True)\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w)+self.b\n    \ndense_layer = MyLayer(3,5)\n\nx = tf.ones((1,5))\n\nprint(dense_layer(x) )\nprint()\nprint(f\"Weights = {dense_layer.weights[0].numpy()} \\n\\nand biases {dense_layer.weights[1].numpy()}\")"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#create-a-dropout-layer-as-a-custom-layer",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#create-a-dropout-layer-as-a-custom-layer",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Create a Dropout layer as a custom layer",
    "text": "Create a Dropout layer as a custom layer\nN.B. uses tf.nn primitive Neural Net (NN) Operations.\n\nclass MyDropout(Layer):\n\n    def __init__(self, rate):\n        super(MyDropout, self).__init__()\n        self.rate = rate\n        \n    def call(self, inputs):\n        # Define forward pass for dropout layer\n        return tf.nn.dropout(inputs, rate=self.rate)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#add-activation-functions",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#add-activation-functions",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Add activation functions",
    "text": "Add activation functions\nTo add activation functions in the layer\n\nadd activation=None to the __init__ inputs so it accepts an activation but defaults to None if doesn’t recieve one\nadd the activation to the self variable\n\nuse self.activation = tf.keras.activations.get(activation)\ni.e. so we can pass a string or a function\n\ncall the activation function within the call\n\ni.e. return  self.activation(tf.matmul(inputs, self.w)+self.b)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#custom-layers-in-a-model",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#custom-layers-in-a-model",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Custom layers in a model",
    "text": "Custom layers in a model\nCan create the model by passing the layer into keras.Sequential as a list. In the same way as done with other layer elements.\n\nxs = np.arange(-1,5,dtype=float)\nys = xs*2 -1\n\nmodel = tf.keras.Sequential([SimpleDense(units=1)])\n\nmodel.compile(optimizer='sgd',loss='mse')\nmodel.fit(xs,ys,epochs=500,verbose=0)\nprint(model.predict([10.]))\n\n[[18.981386]]"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#model-example-residual-networks",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-CustomLayersModels.html#model-example-residual-networks",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Model example Residual Networks",
    "text": "Model example Residual Networks\n\n\nfrom tensorflow.keras.layers import Conv2D, Dense, Layer\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\n\nclass CNNResidual(Layer):\n    def __init__(self, layers, filters, **kwargs):\n        super(**kwargs).__init__()\n        self.hidden = [Conv2D(filters, (3,3), activation='relu') for _ in range(layers)]\n    def call(self, inputs):\n        x = inputs\n        for layer in self.hidden:\n            x = layer(x)\n        return inputs + x\n    \nclass DNNResidual(Layer):\n    def __init__(self, layers, neurons, **kwargs):\n        super(**kwargs).__init__()\n        self.hidden = [Dense(neurons, activation='relu') for _ in range(layers)]\n    def call(self, inputs):\n        x = inputs\n        for layer in self.hidden:\n            x = layer(x)\n        return inputs + x\n\nclass MyResidual(Model):\n    def __init(self, **kwargs):\n        self.hidden1 = Dense(30, activation='relu')\n        self.block1 = CNNResidual(2, 32)\n        self.block2 = DNNResidual(2, 64)\n        self.out = Dense(1)\n    def call(self, inputs):\n        x = self.hidden1(inputs)\n        x = self.block1(x)\n        for _ in range(1,4):\n            x = self.block2(x)\n        return self.out(x)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#load-from-directory",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#load-from-directory",
    "title": "TensorFlow Images cheat sheet",
    "section": "Load from directory",
    "text": "Load from directory\nIf files are in folders can use flow_from_directory the files would need to be separated by class and training/validation as follows for a classification\ne.g. files in folders like this:\n\n/tmp/cats-v-dogs/validation/cats\n/tmp/cats-v-dogs/validation/dogs\n/tmp/cats-v-dogs/training/cats\n`/tmp/cats-v-dogs/training/dogs\n\n\ntrain_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n                                                      batch_size=256,\n                                                      class_mode='binary',\n                                                      target_size=(150, 150))\n# Test your generators\ntrain_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)\n\n# Put in the fit\nmodel.fit(train_generator,\n                    epochs=15,\n                    verbose=1,\n                    validation_data=validation_generator)"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#an-example-of-transfer-learning-on-images-with-inception",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#an-example-of-transfer-learning-on-images-with-inception",
    "title": "TensorFlow Images cheat sheet",
    "section": "An example of transfer learning on images with Inception",
    "text": "An example of transfer learning on images with Inception\n\nLoad the model pre-trained weights\nImport the model architecture\nGive the model the input shape for data\n\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),                                   include_top = False,                                    weights = None)\nBetter to keep the same shape as the model uses and change your data to match it than to change input_shape to match your data.\ninclude_top=False removes top most layer of the model- the output layer\nweights=None just uses the model architecture- note the weights are loaded on a later line\n\nLoad the weights into the model\nFreeze all the layers\nPick out the front part of the model, as the layers to the end are more specialized\nAdd extra layers to the model that can be fitted to\n\nNote this uses the functional API\n\nMatch the image size of our images to that needed by the model\n\nOur model expects 150X150X3 but our data is 50X50. So we need to multiply our image size by 3. This is done by the UpSampling2D layer\nmodel = tf.keras.layers.UpSampling2D(size=(3,3))(model)\nor use resize if image is bigger tf.image.resize(image, (150, 150,))\n\n# 1- Download the inception v3 weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n# 2- Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# 3- create the model and load in the weights\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n                                  include_top = False, \n                                  weights = None) \n\n# 4- load weights into the model\npre_trained_model.load_weights(local_weights_file)\n\n# 5- Make all the layers in the pre-trained model non-trainable\nfor layers in pre_trained_model.layers:\n    layers.trainable = False\n    \n# 6- Pick out part of the model\nlast_desired_layer = pre_trained_model.get_layer('mixed7')    \nlast_output = last_desired_layer.output\n\n# 7- Add extra layers to the model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)  \n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024,activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1,activation='sigmoid')(x) \n\n# 8. Increase input image sizes to match that needed by model using \n# a layer before the existing model starts\n\nmodel = tf.keras.layers.UpSampling2D(size=(3,3))(model)\n\n# Create the complete model by using the Model class\nmodel = Model(inputs=pre_trained_model.input, outputs=x)\n\n\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001), \n            loss = 'binary_crossentropy',\n            metrics = ['accuracy'])"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#r-cnn",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#r-cnn",
    "title": "TensorFlow Images cheat sheet",
    "section": "R-CNN",
    "text": "R-CNN\nR-CNN (R=region) a region based CNN to implement selective search with neural networks.\n\nTakes input images\nExtract regions using selective search method (~2k)\nExtract features using CNN from each region\n\nwarped to match AlexNet inputs\n\nClassify with support vector machine (SVM) instead of dense layers\nPlus regression to get bounding box of images\nVery slow & computationally expensive\n\n\nRoss Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik, “Rich feature hierarchies for accurate object detection and semantic segmentation” 2014"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#fast-r-cnn",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#fast-r-cnn",
    "title": "TensorFlow Images cheat sheet",
    "section": "Fast R-CNN",
    "text": "Fast R-CNN\nThe aim was to improve issues above with RCNN.\n\nEntire image is fed into the ConvNet\n\nno selective search- computationally expensive\nthis Convnet is trained on finding features\nproduces a feature map of the image\n\nEach feature map can then be fed into fully connected dense layer\n\nget feature vector of image\n\nFeature vector fed into layers to do regression and classification\n\n\nRoss Girshick, Fast R-CNN, 2015"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#faster-r-cnn",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#faster-r-cnn",
    "title": "TensorFlow Images cheat sheet",
    "section": "Faster R-CNN",
    "text": "Faster R-CNN\n\nentire image into Convnet\nsliding window to find areas of interest\nsomething called a Region Proposed Network is used with data to find and create anchor boxes on image\nThe cropped and passed to Dense layers for classification and regression.\n\n Deep Learning for Computer Vision with Python"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#object-detection-in-tensorflow",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#object-detection-in-tensorflow",
    "title": "TensorFlow Images cheat sheet",
    "section": "Object detection in TensorFlow",
    "text": "Object detection in TensorFlow\nhttps://www.tensorflow.org/hub\n\nTensorFlow Hub is a repository of trained machine learning models ready for fine-tuning and deployable anywhere. Reuse trained models like BERT and Faster R-CNN with just a few lines of code.\n\nCopy url from hub page https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1 page for faster rcnn. And copy url is “https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1”\n\nimport tensorflow as tf\nimport tensorflow-hub as hub\n\nmodule_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n\ndetector = hub.load(module_handle).signatures['default']\n\n\nAn example can be found here https://www.tensorflow.org/hub/tutorials/object_detection"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#object-detection-api",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-Images.html#object-detection-api",
    "title": "TensorFlow Images cheat sheet",
    "section": "Object Detection API",
    "text": "Object Detection API\nhttps://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md https://github.com/tensorflow/models/tree/master/research/object_detection https://www.tensorflow.org/guide/checkpoint"
  },
  {
    "objectID": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-NLP.html",
    "href": "posts/MACHINELEARNING/neural_networks/tensorflow/Tensorflow-NLP.html",
    "title": "TensorFlow NLP cheat sheet",
    "section": "",
    "text": "Basic Implementation\nThe standard language model starts with an embedding layer, this then needs to be flattened to a vector, then we can add a dense layer before an output layer.\nThe Embedding layer creates a vector-space for the text data. So for example, the words beautiful and ugly may be in opposite directions. And words such as cat and kitten may be close together in vector space.\nGlobalAveragePooling1Dcan be replaced by Flatten()\n\nmodel = tf.keras.Sequential([ \n    tf.keras.layers.Embedding(num_words,embedding_dim,input_length=maxlen),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(5,'softmax')\n])\n\nThe model above does not take account for the order of words,\nIf we want to do this we can insert an additional layer after the embedding layer. For example, by using the LSTM model as below\n\nmodel_lstm= tf.keras.Sequential([\n    tf.keras.layers.Embedding(VOCAB_SIZE,EMBEDDING_DIM,input_length=MAXLEN),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')   \n])\n\nWe can even insert a conolution layer after the embedding instead\ntf.keras.layers.Conv1D(128,5,activation='relu')\nFor two consecutive layers of RNNs use return_sequences=True\n\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),\n\n\n\nText data Tokenizer\n\nCreate a Tokenizer instance\nFit tokenizer to text data with tokenizer.fit_on_texts(text_data)\nConvert text to sequences with sequences = tokenizer.texts_to_sequences(text_data)\n\nFor example, the following words have the indices: apple->1, brain->2, cat->3, that->4, is->5\nAnd a sequence of text within the data can be converted to a sequence: “that cat apple is brain” -> (4, 3, 1, 5, 2)\n\nGet the word index word_index = tokenizer.word_index\nGet the text back from the sequences text = tokenizer.sequences_to_texts(sequences)\n\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(oov_token=\"<OOV>\",num_words=10_000)\ntokenizer.fit_on_texts(text_data)\n\nsequences = label_tokenizer.texts_to_sequences(text_data)"
  },
  {
    "objectID": "posts/MACHINELEARNING/NLP stuff/NLP-Of-TravelTweets.html#introduction",
    "href": "posts/MACHINELEARNING/NLP stuff/NLP-Of-TravelTweets.html#introduction",
    "title": "Natural Language Processing of Travel Tweets",
    "section": "Introduction",
    "text": "Introduction\nTravel analysis of twitter feeds of UK travel companies TUI and Jet2 twitter accounts before and during the COVID pandemic.\n\nTwitter data is obtained from the twitter API using tweepy.\nNLP analysis is done using a zero-shot method from transformers.\nAnalyis of NLP data is kept at a basic level using pandas and matplotlib"
  },
  {
    "objectID": "posts/MACHINELEARNING/NLP stuff/NLP-Of-TravelTweets.html#twitter-data",
    "href": "posts/MACHINELEARNING/NLP stuff/NLP-Of-TravelTweets.html#twitter-data",
    "title": "Natural Language Processing of Travel Tweets",
    "section": "Twitter Data",
    "text": "Twitter Data\nTweets were obtained using the twitter API and tweepy more details on twitter and API here- tweepy.\nI decided to keep the query simple and just use tweets containing the handle of TUI and Jet2’s UK twitter accounts, as shown below. This was mainly because of the API limitation meant experimenting on the best query took away from getting data.\nquery='@tuiuk' or query='@jet2tweets'\nI also decided to get tweets from a 3 day period, at first the start of a month and later in the middle. The tweets were focussed on dates around January 2020 (the start of the pandemic), with data obtained up to ~2 years before this and just over 2 years after this to the present (April 2022). And Use the search_full_archive call from twitter api. Broadly the call is as shown below.\nfrom datetime import date\nfrom datetime import timedelta\nstart_time = date.fromisoformat('2020-02-01') end_time = start_time + timedelta(3)\nouta=api.search_full_archive(label=\"mytwitterlabel\",          query=query,toDate=toDate,fromDate=fromDate)\nThis leads to around 1500 tweets per firm at the time of analysis, due to twitter API call being limited.\n\nThe number of tweets for Tui and Jet2 after removing ‘duplicate’ tweets"
  },
  {
    "objectID": "posts/MACHINELEARNING/NLP stuff/NLP-Of-TravelTweets.html#natural-language-processing-nlp",
    "href": "posts/MACHINELEARNING/NLP stuff/NLP-Of-TravelTweets.html#natural-language-processing-nlp",
    "title": "Natural Language Processing of Travel Tweets",
    "section": "Natural Language Processing (NLP)",
    "text": "Natural Language Processing (NLP)\nThe most ‘reliable’ way to analyse text data is to do a two step process:\n\ncreating a language model for the data\nusing this language model with labelled data to classify different texts\n\nThis method is shown here https://www.kaggle.com/code/thomassimm/imdb-sentiment-analysis for sentiment analysis (i.e. are reviews positive or negative) of IMDB data. But the labels need not be positive or negative but can be more nuanced.\nHowever, for this twitter data there is no labelled data. I could label the data myself but will first try an alternative approach-> the zero shot learning method. The advantage is no labelled data is needed nor any prior training. But the accuracy will be reduced without any training as shown below.\n\nAnother advantage of the method is that it can be used to classify text data by broad labels based on the language model as shown by the example from the link below:\nsentence = 'Who are you voting for in 2020?'\nlabels = ['business', 'art & culture', 'politics']\nAnd the similarity for each label (high the better):\nlabel: politics     similarity: 0.21561521291732788\nlabel: business     similarity: 0.004524140153080225\nlabel: art & culture    similarity: -0.027396833524107933\n\nLabels for travel data\nAt this point in analysis the goals are broad, I mainly want to know if I can understand how customers were reacting to the travel restriction changes being imposed on them and how this differed for the two travel companies. So what may be things we would want to classify from the tweets:\n\nHow happy/unhappy are the customers?\nIs there a change in the number of what would be classed as complaints?\nCan sentiments be separated by what is the cause? e.g. customer service, cancellations, company policies\n(similar to above) What do the tweets refer to?\nCan we remove customer tweets from spam/promotional details/business changes etc?\n\nAfter a bit of iterating I decided on the following labels (see https://www.kaggle.com/code/thomassimm/travel-tweets-nlp/ for trying out different labels).\ncandidate_labels=['query','complaint',                   'holiday','hotel',                   'flight','flight cancellation','flight delay',                   'website or app problem','customer service',                   'travel regulations','price',                  'holiday cancellation']\nLet us examine how the labels work for different tweets (picked randomly but avoiding tweets with similarity):\n    A) Hi there, do you know the transfer time? I couldn’t see it on the website. Thanks \n\nquery 0.98\ncomplaint 0.73\n\nholiday 0.00\n\nhotel 0.62\nflight 0.24\n\nflight cancellation 0.01\n\nflight delay 0.15\n\nwebsite or app problem 0.89\n\ncustomer service 0.97\n\ntravel regulations 0.26\n\nprice 0.00\nholiday cancellation 0.00\n  B) Worst ever sent details of complaint Florida villa including memory stick with photos sent in never heard a thing don’t bother they just ignore you\nquery 0.72\ncomplaint 0.98\n\nholiday 0.73\n\nhotel 0.03\nflight 0.00\n\nflight cancellation 0.00\n\nflight delay 0.00\n\nwebsite or app problem 0.00\n\ncustomer service 0.82\n\ntravel regulations 0.06\n\nprice 0.09\nholiday cancellation 0.13\n      C) hi I’ve been trying to book a holiday for a few days on my pc or via the mobile app but when I try to check out I get this error message\nquery 0.73\ncomplaint 0.97\n\nholiday 0.94\n\nhotel 0.47\nflight 0.17\n\nflight cancellation 0.00\n\nflight delay 0.00\n\nwebsite or app problem 1.00\n\ncustomer service 0.70\n\ntravel regulations 0.22\n\nprice 0.07\nholiday cancellation 0.94\n      D) how do I amend dates on my holiday. Iv tried ringing customer service but was given wrong number to ring. Thanks \nquery 0.91\ncomplaint 0.93\n\nholiday 0.99\n\nhotel 0.17\nflight 0.11\n\nflight cancellation 0.02\n\nflight delay 0.02\n\nwebsite or app problem 0.00\n\ncustomer service 0.67\n\ntravel regulations 0.57\n\nprice 0.00\nholiday cancellation 0.38\n      E) Maybe not quite neighbouring - Trinidad and Tobago 😁😁😂 \nquery 0.37\ncomplaint 0.87\n\nholiday 0.03\n\nhotel 0.03\nflight 0.03\n\nflight cancellation 0.01\n\nflight delay 0.01\n\nwebsite or app problem 0.02\n\ncustomer service 0.06\n\ntravel regulations 0.08\n\nprice 0.04\nholiday cancellation 0.06\n\nSome quick comments:\n\nOverall the labels make sense to the particular tweets.\nComplaint seems to be high for all even when they are clearly not complaints (D and E). Although, obvious complaints have higher values. Maybe combine with sentiment analysis?\nWebsite and app issues well picked up, preseumably as they use the words website or app\nThe one with no relevance to customer service (E) scores low for query and customer service, so maybe the metric can help to distinguish these.\nHighest value for flight was for A even though flight not explicitly mentioned\n\nLots of positives from this small selection. But to get a good idea of classification may take some more modication in terms of what to use and what values they give for different things. Perhaps this can be done as a neural network after some sort of labelling?"
  },
  {
    "objectID": "posts/MACHINELEARNING/NLP stuff/NLP-Of-TravelTweets.html#analysis-of-labelled-data",
    "href": "posts/MACHINELEARNING/NLP stuff/NLP-Of-TravelTweets.html#analysis-of-labelled-data",
    "title": "Natural Language Processing of Travel Tweets",
    "section": "Analysis of Labelled data",
    "text": "Analysis of Labelled data\nA brief analysis of the NLP results is given here https://www.kaggle.com/code/thomassimm/travel-tweets-analyseresults and presented below.\nThe most obvious thing to check first is the change in the sentiment of tweets. The figure below does this by taking the average of the positive sentiment for each time period.\n\nSentiment\n\nSome initial comments:\n\nJet2 gets more positive tweets than Tui\nThe data may be noisy. The changes before the pandemic are noticeably large and it is not obvious if these are real trends or just noise. More digging would need to be done to establish what the changes are before COVID before the change during COVID could be assessed.\nThe overall sentiment appears to be at a low in early 2022, the easing of restrictions may be suggesting a more positive sentiment in the future.\nSince this is an average of a random selection of tweets. A change in the nature of the tweets would have a big influence on the results.\n\n\n\nCustomer Service Queries\nGiven the last of the comments (the nature of the tweets), we may wish to separate tweets based on some overall criteria- e.g. review (inclusing complaint), query and other (including none customer queries, general comments, spam etc). Or remove the last of these by some other criteria such as ‘customer service’ and/or ‘query’ more than a certain amount.\n \nBased on the above figures the percentage of tweets that are labelled ‘query’ or ‘customer service’ increase sharply during the pandemic. This would make sense given the confusion around the situation and the questions that customers will have around COVID regulations and company policies in dealing with these changes.\n\n\nComplaints\nReturning to the overall sentiment figure above, can a classification of tweets based on whether they are a complaint help with the changes?\nAs shown in the figure below the complaint classification shows a clearer increase during the COVID period. Perhaps this offers a better way instead of the sentiment analysis to understand the nature of the tweets, but more analysis would be required.\nThe maximum values for this metric for both cmpanies at the end of 2021 / start of 2022, are worth exploring in more detail"
  },
  {
    "objectID": "posts/MACHINELEARNING/NLP stuff/NLPtextgenerator.html#introduction",
    "href": "posts/MACHINELEARNING/NLP stuff/NLPtextgenerator.html#introduction",
    "title": "Using NLP for text generation",
    "section": "Introduction",
    "text": "Introduction\n\nNLP\nNLP, or natural language processing, is a machine learning priocess used on language data. Some applications include:\n\nsearch, ranking\nspam detection\nads recommendation\nemail categorization\nmachine translation\nspeech recognition\nSentiment analysis\n\nFrom FastAI FastBooks:\nWhat we call a language model is a model that has been trained to guess what the next word in a text is (having read the ones before). This kind of task is called self-supervised learning: we do not need to give labels to our model, just feed it lots and lots of texts. It has a process to automatically get labels from the data, and this task isn't trivial: to properly guess the next word in a sentence, the model will have to develop an understanding of the English (or other) language\n\nEven if our language model knows the basics of the language we are using in the task (e.g., our pretrained model is in English), it helps to get used to the style of the corpus we are targeting. It may be more informal language, or more technical, with new words to learn or different ways of composing sentences. In the case of the IMDb dataset, there will be lots of names of movie directors and actors, and often a less formal style of language than that seen in Wikipedia.\n\nWe already saw that with fastai, we can download a pretrained English language model and use it to get state-of-the-art results for NLP classification."
  },
  {
    "objectID": "posts/MACHINELEARNING/NLP stuff/NLPtextgenerator.html#what-is-below",
    "href": "posts/MACHINELEARNING/NLP stuff/NLPtextgenerator.html#what-is-below",
    "title": "Using NLP for text generation",
    "section": "What is below",
    "text": "What is below\nHere I’ll use the IMDB dataset and train it on the works of Shakespeare to generate text in the style of his work given a starting few words.\nUses fastAI, modified from “10_nlp.ipynb” in fastAI/fastbook\nhttps://colab.research.google.com/drive/11JRjYu7XsmSzo3IT8oH2KNf-e-v6W5tf?usp=sharing"
  },
  {
    "objectID": "posts/MACHINELEARNING/NLP stuff/NLPtextgenerator.html#code",
    "href": "posts/MACHINELEARNING/NLP stuff/NLPtextgenerator.html#code",
    "title": "Using NLP for text generation",
    "section": "Code",
    "text": "Code\n\n# Some imports\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\nfrom fastbook import *\nfrom IPython.display import display,HTML\n\nfrom fastai.text.all import *\n\n\nGet some text to act as a style\n\n# A URL containing the works of Shakespeare\nurl='https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt'\n\n# Going to put in a folder called BARD which we create\ndest='BARD'\nimport os\nos.mkdir(dest)\n\n# get the text from the url and put as data\nimport requests\nresponse = requests.get(url)\ndata = response.text\n\n# reduce data to miss start and end guff\nxstart=10450\nxend=580\ndata = data[xstart:-xend]\n\n# create a text file every 1000\n# use format number_0.txt seems to work best for DataBlock\nrr=int(len(data)/1000)\nfor i in range(rr):\n    with open(dest + '/{}_0.txt'.format(str(i)),'w') as f:\n        f.writelines(data[ (i-1)*1000:i*1000 ])\n\n\n\nLanguage model using DataBlock\n\n# create path\npath=Path()\n\n# get's the text parts- will just come from folder dest \n# where the text files are saved\nget_shak = partial(get_text_files,folders=dest)\n\n# Craete a dataBlock- using the Class of TextBlock and the classes \n# in-built function from folder\ndbb = DataBlock(\n    blocks=TextBlock.from_folder(path, is_lm=True),\n    get_items=get_shak, splitter=RandomSplitter(0.1)\n)\n\n# Now create the dataLoaders\ndls =dbb.dataloaders(path, path=path, bs=128, seq_len=80)\n\n# Have a look at the batches\ndls.show_batch(max_n=2)\n\n\n\n\nCreate model and Run\n\nlearn = language_model_learner(\n    dls, AWD_LSTM, drop_mult=0.3, \n    metrics=[accuracy, Perplexity()]).to_fp16()\n\n\nlearn.fit_one_cycle(1, 2e-2)\n\n\n\nlearn.unfreeze()\nlearn.fit_one_cycle(10, 2e-3)"
  },
  {
    "objectID": "posts/MACHINELEARNING/NLP stuff/NLPtextgenerator.html#model-text-generation",
    "href": "posts/MACHINELEARNING/NLP stuff/NLPtextgenerator.html#model-text-generation",
    "title": "Using NLP for text generation",
    "section": "Model Text Generation",
    "text": "Model Text Generation\n\nTEXT = \"Hi Romeo how are you?\"\nN_WORDS = 40\nN_SENTENCES = 4\npreds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n         for _ in range(N_SENTENCES)]\n\n\nprint(\"\\n\".join(preds))\n\n“Cannot get rid of this spot” 30 words, 2 sentences\nCan not get rid of this spot ? No ; I 'll set a foot to Caesar . If i can tell you , Triumvirate , that know the heads of\n\nCan not get rid of this spot ? When one sees England here , he next is sure to be sent for . If i be not , my King , you must\n“Hi Romeo how are you?” 60words 2sent. 0.75temp.\nHi Romeo how are you ? What 's your will ? My heart is split . What , my soul ! My body 's as cold as wax ; my heart is now as a nail in my heart ; thou shalt see Romeo set a crown on't ! Come , and that ring i gave him , the ring\n“Where shall i go for my holiday?”\nWhere shall i go for my holiday ? Am i to France ? Are you English ? Are you a Spanish man ? [ aside ] i know not what ; nor no other man but this . [ they speak ] If i speak , i am going .\n“Poor me , poor me , poor me another drink”\nPoor me , poor me , poor me another drink , I 'll burn out King Lear 's grave . Thou art too dear to me ; i am perfect i am least of all . I 'll go live i ' th ' middle , and there will i not live in this ."
  },
  {
    "objectID": "posts/MACHINELEARNING/RandomForests.html#decision-trees",
    "href": "posts/MACHINELEARNING/RandomForests.html#decision-trees",
    "title": "Decision Trees and Random Forests",
    "section": "Decision Trees",
    "text": "Decision Trees\nA decision tree asks a series of binary questions about the data, whereupon the data is split into two branches. For each of these branches another question can be asked, or a prediction made. The branches continue until a prediction is made.\nThese are created using training data and can subsequently be used with test data.\nDecisionTreeRegressor?\nDecisionTreeRegressor(     *,     criterion='squared_error',     splitter='best',     max_depth=None,     min_samples_split=2,     min_samples_leaf=1,     min_weight_fraction_leaf=0.0,     max_features=None,     random_state=None,     max_leaf_nodes=None,     min_impurity_decrease=0.0,     ccp_alpha=0.0, )\n\nChanging paramaters\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,max_depth=2)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,min_samples_split=30_000)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,min_samples_leaf=30_000)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n# DecisionTreeRegressor?\n\n\n\nm = DecisionTreeRegressor(max_features=3,max_leaf_nodes=10)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\n\nHyper Parameters\n\n\n\n\n\n\n\n\nParameter\nDescription\nDefault\n\n\n\n\nmax_depth\nThe maximum number of branches to get to the result.  ie top to bottom length.\nNone\n\n\nmax_leaf_nodes\nThe total number of branches\nNone\n\n\nmin_samples_split\nThe minimum number of samples required to split an internal node\n2\n\n\nmin_samples_leaf\nThe minimum number of samples required to be at a leaf node.\n1\n\n\nmax_features\nMaximum number of features (i.e. parameters using to fit or X)\nNone"
  },
  {
    "objectID": "posts/MACHINELEARNING/RandomForests.html#random-forests",
    "href": "posts/MACHINELEARNING/RandomForests.html#random-forests",
    "title": "Decision Trees and Random Forests",
    "section": "Random Forests",
    "text": "Random Forests\nRandom forests use many decision trees using ensembling (combining multiple models). Today it is, perhaps, the most widely used and practically important machine learning method.\nRandom forests uses Bagging as the ensemble method. The other main one being Boosting.\nIn bagging many decision tree models are combined together by averaging them. Each decision tree is trained on a different data subset and can have different parameters to fit to the data.\n“Bagging Predictors” Leo Breiman > : Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions… The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests… show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.\nHere is the procedure that Breiman is proposing:\n\nRandomly choose a subset of the rows of your data (i.e., “bootstrap replicates of your learning set”).\nTrain a model using this subset.\nSave that model, and then return to step 1 a few times.\nThis will give you a number of trained models. To make a prediction, predict using all of the models, and then take the average of each of those model’s predictions.\n\n\n\n\n\n\n\n\nDecision trees\nRandom Forests\n\n\n\n\nCan suffer from overfitting.  Care should be taken with the hyper parameters and use of validation data\nSubsets of the data are used for each model and the results averaged  So overfitting is mostly taken care of\n\n\nFaster computation\nSlower\n\n\nFormulate a set of rules fore predictions\nNo rules\n\n\n\n\nHyper Parameters\n\n\n\n\n\n\n\n\nParameter\nDescription\nDefault\n\n\n\n\nn_estimators\nnumber of trees the algorithm builds before averaging the predictions\n100\n\n\nmax_features\nMaximum number of features (i.e. parameters using to fit or X)\n1.0 (regression or sqrt (classification)\n\n\nmin_samples_leaf\nThe minimum number of samples required to be at a leaf node.\n1\n\n\nn_jobs\nHow many processors can be used  =1 uses one processor, =-1 no limit on number\nNone\n\n\noob_score\nOOB=Out of the bag. In this one-third of the sample is not used to train the data instead used to evaluate its performance\nFalse\n\n\n\n\nOne of the most important properties of random forests is that they aren’t very sensitive to the hyperparameter choices, such as max_features. You can set n_estimators to as high a number as you have time to train—the more trees you have, the more accurate the model will be. max_samples can often be left at its default, unless you have over 200,000 data points, in which case setting it to 200,000 will make it train faster with little impact on accuracy. max_features=0.5 and min_samples_leaf=4 both tend to work well, although sklearn’s defaults work well too.\n\nFastAI\n https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html > In the plot, the blue plot line uses the fewest features and the green line uses the most (it uses all the features). As you can see in <>, the models with the lowest error result from using a subset of features but with a larger number of trees.\nFastAI\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y); \n\nsamp_idx = np.random.permutation(len(y))[:500]\ndtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n        orientation='LR')"
  },
  {
    "objectID": "posts/MACHINELEARNING/RandomForests.html#implementaion",
    "href": "posts/MACHINELEARNING/RandomForests.html#implementaion",
    "title": "Decision Trees and Random Forests",
    "section": "Implementaion",
    "text": "Implementaion\nhttps://www.kaggle.com/thomassimm/rf-swanseahouses"
  },
  {
    "objectID": "posts/MACHINELEARNING/RandomForests.html#bibliography",
    "href": "posts/MACHINELEARNING/RandomForests.html#bibliography",
    "title": "Decision Trees and Random Forests",
    "section": "Bibliography",
    "text": "Bibliography\n\nFast AI - 09- Tabular Data\nUnderstanding Random Forest\nScikit learn & scikit-learn 2"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#introduction",
    "href": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#introduction",
    "title": "Body position recognition using FastAI",
    "section": "Introduction",
    "text": "Introduction\nThis is a first step in a project to analyse golf swings.\nIn this first step I try to identify different parts of the body and golf equipment during the golf swing. This step is of limited success for overall analysis but the steps used are useful for the lessons learnt.\nThis work uses deep learning to identify locations (vectors) on images and fitting by regression.\nIn this step I will use a dataSet found at  Git Hub GolfSwing and the paper of the work https://arxiv.org/abs/1903.06528.\nWhat this dataset/paper does is split the golf swing into a number of sequences based on the position of the body and golf club, e.g. start, golf club parallel to ground, striking the ball etc. We will call these the golf positions. These positions are shown below.\n\n\n\nvia GIPHY\n\n\nThe dataset includes a series of videos that have been characterised based on the different swing sequences.\n\nSteps in this page\n\nDownload the video dataset and the details of the frames of the different positions\nCreate images at the different positions from the videos\nClassify points on the images and a file for each image of these\nUpload data to GitHub and download on notebook for analysis\nUse deep learning to identify the positions on the images"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#use-the-video-analysis-dataset-to-create-images-of-golf-swings",
    "href": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#use-the-video-analysis-dataset-to-create-images-of-golf-swings",
    "title": "Body position recognition using FastAI",
    "section": "Use the video analysis dataset to create images of golf swings",
    "text": "Use the video analysis dataset to create images of golf swings\nFirst I cloned the directory (https://github.com/wmcnally/golfdb) onto my local PC. I then need to identify which videos to use- I want the ones behind the golfer and preferably of lower frame rate.\nBelow are the names of the videos I selected\n\nimport numpy as np\nimport os\n\nuseVids=[1,3,5,7,13,24,43,46,48,71,77,81,83,89,93,242,681,1060]\nnp.shape(useVids)\n\n(18,)\n\n\nI now want to find the frames in each video that represent the selected positions.\nThese exist in a ‘.pkl’ file. So we open the file and then select the videos (rows) we want to use.\n\nimport pandas as pd\nimport pickle\n\nfile_path= cda + \"\\data\\\\golfDB.pkl\"\n\n\ndata = pickle.load(open(file_path,\"rb\"))\naa=[]\ni=0\nfor ii in useVids:\n    if i==0:\n        aa=data[ii==data.id]\n        \n    else:\n        aa=aa.append(data[ii==data.id])\n       \n    i=i+1\naa.reset_index(drop=True,inplace=True)\naa.tail()\n\n\nIn the DataFrame (aa) the details we want are just the ‘events’ so we know what frames to save as images from the videos\nFirst we create a function that takes a video location and details of the frames (or the selected golf positions) and then creates a new folder containing images of those frames.\nThis uses the library cv2 and a secondary check to normalise the positions if it is different from that given (this was useful in earlier versions but later ones the frame number matched that given by the aa dataFrame).\nThe function works by finding a frame rate then stepping through the video by adding the time per frame after each step. If the frame is at a position given by the input (from aa) it is saved as an image.\n\ndef createImages(fila,pos):\n    ''' \n    Given a video file location (fila) it will save as images to a folder\n    Given positions in video (pos) these images from the video are saved\n    pos is created based on positions of swings\n    '''\n    import cv2\n    import numpy as np\n    import os\n    \n    # create a video capture object\n    cap = cv2.VideoCapture(fila)\n    \n    # get details of the video clip\n    duration = cap.get(cv2.CAP_PROP_POS_MSEC)\n    \n    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    duration_seconds = frame_count / fps\n    print('duration is ',duration,'. frame_count is ',frame_count,'. fps is ',fps,'. duration sec is',duration_seconds)\n    \n    #alter pos based on frame count\n    posb4=pos\n    pos=(pos/(np.max(pos)/frame_count))\n    pos=np.array([int(nn) for nn in pos])\n    pos=pos[1:-2]#ignore first value and last two\n    \n    \n    # create a folder if it doesn't exist\n    folder = fila.split('\\\\')[-1].split('.')[0]\n    folder = '_images'+folder\n    print(folder)\n    try:\n        os.mkdir(folder)\n    except:\n        pass\n\n    \n    vidcap = cap\n    \n    # this function creates an image from part of a video and \n    # saves as a JPG file\n    def getFrame(sec,go):\n        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec)\n        hasFrames,image = vidcap.read()\n        if hasFrames and go:\n            cv2.imwrite(os.path.join(folder,\"frame{:d}.jpg\".format(count)), image)     # save frame as JPG file\n        return hasFrames\n    \n    # goes through the video clip and steps through based on frame rate\n    sec = 0\n    frameRate = 1000/fps \n    count=1\n    go=0\n    success = True\n    while success:\n        count = count + 1\n        sec = sec + frameRate\n        #only saves images if at positions in pos\n        if count in pos:\n            go=1\n        else:\n            go=0\n        success = getFrame(sec,go)\n\n    print(\"{} images are extacted in {}.\".format(count,folder))\n\nAnd below I call the script for the videos I selected\n\nimport cv2\nfila = cda + '\\\\data\\\\videos_160\\\\'\nfor ii,aai in enumerate(aa.id):\n    fold = fila + str(aai)+'.mp4'\n    pos=aa.iloc[ii,7]\n    pos=pos-pos[0]\n    if ii>1:\n        cII(fold,pos)\n        cap = createImages.VideoCapture(fold)\n\nSo now we have a series of folders for each video with images given by the selected positions"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#manually-classify-points-on-the-images",
    "href": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#manually-classify-points-on-the-images",
    "title": "Body position recognition using FastAI",
    "section": "Manually classify points on the images",
    "text": "Manually classify points on the images\nTo be able to perform analysis on the images they first need to be labelled.\nTo do this I decided to take the manual approach and classify the images myself. I decided to choose the following regions in each image: - The ball - The end of the golf club (clubhead) - The back wrist - the back elbow - the top of the head\nThis is done using the follwing function\n\ndef imDo(im):\n    \n    fig=plt.figure(figsize=(20, 15))\n    plt.imshow(im)\n\n    def tellme(s):\n        print(s)\n        plt.title(s, fontsize=16)\n\n    tellme('You will define golf swing, click to begin')\n\n    plt.waitforbuttonpress()\n\n    while True:\n        pts = []\n        while len(pts) < 5:\n            tellme('Select golf ball-golf club- wrist- elbow- head with mouse')\n            pts = np.asarray(plt.ginput(5, timeout=-1))\n            if len(pts) < 5:\n                tellme('Too few points, starting over')\n                time.sleep(1)  # Wait a second\n        \n        ph = plt.plot(pts[:, 0], pts[:, 1], marker='x',markersize=20,markeredgewidth=3)\n\n        tellme('Happy? Key click for yes, mouse click for no')\n\n        if plt.waitforbuttonpress():\n            break\n    plt.close(fig)\n    return pts\n\nBefore we can call this function we want to make sure the image appears as a new window\nAlso some imports\n\nimport fastbook\n\nfrom fastbook import *\nfrom fastai.vision.all import *\nimport matplotlib\n\ncda = os.getcwd()\n\nmatplotlib.use('TKAgg')\n\nNow for each image file created, the script below runs imDo which plots the image then asks the user to select 5 points on the image for classification.\nthese points are then save as txt file with the same name as the image file to be used later in modeling\n\n\nfoldOuta=cda+'//_dataSel//'\nlsa = os.listdir(foldOuta)\nlsa\nptsALL=[]\nfor ii,folds in enumerate(lsa):\n    if ii>0:\n        print(folds)\n        img_files = get_image_files(foldOuta+folds)\n        for fils in img_files:\n            im = PILImage.create(fils)\n            pts=imDo(im)\n            ptsALL.append(pts)\n            fnom=str(fils).split('\\\\')[-1].split('.')[0]\n            \n            np.savetxt(foldOuta+folds+'\\\\'+fnom+'.txt',pts)"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#upload-data-for-use-in-modeling",
    "href": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#upload-data-for-use-in-modeling",
    "title": "Body position recognition using FastAI",
    "section": "Upload data for use in modeling",
    "text": "Upload data for use in modeling\nFastai has a function called untar_data that prepares images in a .tgz folder ready to use for analysis.\nA tgz file can be made by a Python script, but all the ones I tried produced an error, so instead I used\nTo create a tar file see https://opensource.com/article/17/7/how-unzip-targz-file\nOpen up a terminal go to the folder that contains the folder wanting to compress and then tar with the command line\ntar –create –verbose –file GC.tgz GolfComb\nI have then uploaded it to GitHub. Go to the file on Github open it and right click on ‘view raw’ and select copy link."
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#model-the-data",
    "href": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#model-the-data",
    "title": "Body position recognition using FastAI",
    "section": "Model the data",
    "text": "Model the data\nThe rest needs to be done with a GPU. I have done this with https://colab.research.google.com/ (free time is limited but details not published) and the code tab for a notebook on https://www.kaggle.com/ (36 h per month for free)\nFirst import the fastai stuff\n\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\nfrom fastbook import *\n\n\nfrom fastai.vision.all import *\n\nimport os\nimport re\nimport numpy\n\nuntar the data and set the path\n\nurl='https://github.com/ThomasHSimm/GolfSwingTSimm/blob/main/_dataSel/GC.tgz?raw=true'\n\npath = untar_data(url)\n\n\nPath.BASE_PATH = path\n\nHave a look at the data\n\n(path/'Test').ls()\n\n\nA function to classify the points on the image\nLoads the text file for each image and returns a TensorPoint object of points on the image\n\ndef get_pointa_img(fileo):\n     \n    txtfile = str(fileo)[0:-4] + '.txt'\n    # print(txtfile)\n    pts=np.loadtxt(txtfile)\n    pp=pts[-1,:]\n    # print(pp)\n    return TensorPoint(pp)\n\nCreate a DataBlock\nThe DataBlock is the foundation of the model. It needs to know - the location of the images, - the label for the images (points on images in this case) - separation of data into test and validation sets (done automatically if not specified) - the type of data used blocks=(ImageBlock, PointBlock) - any resizing of images - any transforms (Data Augmentation)\n\nitem_tfms = [Resize(448, method='squish')]\nbiwi = DataBlock(\n    blocks=(ImageBlock, PointBlock),\n    get_items=get_image_files,\n    item_tfms=item_tfms,\n    get_y=get_pointa_img,\n    batch_tfms=[*aug_transforms(size=224, min_scale=0.75),\n                               Normalize.from_stats(*imagenet_stats)])\n\nNow create a DataLoaders object which has the path of the data and the batch size (here 30)\nBatch size is important to specify to avoid memory issues\n\ndls = biwi.dataloaders(path,30)\n\nNow create the learner\nPass it the dataLoaders, we’re doing transfer learning from resnet50 (imageNet trained model), what metrics we’ll use for loss, and the range in y values we want\n\nlearn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.02),y_range=(-1,1))\n\nHave a look at the data. Can see the transforms\n\ndls.show_batch(max_n=8, figsize=(12,12))\n\n\n\n\nFind the best learning rate\n\n\nlearn.lr_find()\n\n\nTo fit the model we have a few options:\n\nlearn.fit(10,lr=4e-3)\nlearn.fit_one_cycle()\nlearn.fine_tune(10, base_lr=1e-3, freeze_epochs=7)\nlearn.fine_tune(15, lr)\n\nFastAI adds an extra 2 layers on the end of neural network these can then be fitted using fine_tune. It is recommended to do a few fits frozen before unfreezing. This is normally the best option for transfer learning.\nBut the other ones can be used. In general fit can be more unstable and lead to bigger losses, but can be useful if fine_tune is not bringing losses down.\nhttps://forums.fast.ai/t/fine-tune-vs-fit-one-cycle/66029/6\nfit_one_cycle = New Model\nfine_tuning = with Transfer Learning?\n\nI’d say yes but with a very strong but, only because it’s easy to fall into a trap that way. fine_tuning is geared towards transfer learning specifically, but you can also just do fit_one_cycle as well! (Or flat_cos).\n\nFor beginners it’s a great starting fit function (and advanced too), but also don’t forget that you can then build on what that function is doing. For instance, I wonder how modifying/adapting that function for Ranger/flat_cos would need to change!\n\nlearn.fine_tune(10, base_lr=1e-3, freeze_epochs=7)\n\n\n\nlearn.lr_find()\n\n\nSome more fitting, reducing the learning rate after steps\n\nlearn.fit(20,lr=1e-4)\n\n\nSome more fitting\nMixing fit with fine_tune and reducing learning rate seems to work best for reducing loss\nLoss here is:\ntrain_loss  valid_loss\n\n0.054042    0.008305"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#results",
    "href": "posts/PROJECTS/Golf_swing/GolfPos1FastAI.html#results",
    "title": "Body position recognition using FastAI",
    "section": "Results",
    "text": "Results\nLook at the results, pretty good for ~10 mins of 81 images of learning although doesn’t always get the top of the head.\n\nlearn.show_results()\n\n\n\n#save the model\nlearn.export(fname='headTry1.pkl')\n\nHowever, when this is generalised to other points, such as hands and clubhead, that are less static the results are poor.\nPresumably a combination of the low resolution of the images making it difficult to identify features and the lack of images.\n\nIncreasing the res of the images/videos improves the classification considerably.\nBut still not quite there, probably needs more labelling\ntrain_loss     valid_loss\n0.030079       0.031188"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart2.html#overview",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart2.html#overview",
    "title": "Golf Swing Part II- Separating Swing Positions",
    "section": "Overview",
    "text": "Overview\nIn a previous part Part 1 a neural network model was used to find positions on the body during a golf swing. This work used images taken from videos of golf swing (analysed using the code below by the authors listed) because it is often easier to work with images rather than videos.\nBut to get images of the golf swing to analyse it can be useful to get them at different parts of the golf swing. This is what this part does.\nTaken from https://github.com/wmcnally/golfdb and shown in the paper here https://arxiv.org/abs/1903.06528\n[Ref Paper] McNally, William, et al. \"Golfdb: A video database for golf swing sequencing.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 2019\nThe code separates the golf swing into a number of different segments based on body and golf club positions.\nThis code can be run on kaggle here https://www.kaggle.com/thomassimm/golfdb-lessimports\nThe input is an mp3 file of a golf swing\nThe ouput is a series of images at different parts of the golf swing"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart2.html#the-code",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart2.html#the-code",
    "title": "Golf Swing Part II- Separating Swing Positions",
    "section": "The Code",
    "text": "The Code\n\nSpecify the file to use\nAdd downloaded directory (not always necsessary) and specify the video file.\n\n!cp -r ../input/golfdb3/* ./\n\nstra='../input/golfdb3/test_video.mp4'\nstra='../input/golfdb2/golfdb/data/videos_160/1017.mp4'\nstra\n\n\n\nImports, classes and defs\nSome imports. Neural nets using Torch\n\nimport scipy.io\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n# from eval import ToTensor, Normalize\n# from model import EventDetector\nimport numpy as np\nimport torch.nn.functional as F\nimport cv2\nfrom torch.autograd import Variable\n\nThe following classes and definitions are taken from the files in the GitHub directory\n\nclass SampleVideo(Dataset):\n    def __init__(self, path, input_size=160, transform=None):\n        self.path = path\n        self.input_size = input_size\n        self.transform = transform\n\n    def __len__(self):\n        return 1\n\n    def __getitem__(self, idx):\n        cap = cv2.VideoCapture(self.path)\n        frame_size = [cap.get(cv2.CAP_PROP_FRAME_HEIGHT), cap.get(cv2.CAP_PROP_FRAME_WIDTH)]\n        ratio = self.input_size / max(frame_size)\n        new_size = tuple([int(x * ratio) for x in frame_size])\n        delta_w = self.input_size - new_size[1]\n        delta_h = self.input_size - new_size[0]\n        top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n        left, right = delta_w // 2, delta_w - (delta_w // 2)\n\n        # preprocess and return frames\n        images = []\n        for pos in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n            _, img = cap.read()\n            resized = cv2.resize(img, (new_size[1], new_size[0]))\n            b_img = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT,\n                                       value=[0.406 * 255, 0.456 * 255, 0.485 * 255])  # ImageNet means (BGR)\n\n            b_img_rgb = cv2.cvtColor(b_img, cv2.COLOR_BGR2RGB)\n            images.append(b_img_rgb)\n        cap.release()\n        labels = np.zeros(len(images)) # only for compatibility with transforms\n        sample = {'images': np.asarray(images), 'labels': np.asarray(labels)}\n        if self.transform:\n            sample = self.transform(sample)\n        return sample\n\n\nclass ToTensor(object):\n    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n    def __call__(self, sample):\n        images, labels = sample['images'], sample['labels']\n        images = images.transpose((0, 3, 1, 2))\n        return {'images': torch.from_numpy(images).float().div(255.),\n                'labels': torch.from_numpy(labels).long()}\n\n\nclass Normalize(object):\n    def __init__(self, mean, std):\n        self.mean = torch.tensor(mean, dtype=torch.float32)\n        self.std = torch.tensor(std, dtype=torch.float32)\n\n    def __call__(self, sample):\n        images, labels = sample['images'], sample['labels']\n        images.sub_(self.mean[None, :, None, None]).div_(self.std[None, :, None, None])\n        return {'images': images, 'labels': labels}\n\n\nimport torch.nn as nn\nimport math\n\n\"\"\"\nhttps://github.com/tonylins/pytorch-mobilenet-v2\n\"\"\"\n\ndef conv_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU6(inplace=True)\n    )\n\n\ndef conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU6(inplace=True)\n    )\n\n\nclass InvertedResidual(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio):\n        super(InvertedResidual, self).__init__()\n        self.stride = stride\n        assert stride in [1, 2]\n\n        hidden_dim = round(inp * expand_ratio)\n        self.use_res_connect = self.stride == 1 and inp == oup\n\n        if expand_ratio == 1:\n            self.conv = nn.Sequential(\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        else:\n            self.conv = nn.Sequential(\n                # pw\n                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n\n    def forward(self, x):\n        if self.use_res_connect:\n            return x + self.conv(x)\n        else:\n            return self.conv(x)\n\n\nclass MobileNetV2(nn.Module):\n    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n        super(MobileNetV2, self).__init__()\n        block = InvertedResidual\n        min_depth = 16\n        input_channel = 32\n        last_channel = 1280\n        interverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # building first layer\n        assert input_size % 32 == 0\n        input_channel = int(input_channel * width_mult) if width_mult >= 1.0 else input_channel\n        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n        self.features = [conv_bn(3, input_channel, 2)]\n        # building inverted residual blocks\n        for t, c, n, s in interverted_residual_setting:\n            output_channel = max(int(c * width_mult), min_depth)\n            for i in range(n):\n                if i == 0:\n                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n                else:\n                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n                input_channel = output_channel\n        # building last several layers\n        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n        # make it nn.Sequential\n        self.features = nn.Sequential(*self.features)\n\n        # building classifier\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(self.last_channel, n_class),\n        )\n\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.mean(3).mean(2)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\nimport torch.nn as nn\nclass EventDetector(nn.Module):\n    def __init__(self, pretrain, width_mult, lstm_layers, lstm_hidden, bidirectional=True, dropout=True):\n        super(EventDetector, self).__init__()\n        self.width_mult = width_mult\n        self.lstm_layers = lstm_layers\n        self.lstm_hidden = lstm_hidden\n        self.bidirectional = bidirectional\n        self.dropout = dropout\n\n        net = MobileNetV2(width_mult=width_mult)\n        state_dict_mobilenet = torch.load('mobilenet_v2.pth.tar')\n        if pretrain:\n            net.load_state_dict(state_dict_mobilenet)\n\n        self.cnn = nn.Sequential(*list(net.children())[0][:19])\n        self.rnn = nn.LSTM(int(1280*width_mult if width_mult > 1.0 else 1280),\n                           self.lstm_hidden, self.lstm_layers,\n                           batch_first=True, bidirectional=bidirectional)\n        if self.bidirectional:\n            self.lin = nn.Linear(2*self.lstm_hidden, 9)\n        else:\n            self.lin = nn.Linear(self.lstm_hidden, 9)\n        if self.dropout:\n            self.drop = nn.Dropout(0.5)\n\n    def init_hidden(self, batch_size):\n        if self.bidirectional:\n            return (Variable(torch.zeros(2*self.lstm_layers, batch_size, self.lstm_hidden).cuda(), requires_grad=True),\n                    Variable(torch.zeros(2*self.lstm_layers, batch_size, self.lstm_hidden).cuda(), requires_grad=True))\n        else:\n            return (Variable(torch.zeros(self.lstm_layers, batch_size, self.lstm_hidden).cuda(), requires_grad=True),\n                    Variable(torch.zeros(self.lstm_layers, batch_size, self.lstm_hidden).cuda(), requires_grad=True))\n\n    def forward(self, x, lengths=None):\n        batch_size, timesteps, C, H, W = x.size()\n        self.hidden = self.init_hidden(batch_size)\n\n        # CNN forward\n        c_in = x.view(batch_size * timesteps, C, H, W)\n        c_out = self.cnn(c_in)\n        c_out = c_out.mean(3).mean(2)\n        if self.dropout:\n            c_out = self.drop(c_out)\n\n        # LSTM forward\n        r_in = c_out.view(batch_size, timesteps, -1)\n        r_out, states = self.rnn(r_in, self.hidden)\n        out = self.lin(r_out)\n        out = out.view(batch_size*timesteps,9)\n\n        return out\n\n\n\nRun the code\n\nseq_length=64\n\nds = SampleVideo(stra, transform=transforms.Compose([ToTensor(),\n                                Normalize([0.485, 0.456, 0.406],\n                                          [0.229, 0.224, 0.225])]))\n\ndl = DataLoader(ds, batch_size=1, shuffle=False, drop_last=False)\n\nmodel = EventDetector(pretrain=True,\n                      width_mult=1.,\n                      lstm_layers=1,\n                      lstm_hidden=256,\n                      bidirectional=True,\n                      dropout=False)\ntry:\n    save_dict = torch.load('models/swingnet_1800.pth.tar')\nexcept:\n    print(\"Model weights not found. Download model weights and place in 'models' folder. See README for instructions\")\n    \n    \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nmodel.load_state_dict(save_dict['model_state_dict'])\nmodel.to(device)\nmodel.eval()\nprint(\"Loaded model weights\")\n\nprint('Testing...')\nfor sample in dl:\n    images = sample['images']\n    # full samples do not fit into GPU memory so evaluate sample in 'seq_length' batches\n    batch = 0\n    while batch * seq_length < images.shape[1]:\n        if (batch + 1) * seq_length > images.shape[1]:\n            image_batch = images[:, batch * seq_length:, :, :, :]\n        else:\n            image_batch = images[:, batch * seq_length:(batch + 1) * seq_length, :, :, :]\n        logits = model(image_batch.cuda())\n        if batch == 0:\n            probs = F.softmax(logits.data, dim=1).cpu().numpy()\n        else:\n            probs = np.append(probs, F.softmax(logits.data, dim=1).cpu().numpy(), 0)\n        batch += 1\n\n        \nevents = np.argmax(probs, axis=0)[:-1]\nprint('Predicted event frames: {}'.format(events))\n\n\nconfidence = []\nfor i, e in enumerate(events):\n    confidence.append(probs[e, i])\nprint('Confidence: {}'.format([np.round(c, 3) for c in confidence]))\n\nOutput:\nUsing device: cuda\nLoaded model weights\nTesting…\nPredicted event frames: [ 82 121 137 166 189 203 213 245]\nConfidence: [0.215, 0.376, 0.79, 0.767, 0.827, 0.968, 0.935, 0.247]"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart2.html#plot-the-results",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart2.html#plot-the-results",
    "title": "Golf Swing Part II- Separating Swing Positions",
    "section": "Plot the results",
    "text": "Plot the results\n\nimport os\n##delte images\nlsa=os.listdir()\nfimg=[ ll for ll in lsa if ll.split('.')[-1]=='jpg']\n# print(fimg)\nimgs=[os.remove(ff) for ff in fimg]\n\nfimg=[ ll for ll in lsa if ll.split('.')[-1]=='jpg']\n\n\ndef createImages(fila,pos,nomS):\n    ''' \n    Given a video file location (fila) it will save as images to a folder\n    Given positions in video (pos) these images from the video are saved\n    pos is created based on positions of swings\n    '''\n    import cv2\n    cap = cv2.VideoCapture(fila)\n    eventNom=[0,1,2,3,4,5,6,7]\n    for i, e in enumerate(events):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, e)\n        _, img = cap.read()\n        cv2.imwrite(os.path.join(os.getcwd(),'_'+ nomS+'_'+\"frame{:d}.jpg\".format(eventNom[i])), img)     # save frame as JPG file\n    \n    \nfila=stra\npos=events\ncreateImages(fila,pos,'10')\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nlsa=os.listdir()\nfimg=[ ll for ll in lsa if ll.split('.')[-1]=='jpg']\nfimg.sort()\n\nimgs=[mpimg.imread(ff) for ff in fimg]\n\n\ncap = cv2.VideoCapture(stra)\n\n\n# plt.subplot(4,2,1)\nf, axs = plt.subplots(4,2,figsize=(15,15))\nfor i, e in enumerate(events):\n    cap.set(cv2.CAP_PROP_POS_FRAMES, e)\n    _, img = cap.read()\n    plt.subplot(4,2,i+1)\n    plt.imshow(img)\n    plt.title(e)"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#overview",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#overview",
    "title": "Golf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App",
    "section": "Overview",
    "text": "Overview\nIn a previous part Part 1 a neural network model was used to find positions on the body during a golf swing. The model was not particularly succesful, perhaps due to the lack of data (specific to the golf swing) that was used to train the model on.\nThis problem can be got around by using a model that has been pre-trained on human gestures. Several pre-trained models can be found here Pre-trained models. I tried a few and found the chose the model keypoint-rcnn-resnet50-fpn-coco-torch worked well with this data. Link to model and Paper of model.\nThe input to the model is taken from Part 2 which separated a golf video into a series of images of the swing.\nIn this page I use the model with both fiftyOne and as a streamlit app.\n\nyoutube: https://youtu.be/Q0BB0huWb6s https://youtu.be/Q0BB0huWb6s"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#code",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#code",
    "title": "Golf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App",
    "section": "Code",
    "text": "Code\nThe code can be run on google colab here COCO50_1 (works best on google chrome)"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#installs-and-imports",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#installs-and-imports",
    "title": "Golf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App",
    "section": "Installs and imports",
    "text": "Installs and imports\n\n!pip uninstall opencv_python_headless\n\n!pip install opencv-python-headless==4.5.4.60\n\n!pip install fiftyone\n\nimport fiftyone as fo"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#upoad-some-images-to-the-workspace",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#upoad-some-images-to-the-workspace",
    "title": "Golf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App",
    "section": "Upoad some images to the workspace",
    "text": "Upoad some images to the workspace\nUntar and create a dataset object from them\nAnd look at them\nThe image files can be found here GC2.tgz\n\nimport tarfile\nmy_tar = tarfile.open('/content/GC2.tgz')\nmy_tar.extractall('/content/my_folder') # specify which folder to extract to\nmy_tar.close()\n\n\nimport fiftyone as fo\nimport fiftyone.zoo as foz\n\nimport fiftyone as fo\n\nname = \"my_folder\"\ndataset_dir = \"/content\"\n\n# Create the dataset\ndataset = fo.Dataset.from_dir(\n    dataset_dir=dataset_dir,\n    dataset_type=fo.types.ImageDirectory,\n    name=name,\n)\n\nsession = fo.launch_app(dataset)\n\n\nThis screen is interative and allows us to look at the images"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#load-the-trained-model",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#load-the-trained-model",
    "title": "Golf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App",
    "section": "Load the trained model",
    "text": "Load the trained model\nApply the model to the dataset\nView the results\n\nmodel = foz.load_zoo_model(\"keypoint-rcnn-resnet50-fpn-coco-torch\")\n\n# label_types=[\"classification\", \"classifications\", \"detections\", \"instances\", \"segmentations\", \"keypoints\", \"polylines\", \"polygons\", \"scalar\"],\n\ndataset.apply_model(model, label_field=\"predictions\",label_types='predictions_keypoints')\n\nsession = fo.launch_app(dataset)\n\n\n\nyoutube: https://youtu.be/dkxtOBWD7Vw"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#extract-data-from-the-model",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#extract-data-from-the-model",
    "title": "Golf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App",
    "section": "Extract data from the model",
    "text": "Extract data from the model\nWe might want to use the data from the model outside of fiftyOne.\nIn the following I extract the data so that it can be plotted.\n\ndef plotPredOne(i):\n  import numpy as np\n\n  import matplotlib.pyplot as plt\n  import matplotlib.image as mpimg\n\n  img = mpimg.imread(i['filepath'])\n\n  #need to take account of more than one person in image\n  points1 = np.array(i['predictions_keypoints']['keypoints'][0]['points'])\n  adjPts = np.shape(img)[0]\n  box1 = np.array(i['predictions_detections']['detections'][0]['bounding_box']) \n  box1=box1*adjPts\n  # Bboxes are in [top-left-x, top-left-y, width, height] format\n  box2=np.array([ \n      [box1[0], box1[1]],\n      [box1[0] +box1[2] ,box1[1] ],\n      [box1[0] +box1[2] ,box1[1] +box1[3]] ,\n      [box1[0]  ,box1[1] +box1[3]],\n      [box1[0], box1[1]]\n      ])\n \n  plt.figure()\n  plt.imshow(img)\n\n  plt.plot(points1[:,0]*adjPts,points1[:,1]*adjPts, '+k',markersize=10,linewidth=3)\n  plt.plot(box2[:,0],box2[:,1], '--og',markersize=10,linewidth=3)\n\n    #back of body\n  v=[4,6,12,14,16]\n  plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-k<',markersize=10,linewidth=2)\n\n  #front of body\n  v=[0,5,11,13,15]\n  plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-w>',markersize=10,linewidth=2)\n\n  vects = np.array([[ 5,6],#shoulders also 4?\n         [11,12], #hips\n         [13,14], #knees\n         [15,16],#heels\n         [7,8],#elbows\n         [9,10],#hands\n         ]) \n  mak='gcyrmb'\n  for iv,v in enumerate(vects):\n    plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-'+mak[iv],markersize=10,linewidth=3)\n\n\nfor iii,i in enumerate(dataset):\n  \n  plotPredOne(i)"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#convert-into-a-streamlit-app",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#convert-into-a-streamlit-app",
    "title": "Golf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App",
    "section": "Convert into a Streamlit App",
    "text": "Convert into a Streamlit App\nTo convert to a streamlit app I will use the PyTorch module rather than the fiftyOne.\nI will also keep it simple by loading only 3 images- start of swing, top of backswing and at impact- and modeling these at the start of the load part of the app.\nThe app will then just plot the images as shown above.\n\nImports and give the app a title\n\nimport streamlit as st\nimport torch\nimport torchvision\nfrom torchvision import transforms\nfrom PIL import Image\nimport tarfile\nimport os\nfrom torchvision.io import read_image\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nst.title('Golf Swing')\n\n\n\nLoading the data & applying the model\nCreate a function to load data and model the data\nload_data(choi)\nImages are loaded from Gc2.tgz\nmy_tar = tarfile.open(cda2+'/GC2.tgz')\nThe particular model to use is loaded\nmodel = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\nmodel.eval()\nImages are loaded and converted to a tensor\nnumber_img = Image.open(cda2+'/images/'+image_filename)\nconvert_tensor = transforms.ToTensor()\nAnd predictions are made\npredictions=model(imgTens)\nIn the main body the function is called\ndata_load_state = st.text('Loading data...')\npredictions,imgLocAll,cda2=load_data(1)\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\n# So only have to do this when app launches\n@st.cache()\n\n# the function 'choi' is the video file to use\ndef load_data(choi):\n\n    # the images are in the GC2.tgz file- this needs to be untarred first\n    cda = os.getcwd()\n    cda2=cda\n    my_tar = tarfile.open(cda2+'/GC2.tgz')\n    my_tar.extractall(cda2) # specify which folder to extract to\n    my_tar.close()\n\n    # Create a variable of the image names and which video they are part of\n    imgAll=[]\n    vidAll=[]\n    i=0\n    last1=' '\n    for xx in os.listdir(cda2+'/images/'):\n        if xx[-1]=='g':\n            imgAll = np.append(imgAll, xx)\n            if xx.split('_')[1]!=last1:\n                i=i+1\n            vidAll=np.append(vidAll,i)\n            last1=xx.split('_')[1]\n\n    vidAllUnq=np.unique(vidAll)\n    \n    # Load the model to be used\n    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\n    model.eval()\n    \n    # Select the images to be used\n    imgs = imgAll[vidAll==vidAllUnq[choi]]\n\n    # make sure in correct order\n    aa=[int(xx.split('_')[-1].split('e')[1].split('.')[0]) for xx in imgs]\n    ind=sorted(range(len(aa)), key=lambda k: aa[k])\n    imgs=imgs[ind]\n\n    # create tensor of images to be used- here 3 (images) X width X height\n    imgTens=[]\n    imgLocAll=[]\n    \n    # Just use the start, top and impact of swing\n    iiUse=[0,3,5]\n    for ii,image_filename in enumerate(imgs):\n    #             print(cda2+'images/'+image_filename)\n        if ii in iiUse:\n            number_img = Image.open(cda2+'/images/'+image_filename)\n            convert_tensor = transforms.ToTensor()\n            number_img=convert_tensor(number_img)\n            imgTens.append(number_img)\n            imgLocAll.append(image_filename)\n\n    # Make the predictions\n    predictions=model(imgTens)\n    \n    return predictions,imgLocAll,cda2\n\n# Outside the function, the load function is called\ndata_load_state = st.text('Loading data...')\npredictions,imgLocAll,cda2=load_data(1)\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\n\n\nStreamlit user interface\nUser selects the images from this box:\nchoice=imgLocAll\nimgSEL = st.sidebar.selectbox(     'Select how to search',      choice)\nDisplay to user what swing it is:\nSwingPos=['Start','Back','Through']\nSwingPos[numSEL]\nAnd at the end of the file the figure is displayed in streamlit with the following command:\nst.pyplot(fig)\n\n\nThe plot part\nExtract the data from the model about different parts of the body:\npoints1=np.array([x.detach().numpy()[0:2] for x in predictions[numSEL]['keypoints'][0]])\nThe plot lines plot different parts of the body, the following plot the back of the body\nv=[4,6,12,14,16]\nplt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-w<',markersize=10,linewidth=2)\n\n# load the images so can be plotted\nimg = mpimg.imread(cda2+'/images/'+imgSEL)\n\n# the image selected\nnumSEL=[oo for oo,x in enumerate(choice) if x==imgSEL][0]\n\n# get data from model as a numpy array - here want keypoints other info is also available\npoints1=np.array([x.detach().numpy()[0:2] for x in predictions[numSEL]['keypoints'][0]])\n\n# create a plot\nfig=plt.figure(figsize=(7,7))\nplt.imshow(img)\n\n# Plot across back and front of body\nadjPts=1\n#back of body\nv=[4,6,12,14,16]\nplt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-w<',markersize=10,linewidth=2)\n\n#front of body\nv=[0,5,11,13,15]\nplt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-k>',markersize=10,linewidth=2)\n\n# Plot over lines on body\nvects = np.array([[ 5,6],#shoulders also 4?\n     [11,12], #hips\n     [13,14], #knees\n     [15,16],#heels\n     [7,8],#elbows\n     [9,10],#hands\n     ]) \nmak='gcyrmb'\nfor iv,v in enumerate(vects):\n    plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-'+mak[iv],markersize=10,linewidth=3)\n\nLEG=['Back','Front','Shoulders','Hips','Knees','Heels','Elbows','Hands']\nplt.legend(LEG)\nfor x in points1:\n    plt.plot(x[0],x[1],'+b')\n\n\n\nRequirements.txt\nFinally streamlit needs a requirements text in the GitHub repository\n\ntorch\ntorchvision\nPillow\nmatplotlib\nnumpy"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#the-streamlit-app",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart3.html#the-streamlit-app",
    "title": "Golf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App",
    "section": "The Streamlit App",
    "text": "The Streamlit App\nStreamlit App\nGitHub page\n\nyoutube: https://youtu.be/Q0BB0huWb6s"
  },
  {
    "objectID": "posts/PROJECTS/Golf_swing/GolfSwingPart4.html#modifications-to-code-for-separating-swing-video",
    "href": "posts/PROJECTS/Golf_swing/GolfSwingPart4.html#modifications-to-code-for-separating-swing-video",
    "title": "ThomasHSimm",
    "section": "Modifications to code for separating swing video",
    "text": "Modifications to code for separating swing video\n\n- Imported files are not saved to a location\nThis means can’t pass ‘path’ when creating the Dataset. So that line is removed from the __init__\nIn theory the video could then be loaded with cap = cv2.VideoCapture(self) but this doesn’t work as openCV requires a file. So a get around for this is create a temp file https://discuss.streamlit.io/t/how-to-access-uploaded-video-in-streamlit-by-open-cv/5831/4\nf = st.file_uploader(\"Upload file\")\ntfile = tempfile.NamedTemporaryFile(delete=False)\ntfile.write(f.read())\nvf = cv.VideoCapture(tfile.name)\nFor the same reason the image files are not saved as a file\n\n\n- Video load issue\nIf the video is loaded a second time ret, img = cv2.VideoCapture there are problems receieving the video i.e. ret=False.\nA get around used was to copy the imported file\nuploaded_filesCOPY = copy.copy( uploaded_files )\n\n\n- Using on a CPU instead of a GPU\nThe code needed modifying slightly to allow it to work using a CPU. Although it does have the following line, a few more changes were needed\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nAdding a description in the loads\ntorch.load('mobilenet_v2.pth.tar',map_location=torch.device('cpu'))\nRemoving the cdu() part at end of e.g. variables\nVariable(torch.zeros(2*self.lstm_layers, batch_size, self.lstm_hidden).cuda()\n# to     \nVariable(torch.zeros(2*self.lstm_layers, batch_size, self.lstm_hidden)"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#background",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#background",
    "title": "Olympics data with SQL and pandas- height weight and age",
    "section": "Background",
    "text": "Background\nI did some initial plots on the changes in the characteristics of athletes given in the data, height, weight and age, of athletes attending the Olympics by year (see below).\nFrom these plots I was really intrigued as to what may be the cause of these changes.\nMainly what was happening between 1960 and 1980 were there seemed to be changes in each of the parameters?\nMy initial thought was this could be related to some combination of - a switch from amateurs to professionals - the Cold War between USA and USSR - an after effect of WWII\n\n\n\n\nOlympic Background\nThroughout much of the Olympic’s history there has been tension around professionals and amateur athletes. The games were intended for amateur athletes, and those who played sport professionally were banned or even had their medals stripped.\nThe reasoning behind amateurism was based on how sport was seen by the aristrocracy and greatly influenced Pierre de Coubertin, who is thought of as the father of the Olympic games:\n\"There was also a prevailing concept of fairness, in which practising or training was considered tantamount to cheating.[2] Those who practised a sport professionally were considered to have an unfair advantage over those who practised it merely as a hobby.[2]\"\nThe Soviet Union, who competed from 1952-1988, entered teams of athletes who were all nominally students, soldiers, or working in a profession, but all of whom were in reality paid by the state to train on a full-time basis.[3] The situation greatly disadvantaged American and Western European athletes, and was a major factor in the decline of American medal hauls in the 1970s and 1980s. However, workarounds in Western countries also allowed individuals to focus full-time on sport while passing the amateur rules.[4]\nThis abuse of amateur rules by the Eastern Bloc nations prompted the IOC to shift away from pure amateurism.The rules were steadily relaxed from 1972, amounting only to technicalities and lip service, until being completely abandoned in the 1990s\n\nWikipedia Olympic Games And Amateurism\nEassom 1994, pp. 120–123\n“The Role of Sports in The Soviet Union – Guided History”. blogs.bu.edu.\nDegrees of Difficulty: How Women’s Gymnastics Rose to Prominence and Fell from Grace”, by Georgia Cervin"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#load-data-and-libraries",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#load-data-and-libraries",
    "title": "Olympics data with SQL and pandas- height weight and age",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandasql import sqldf\nimport copy\nimport numpy as np\nimport scipy.stats\n\n\ndf_F_S =pd.read_csv('athlete_F_S')\ndf_F_W=pd.read_csv('athlete_F_W')\ndf_M_S=pd.read_csv('athlete_M_S')\ndf_M_W=pd.read_csv('athlete_M_W')\n\ndf_all_athletes= pd.read_csv('all_athletes')\ndf_country= pd.read_csv('country')\ndf_event= pd.read_csv('event')\n# df_games= pd.read_csv('games')\n# df_population= pd.read_csv('population')\n\n# df_country = df_country.groupby('NOC').max()\n# df_country.head(10)"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#what-are-the-best-weight-height-age",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#what-are-the-best-weight-height-age",
    "title": "Olympics data with SQL and pandas- height weight and age",
    "section": "What are the best Weight, Height, Age?",
    "text": "What are the best Weight, Height, Age?\nObviously this will depend on event. But if we average across events what are - the best of values of these? - and how do these change with time?\nTo get this figure the methodology is fairly simple, in the SQL query: - We take the average of weight, height, age across years and medal type - Because we want a simple binary answer (medal or not) we create a variable called medal which is 1 if they got a medal and 0 otherwise - We then group on this and take an average - The two function below are just so we can plot for avg_weight, avg_height and avg_age without repeating the same steps\nhere Male summer athletes are used but the result for female summer athletes show the same trend\n\nmedalQ=sqldf('\\\n    SELECT                                 \\\n        Year,                              \\\n        medal,                             \\\n        AVG(avg_weight)    AS avg_weight,  \\\n        AVG(avg_height)    AS avg_height,  \\\n        AVG(avg_age)       AS avg_age      \\\n    FROM                                   \\\n         (SELECT                           \\\n         Year,                             \\\n         MAX(Medal_Gold,Medal_Silver,Medal_Bronze)\\\n                           AS medal,       \\\n         avg(Weight)       AS avg_weight,  \\\n         AVG(Height)       AS avg_height,  \\\n         AVG(age)          AS avg_age      \\\n         from df_M_S                       \\\n         group by                          \\\n             Year,                         \\\n             Medal_Gold,Medal_Silver,Medal_Bronze           \\\n         order by Year asc) A              \\\n     GROUP BY Year, medal;',locals())  \nmedalQ.head()\n\n\n\n\n\n  \n    \n      \n      Year\n      medal\n      avg_weight\n      avg_height\n      avg_age\n    \n  \n  \n    \n      0\n      1896\n      0\n      70.444444\n      169.916667\n      23.896552\n    \n    \n      1\n      1896\n      1\n      71.551282\n      175.217949\n      23.211671\n    \n    \n      2\n      1900\n      0\n      76.971429\n      175.054545\n      29.428571\n    \n    \n      3\n      1900\n      1\n      72.711355\n      178.202932\n      28.454139\n    \n    \n      4\n      1904\n      0\n      71.742424\n      175.131579\n      26.752080\n    \n  \n\n\n\n\n\ndef modname(string):\n    string=''.join([string[0].upper(),string[1:].lower()])\n    string=string.replace('_',' ')\n    return string\n    \ndef plotMedal(plotchoi,medalQ):\n    plt.subplots(figsize=(8,5))\n    plt.plot(medalQ[medalQ.medal==1].Year,medalQ[medalQ.medal==1][plotchoi],'g*-')\n\n    plt.plot(medalQ[medalQ.medal==0].Year,medalQ[medalQ.medal==0][plotchoi],'rv--')\n\n    plt.legend(['Medal','No medal'])\n    plt.grid(True)\n    plt.xlabel('Year')\n    plt.ylabel(modname(plotchoi))\n\n\nplotchoi='avg_height'\nplotMedal(plotchoi,medalQ)\n\nplotchoi='avg_weight'\nplotMedal(plotchoi,medalQ)\n\nplotchoi='avg_age'\nplotMedal(plotchoi,medalQ)\nplt.ylim([18,40])\n\n(18.0, 40.0)\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer: What is the best weight, height and age?\n\nAge, height and weight of athletes change with year\nAfter the initial years (> ~1930)\n\nAthletes who get more medals have greater height and weight\nWhereas, the age is indistinguishable"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#the-change-in-athletes-based-on-weight-height-and-age",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#the-change-in-athletes-based-on-weight-height-and-age",
    "title": "Olympics data with SQL and pandas- height weight and age",
    "section": "The change in athletes based on weight, height and age",
    "text": "The change in athletes based on weight, height and age\nHere the methodology used to produce the figures in the background section is presented.\nThe method is fairly simple, we just use each athlete table and then GROUP BY year and take the averages\n\ndf_F=\\\n     sqldf('SELECT                              \\\n              Year,                             \\\n               avg(Height) AS avg_height,       \\\n               avg(Weight) AS avg_weight,       \\\n               avg(Age)    AS avg_age           \\\n            FROM                                \\\n                df_F_S AS d                     \\\n            GROUP BY                            \\\n               Year                             \\\n            ORDER BY                            \\\n                Year asc;',locals())\ndf_M=\\\n     sqldf('SELECT                              \\\n              Year,                             \\\n               avg(Height) AS avg_height,       \\\n               avg(Weight) AS avg_weight,       \\\n               avg(Age)    AS avg_age           \\\n            FROM                                \\\n                df_M_S AS d                     \\\n            GROUP BY                            \\\n               Year                             \\\n            ORDER BY                            \\\n                Year asc;',locals())\n               \ndf_Fw=\\\n     sqldf('SELECT                              \\\n              Year,                             \\\n               avg(Height) AS avg_height,       \\\n               avg(Weight) AS avg_weight,       \\\n               avg(Age)    AS avg_age           \\\n            FROM                                \\\n                df_F_W AS d                     \\\n            GROUP BY                            \\\n               Year                             \\\n            ORDER BY                            \\\n                Year asc;',locals())\ndf_Mw=\\\n     sqldf('SELECT                              \\\n              Year,                             \\\n               avg(Height) AS avg_height,       \\\n               avg(Weight) AS avg_weight,       \\\n               avg(Age)    AS avg_age           \\\n            FROM                                \\\n                df_M_W AS d                     \\\n            GROUP BY                            \\\n               Year                             \\\n            ORDER BY                            \\\n                Year asc;',locals())\n               \ndf_F.head()                    \n\n\n\n\n\n  \n    \n      \n      Year\n      avg_height\n      avg_weight\n      avg_age\n    \n  \n  \n    \n      0\n      1900\n      NaN\n      NaN\n      29.791667\n    \n    \n      1\n      1904\n      NaN\n      NaN\n      50.230769\n    \n    \n      2\n      1906\n      NaN\n      NaN\n      23.500000\n    \n    \n      3\n      1908\n      NaN\n      NaN\n      33.897436\n    \n    \n      4\n      1912\n      NaN\n      NaN\n      22.379310\n    \n  \n\n\n\n\n\ndef yrplot(df_F,df_M,df_Fw,df_Mw,whatplot= 'avg_weight'): \n    cola=['r>','b<','mo','cs']\n\n    plt.subplots(figsize=(6,4))\n    plt.plot(df_F.Year,df_F[whatplot],cola[0],markersize=10)\n\n    plt.plot(df_M.Year,df_M[whatplot],cola[1],markersize=10)\n\n    plt.plot(df_Fw.Year,df_Fw[whatplot],cola[2])\n    plt.plot(df_Mw.Year,df_Mw[whatplot],cola[3])\n\n    def doPlot(df_F,avgNo,whatplot,col,lw):\n        bb = df_F.Year.rolling(avgNo).mean()\n        cc = df_F[whatplot]\n        cc = cc.rolling(avgNo).mean()\n        plt.plot(bb,cc,col,linewidth=lw)\n\n    doPlot(df_F,3,whatplot,'r-',4)\n    doPlot(df_M,3,whatplot,'b-',4)\n\n    doPlot(df_Fw,3,whatplot,'m--',2)\n    doPlot(df_Mw,3,whatplot,'c--',2)\n\n    plt.legend(['Female Summer','Male Summer','Female Winter','Male Winter'])\n    plt.ylabel(modname(whatplot),fontsize=14)\n    plt.xlabel('Year',fontsize=14)\n    plt.xlim([1890, 2020])\n    plt.grid(True)\n\n\nyrplot(df_F,df_M,df_Fw,df_Mw,whatplot= 'avg_weight')\nyrplot(df_F,df_M,df_Fw,df_Mw,whatplot= 'avg_height')\nyrplot(df_F,df_M,df_Fw,df_Mw,whatplot= 'avg_age')\nplt.ylim([18,35]);\n\n\n\n\n\n\n\n\n\n\n\nAre the changes due to changes in athletes or changes in the Olympics?\n\nJoin athlete table df_M_S with event table df_event\n\nUse this to get a list of events and the year they occur\n\nGroup this table\n\nTo get which event meet criteria of a minimum date, maximum date and having occured so many times\n\n\n(select\nEvent_id\n……\nAND max(year)>1990) usea\n\nGroup the table of events with the athlete table df_M_S\nTake the average over the events and year\nTake this average just over year\n\nThis stops changes due to changes in number of athletes in a particular event\n\n\nThere are 15-20 events included in the results below. Although, a relatively low figure this still represents a lot of athletes. Furthermore, when we split these events into 2 the same trends we find in all the data are seen in the two splits. The absolute values can differ but the min./max. values seem to fairly consistent. But obviously more exploration would be beneficial if this is led by theories or experts in the areas. Without this we could spend forever looking for trends.\n\n# --find events that have occured more than a set amount within a range of dates\n# -- i.e. events that can focus on to see results of changes with time\n\ndef do_same_event(df_M_S,df_F_S,df_event,athlete_df_name='df_M_S',counta='17',yr_start='1900',yr_end='1990'):\n    tempa= sqldf('                               \\\n    SELECT                                   \\\n        Year,                                \\\n        avg(wgt)            AS avg_weight,   \\\n        avg(hgt)            AS avg_height,   \\\n        avg(aga)            AS avg_age       \\\n    FROM                                     \\\n        (SELECT                              \\\n        Year,                                \\\n        AVG(weight)         AS wgt,          \\\n        AVG(height)         AS hgt,          \\\n        AVG(age)            AS aga           \\\n        FROM                                 \\\n        (SELECT                              \\\n          Event_id                           \\\n        FROM                                 \\\n            (SELECT                          \\\n            E.Event_id,                      \\\n            Year,                            \\\n            count(*)        AS counta        \\\n            FROM                             \\\n                {0}         AS A             \\\n            LEFT JOIN                        \\\n                df_event    AS E             \\\n            ON                               \\\n                E.event_id = A.event_id      \\\n            GROUP BY                         \\\n                E.Event_id,                  \\\n                Year                         \\\n            ORDER BY year asc) AA            \\\n        GROUP BY AA.Event_id                 \\\n        HAVING COUNT(*) >{1}                 \\\n        AND MIN(year)<{2}                    \\\n        AND MAX(year)>{3}                    \\\n        ORDER BY event_id asc                \\\n        LIMIT 80) usea                       \\\n        LEFT JOIN                            \\\n            {0}              AS a            \\\n        ON                                   \\\n            usea.event_id = a.event_id       \\\n        GROUP BY                             \\\n            year,                            \\\n            usea.event_id                    \\\n        ORDER BY year asc) two               \\\n        GROUP BY year;'.format(athlete_df_name,counta,yr_start,yr_end),locals())\n    return tempa\n\n\ntempaM = do_same_event(df_M_S,df_F_S,df_event,'df_M_S')\ntempaF = do_same_event(df_M_S,df_F_S,df_event,'df_F_S',counta='12',yr_start='1945',yr_end='1990')\n\ntempaF.head()\n\n\n\n\n\n  \n    \n      \n      Year\n      avg_weight\n      avg_height\n      avg_age\n    \n  \n  \n    \n      0\n      1900\n      NaN\n      NaN\n      25.250000\n    \n    \n      1\n      1906\n      NaN\n      NaN\n      23.500000\n    \n    \n      2\n      1908\n      NaN\n      NaN\n      31.200000\n    \n    \n      3\n      1912\n      NaN\n      NaN\n      21.759259\n    \n    \n      4\n      1920\n      NaN\n      160.145833\n      21.737132\n    \n  \n\n\n\n\n\ndef modname(string):\n    string=''.join([string[0].upper(),string[1:].lower()])\n    string=string.replace('_',' ')\n    return string\n\ndef yrplot1(df_F,df_M,whatplot): \n    cola=['r>','b<','mo','cs']\n\n    fig,ax=plt.subplots(figsize=(8,5))\n    ax.plot(df_F.Year,df_F[whatplot],cola[0],markersize=10)\n    ax2=ax.twinx()\n    ax2.plot(df_M.Year,df_M[whatplot],cola[1],markersize=10)\n\n#     plt.plot(df_Fw.Year,df_Fw[whatplot],cola[2])\n#     plt.plot(df_Mw.Year,df_Mw[whatplot],cola[3])\n\n\n    def doPlot(df_F,avgNo,whatplot,col,lw,xx):\n        bb = df_F.Year.rolling(avgNo).mean()\n        cc = df_F[whatplot]\n        cc = cc.rolling(avgNo).mean()\n        xx.plot(bb,cc,col,linewidth=lw)\n\n    doPlot(df_F,3,whatplot,'r-',4,ax)\n    doPlot(df_M,3,whatplot,'b-',4,ax2)\n\n#     doPlot(df_Fw,3,whatplot,'m--',2)\n#     doPlot(df_Mw,3,whatplot,'c--',2)\n\n    fig.legend(['Female Summer','-','Male Summer','-'],loc='upper center')#,'Female Winter','Male Winter'])\n    ax.set_ylabel('Female ' + modname(whatplot),fontsize=14)\n    ax2.set_ylabel('Male ' + modname(whatplot),fontsize=14)\n    ax.set_xlabel('Year',fontsize=14)\n    plt.xlim([1890, 2020])\n    ax2.grid(True)\n    \n\n\nyrplot1(tempaF,tempaM,whatplot= 'avg_weight')\nyrplot1(tempaF,tempaM,whatplot= 'avg_height')\nyrplot1(tempaF,tempaM,whatplot= 'avg_age')\n# no limit"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#the-cold-war",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL-HeightWeightAge.html#the-cold-war",
    "title": "Olympics data with SQL and pandas- height weight and age",
    "section": "The Cold War",
    "text": "The Cold War\n\ndef yrplot(df__,whatplot= 'avg_weight'): \n    \n    countries=['EST', 'EUN' ,'ROW', 'USA' ,'WES']\n    \n#     df__.NOCSMALL.unique()\n#     countries=np.sort(countries)\n    print(countries)\n    cola=['>','o','+','*','<']\n    colur=[[1,0.6,.6],[1,0,0],[.5,.5,.5],[0,0,1],[.6,.6,1]]\n#     ['EST' 'EUN' 'ROW' 'USA' 'WES']\n#     'EST','USA','WES','ROW','EUN'\n\n    fig,ax1=plt.subplots(figsize=(8,5))\n    \n    for i,country in enumerate(countries):\n        if country!='ROW':\n            ax1.plot(df__[df__.NOCSMALL==country].Year,\\\n                 df__[df__.NOCSMALL==country][whatplot],\\\n                 marker=cola[i],linestyle='None',color=colur[i]\\\n                 ,markersize=10)\n\n\n    def doPlot(df_F,avgNo,whatplot,country,col,lw,ax1):\n        bb = df_F[df__.NOCSMALL==country].Year.rolling(avgNo).mean()\n        cc = df_F[df__.NOCSMALL==country][whatplot]\n        cc = cc.rolling(avgNo).mean()\n        ax1.plot(bb,cc,linewidth=lw,color=col)\n        return ax1\n\n    for i,country in enumerate(countries):\n        if country!='ROW':\n            ax1=doPlot(df__,avgNo=3,whatplot=whatplot,country=country,col=colur[i],lw=3,ax1=ax1)\n    \n    lega = ['East Europe','Russia','USA','West Europe']\n    plt.legend(lega)\n    plt.grid(True)\n    plt.ylabel(modname(whatplot))\n    \n    return ax1\n\n\ndef get_df_USA_USSR(df_M_S,df_F_S,nameDF):\n    USA_USSR=sqldf(\\\n           'SELECT                            \\\n              Year,                           \\\n              NOCSMALL,                       \\\n              AVG(avg_height)  AS avg_height, \\\n              AVG(avg_weight)  AS avg_weight, \\\n              AVG(avg_age)     AS avg_age,    \\\n              SUM(number_of_athletes) AS number_of_athletes         \\\n           FROM                                    \\\n               (SELECT                             \\\n                   Year,                           \\\n                   AVG(avg_height)  AS avg_height, \\\n                   AVG(avg_weight)  AS avg_weight, \\\n                   AVG(avg_age)     AS avg_age,    \\\n                   SUM(num_ath) AS number_of_athletes,        \\\n                   CASE                                \\\n                       WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n                       WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n                       WHEN NOC=\"USA\" THEN \"USA\"       \\\n                       WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n                       ELSE \"ROW\"\\\n                   END AS NOCSMALL,                     \\\n                   NOC\\\n               FROM                               \\\n                  (SELECT                         \\\n                  Year,                           \\\n                  NOC,                            \\\n                  avg(Height) AS avg_height,      \\\n                  avg(Weight) AS avg_weight,      \\\n                  avg(Age)    AS avg_age,         \\\n                  count(*)    AS num_ath          \\\n                  FROM                            \\\n                    {} AS d                       \\\n                  GROUP BY                        \\\n                    Year,NOC                      \\\n                  ORDER BY                        \\\n                    Year asc) A                   \\\n              GROUP BY                            \\\n                Year,NOC) B                       \\\n           GROUP BY Year, NOCSMALL ;'.format(nameDF),locals())\n    return USA_USSR\n\n\ndef do_USA_USSR(df_M_S,df_F_S,men_women,whatplot):\n    if men_women=='men':\n        nameDF='df_M_S'\n    elif men_women=='women':\n        nameDF='df_F_S'\n    \n        \n    USA_USSR_F = get_df_USA_USSR(df_M_S,df_F_S,nameDF)\n    ax1=yrplot(USA_USSR_F,whatplot)\n    \n    return ax1\n    \n    \n\n\ndo_USA_USSR(df_M_S,df_F_S,'men','avg_weight')\nplt.ylim([65, 90])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n(65.0, 90.0)\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'women','avg_weight')\nplt.ylim([50, 70])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n(50.0, 70.0)\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'men','avg_height')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Avg height'>\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'women','avg_height')\n# plt.ylim([65, 90])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Avg height'>\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'men','avg_age')\n# plt.ylim([65, 90])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Avg age'>\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'women','avg_age')\nplt.ylim([18, 35])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n(18.0, 35.0)\n\n\n\n\n\n\ndef number_of_athletes_USA_USSR(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                 \\\n        Year,                              \\\n        NOCSMALL,                          \\\n        count(*) AS number_of_athletes,     \\\n        \"F\" AS Sex                          \\\n    FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_F_S                       \\\n         group by athlete_ID,Year               \\\n         order by Year asc) A              \\\n     GROUP BY Year, NOCSMALL               \\\n     UNION ALL                                 \\\n     SELECT                                \\\n        Year,                              \\\n        NOCSMALL,                          \\\n        count(*) AS number_of_athletes,     \\\n        \"M\" AS Sex                          \\\n    FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_M_S                       \\\n         group by athlete_ID,Year          \\\n         order by Year asc) A              \\\n     GROUP BY Year, NOCSMALL;',locals()  )\n    return testa2\n\ndef number_of_medals_USA_USSR(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                 \\\n            COUNT(*) AS number_of_medals,\\\n            Year, Sex, NOCSMALL\\\n        FROM \\\n        (SELECT NOCSMALL,Year,Sex,COUNT(*) AS counta\\\n        FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         event_ID,                          \\\n         \"F\"   AS Sex,                      \\\n         Medal_Gold,Medal_Silver,Medal_Bronze,\\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_F_S                       \\\n         WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1\\\n         UNION ALL                                 \\\n         SELECT                           \\\n         athlete_ID,                        \\\n         event_ID,                          \\\n         \"M\" AS Sex,                       \\\n         Medal_Gold,Medal_Silver,Medal_Bronze,\\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_M_S                       \\\n         WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1\\\n         order by Year asc) A\\\n     GROUP BY \\\n         Year, NOCSMALL,event_id,Medal_Gold,Medal_Silver,Medal_Bronze)  AS B\\\n GROUP BY Year, NOCSMALL, Sex\\\n                 ;',locals()  )                                       \n    return testa2\n\n\nUSA_USSR_medals=number_of_medals_USA_USSR(df_F_S,df_M_S)\nUSA_USSR_athletes=number_of_athletes_USA_USSR(df_F_S,df_M_S)\n\n\nUSA_USSR_medals.head()\n\n\n\n\n\n  \n    \n      \n      number_of_medals\n      Year\n      Sex\n      NOCSMALL\n    \n  \n  \n    \n      0\n      11\n      1896\n      M\n      EST\n    \n    \n      1\n      61\n      1896\n      M\n      ROW\n    \n    \n      2\n      19\n      1896\n      M\n      USA\n    \n    \n      3\n      29\n      1896\n      M\n      WES\n    \n    \n      4\n      2\n      1900\n      F\n      EST\n    \n  \n\n\n\n\n\nyrplot(USA_USSR_medals[USA_USSR_medals.Sex=='F'],whatplot= 'number_of_medals')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Number of medals'>\n\n\n\n\n\n\nyrplot(USA_USSR_medals[USA_USSR_medals.Sex=='M'],whatplot= 'number_of_medals')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Number of medals'>\n\n\n\n\n\n\nyrplot(USA_USSR_athletes[USA_USSR_athletes.Sex=='F'],whatplot= 'number_of_athletes')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Number of athletes'>\n\n\n\n\n\n\nyrplot(USA_USSR_athletes[USA_USSR_athletes.Sex=='M'],whatplot= 'number_of_athletes')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Number of athletes'>"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL.html#introduction",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL.html#introduction",
    "title": "Olympics data with SQL and pandas",
    "section": "Introduction",
    "text": "Introduction\nThis project looks to understand the changing nature of the Olympics and how it reflects changes in athletes, sporting activities, and global politics. The Olympic Games are considered the world’s foremost sports competition with more than 200 nations participating [1,2], and in Tokyo in 2020 there was a broadcast audience of more than 3 billion with estimates of 3 out of 4 people following the Olympics [3].\nSince it’s inception over 100 years ago many changes have occured. In global politics countries have split and unified, populations have changed and the power distribution across nations fluctuated. In society there have been changes in the rights and roles of women. Finally, in sport there has been a move from amateur atheletes to professionalism and a change in the popularity of different sports.\nDue to it’s global importance, the question this work looks to answer is if data on the Olympics reflect the changes that have occured in the world.\n1.“Overview of Olympic Games”. Encyclopaedia Britannica. Retrieved 4 June 2008\n2.Olympic Games- Wikipedia\n3.Tokyo 2020 audience & insights report December 2021"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL.html#the-data",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL.html#the-data",
    "title": "Olympics data with SQL and pandas",
    "section": "The Data",
    "text": "The Data\nThe most important part of any analysis is the data. In Olympics data with SQL and pandas- create the tables I present the data to be analysed and do some initial processing.\nThe main thing here is to seperate the data into useable tables for analysis, as summarised in the entity relationship diagram (ERD) below."
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL.html#analysis",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL.html#analysis",
    "title": "Olympics data with SQL and pandas",
    "section": "Analysis",
    "text": "Analysis\nBased on a brief analysis of the data three broad questions to be investigated were posed:\n\nWhat are the characteristics of athletes? How does this change with time, and can it be linked with societal or global changes?\nWhat countries do better at the Olympics? Is there a way to quantify this?\nWhat is the influence of a games being a home event?\n\nIn the following parts these are explore in more detail.\n\nAthlete Analysis\nI did some initial plots on the changes in the characteristics of athletes given in the data, height, weight and age, of athletes attending the Olympics by year (see below).\nFrom these plots I was really intrigued as to what may be the cause of these changes.\nMainly what was happening between 1960 and 1980 were there seemed to be changes in each of the parameters?\nMy initial thought was this could be related to some combination of - a switch from amateurs to professionals - the Cold War between USA and USSR - an after effect of WWII\nOlympics data with SQL and pandas- height weight and age\n\n\nNation Analysis\nDue to the global importance of the Olympics, in 2020 there was a broadcast audience of more than 3 billion, I was interested to explore whether countries with the most medals will reflect global politics. And to see if the countries with most influence get more medals.\nOlympics data with SQL and pandas- GDP and population\n\n\nGames Analysis\nIn this part the hypothesis considered is:\nAt a home Olympic games a nation will on average obtain more medals than at other games\n\nBut can we quantify this effect?\nAre there any residual effects before and after the games?\nWhat about a home continent games?\n\nOlympics data with SQL and pandas- home games"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL.html#presentation",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL.html#presentation",
    "title": "Olympics data with SQL and pandas",
    "section": "Presentation",
    "text": "Presentation\nTo present this data in a unified form the following presentation was produced.\nThis is a hypothetical presentation:\n\nWho\nThe audience is a fictional research group at Swansea University (UK) called the Sports History Group.\nThis group is a cross-departmental, working across the History and Sports Science department. The group consists of two lecturers (one in each department), three post doctoral researchers, five PhD students and three Masters students.\n\n\nWhy\nThe work I am presenting has overlap with several of the reserachers/students.\nThe main goal is a scoping exercise with one of the post doctoral researchers and the two lecturers who have identified a grant proposal. The Olympics commitee have put out a grant application. The aim of this is to produce a report on the influence the Olympics has had on Geo-Politics and on Athletes and Sport in general. With guidance on what the Olympics can do in the future to maintain and enhance its globally importance, and how it can positively impact Olympic athletes.\n\n\nWhat / How\nMore details are in the presentation"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createCountryDF.html#overview",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createCountryDF.html#overview",
    "title": "Olympics data with SQL and pandas- creating a country table",
    "section": "Overview",
    "text": "Overview\nThe country table needed extra analysis so I seperated it from the rest of the analysis.\nIt also requires importing some new data, which I will add here too\n\nimport pandas as pd\nfrom pandasql import sqldf\nimport matplotlib.pyplot as plt\nimport re \n\n\ndf= pd.read_csv(\"athlete_events.csv\")\ndf2=pd.read_csv(\"noc_regions.csv\")\n\nThe next line is just to add a unique ID for athletes when the data is split up later\n\ndf= df.reset_index()\ndf.rename(columns={'index':'event_athlete_ID','ID':'athlete_ID'},inplace=True)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      1\n      A Dijiang\n      M\n      24.0\n      180.0\n      80.0\n      China\n      CHN\n      1992 Summer\n      1992\n      Summer\n      Barcelona\n      Basketball\n      Basketball Men's Basketball\n      NaN\n    \n    \n      1\n      1\n      2\n      A Lamusi\n      M\n      23.0\n      170.0\n      60.0\n      China\n      CHN\n      2012 Summer\n      2012\n      Summer\n      London\n      Judo\n      Judo Men's Extra-Lightweight\n      NaN\n    \n    \n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      24.0\n      NaN\n      NaN\n      Denmark\n      DEN\n      1920 Summer\n      1920\n      Summer\n      Antwerpen\n      Football\n      Football Men's Football\n      NaN\n    \n    \n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      34.0\n      NaN\n      NaN\n      Denmark/Sweden\n      DEN\n      1900 Summer\n      1900\n      Summer\n      Paris\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      Gold\n    \n    \n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n  \n\n\n\n\n\ndf2.head()\n\n\n\n\n\n  \n    \n      \n      NOC\n      region\n      notes\n    \n  \n  \n    \n      0\n      AFG\n      Afghanistan\n      NaN\n    \n    \n      1\n      AHO\n      Curacao\n      Netherlands Antilles\n    \n    \n      2\n      ALB\n      Albania\n      NaN\n    \n    \n      3\n      ALG\n      Algeria\n      NaN\n    \n    \n      4\n      AND\n      Andorra\n      NaN\n    \n  \n\n\n\n\n\nWhat do we use to value to identify a nation\n\nprint('There are {} unique teams and {} unique NOCs in df.\\n     \\\nAnd {} unique NOC values, {} unique regions and {} unique notes in df2.'.format( \\\n    len(pd.unique(df.Team)),len(pd.unique(df.NOC)), \n    len(pd.unique(df2.region)),len(pd.unique(df2.region)),len(pd.unique(df2.notes)) ))\n\n\nThere are 1184 unique teams and 230 unique NOCs in df.\n     And 207 unique NOC values, 207 unique regions and 22 unique notes in df2.\n\n\n1184 Seems a lot of teams to consider, it may be best to stick with using NOC as a unique identifier for a country. We can then probably use regions as the name of the country.\nLet’s have a look at the values of teams,NOC and regions\n\nsqldf(\"SELECT                                \\\n         NOC,                                \\\n         Team,                               \\\n         count(*)                            \\\n       FROM                                  \\\n         df                                  \\\n       GROUP BY                              \\\n         Team, NOC                           \\\n       ORDER BY team DESC                    \\\n       LIMIT 30;\",locals())\n\n\n\n\n\n  \n    \n      \n      NOC\n      Team\n      count(*)\n    \n  \n  \n    \n      0\n      FIN\n      rn-2\n      5\n    \n    \n      1\n      BEL\n      Zut\n      3\n    \n    \n      2\n      ZIM\n      Zimbabwe\n      309\n    \n    \n      3\n      GRE\n      Zefyros\n      2\n    \n    \n      4\n      ZAM\n      Zambia\n      183\n    \n    \n      5\n      YUG\n      Yugoslavia-2\n      10\n    \n    \n      6\n      YUG\n      Yugoslavia-1\n      10\n    \n    \n      7\n      YUG\n      Yugoslavia\n      2558\n    \n    \n      8\n      SUI\n      Ylliam VIII\n      5\n    \n    \n      9\n      SUI\n      Ylliam VII\n      6\n    \n    \n      10\n      SUI\n      Ylliam II\n      5\n    \n    \n      11\n      GBR\n      Yeoman XII\n      3\n    \n    \n      12\n      GBR\n      Yeoman VII\n      3\n    \n    \n      13\n      RSA\n      Yeoman V\n      3\n    \n    \n      14\n      BAH\n      Yeoman\n      4\n    \n    \n      15\n      YEM\n      Yemen\n      32\n    \n    \n      16\n      MYA\n      Yangon\n      2\n    \n    \n      17\n      MEX\n      Xolotl\n      3\n    \n    \n      18\n      FIN\n      Xantippa\n      3\n    \n    \n      19\n      GBR\n      Wolseley-Siddeley-1\n      4\n    \n    \n      20\n      CAN\n      Winnipeg Shamrocks-1\n      12\n    \n    \n      21\n      CAN\n      Windor\n      2\n    \n    \n      22\n      NED\n      Willem-Six\n      3\n    \n    \n      23\n      ARG\n      Wiking\n      5\n    \n    \n      24\n      USA\n      Widgeon\n      2\n    \n    \n      25\n      FRA\n      Whitini Star\n      1\n    \n    \n      26\n      DEN\n      White Lady\n      3\n    \n    \n      27\n      JPN\n      Whisper\n      1\n    \n    \n      28\n      CAN\n      Whirlaway\n      2\n    \n    \n      29\n      USA\n      Western Rowing Club-3\n      6\n    \n  \n\n\n\n\nTeam in df seems to not reflect the country very well. e.g. Whisper is not a country but JPN probably represents Japan.\nSo the use of NOC seems to make sense\nNow let us consider the NOC, region and notes variables\n\nsqldf(\"SELECT                                \\\n         NOC,                                \\\n         Region,                             \\\n         Notes,                              \\\n         count(*)                            \\\n       FROM                                  \\\n         df2                                 \\\n       GROUP BY                              \\\n         NOC, Region, Notes                  \\\n       ORDER BY Region DESC                  \\\n       LIMIT 30;\",locals())\n\n\n\n\n\n  \n    \n      \n      NOC\n      region\n      notes\n      count(*)\n    \n  \n  \n    \n      0\n      RHO\n      Zimbabwe\n      None\n      1\n    \n    \n      1\n      ZIM\n      Zimbabwe\n      None\n      1\n    \n    \n      2\n      ZAM\n      Zambia\n      None\n      1\n    \n    \n      3\n      YAR\n      Yemen\n      North Yemen\n      1\n    \n    \n      4\n      YEM\n      Yemen\n      None\n      1\n    \n    \n      5\n      YMD\n      Yemen\n      South Yemen\n      1\n    \n    \n      6\n      ISV\n      Virgin Islands, US\n      Virgin Islands\n      1\n    \n    \n      7\n      IVB\n      Virgin Islands, British\n      None\n      1\n    \n    \n      8\n      VIE\n      Vietnam\n      None\n      1\n    \n    \n      9\n      VNM\n      Vietnam\n      None\n      1\n    \n    \n      10\n      VEN\n      Venezuela\n      None\n      1\n    \n    \n      11\n      VAN\n      Vanuatu\n      None\n      1\n    \n    \n      12\n      UZB\n      Uzbekistan\n      None\n      1\n    \n    \n      13\n      URU\n      Uruguay\n      None\n      1\n    \n    \n      14\n      UAE\n      United Arab Emirates\n      None\n      1\n    \n    \n      15\n      UKR\n      Ukraine\n      None\n      1\n    \n    \n      16\n      UGA\n      Uganda\n      None\n      1\n    \n    \n      17\n      USA\n      USA\n      None\n      1\n    \n    \n      18\n      GBR\n      UK\n      None\n      1\n    \n    \n      19\n      TKM\n      Turkmenistan\n      None\n      1\n    \n    \n      20\n      TUR\n      Turkey\n      None\n      1\n    \n    \n      21\n      TUN\n      Tunisia\n      None\n      1\n    \n    \n      22\n      TTO\n      Trinidad\n      Trinidad and Tobago\n      1\n    \n    \n      23\n      WIF\n      Trinidad\n      West Indies Federation\n      1\n    \n    \n      24\n      TGA\n      Tonga\n      None\n      1\n    \n    \n      25\n      TOG\n      Togo\n      None\n      1\n    \n    \n      26\n      TLS\n      Timor-Leste\n      None\n      1\n    \n    \n      27\n      THA\n      Thailand\n      None\n      1\n    \n    \n      28\n      TAN\n      Tanzania\n      None\n      1\n    \n    \n      29\n      TJK\n      Tajikistan\n      None\n      1\n    \n  \n\n\n\n\nNOC doesn’t look unique enough for us. For example, - Zimbabwe is RHO and ZIM and this probably just reflects a name change in the country - Yemen has 3 NOC values, presumably reflecting the unification that took place in 1990. Most of these differences are not that important to what I am looking at, where it would be better to have a broader description of a nation\nSo what I will do is - use the region tag as a unique identifier of a country - replace multiple NOC values of a single country with a single NOC value\nThe first step is to identify which regions have multiple NOC values. We can do this again in SQL by creating a new table\n\nd1=sqldf(\"SELECT                               \\\n            NOC,                               \\\n            region,                            \\\n            notes,                             \\\n            count(*)                           \\\n         FROM                                  \\\n            df2                                \\\n         GROUP BY                              \\\n            region                             \\\n         HAVING COUNT(*)>1                     \\\n         ORDER BY count(*) DESC;\",locals())\nd1\n\n\n\n\n\n  \n    \n      \n      NOC\n      region\n      notes\n      count(*)\n    \n  \n  \n    \n      0\n      FRG\n      Germany\n      None\n      4\n    \n    \n      1\n      YAR\n      Yemen\n      North Yemen\n      3\n    \n    \n      2\n      SCG\n      Serbia\n      Serbia and Montenegro\n      3\n    \n    \n      3\n      EUN\n      Russia\n      None\n      3\n    \n    \n      4\n      MAL\n      Malaysia\n      None\n      3\n    \n    \n      5\n      BOH\n      Czech Republic\n      Bohemia\n      3\n    \n    \n      6\n      ROT\n      None\n      Refugee Olympic Team\n      3\n    \n    \n      7\n      RHO\n      Zimbabwe\n      None\n      2\n    \n    \n      8\n      VIE\n      Vietnam\n      None\n      2\n    \n    \n      9\n      TTO\n      Trinidad\n      Trinidad and Tobago\n      2\n    \n    \n      10\n      SYR\n      Syria\n      None\n      2\n    \n    \n      11\n      CRT\n      Greece\n      Crete\n      2\n    \n    \n      12\n      CHN\n      China\n      None\n      2\n    \n    \n      13\n      CAN\n      Canada\n      None\n      2\n    \n    \n      14\n      ANZ\n      Australia\n      Australasia\n      2\n    \n  \n\n\n\n\nWe can then create a table to get - the country, - the new NOC value for each country - all the NOC values that correspond to that country\n\nd2=sqldf(\"SELECT                            \\\n            d1.NOC      AS new_NOC,         \\\n            df2.NOC     AS orig_NOC,        \\\n            df2.region,                     \\\n            df2.notes                       \\\n          FROM                              \\\n            d1                              \\\n          LEFT JOIN                         \\\n            df2                             \\\n          ON                                \\\n            d1.region=df2.region            \\\n          ORDER BY                          \\\n            df2.region DESC;\",locals())\nd2\n\n\n\n\n\n  \n    \n      \n      new_NOC\n      orig_NOC\n      region\n      notes\n    \n  \n  \n    \n      0\n      RHO\n      RHO\n      Zimbabwe\n      None\n    \n    \n      1\n      RHO\n      ZIM\n      Zimbabwe\n      None\n    \n    \n      2\n      YAR\n      YAR\n      Yemen\n      North Yemen\n    \n    \n      3\n      YAR\n      YEM\n      Yemen\n      None\n    \n    \n      4\n      YAR\n      YMD\n      Yemen\n      South Yemen\n    \n    \n      5\n      VIE\n      VIE\n      Vietnam\n      None\n    \n    \n      6\n      VIE\n      VNM\n      Vietnam\n      None\n    \n    \n      7\n      TTO\n      TTO\n      Trinidad\n      Trinidad and Tobago\n    \n    \n      8\n      TTO\n      WIF\n      Trinidad\n      West Indies Federation\n    \n    \n      9\n      SYR\n      SYR\n      Syria\n      None\n    \n    \n      10\n      SYR\n      UAR\n      Syria\n      United Arab Republic\n    \n    \n      11\n      SCG\n      SCG\n      Serbia\n      Serbia and Montenegro\n    \n    \n      12\n      SCG\n      SRB\n      Serbia\n      None\n    \n    \n      13\n      SCG\n      YUG\n      Serbia\n      Yugoslavia\n    \n    \n      14\n      EUN\n      EUN\n      Russia\n      None\n    \n    \n      15\n      EUN\n      RUS\n      Russia\n      None\n    \n    \n      16\n      EUN\n      URS\n      Russia\n      None\n    \n    \n      17\n      MAL\n      MAL\n      Malaysia\n      None\n    \n    \n      18\n      MAL\n      MAS\n      Malaysia\n      None\n    \n    \n      19\n      MAL\n      NBO\n      Malaysia\n      North Borneo\n    \n    \n      20\n      CRT\n      CRT\n      Greece\n      Crete\n    \n    \n      21\n      CRT\n      GRE\n      Greece\n      None\n    \n    \n      22\n      FRG\n      FRG\n      Germany\n      None\n    \n    \n      23\n      FRG\n      GDR\n      Germany\n      None\n    \n    \n      24\n      FRG\n      GER\n      Germany\n      None\n    \n    \n      25\n      FRG\n      SAA\n      Germany\n      None\n    \n    \n      26\n      BOH\n      BOH\n      Czech Republic\n      Bohemia\n    \n    \n      27\n      BOH\n      CZE\n      Czech Republic\n      None\n    \n    \n      28\n      BOH\n      TCH\n      Czech Republic\n      None\n    \n    \n      29\n      CHN\n      CHN\n      China\n      None\n    \n    \n      30\n      CHN\n      HKG\n      China\n      Hong Kong\n    \n    \n      31\n      CAN\n      CAN\n      Canada\n      None\n    \n    \n      32\n      CAN\n      NFL\n      Canada\n      Newfoundland\n    \n    \n      33\n      ANZ\n      ANZ\n      Australia\n      Australasia\n    \n    \n      34\n      ANZ\n      AUS\n      Australia\n      None\n    \n    \n      35\n      ROT\n      None\n      None\n      None\n    \n  \n\n\n\n\nAnd finally replace the values of NOC in df and df2 with the new values for countries with duplicate values\nEasier to do this with Python\n\nfor i,old_NOC in enumerate(d2.orig_NOC):\n    df.loc[df.NOC==old_NOC,'NOC']=d2.loc[i,'new_NOC']\n    df2.loc[df2.NOC==old_NOC,'NOC']=d2.loc[i,'new_NOC']\n    \n\n\n\nGDP data\nWikipedia was used to get data on population and GDP of different countries. The data was imported using Excel’s capability to give it a url to obtain the table, and saved as different tabs in the file CountryData.xlsx. For GDP I selected the World Bank Estimate.\n\nGDP data\nPopulation data\n\nWebsite urls correct as of 23/7/22\n\ndf_GDP = pd.read_excel('CountryData.xlsx',sheet_name=2)\n\ndf_GDP=df_GDP.drop(columns=['IMF[1][12] Estimate','IMF[1][12] Year','United Nations[13] Estimate','United Nations[13] Year','World Bank[14][15] Year'])\ndf_GDP=df_GDP.rename(columns={'World Bank[14][15] Estimate':'GDP','Country/Territory':'Country','UN Region':'Continent'},errors='raise')\n\ndf_GDP.head(10)\n\n\n\n\n\n  \n    \n      \n      Country\n      Continent\n      GDP\n    \n  \n  \n    \n      0\n      World\n      -\n      84,705,567\n    \n    \n      1\n      United States\n      Americas\n      20,936,600\n    \n    \n      2\n      China\n      Asia\n      14,722,731\n    \n    \n      3\n      Japan\n      Asia\n      4,975,415\n    \n    \n      4\n      Germany\n      Europe\n      3,806,060\n    \n    \n      5\n      India\n      Asia\n      2,622,984\n    \n    \n      6\n      United Kingdom\n      Europe\n      2,707,744\n    \n    \n      7\n      France\n      Europe\n      2,603,004\n    \n    \n      8\n      Canada\n      Americas\n      1,643,408\n    \n    \n      9\n      Italy\n      Europe\n      1,886,445\n    \n  \n\n\n\n\nmake column GDP an integer, and remove the comma\n\ndf_GDP['GDP']=[x.replace(',','') for x in df_GDP['GDP']]\n\ndf_GDP['GDP']=pd.to_numeric(df_GDP['GDP'],errors='coerce').fillna(0).astype('int')\n\nWe now need to match the names of countries from the data we have found on the internet with the Olympics data.\nA good example of this is United Kingdom, which can be named several ways (with slightly different meanings) including: UK, Great Britain, Great Britain, Great Britain and Northern Ireland, GB.\nThe function changeDF_country takes the imported dataframes and df2 as inputs and outputs the imported dataframes with corrected NOC and country values\n\nChecks whether country in imported df matches region in df\n\n\nIf so country doesn’t need to be changed and can provide matching NOC value\n\n\nIf not above then see if df2.notes matches the country\n\n\nIf so can return country and NOC matching the notes that match\n\n\nIf not aboves, try some name changes, like United States to USA\n\n\nThen return the matching NOC and country and NOC matching values\n\n\nNone of the above\n\n\nThen return country given and give NOC a name to show there was no match.\nPrint out the name of the country where no match was found. To see if missing anything big or obvious\n\n\ndef getNation(region_to_check):\n       \n    if region_to_check=='United States':\n        region_out = 'USA'\n    elif bool(re.search(r'Germany', region_to_check)):\n        region_out='Germany'\n    elif region_to_check=='United Kingdom':\n        region_out = 'UK'\n    elif region_to_check=='Soviet Union':\n        region_out='Russia'\n    else:\n        region_out=region_to_check\n        print('nothing found for {}'.format(region_out))\n    \n    return region_out\n\ndef changeDF_country(df__,df2):\n    xALL,nocALL=[],[]\n    for i in range(len(df__)):\n        country_check = df__.loc[i,'Country']\n#         print(i,country_check)\n        boolCountry=df2.region==country_check\n        x=df2[boolCountry].region\n        \n        try:\n            x=str(x.iloc[0])\n            df2.loc[boolCountry,'region']=x\n        except:\n            if len(x)<1:\n                boolCountry=df2.notes==df__.loc[i,'Country']\n                x=df2[boolCountry].region\n                try:\n                    x=str(x.iloc[0])\n                    df2.loc[boolCountry,'region']=x\n                except:\n                    if len(x)<1:\n                        country_check=getNation(df__.loc[i,'Country'])\n                        boolCountry=df2.region==country_check\n                        x=df2[boolCountry].region\n                        try:\n                            x=str(x.iloc[0])\n                            df2.loc[boolCountry,'region']=x\n                        except:\n                            x=country_check\n        xALL.append(x)\n        try:\n            nocALL.append(df2[boolCountry].NOC.iloc[0])\n        except:\n            nocALL.append('---')\n            \n#         print('x= ',x)\n#         print('-------------------')\n#         if i==42:\n#             break\n#     print(nocALL)\n    try:\n        df__.insert(1,'NOC',nocALL)\n        df__.insert(1,'Nation',xALL)#,'Nation',xALL})\n    except:\n        print('done allready')\n    return df__\n        \n\n\ndf_GDP=changeDF_country(df_GDP,df2)\n\nnothing found for World\nnothing found for DR Congo\nnothing found for Bolivia\nnothing found for Macau\nnothing found for Congo\nnothing found for North Macedonia\nnothing found for New Caledonia\nnothing found for French Polynesia\nnothing found for Eswatini\nnothing found for Greenland\nnothing found for Curaçao\nnothing found for East Timor\nnothing found for Zanzibar\nnothing found for British Virgin Islands\nnothing found for Northern Mariana Islands\nnothing found for Saint Kitts and Nevis\nnothing found for Saint Vincent and the Grenadines\nnothing found for Sint Maarten\nnothing found for São Tomé and Príncipe\nnothing found for Anguilla\nnothing found for Montserrat\n\n\n\n\nPopulation table\nThe same thing as above but for the population data\n\ndf_population = pd.read_excel('CountryData.xlsx',sheet_name=0)\ndf_population.head(5)\n\n\n\n\n\n  \n    \n      \n      Rank\n      Country / Dependency\n      UN Region\n      Population\n      Percentage of the world\n      Date\n      Source (official or from the United Nations)\n      Notes\n      Column9\n    \n  \n  \n    \n      0\n      –\n      World\n      NaN\n      7965207000\n      1.0000\n      2022-07-20\n      UN projection[2]\n      NaN\n      NaN\n    \n    \n      1\n      1\n      China\n      Asia\n      1412600000\n      0.1770\n      2021-12-31\n      National annual estimate\n      The population figure refers to mainland China...\n      NaN\n    \n    \n      2\n      2\n      India\n      Asia\n      1373761000\n      0.1720\n      2022-03-01\n      Annual national estimate\n      The figure includes the population of Indian-a...\n      NaN\n    \n    \n      3\n      3\n      United States\n      Americas\n      332906919\n      0.0418\n      2022-07-20\n      National population clock\n      The figure includes the 50 states and the Dist...\n      NaN\n    \n    \n      4\n      4\n      Indonesia\n      Asia\n      272248500\n      0.0342\n      2021-07-01\n      National annual estimate\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n\ndf_population.drop(columns=['Percentage of the world','Date','Source (official or from the United Nations)','Column9','Notes'],inplace=True)\ndf_population=df_population.rename(columns={'Country / Dependency':'Country','UN Region':'Continent'},errors='raise')\n\ndf_population\n\n\n\n\n\n  \n    \n      \n      Rank\n      Country\n      Continent\n      Population\n    \n  \n  \n    \n      0\n      –\n      World\n      NaN\n      7965207000\n    \n    \n      1\n      1\n      China\n      Asia\n      1412600000\n    \n    \n      2\n      2\n      India\n      Asia\n      1373761000\n    \n    \n      3\n      3\n      United States\n      Americas\n      332906919\n    \n    \n      4\n      4\n      Indonesia\n      Asia\n      272248500\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      237\n      –\n      Niue\n      Oceania\n      1549\n    \n    \n      238\n      –\n      Tokelau (New Zealand)\n      Oceania\n      1501\n    \n    \n      239\n      195\n      Vatican City\n      Europe\n      825\n    \n    \n      240\n      –\n      Cocos (Keeling) Islands (Australia)\n      Oceania\n      573\n    \n    \n      241\n      –\n      Pitcairn Islands (United Kingdom)\n      Oceania\n      40\n    \n  \n\n242 rows × 4 columns\n\n\n\n\ndf_population=changeDF_country(df_population,df2)\n\nnothing found for World\nnothing found for DR Congo\nnothing found for Bolivia\nnothing found for Hong Kong (China)\nnothing found for Congo\nnothing found for Puerto Rico (United States)\nnothing found for North Macedonia\nnothing found for East Timor\nnothing found for Eswatini\nnothing found for Macau (China)\nnothing found for Western Sahara\nnothing found for Northern Cyprus\nnothing found for Transnistria\nnothing found for French Polynesia (France)\nnothing found for New Caledonia (France)\nnothing found for Abkhazia\nnothing found for São Tomé and Príncipe\nnothing found for Guam (United States)\nnothing found for Curaçao (Netherlands)\nnothing found for Artsakh\nnothing found for Aruba (Netherlands)\nnothing found for Saint Vincent and the Grenadines\nnothing found for Jersey (British Crown Dependency)\nnothing found for U.S. Virgin Islands (United States)\nnothing found for Isle of Man (British Crown Dependency)\nnothing found for Cayman Islands (United Kingdom)\nnothing found for Bermuda (United Kingdom)\nnothing found for Guernsey (British Crown Dependency)\nnothing found for Greenland (Denmark)\nnothing found for Saint Kitts and Nevis\nnothing found for Faroe Islands (Denmark)\nnothing found for South Ossetia\nnothing found for American Samoa (United States)\nnothing found for Northern Mariana Islands (United States)\nnothing found for Turks and Caicos Islands (United Kingdom)\nnothing found for Sint Maarten (Netherlands)\nnothing found for Gibraltar (United Kingdom)\nnothing found for Saint Martin (France)\nnothing found for Åland (Finland)\nnothing found for British Virgin Islands (United Kingdom)\nnothing found for Anguilla (United Kingdom)\nnothing found for Wallis and Futuna (France)\nnothing found for Saint Barthélemy (France)\nnothing found for Saint Helena, Ascension and Tristan da Cunha (United Kingdom)\nnothing found for Saint Pierre and Miquelon (France)\nnothing found for Montserrat (United Kingdom)\nnothing found for Falkland Islands (United Kingdom)\nnothing found for Christmas Island (Australia)\nnothing found for Norfolk Island (Australia)\nnothing found for Niue\nnothing found for Tokelau (New Zealand)\nnothing found for Vatican City\nnothing found for Cocos (Keeling) Islands (Australia)\nnothing found for Pitcairn Islands (United Kingdom)\n\n\n\n\nCombine everything for one country table\nNow we merge all data sets together. I’ll use pandas but this is the same as a SQL left outer join. Because we want to keep all the NOC values in df2 we start with that then join each one after\n\ndf_country=[]\ndf_country=df2.merge(df_population,left_on='NOC',right_on='NOC')\n\ndf_country=df_country.merge(df_GDP,left_on='Nation',right_on='Nation')\ndf_country.drop(columns=['Continent_y','Country_x','Country_y','NOC_y','Rank','notes','region'],inplace=True)\ndf_country=df_country.rename(columns={'NOC_x':'NOC','Continent_x':'Continent'},errors='raise')\n\n# We have multiple versions of Nation so we just take the max one\ndf_country = df_country.groupby('NOC').max()\n\n\ndf_country.to_csv('country')\n\ndf.to_csv(\"athlete_events.csv\")\ndf2.to_csv(\"noc_regions.csv\")"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#introduction",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#introduction",
    "title": "Olympics data with SQL and pandas- create the tables",
    "section": "Introduction",
    "text": "Introduction\nTwo csv files (representing two different tables) were imported to databricks.\nThe main table (athlete_events) consists of 270,000 rows, whereas the unique names in the table are 135,000, or around half the total.\n\nLots of columns and lots that are objects,\n\nso we want to refine this by reducing columns and making it an integer or something smaller than object if possible\n\nThere are some NaN values, particularly for height/weight at earlier games and also for medals\nAn athlete can be represented in several rows if they do multiple events or at different games (e.g. Christine Jacoba Aaftink). So we may want a seperate ID that incorporate the athlete and the event/games that is unique\nThe TEAM, NOC we only want one identifier and a seperate table for countries\n\nThe first step was to split the table up. - First the users are split up based on whether they are male or female and whether they are in the summer or winter games. So split into 4. - Secondly not all data is needed for these athletes table, so instead of 15 columns this is reduced to 9 - Thirdly, the size of these athlete table is reduced by replacing several variables from string to int to reduce the size. Since for example, there is only a limited number of events.\nAn entity relationship diagram (ERD) of the tables described above was developed as shown below.\nThose highlighted in blue and light blue would require additional data, the darkness of blue representing how much new data is needed.\nLucid Chart was used to produce the ERD\n\nN.B. Most of these are steps not really necessary for this dataset, but I wanted to practice SQL (and pandas). If this was a real world problem I would weigh up the benefits of the splitting in terms of my time and computation to see if it was really necessary.\n\nCreating a country table\nIn a separate page (https://thomashsimm.com/sql/pandas/python/olympics/2022/07/29/OlympicsSQL_createCountryDF.html) I show how I created the country table.\nI also made some slight changes to the two main DataFrames df2 and df. Basically just to change the country label and add unique athlete and athlete + event ids\ndf= df.reset_index()\ndf.rename(columns={'index':'event_athlete_ID','ID':'athlete_ID'},inplace=True)\nThe main part is to get rid of some duplicate NOC values, mostly correct but will not work in some regards e.g. China and Hong Kong.\n\n# This gets region (or countries) which are repeated with different NOC values\nd1=sqldf(\"SELECT                              \\\n       NOC, region,notes,count(*)             \\\n       FROM df2                               \\\n       GROUP BY region                        \\\n       HAVING COUNT(*)>1                      \\\n       ORDER BY count(*) DESC;\",locals())\n\n# this then creates a table with one NOC per region and the original NOC values\n# we'll use the new NOC (one per region) a the new index\nd2=sqldf(\"SELECT                              \\\n       d1.NOC as new_NOC,df2.NOC orig_NOC,df2.region,df2.notes             \\\n       FROM d1                                \\\n       LEFT JOIN df2                          \\\n       ON d1.region=df2.region                \\\n      ORDER BY df2.region DESC;\",locals())\n\n\n# then replace the regions with several NOC values with the new one\nfor i,old_NOC in enumerate(d2.orig_NOC):\n    df.loc[df.NOC==old_NOC,'NOC']=d2.loc[i,'new_NOC']\n    df2.loc[df2.NOC==old_NOC,'NOC']=d2.loc[i,'new_NOC']\n\n\ndf= pd.read_csv(\"athlete_events.csv\")\ntry:\n    df.drop(columns='Unnamed: 0',inplace=True)\nexcept:\n    pass\ndf2=pd.read_csv(\"noc_regions.csv\")"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#look-at-the-data",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#look-at-the-data",
    "title": "Olympics data with SQL and pandas- create the tables",
    "section": "Look at the data",
    "text": "Look at the data\n\n# !pip install pandasql\nimport pandas as pd\nfrom pandasql import sqldf\nimport matplotlib.pyplot as plt\nimport re \n\ndf\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      1\n      A Dijiang\n      M\n      24.0\n      180.0\n      80.0\n      China\n      CHN\n      1992 Summer\n      1992\n      Summer\n      Barcelona\n      Basketball\n      Basketball Men's Basketball\n      NaN\n    \n    \n      1\n      1\n      2\n      A Lamusi\n      M\n      23.0\n      170.0\n      60.0\n      China\n      CHN\n      2012 Summer\n      2012\n      Summer\n      London\n      Judo\n      Judo Men's Extra-Lightweight\n      NaN\n    \n    \n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      24.0\n      NaN\n      NaN\n      Denmark\n      DEN\n      1920 Summer\n      1920\n      Summer\n      Antwerpen\n      Football\n      Football Men's Football\n      NaN\n    \n    \n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      34.0\n      NaN\n      NaN\n      Denmark/Sweden\n      DEN\n      1900 Summer\n      1900\n      Summer\n      Paris\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      Gold\n    \n    \n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      271111\n      271111\n      135569\n      Andrzej ya\n      M\n      29.0\n      179.0\n      89.0\n      Poland-1\n      POL\n      1976 Winter\n      1976\n      Winter\n      Innsbruck\n      Luge\n      Luge Mixed (Men)'s Doubles\n      NaN\n    \n    \n      271112\n      271112\n      135570\n      Piotr ya\n      M\n      27.0\n      176.0\n      59.0\n      Poland\n      POL\n      2014 Winter\n      2014\n      Winter\n      Sochi\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Individual\n      NaN\n    \n    \n      271113\n      271113\n      135570\n      Piotr ya\n      M\n      27.0\n      176.0\n      59.0\n      Poland\n      POL\n      2014 Winter\n      2014\n      Winter\n      Sochi\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Team\n      NaN\n    \n    \n      271114\n      271114\n      135571\n      Tomasz Ireneusz ya\n      M\n      30.0\n      185.0\n      96.0\n      Poland\n      POL\n      1998 Winter\n      1998\n      Winter\n      Nagano\n      Bobsleigh\n      Bobsleigh Men's Four\n      NaN\n    \n    \n      271115\n      271115\n      135571\n      Tomasz Ireneusz ya\n      M\n      34.0\n      185.0\n      96.0\n      Poland\n      POL\n      2002 Winter\n      2002\n      Winter\n      Salt Lake City\n      Bobsleigh\n      Bobsleigh Men's Four\n      NaN\n    \n  \n\n271116 rows × 16 columns\n\n\n\n\ndf.dtypes\n\nevent_athlete_ID      int64\nathlete_ID            int64\nName                 object\nSex                  object\nAge                 float64\nHeight              float64\nWeight              float64\nTeam                 object\nNOC                  object\nGames                object\nYear                  int64\nSeason               object\nCity                 object\nSport                object\nEvent                object\nMedal                object\ndtype: object\n\n\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      athlete_ID\n      Age\n      Height\n      Weight\n      Year\n    \n  \n  \n    \n      count\n      271116.000000\n      271116.000000\n      261642.000000\n      210945.000000\n      208241.000000\n      271116.000000\n    \n    \n      mean\n      135557.500000\n      68248.954396\n      25.556898\n      175.338970\n      70.702393\n      1978.378480\n    \n    \n      std\n      78264.592128\n      39022.286345\n      6.393561\n      10.518462\n      14.348020\n      29.877632\n    \n    \n      min\n      0.000000\n      1.000000\n      10.000000\n      127.000000\n      25.000000\n      1896.000000\n    \n    \n      25%\n      67778.750000\n      34643.000000\n      21.000000\n      168.000000\n      60.000000\n      1960.000000\n    \n    \n      50%\n      135557.500000\n      68205.000000\n      24.000000\n      175.000000\n      70.000000\n      1988.000000\n    \n    \n      75%\n      203336.250000\n      102097.250000\n      28.000000\n      183.000000\n      79.000000\n      2002.000000\n    \n    \n      max\n      271115.000000\n      135571.000000\n      97.000000\n      226.000000\n      214.000000\n      2016.000000"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#create-all_athletes-table",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#create-all_athletes-table",
    "title": "Olympics data with SQL and pandas- create the tables",
    "section": "Create all_athletes table",
    "text": "Create all_athletes table\nBecause we are splitting the athlete data based on Summer/Winter and Male/Female we need a folder to be able to join or access different parts of the individual athlete tables.\n\ndf= df.reset_index()\ndf.rename(columns={'index':'event_athlete_ID','ID':'athlete_ID'},inplace=True)\ndf.head(10)\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      0\n      1\n      A Dijiang\n      M\n      24.0\n      180.0\n      80.0\n      China\n      CHN\n      1992 Summer\n      1992\n      Summer\n      Barcelona\n      Basketball\n      Basketball Men's Basketball\n      NaN\n    \n    \n      1\n      1\n      1\n      2\n      A Lamusi\n      M\n      23.0\n      170.0\n      60.0\n      China\n      CHN\n      2012 Summer\n      2012\n      Summer\n      London\n      Judo\n      Judo Men's Extra-Lightweight\n      NaN\n    \n    \n      2\n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      24.0\n      NaN\n      NaN\n      Denmark\n      DEN\n      1920 Summer\n      1920\n      Summer\n      Antwerpen\n      Football\n      Football Men's Football\n      NaN\n    \n    \n      3\n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      34.0\n      NaN\n      NaN\n      Denmark/Sweden\n      DEN\n      1900 Summer\n      1900\n      Summer\n      Paris\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      Gold\n    \n    \n      4\n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      5\n      5\n      5\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n    \n      6\n      6\n      6\n      5\n      Christine Jacoba Aaftink\n      F\n      25.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1992 Winter\n      1992\n      Winter\n      Albertville\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      7\n      7\n      7\n      5\n      Christine Jacoba Aaftink\n      F\n      25.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1992 Winter\n      1992\n      Winter\n      Albertville\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n    \n      8\n      8\n      8\n      5\n      Christine Jacoba Aaftink\n      F\n      27.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1994 Winter\n      1994\n      Winter\n      Lillehammer\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      9\n      9\n      9\n      5\n      Christine Jacoba Aaftink\n      F\n      27.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1994 Winter\n      1994\n      Winter\n      Lillehammer\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n  \n\n\n\n\n\ndf_all_athletes=df[['event_athlete_ID','athlete_ID','Name','Sex','Season']]\ndf_all_athletes                    \n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      athlete_ID\n      Name\n      Sex\n      Season\n    \n  \n  \n    \n      0\n      0\n      0\n      1\n      A Dijiang\n      M\n      Summer\n    \n    \n      1\n      1\n      1\n      2\n      A Lamusi\n      M\n      Summer\n    \n    \n      2\n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      Summer\n    \n    \n      3\n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      Summer\n    \n    \n      4\n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      Winter\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      271111\n      271111\n      271111\n      135569\n      Andrzej ya\n      M\n      Winter\n    \n    \n      271112\n      271112\n      271112\n      135570\n      Piotr ya\n      M\n      Winter\n    \n    \n      271113\n      271113\n      271113\n      135570\n      Piotr ya\n      M\n      Winter\n    \n    \n      271114\n      271114\n      271114\n      135571\n      Tomasz Ireneusz ya\n      M\n      Winter\n    \n    \n      271115\n      271115\n      271115\n      135571\n      Tomasz Ireneusz ya\n      M\n      Winter\n    \n  \n\n271116 rows × 6 columns"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#creating-an-events-table",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#creating-an-events-table",
    "title": "Olympics data with SQL and pandas- create the tables",
    "section": "Creating an Events Table",
    "text": "Creating an Events Table\nIn this table the individual events are displayed. e.g. 100m Mens Sprint Athletics or Womens Football\n\nprint(\"There are {} unique sports and {} unique events \".format(len(pd.unique(df.Sport)), len(pd.unique(df.Event))))\n\nThere are 66 unique sports and 765 unique events \n\n\nBecause of the way that events are named they won’t be duplicated, e.g. 400m breaststroke swimming will be different from 400m athletics running because the name is prefixed with Athletics Women, Swimming Men etc\nInstead of using one hot encoding (get_dummies for pandas as done with medals) we want a different number for each unique event in one column. To do this we can use factorize\naa=pd.factorize(df.ColumnCheck)\nwill give us a variable where - aa[0] is a list of numbers of length of rows in df, where each value represents a different event - aa[1] is then a list of the events of length of the unique events, aa[1][0] is event = 0, aa[1][1] is event = 1 etc - so below aa[1][0] = ‘Basketball Men’s Basketball’ and each row in the df with this event will have a 0 in aa[0]\n\nevent_details=pd.factorize(df.Event)\nevent_details[1][0:100], event_details[0][1:10]\n\n(Index(['Basketball Men's Basketball', 'Judo Men's Extra-Lightweight',\n        'Football Men's Football', 'Tug-Of-War Men's Tug-Of-War',\n        'Speed Skating Women's 500 metres',\n        'Speed Skating Women's 1,000 metres',\n        'Cross Country Skiing Men's 10 kilometres',\n        'Cross Country Skiing Men's 50 kilometres',\n        'Cross Country Skiing Men's 10/15 kilometres Pursuit',\n        'Cross Country Skiing Men's 4 x 10 kilometres Relay',\n        'Cross Country Skiing Men's 30 kilometres',\n        'Athletics Women's 100 metres',\n        'Athletics Women's 4 x 100 metres Relay', 'Ice Hockey Men's Ice Hockey',\n        'Swimming Men's 400 metres Freestyle', 'Badminton Men's Singles',\n        'Sailing Women's Windsurfer', 'Biathlon Women's 7.5 kilometres Sprint',\n        'Swimming Men's 200 metres Breaststroke',\n        'Swimming Men's 400 metres Breaststroke',\n        'Gymnastics Men's Individual All-Around',\n        'Gymnastics Men's Team All-Around', 'Gymnastics Men's Floor Exercise',\n        'Gymnastics Men's Horse Vault', 'Gymnastics Men's Parallel Bars',\n        'Gymnastics Men's Horizontal Bar', 'Gymnastics Men's Rings',\n        'Gymnastics Men's Pommelled Horse', 'Athletics Men's Shot Put',\n        'Art Competitions Mixed Sculpturing, Unknown Event',\n        'Alpine Skiing Men's Downhill', 'Alpine Skiing Men's Super G',\n        'Alpine Skiing Men's Giant Slalom', 'Alpine Skiing Men's Slalom',\n        'Alpine Skiing Men's Combined', 'Handball Women's Handball',\n        'Weightlifting Women's Super-Heavyweight',\n        'Wrestling Men's Light-Heavyweight, Greco-Roman',\n        'Speed Skating Men's 500 metres', 'Speed Skating Men's 1,500 metres',\n        'Gymnastics Men's Team All-Around, Free System', 'Luge Women's Singles',\n        'Water Polo Men's Water Polo', 'Sailing Mixed Three Person Keelboat',\n        'Hockey Women's Hockey', 'Rowing Men's Lightweight Double Sculls',\n        'Athletics Men's Pole Vault', 'Athletics Men's High Jump',\n        'Sailing Men's Two Person Dinghy', 'Athletics Men's 1,500 metres',\n        'Bobsleigh Men's Four', 'Swimming Men's 100 metres Butterfly',\n        'Swimming Men's 200 metres Butterfly',\n        'Swimming Men's 4 x 100 metres Medley Relay',\n        'Football Women's Football', 'Fencing Men's Foil, Individual',\n        'Fencing Men's epee, Individual', 'Fencing Men's epee, Team',\n        'Speed Skating Men's 5,000 metres', 'Speed Skating Men's 10,000 metres',\n        'Sailing Mixed 8 metres', 'Equestrianism Mixed Jumping, Individual',\n        'Cross Country Skiing Men's 15 kilometres',\n        'Shooting Men's Small-Bore Rifle, Prone, 50 metres',\n        'Shooting Men's Rapid-Fire Pistol, 25 metres', 'Shooting Men's Trap',\n        'Athletics Men's 4 x 100 metres Relay', 'Athletics Men's Long Jump',\n        'Boxing Men's Light-Welterweight', 'Athletics Women's Javelin Throw',\n        'Wrestling Men's Heavyweight, Freestyle', 'Taekwondo Men's Flyweight',\n        'Boxing Men's Heavyweight', 'Athletics Men's 5,000 metres',\n        'Cycling Men's Road Race, Individual', 'Cycling Men's Road Race, Team',\n        'Weightlifting Men's Lightweight', 'Weightlifting Men's Middleweight',\n        'Rowing Men's Coxless Pairs', 'Judo Men's Half-Middleweight',\n        'Taekwondo Women's Flyweight', 'Boxing Men's Flyweight',\n        'Basketball Women's Basketball', 'Diving Men's Platform',\n        'Canoeing Men's Canadian Doubles, 500 metres',\n        'Canoeing Men's Canadian Doubles, 1,000 metres',\n        'Canoeing Men's Kayak Fours, 1,000 metres', 'Handball Men's Handball',\n        'Rowing Women's Coxless Pairs', 'Boxing Men's Middleweight',\n        'Judo Men's Lightweight', 'Boxing Men's Featherweight',\n        'Tennis Men's Doubles', 'Shooting Mixed Skeet',\n        'Wrestling Men's Featherweight, Freestyle',\n        'Sailing Mixed Two Person Heavyweight Dinghy',\n        'Athletics Women's Shot Put', 'Rowing Men's Coxed Eights',\n        'Cycling Women's Sprint', 'Cycling Women's 500 metres Time Trial'],\n       dtype='object'),\n array([1, 2, 3, 4, 5, 4, 5, 4, 5], dtype=int64))\n\n\n\ndf.insert(2,'event_id',event_details[0])\ndf.head(10)\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      0\n      0\n      1\n      A Dijiang\n      M\n      24.0\n      180.0\n      80.0\n      China\n      CHN\n      1992 Summer\n      1992\n      Summer\n      Barcelona\n      Basketball\n      Basketball Men's Basketball\n      NaN\n    \n    \n      1\n      1\n      1\n      1\n      2\n      A Lamusi\n      M\n      23.0\n      170.0\n      60.0\n      China\n      CHN\n      2012 Summer\n      2012\n      Summer\n      London\n      Judo\n      Judo Men's Extra-Lightweight\n      NaN\n    \n    \n      2\n      2\n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      24.0\n      NaN\n      NaN\n      Denmark\n      DEN\n      1920 Summer\n      1920\n      Summer\n      Antwerpen\n      Football\n      Football Men's Football\n      NaN\n    \n    \n      3\n      3\n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      34.0\n      NaN\n      NaN\n      Denmark/Sweden\n      DEN\n      1900 Summer\n      1900\n      Summer\n      Paris\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      Gold\n    \n    \n      4\n      4\n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      5\n      5\n      5\n      5\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n    \n      6\n      6\n      6\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      25.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1992 Winter\n      1992\n      Winter\n      Albertville\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      7\n      7\n      7\n      5\n      5\n      Christine Jacoba Aaftink\n      F\n      25.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1992 Winter\n      1992\n      Winter\n      Albertville\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n    \n      8\n      8\n      8\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      27.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1994 Winter\n      1994\n      Winter\n      Lillehammer\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      9\n      9\n      9\n      5\n      5\n      Christine Jacoba Aaftink\n      F\n      27.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1994 Winter\n      1994\n      Winter\n      Lillehammer\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n  \n\n\n\n\n\nevent_details=pd.factorize(df.Event)\ndf_event = pd.DataFrame(event_details[1])\ndf_event\n\n\n\n\n\n  \n    \n      \n      0\n    \n  \n  \n    \n      0\n      Basketball Men's Basketball\n    \n    \n      1\n      Judo Men's Extra-Lightweight\n    \n    \n      2\n      Football Men's Football\n    \n    \n      3\n      Tug-Of-War Men's Tug-Of-War\n    \n    \n      4\n      Speed Skating Women's 500 metres\n    \n    \n      ...\n      ...\n    \n    \n      760\n      Weightlifting Men's All-Around Dumbbell Contest\n    \n    \n      761\n      Archery Men's Au Chapelet, 33 metres\n    \n    \n      762\n      Archery Men's Au Cordon Dore, 33 metres\n    \n    \n      763\n      Archery Men's Target Archery, 28 metres, Indiv...\n    \n    \n      764\n      Aeronautics Mixed Aeronautics\n    \n  \n\n765 rows × 1 columns\n\n\n\n\n\ndf_event = df[['Sport','Event','Sex','Season']]\n\nevent_details=pd.factorize(df.Sport)\ndf_event.insert(0,'sport_id',event_details[0])\n\nevent_details=pd.factorize(df.Event)\ndf_event.insert(0,'event_id',event_details[0])\n\n\ndf_event\n\n\n\n\n\n  \n    \n      \n      event_id\n      sport_id\n      Sport\n      Event\n      Sex\n      Season\n    \n  \n  \n    \n      0\n      0\n      0\n      Basketball\n      Basketball Men's Basketball\n      M\n      Summer\n    \n    \n      1\n      1\n      1\n      Judo\n      Judo Men's Extra-Lightweight\n      M\n      Summer\n    \n    \n      2\n      2\n      2\n      Football\n      Football Men's Football\n      M\n      Summer\n    \n    \n      3\n      3\n      3\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      M\n      Summer\n    \n    \n      4\n      4\n      4\n      Speed Skating\n      Speed Skating Women's 500 metres\n      F\n      Winter\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      271111\n      461\n      18\n      Luge\n      Luge Mixed (Men)'s Doubles\n      M\n      Winter\n    \n    \n      271112\n      418\n      48\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Individual\n      M\n      Winter\n    \n    \n      271113\n      419\n      48\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Team\n      M\n      Winter\n    \n    \n      271114\n      50\n      22\n      Bobsleigh\n      Bobsleigh Men's Four\n      M\n      Winter\n    \n    \n      271115\n      50\n      22\n      Bobsleigh\n      Bobsleigh Men's Four\n      M\n      Winter\n    \n  \n\n271116 rows × 6 columns\n\n\n\n\ndf_event = df_event.drop_duplicates().reset_index(drop=True)\ndf_event#[df_event.Sex=='F'].head(30)\n\n\n\n\n\n  \n    \n      \n      event_id\n      sport_id\n      Sport\n      Event\n      Sex\n      Season\n    \n  \n  \n    \n      0\n      0\n      0\n      Basketball\n      Basketball Men's Basketball\n      M\n      Summer\n    \n    \n      1\n      1\n      1\n      Judo\n      Judo Men's Extra-Lightweight\n      M\n      Summer\n    \n    \n      2\n      2\n      2\n      Football\n      Football Men's Football\n      M\n      Summer\n    \n    \n      3\n      3\n      3\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      M\n      Summer\n    \n    \n      4\n      4\n      4\n      Speed Skating\n      Speed Skating Women's 500 metres\n      F\n      Winter\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      824\n      221\n      10\n      Sailing\n      Sailing Mixed 7 metres\n      F\n      Summer\n    \n    \n      825\n      333\n      10\n      Sailing\n      Sailing Mixed 6 metres\n      F\n      Summer\n    \n    \n      826\n      764\n      65\n      Aeronautics\n      Aeronautics Mixed Aeronautics\n      M\n      Summer\n    \n    \n      827\n      677\n      13\n      Art Competitions\n      Art Competitions Mixed Sculpturing, Medals And...\n      F\n      Summer\n    \n    \n      828\n      648\n      13\n      Art Competitions\n      Art Competitions Mixed Unknown Event\n      F\n      Summer\n    \n  \n\n829 rows × 6 columns\n\n\n\n\nAn additional columns in event_table\nLets add a column representing if the sport is a team sport or individual. We can’t do this on the unique members of a team in that event because the team can have multiple members in an individual event. Instead, we can look for how many people took the gold medal. Should work for most circumstances as the gold shouldn’t be shared- so if 2 people won gold it should represent a team sport of 2 people.\nThis is a little convoluted so I’ll do it in two steps in SQL. One way to calculate and one to join this new table back in with df_event\n\ndf_event_temp=sqldf(\"SELECT                   \\\n      event_id,event,num_athletes    \\\n      FROM                                    \\\n      (SELECT                                 \\\n          event,                              \\\n          event_id,                           \\\n          COUNT(*)    as num_athletes         \\\n      FROM df                                 \\\n      WHERE Medal='Gold'                      \\\n      GROUP BY Team, event_id, Games          \\\n      ORDER BY event_id                       \\\n      )                                       \\\n      GROUP BY event_id                       \\\n                    ;\",   locals())                               \n\ndf_event_temp\n\n\n\n\n\n  \n    \n      \n      event_id\n      event\n      num_athletes\n    \n  \n  \n    \n      0\n      0\n      Basketball Men's Basketball\n      12\n    \n    \n      1\n      1\n      Judo Men's Extra-Lightweight\n      1\n    \n    \n      2\n      2\n      Football Men's Football\n      16\n    \n    \n      3\n      3\n      Tug-Of-War Men's Tug-Of-War\n      6\n    \n    \n      4\n      4\n      Speed Skating Women's 500 metres\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      745\n      760\n      Weightlifting Men's All-Around Dumbbell Contest\n      1\n    \n    \n      746\n      761\n      Archery Men's Au Chapelet, 33 metres\n      1\n    \n    \n      747\n      762\n      Archery Men's Au Cordon Dore, 33 metres\n      1\n    \n    \n      748\n      763\n      Archery Men's Target Archery, 28 metres, Indiv...\n      1\n    \n    \n      749\n      764\n      Aeronautics Mixed Aeronautics\n      1\n    \n  \n\n750 rows × 3 columns\n\n\n\n\ndf_event_temp      = sqldf(\"SELECT                                \\\n                      d.event_id,                            \\\n                      d.sport_id,                            \\\n                      d.Sport,                               \\\n                      d.Event,                               \\\n                      d.Sex,                                 \\\n                      d.Season,                              \\\n                      t.num_athletes                         \\\n                FROM df_event  as d                          \\\n                LEFT JOIN                                    \\\n                    df_event_temp  as t                      \\\n                ON                                           \\\n                    t.event_id=d.event_id                    \\\n                ORDER BY d.event_id                          \\\n                      ;\",locals())\n\n\n\n# df_event_temp[((df_event_temp.Sex=='F') & (df_event_temp.Season=='Winter'))].head(30)\n\ndf_event=df_event_temp\n\nAnd make the last column int not float (CAST didn’t seem to work perhaps due to NaN values?)\n\ndf_event.fillna(0,inplace=True)\ndf_event = df_event.astype({'num_athletes':'int'})\n\n\n# sanity check\ndf_event[((df_event['num_athletes']==4) & (df_event['Season']=='Winter'))]\n\n\n\n\n\n  \n    \n      \n      event_id\n      sport_id\n      Sport\n      Event\n      Sex\n      Season\n      num_athletes\n    \n  \n  \n    \n      9\n      9\n      5\n      Cross Country Skiing\n      Cross Country Skiing Men's 4 x 10 kilometres R...\n      M\n      Winter\n      4\n    \n    \n      53\n      50\n      22\n      Bobsleigh\n      Bobsleigh Men's Four\n      M\n      Winter\n      4\n    \n    \n      215\n      204\n      40\n      Nordic Combined\n      Nordic Combined Men's Team\n      M\n      Winter\n      4\n    \n    \n      238\n      226\n      11\n      Biathlon\n      Biathlon Men's 4 x 7.5 kilometres Relay\n      M\n      Winter\n      4\n    \n    \n      274\n      259\n      11\n      Biathlon\n      Biathlon Mixed 2 x 6 kilometres and 2 x 7.5 ki...\n      M\n      Winter\n      4\n    \n    \n      275\n      259\n      11\n      Biathlon\n      Biathlon Mixed 2 x 6 kilometres and 2 x 7.5 ki...\n      F\n      Winter\n      4\n    \n    \n      330\n      310\n      11\n      Biathlon\n      Biathlon Women's 4 x 7.5 kilometres Relay\n      F\n      Winter\n      4\n    \n    \n      451\n      419\n      48\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Team\n      M\n      Winter\n      4\n    \n    \n      470\n      435\n      52\n      Short Track Speed Skating\n      Short Track Speed Skating Men's 5,000 metres R...\n      M\n      Winter\n      4\n    \n    \n      478\n      443\n      11\n      Biathlon\n      Biathlon Women's 4 x 6 kilometres Relay\n      F\n      Winter\n      4\n    \n    \n      504\n      466\n      5\n      Cross Country Skiing\n      Cross Country Skiing Women's 4 x 5 kilometres ...\n      F\n      Winter\n      4\n    \n    \n      510\n      472\n      22\n      Bobsleigh\n      Bobsleigh Men's Four/Five\n      M\n      Winter\n      4\n    \n    \n      533\n      492\n      52\n      Short Track Speed Skating\n      Short Track Speed Skating Women's 3,000 metres...\n      F\n      Winter\n      4\n    \n    \n      615\n      572\n      18\n      Luge\n      Luge Mixed Team Relay\n      M\n      Winter\n      4\n    \n    \n      616\n      572\n      18\n      Luge\n      Luge Mixed Team Relay\n      F\n      Winter\n      4\n    \n    \n      640\n      594\n      59\n      Military Ski Patrol\n      Military Ski Patrol Men's Military Ski Patrol\n      M\n      Winter\n      4\n    \n  \n\n\n\n\n\ndf[df.event_id==572][['Sport','Event','Sex']].tail(6),df_event[df_event.event_id==572]\n\n(       Sport                  Event Sex\n 255927  Luge  Luge Mixed Team Relay   M\n 258882  Luge  Luge Mixed Team Relay   M\n 262369  Luge  Luge Mixed Team Relay   F\n 267369  Luge  Luge Mixed Team Relay   M\n 268477  Luge  Luge Mixed Team Relay   M\n 270261  Luge  Luge Mixed Team Relay   M,\n      event_id  sport_id Sport                  Event Sex  Season  num_athletes\n 615       572        18  Luge  Luge Mixed Team Relay   M  Winter             4\n 616       572        18  Luge  Luge Mixed Team Relay   F  Winter             4)"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#add-a-games-table",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#add-a-games-table",
    "title": "Olympics data with SQL and pandas- create the tables",
    "section": "Add a Games table",
    "text": "Add a Games table\nThe games table is used to give information about a particular Olympic games including - Where it was staged - Is it a summer or winter games - The year it was staged\nUsing the same methodology as before we want to - create a unique id for the games - replace this in the athlete tables - add a new table with the unique id and additional information about the particular games\nThis is more complex than the events table because we want to add additional data about the cities where the games were held. This data is obtained from wikipedia as before. So some of the methodology used in creating the country table is used here.\nThere’s a strange thing that there are two summer games in one year\n\ndf=df.sort_values(by=['Year','City'])\n\n\n# event_details=pd.factorize(pd.lib.fast_zip([df.Games, df.City]))\ntuples = df[['Games', 'City']].apply(tuple, axis=1)\nevent_details = pd.factorize( tuples )\nevent_details[1][0:10], event_details[0][1:10],len(event_details[1]),len(event_details[0])\n\n(Index([   ('1896 Summer', 'Athina'),     ('1900 Summer', 'Paris'),\n        ('1904 Summer', 'St. Louis'),    ('1906 Summer', 'Athina'),\n           ('1908 Summer', 'London'), ('1912 Summer', 'Stockholm'),\n        ('1920 Summer', 'Antwerpen'),  ('1924 Winter', 'Chamonix'),\n            ('1924 Summer', 'Paris'), ('1928 Summer', 'Amsterdam')],\n       dtype='object'),\n array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n 52,\n 271116)\n\n\n\ndf.insert(3,'games_id',event_details[0])\ndf\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      games_id\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      3079\n      3079\n      3079\n      191\n      0\n      1724\n      Aristidis Akratopoulos\n      M\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Tennis\n      Tennis Men's Singles\n      NaN\n    \n    \n      3080\n      3080\n      3080\n      92\n      0\n      1724\n      Aristidis Akratopoulos\n      M\n      NaN\n      NaN\n      NaN\n      Greece-3\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Tennis\n      Tennis Men's Doubles\n      NaN\n    \n    \n      3081\n      3081\n      3081\n      191\n      0\n      1725\n      Konstantinos \"Kostas\" Akratopoulos\n      M\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Tennis\n      Tennis Men's Singles\n      NaN\n    \n    \n      3082\n      3082\n      3082\n      92\n      0\n      1725\n      Konstantinos \"Kostas\" Akratopoulos\n      M\n      NaN\n      NaN\n      NaN\n      Greece-3\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Tennis\n      Tennis Men's Doubles\n      NaN\n    \n    \n      7348\n      7348\n      7348\n      100\n      0\n      4113\n      Anastasios Andreou\n      M\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Athletics\n      Athletics Men's 110 metres Hurdles\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      271024\n      271024\n      271024\n      15\n      51\n      135528\n      Marc Zwiebler\n      M\n      32.0\n      181.0\n      75.0\n      Germany\n      FRG\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Badminton\n      Badminton Men's Singles\n      NaN\n    \n    \n      271053\n      271053\n      271053\n      11\n      51\n      135547\n      Viktoriya Viktorovna Zyabkina\n      F\n      23.0\n      174.0\n      62.0\n      Kazakhstan\n      KAZ\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Athletics\n      Athletics Women's 100 metres\n      NaN\n    \n    \n      271054\n      271054\n      271054\n      174\n      51\n      135547\n      Viktoriya Viktorovna Zyabkina\n      F\n      23.0\n      174.0\n      62.0\n      Kazakhstan\n      KAZ\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Athletics\n      Athletics Women's 200 metres\n      NaN\n    \n    \n      271055\n      271055\n      271055\n      12\n      51\n      135547\n      Viktoriya Viktorovna Zyabkina\n      F\n      23.0\n      174.0\n      62.0\n      Kazakhstan\n      KAZ\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Athletics\n      Athletics Women's 4 x 100 metres Relay\n      NaN\n    \n    \n      271110\n      271110\n      271110\n      82\n      51\n      135568\n      Olga Igorevna Zyuzkova\n      F\n      33.0\n      171.0\n      69.0\n      Belarus\n      BLR\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Basketball\n      Basketball Women's Basketball\n      NaN\n    \n  \n\n271116 rows × 19 columns\n\n\n\n\ndf[['games_id','Games','City']].groupby(['games_id','Games']).count()\n\n\n\n\n\n  \n    \n      \n      \n      City\n    \n    \n      games_id\n      Games\n      \n    \n  \n  \n    \n      0\n      1896 Summer\n      380\n    \n    \n      1\n      1900 Summer\n      1936\n    \n    \n      2\n      1904 Summer\n      1301\n    \n    \n      3\n      1906 Summer\n      1733\n    \n    \n      4\n      1908 Summer\n      3101\n    \n    \n      5\n      1912 Summer\n      4040\n    \n    \n      6\n      1920 Summer\n      4292\n    \n    \n      7\n      1924 Winter\n      460\n    \n    \n      8\n      1924 Summer\n      5233\n    \n    \n      9\n      1928 Summer\n      4992\n    \n    \n      10\n      1928 Winter\n      582\n    \n    \n      11\n      1932 Winter\n      352\n    \n    \n      12\n      1932 Summer\n      2969\n    \n    \n      13\n      1936 Summer\n      6506\n    \n    \n      14\n      1936 Winter\n      895\n    \n    \n      15\n      1948 Summer\n      6405\n    \n    \n      16\n      1948 Winter\n      1075\n    \n    \n      17\n      1952 Summer\n      8270\n    \n    \n      18\n      1952 Winter\n      1088\n    \n    \n      19\n      1956 Winter\n      1307\n    \n    \n      20\n      1956 Summer\n      4829\n    \n    \n      21\n      1956 Summer\n      298\n    \n    \n      22\n      1960 Summer\n      8119\n    \n    \n      23\n      1960 Winter\n      1116\n    \n    \n      24\n      1964 Winter\n      1778\n    \n    \n      25\n      1964 Summer\n      7702\n    \n    \n      26\n      1968 Winter\n      1891\n    \n    \n      27\n      1968 Summer\n      8588\n    \n    \n      28\n      1972 Summer\n      10304\n    \n    \n      29\n      1972 Winter\n      1655\n    \n    \n      30\n      1976 Winter\n      1861\n    \n    \n      31\n      1976 Summer\n      8641\n    \n    \n      32\n      1980 Winter\n      1746\n    \n    \n      33\n      1980 Summer\n      7191\n    \n    \n      34\n      1984 Summer\n      9454\n    \n    \n      35\n      1984 Winter\n      2134\n    \n    \n      36\n      1988 Winter\n      2639\n    \n    \n      37\n      1988 Summer\n      12037\n    \n    \n      38\n      1992 Winter\n      3436\n    \n    \n      39\n      1992 Summer\n      12977\n    \n    \n      40\n      1994 Winter\n      3160\n    \n    \n      41\n      1996 Summer\n      13780\n    \n    \n      42\n      1998 Winter\n      3605\n    \n    \n      43\n      2000 Summer\n      13821\n    \n    \n      44\n      2002 Winter\n      4109\n    \n    \n      45\n      2004 Summer\n      13443\n    \n    \n      46\n      2006 Winter\n      4382\n    \n    \n      47\n      2008 Summer\n      13602\n    \n    \n      48\n      2010 Winter\n      4402\n    \n    \n      49\n      2012 Summer\n      12920\n    \n    \n      50\n      2014 Winter\n      4891\n    \n    \n      51\n      2016 Summer\n      13688\n    \n  \n\n\n\n\n\n# Load the games table \ndf_games = pd.read_excel('CitiesOlympics.xlsx',sheet_name=0)\n\n# then sort by year and city like did with df, reset the index\ndf_games=df_games.sort_values(by=['Year','City']).reset_index(drop=True)\n# and replace games_id with new ordered index\ndf_games['games_id']=df_games.index\n\n## sanity check to see if the two tables for games match\n# sanity\ndtemp=df[['games_id','Games','City','Year']].groupby(['games_id','Games','City']).count()\ndtemp.reset_index(inplace=True)\n\npd.concat([df_games[['City','Year','Summer']], dtemp ], axis=1)\n\n# \n\n\n\n\n\n  \n    \n      \n      City\n      Year\n      Summer\n      games_id\n      Games\n      City\n      Year\n    \n  \n  \n    \n      0\n      Athens\n      1896\n      1\n      0\n      1896 Summer\n      Athina\n      380\n    \n    \n      1\n      Paris\n      1900\n      1\n      1\n      1900 Summer\n      Paris\n      1936\n    \n    \n      2\n      St. Louis\n      1904\n      1\n      2\n      1904 Summer\n      St. Louis\n      1301\n    \n    \n      3\n      Athens\n      1906\n      1\n      3\n      1906 Summer\n      Athina\n      1733\n    \n    \n      4\n      London\n      1908\n      1\n      4\n      1908 Summer\n      London\n      3101\n    \n    \n      5\n      Stockholm\n      1912\n      1\n      5\n      1912 Summer\n      Stockholm\n      4040\n    \n    \n      6\n      Antwerp\n      1920\n      1\n      6\n      1920 Summer\n      Antwerpen\n      4292\n    \n    \n      7\n      Chamonix\n      1924\n      0\n      7\n      1924 Winter\n      Chamonix\n      460\n    \n    \n      8\n      Paris\n      1924\n      1\n      8\n      1924 Summer\n      Paris\n      5233\n    \n    \n      9\n      Amsterdam\n      1928\n      1\n      9\n      1928 Summer\n      Amsterdam\n      4992\n    \n    \n      10\n      St. Moritz\n      1928\n      0\n      10\n      1928 Winter\n      Sankt Moritz\n      582\n    \n    \n      11\n      Lake Placid\n      1932\n      0\n      11\n      1932 Winter\n      Lake Placid\n      352\n    \n    \n      12\n      Los Angeles\n      1932\n      1\n      12\n      1932 Summer\n      Los Angeles\n      2969\n    \n    \n      13\n      Berlin\n      1936\n      1\n      13\n      1936 Summer\n      Berlin\n      6506\n    \n    \n      14\n      Garmisch-Partenkirchen\n      1936\n      0\n      14\n      1936 Winter\n      Garmisch-Partenkirchen\n      895\n    \n    \n      15\n      London\n      1948\n      1\n      15\n      1948 Summer\n      London\n      6405\n    \n    \n      16\n      St. Moritz\n      1948\n      0\n      16\n      1948 Winter\n      Sankt Moritz\n      1075\n    \n    \n      17\n      Helsinki\n      1952\n      1\n      17\n      1952 Summer\n      Helsinki\n      8270\n    \n    \n      18\n      Oslo\n      1952\n      0\n      18\n      1952 Winter\n      Oslo\n      1088\n    \n    \n      19\n      Cortina d'Ampezzo\n      1956\n      0\n      19\n      1956 Winter\n      Cortina d'Ampezzo\n      1307\n    \n    \n      20\n      Melbourne\n      1956\n      1\n      20\n      1956 Summer\n      Melbourne\n      4829\n    \n    \n      21\n      Stockholm\n      1956\n      0\n      21\n      1956 Summer\n      Stockholm\n      298\n    \n    \n      22\n      Rome\n      1960\n      1\n      22\n      1960 Summer\n      Roma\n      8119\n    \n    \n      23\n      Squaw Valley\n      1960\n      0\n      23\n      1960 Winter\n      Squaw Valley\n      1116\n    \n    \n      24\n      Innsbruck\n      1964\n      0\n      24\n      1964 Winter\n      Innsbruck\n      1778\n    \n    \n      25\n      Tokyo\n      1964\n      1\n      25\n      1964 Summer\n      Tokyo\n      7702\n    \n    \n      26\n      Grenoble\n      1968\n      0\n      26\n      1968 Winter\n      Grenoble\n      1891\n    \n    \n      27\n      Mexico City\n      1968\n      1\n      27\n      1968 Summer\n      Mexico City\n      8588\n    \n    \n      28\n      Munich\n      1972\n      1\n      28\n      1972 Summer\n      Munich\n      10304\n    \n    \n      29\n      Sapporo\n      1972\n      0\n      29\n      1972 Winter\n      Sapporo\n      1655\n    \n    \n      30\n      Innsbruck\n      1976\n      0\n      30\n      1976 Winter\n      Innsbruck\n      1861\n    \n    \n      31\n      Montreal\n      1976\n      1\n      31\n      1976 Summer\n      Montreal\n      8641\n    \n    \n      32\n      Lake Placid\n      1980\n      0\n      32\n      1980 Winter\n      Lake Placid\n      1746\n    \n    \n      33\n      Moscow\n      1980\n      1\n      33\n      1980 Summer\n      Moskva\n      7191\n    \n    \n      34\n      Los Angeles\n      1984\n      1\n      34\n      1984 Summer\n      Los Angeles\n      9454\n    \n    \n      35\n      Sarajevo\n      1984\n      0\n      35\n      1984 Winter\n      Sarajevo\n      2134\n    \n    \n      36\n      Calgary\n      1988\n      0\n      36\n      1988 Winter\n      Calgary\n      2639\n    \n    \n      37\n      Seoul\n      1988\n      1\n      37\n      1988 Summer\n      Seoul\n      12037\n    \n    \n      38\n      Albertville\n      1992\n      0\n      38\n      1992 Winter\n      Albertville\n      3436\n    \n    \n      39\n      Barcelona\n      1992\n      1\n      39\n      1992 Summer\n      Barcelona\n      12977\n    \n    \n      40\n      Lillehammer\n      1994\n      0\n      40\n      1994 Winter\n      Lillehammer\n      3160\n    \n    \n      41\n      Atlanta\n      1996\n      1\n      41\n      1996 Summer\n      Atlanta\n      13780\n    \n    \n      42\n      Nagano\n      1998\n      0\n      42\n      1998 Winter\n      Nagano\n      3605\n    \n    \n      43\n      Sydney\n      2000\n      1\n      43\n      2000 Summer\n      Sydney\n      13821\n    \n    \n      44\n      Salt Lake City\n      2002\n      0\n      44\n      2002 Winter\n      Salt Lake City\n      4109\n    \n    \n      45\n      Athens\n      2004\n      1\n      45\n      2004 Summer\n      Athina\n      13443\n    \n    \n      46\n      Turin\n      2006\n      0\n      46\n      2006 Winter\n      Torino\n      4382\n    \n    \n      47\n      Beijing\n      2008\n      1\n      47\n      2008 Summer\n      Beijing\n      13602\n    \n    \n      48\n      Vancouver\n      2010\n      0\n      48\n      2010 Winter\n      Vancouver\n      4402\n    \n    \n      49\n      London\n      2012\n      1\n      49\n      2012 Summer\n      London\n      12920\n    \n    \n      50\n      Sochi\n      2014\n      0\n      50\n      2014 Winter\n      Sochi\n      4891\n    \n    \n      51\n      Rio de Janeiro\n      2016\n      1\n      51\n      2016 Summer\n      Rio de Janeiro\n      13688\n    \n  \n\n\n\n\n\nimport re\n\n# starts with a digit (at start of string) or '.'- goes on for undefinable length  \nregex_pattern=r'^[\\d|.]*'\n# starts with a comma then spaces then digits or '.'\nregex_pattern2=',\\s*[\\d|.|]*'\n\ntest_string = df_games.iloc[1,-2]\nprint(test_string)\na=re.search(regex_pattern2, test_string)\n\nfor i in range(len(df_games)):\n#     print(df_games.iloc[i,-2])\n    try:\n        df_games.iloc[i,-1]= re.search(regex_pattern2,df_games.iloc[i,-2])[0][2:] \n        df_games.iloc[i,-2]= re.search(regex_pattern,df_games.iloc[i,-2])[0] \n    except:\n        pass\n\n48.8566° N, 2.3522°\n\n\n\ndef getNation(region_to_check):\n    import re    \n    if region_to_check=='United States':\n        region_out = 'USA'\n    elif bool(re.search(r'Germany', region_to_check)):\n        region_out='Germany'\n    elif region_to_check=='United Kingdom':\n        region_out = 'UK'\n    elif region_to_check=='Soviet Union':\n        region_out='Russia'\n    else:\n        region_out=region_to_check\n        print('nothing found for {}'.format(region_out))\n    \n    return region_out\n\nfor i in range(len(df_games)):\n    x=df2[df2.region==df_games.iloc[i,2]].region\n    if len(x)<1:\n        x=df2[df2.notes==df_games.iloc[i,2]].region\n        if len(x)<1:\n            x=getNation(df_games.iloc[i,2])\n#     \n    try:\n        df_games.iloc[i,2]=str(x.iloc[0]) \n    except:\n        df_games.iloc[i,2]=str(x) \n#     print(x)\n#     if len(x)<1:\n#         print('----------------------------------')\n        \n        \n\n\ndf_games.iloc[10:20,:]\n\n\n\n\n\n  \n    \n      \n      games_id\n      City\n      Country\n      Year\n      Region\n      Summer\n      Winter\n      Latitude\n      Longitude\n    \n  \n  \n    \n      10\n      10\n      St. Moritz\n      Switzerland\n      1928\n      Europe\n      0\n      1\n      46.4908\n      9.8355\n    \n    \n      11\n      11\n      Lake Placid\n      USA\n      1932\n      North America\n      0\n      1\n      27.2931\n      81.3629\n    \n    \n      12\n      12\n      Los Angeles\n      USA\n      1932\n      North America\n      1\n      0\n      34.0522\n      118.2437\n    \n    \n      13\n      13\n      Berlin\n      Germany\n      1936\n      Europe\n      1\n      0\n      52.5200\n      13.4050\n    \n    \n      14\n      14\n      Garmisch-Partenkirchen\n      Germany\n      1936\n      Europe\n      0\n      1\n      47.4919\n      11.0948\n    \n    \n      15\n      15\n      London\n      UK\n      1948\n      Europe\n      1\n      0\n      51.5072\n      0.1276\n    \n    \n      16\n      16\n      St. Moritz\n      Switzerland\n      1948\n      Europe\n      0\n      1\n      46.4908\n      9.8355\n    \n    \n      17\n      17\n      Helsinki\n      Finland\n      1952\n      Europe\n      1\n      0\n      60.1699\n      24.9384\n    \n    \n      18\n      18\n      Oslo\n      Norway\n      1952\n      Europe\n      0\n      1\n      59.9139\n      10.7522\n    \n    \n      19\n      19\n      Cortina d'Ampezzo\n      Italy\n      1956\n      Europe\n      0\n      1\n      46.5405\n      12.1357\n    \n  \n\n\n\n\n\ndf.groupby(['games_id','Year','Games','City']).count().reset_index()\n\n\n\n\n\n  \n    \n      \n      games_id\n      Year\n      Games\n      City\n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Season\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      1896\n      1896 Summer\n      Athina\n      380\n      380\n      380\n      380\n      380\n      380\n      217\n      46\n      49\n      380\n      380\n      380\n      380\n      380\n      143\n    \n    \n      1\n      1\n      1900\n      1900 Summer\n      Paris\n      1936\n      1936\n      1936\n      1936\n      1936\n      1936\n      1146\n      116\n      79\n      1936\n      1936\n      1936\n      1936\n      1936\n      604\n    \n    \n      2\n      2\n      1904\n      1904 Summer\n      St. Louis\n      1301\n      1301\n      1301\n      1301\n      1301\n      1301\n      1027\n      213\n      147\n      1301\n      1301\n      1301\n      1301\n      1301\n      486\n    \n    \n      3\n      3\n      1906\n      1906 Summer\n      Athina\n      1733\n      1733\n      1733\n      1733\n      1733\n      1733\n      990\n      257\n      205\n      1733\n      1733\n      1733\n      1733\n      1733\n      458\n    \n    \n      4\n      4\n      1908\n      1908 Summer\n      London\n      3101\n      3101\n      3101\n      3101\n      3101\n      3101\n      2452\n      475\n      483\n      3101\n      3101\n      3101\n      3101\n      3101\n      831\n    \n    \n      5\n      5\n      1912\n      1912 Summer\n      Stockholm\n      4040\n      4040\n      4040\n      4040\n      4040\n      4040\n      3884\n      721\n      596\n      4040\n      4040\n      4040\n      4040\n      4040\n      941\n    \n    \n      6\n      6\n      1920\n      1920 Summer\n      Antwerpen\n      4292\n      4292\n      4292\n      4292\n      4292\n      4292\n      3447\n      767\n      471\n      4292\n      4292\n      4292\n      4292\n      4292\n      1308\n    \n    \n      7\n      7\n      1924\n      1924 Winter\n      Chamonix\n      460\n      460\n      460\n      460\n      460\n      460\n      403\n      89\n      41\n      460\n      460\n      460\n      460\n      460\n      130\n    \n    \n      8\n      8\n      1924\n      1924 Summer\n      Paris\n      5233\n      5233\n      5233\n      5233\n      5233\n      5233\n      4148\n      885\n      649\n      5233\n      5233\n      5233\n      5233\n      5233\n      832\n    \n    \n      9\n      9\n      1928\n      1928 Summer\n      Amsterdam\n      4992\n      4992\n      4992\n      4992\n      4992\n      4992\n      4119\n      853\n      670\n      4992\n      4992\n      4992\n      4992\n      4992\n      734\n    \n    \n      10\n      10\n      1928\n      1928 Winter\n      Sankt Moritz\n      582\n      582\n      582\n      582\n      582\n      582\n      492\n      122\n      48\n      582\n      582\n      582\n      582\n      582\n      89\n    \n    \n      11\n      11\n      1932\n      1932 Winter\n      Lake Placid\n      352\n      352\n      352\n      352\n      352\n      352\n      329\n      196\n      55\n      352\n      352\n      352\n      352\n      352\n      92\n    \n    \n      12\n      12\n      1932\n      1932 Summer\n      Los Angeles\n      2969\n      2969\n      2969\n      2969\n      2969\n      2969\n      2662\n      1017\n      495\n      2969\n      2969\n      2969\n      2969\n      2969\n      647\n    \n    \n      13\n      13\n      1936\n      1936 Summer\n      Berlin\n      6506\n      6506\n      6506\n      6506\n      6506\n      6506\n      6304\n      1056\n      909\n      6506\n      6506\n      6506\n      6506\n      6506\n      917\n    \n    \n      14\n      14\n      1936\n      1936 Winter\n      Garmisch-Partenkirchen\n      895\n      895\n      895\n      895\n      895\n      895\n      884\n      136\n      78\n      895\n      895\n      895\n      895\n      895\n      108\n    \n    \n      15\n      15\n      1948\n      1948 Summer\n      London\n      6405\n      6405\n      6405\n      6405\n      6405\n      6405\n      5233\n      1053\n      1040\n      6405\n      6405\n      6405\n      6405\n      6405\n      852\n    \n    \n      16\n      16\n      1948\n      1948 Winter\n      Sankt Moritz\n      1075\n      1075\n      1075\n      1075\n      1075\n      1075\n      1071\n      116\n      111\n      1075\n      1075\n      1075\n      1075\n      1075\n      135\n    \n    \n      17\n      17\n      1952\n      1952 Summer\n      Helsinki\n      8270\n      8270\n      8270\n      8270\n      8270\n      8270\n      7993\n      2038\n      2038\n      8270\n      8270\n      8270\n      8270\n      8270\n      897\n    \n    \n      18\n      18\n      1952\n      1952 Winter\n      Oslo\n      1088\n      1088\n      1088\n      1088\n      1088\n      1088\n      1088\n      150\n      149\n      1088\n      1088\n      1088\n      1088\n      1088\n      136\n    \n    \n      19\n      19\n      1956\n      1956 Winter\n      Cortina d'Ampezzo\n      1307\n      1307\n      1307\n      1307\n      1307\n      1307\n      1282\n      344\n      342\n      1307\n      1307\n      1307\n      1307\n      1307\n      150\n    \n    \n      20\n      20\n      1956\n      1956 Summer\n      Melbourne\n      4829\n      4829\n      4829\n      4829\n      4829\n      4829\n      4256\n      2234\n      2232\n      4829\n      4829\n      4829\n      4829\n      4829\n      857\n    \n    \n      21\n      21\n      1956\n      1956 Summer\n      Stockholm\n      298\n      298\n      298\n      298\n      298\n      298\n      258\n      108\n      106\n      298\n      298\n      298\n      298\n      298\n      36\n    \n    \n      22\n      22\n      1960\n      1960 Summer\n      Roma\n      8119\n      8119\n      8119\n      8119\n      8119\n      8119\n      7906\n      7738\n      7675\n      8119\n      8119\n      8119\n      8119\n      8119\n      911\n    \n    \n      23\n      23\n      1960\n      1960 Winter\n      Squaw Valley\n      1116\n      1116\n      1116\n      1116\n      1116\n      1116\n      1108\n      536\n      512\n      1116\n      1116\n      1116\n      1116\n      1116\n      147\n    \n    \n      24\n      24\n      1964\n      1964 Winter\n      Innsbruck\n      1778\n      1778\n      1778\n      1778\n      1778\n      1778\n      1765\n      1369\n      1348\n      1778\n      1778\n      1778\n      1778\n      1778\n      186\n    \n    \n      25\n      25\n      1964\n      1964 Summer\n      Tokyo\n      7702\n      7702\n      7702\n      7702\n      7702\n      7702\n      7659\n      7430\n      7424\n      7702\n      7702\n      7702\n      7702\n      7702\n      1029\n    \n    \n      26\n      26\n      1968\n      1968 Winter\n      Grenoble\n      1891\n      1891\n      1891\n      1891\n      1891\n      1891\n      1872\n      1833\n      1817\n      1891\n      1891\n      1891\n      1891\n      1891\n      199\n    \n    \n      27\n      27\n      1968\n      1968 Summer\n      Mexico City\n      8588\n      8588\n      8588\n      8588\n      8588\n      8588\n      8489\n      8493\n      8493\n      8588\n      8588\n      8588\n      8588\n      8588\n      1057\n    \n    \n      28\n      28\n      1972\n      1972 Summer\n      Munich\n      10304\n      10304\n      10304\n      10304\n      10304\n      10304\n      10211\n      10018\n      9928\n      10304\n      10304\n      10304\n      10304\n      10304\n      1215\n    \n    \n      29\n      29\n      1972\n      1972 Winter\n      Sapporo\n      1655\n      1655\n      1655\n      1655\n      1655\n      1655\n      1652\n      1640\n      1642\n      1655\n      1655\n      1655\n      1655\n      1655\n      199\n    \n    \n      30\n      30\n      1976\n      1976 Winter\n      Innsbruck\n      1861\n      1861\n      1861\n      1861\n      1861\n      1861\n      1850\n      1343\n      1302\n      1861\n      1861\n      1861\n      1861\n      1861\n      211\n    \n    \n      31\n      31\n      1976\n      1976 Summer\n      Montreal\n      8641\n      8641\n      8641\n      8641\n      8641\n      8641\n      8600\n      8283\n      8280\n      8641\n      8641\n      8641\n      8641\n      8641\n      1320\n    \n    \n      32\n      32\n      1980\n      1980 Winter\n      Lake Placid\n      1746\n      1746\n      1746\n      1746\n      1746\n      1746\n      1745\n      1388\n      1374\n      1746\n      1746\n      1746\n      1746\n      1746\n      218\n    \n    \n      33\n      33\n      1980\n      1980 Summer\n      Moskva\n      7191\n      7191\n      7191\n      7191\n      7191\n      7191\n      7005\n      6961\n      6967\n      7191\n      7191\n      7191\n      7191\n      7191\n      1384\n    \n    \n      34\n      34\n      1984\n      1984 Summer\n      Los Angeles\n      9454\n      9454\n      9454\n      9454\n      9454\n      9454\n      9249\n      9032\n      9031\n      9454\n      9454\n      9454\n      9454\n      9454\n      1476\n    \n    \n      35\n      35\n      1984\n      1984 Winter\n      Sarajevo\n      2134\n      2134\n      2134\n      2134\n      2134\n      2134\n      2123\n      1958\n      1954\n      2134\n      2134\n      2134\n      2134\n      2134\n      222\n    \n    \n      36\n      36\n      1988\n      1988 Winter\n      Calgary\n      2639\n      2639\n      2639\n      2639\n      2639\n      2639\n      2635\n      2024\n      2018\n      2639\n      2639\n      2639\n      2639\n      2639\n      263\n    \n    \n      37\n      37\n      1988\n      1988 Summer\n      Seoul\n      12037\n      12037\n      12037\n      12037\n      12037\n      12037\n      11931\n      11719\n      11730\n      12037\n      12037\n      12037\n      12037\n      12037\n      1582\n    \n    \n      38\n      38\n      1992\n      1992 Winter\n      Albertville\n      3436\n      3436\n      3436\n      3436\n      3436\n      3436\n      3435\n      2785\n      2783\n      3436\n      3436\n      3436\n      3436\n      3436\n      318\n    \n    \n      39\n      39\n      1992\n      1992 Summer\n      Barcelona\n      12977\n      12977\n      12977\n      12977\n      12977\n      12977\n      12934\n      10453\n      10473\n      12977\n      12977\n      12977\n      12977\n      12977\n      1712\n    \n    \n      40\n      40\n      1994\n      1994 Winter\n      Lillehammer\n      3160\n      3160\n      3160\n      3160\n      3160\n      3160\n      3158\n      2973\n      2971\n      3160\n      3160\n      3160\n      3160\n      3160\n      331\n    \n    \n      41\n      41\n      1996\n      1996 Summer\n      Atlanta\n      13780\n      13780\n      13780\n      13780\n      13780\n      13780\n      13772\n      11909\n      11959\n      13780\n      13780\n      13780\n      13780\n      13780\n      1842\n    \n    \n      42\n      42\n      1998\n      1998 Winter\n      Nagano\n      3605\n      3605\n      3605\n      3605\n      3605\n      3605\n      3603\n      3521\n      3519\n      3605\n      3605\n      3605\n      3605\n      3605\n      440\n    \n    \n      43\n      43\n      2000\n      2000 Summer\n      Sydney\n      13821\n      13821\n      13821\n      13821\n      13821\n      13821\n      13820\n      13698\n      13695\n      13821\n      13821\n      13821\n      13821\n      13821\n      2004\n    \n    \n      44\n      44\n      2002\n      2002 Winter\n      Salt Lake City\n      4109\n      4109\n      4109\n      4109\n      4109\n      4109\n      4109\n      4080\n      4062\n      4109\n      4109\n      4109\n      4109\n      4109\n      478\n    \n    \n      45\n      45\n      2004\n      2004 Summer\n      Athina\n      13443\n      13443\n      13443\n      13443\n      13443\n      13443\n      13443\n      13407\n      13406\n      13443\n      13443\n      13443\n      13443\n      13443\n      2001\n    \n    \n      46\n      46\n      2006\n      2006 Winter\n      Torino\n      4382\n      4382\n      4382\n      4382\n      4382\n      4382\n      4382\n      4376\n      4366\n      4382\n      4382\n      4382\n      4382\n      4382\n      526\n    \n    \n      47\n      47\n      2008\n      2008 Summer\n      Beijing\n      13602\n      13602\n      13602\n      13602\n      13602\n      13602\n      13600\n      13451\n      13443\n      13602\n      13602\n      13602\n      13602\n      13602\n      2048\n    \n    \n      48\n      48\n      2010\n      2010 Winter\n      Vancouver\n      4402\n      4402\n      4402\n      4402\n      4402\n      4402\n      4402\n      4400\n      4378\n      4402\n      4402\n      4402\n      4402\n      4402\n      520\n    \n    \n      49\n      49\n      2012\n      2012 Summer\n      London\n      12920\n      12920\n      12920\n      12920\n      12920\n      12920\n      12920\n      12752\n      12560\n      12920\n      12920\n      12920\n      12920\n      12920\n      1941\n    \n    \n      50\n      50\n      2014\n      2014 Winter\n      Sochi\n      4891\n      4891\n      4891\n      4891\n      4891\n      4891\n      4891\n      4871\n      4673\n      4891\n      4891\n      4891\n      4891\n      4891\n      597\n    \n    \n      51\n      51\n      2016\n      2016 Summer\n      Rio de Janeiro\n      13688\n      13688\n      13688\n      13688\n      13688\n      13688\n      13688\n      13512\n      13465\n      13688\n      13688\n      13688\n      13688\n      13688\n      2023"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#create-some-smaller-athlete-tables",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#create-some-smaller-athlete-tables",
    "title": "Olympics data with SQL and pandas- create the tables",
    "section": "Create some smaller athlete tables",
    "text": "Create some smaller athlete tables\nFinally the main athletes df file can be split the up by sex and season, since the id’s for different fields have been added\n\nWe don’t really need sex and Season so we can drop these\nWe can also reorder the index (not the athlete ID)\nIf Medals = NaN this probably means they didn’t get one. So we can replace medals with Gold, Silver and Bronze (one-hot encoding)\nInstead of Games, Year, City lets replace with a uniques INT id. And put that data in another dataframe for cities\n\n\n# split and Reset index, so it increases 1,2,3,4,etc\n\ndf_M_S = df[(df.Sex=='M') & (df.Season=='Summer')]\ndf_M_S.reset_index(inplace = True,drop=True)\n\ndf_F_S = df[(df.Sex=='F') & (df.Season=='Summer')]\ndf_F_S.reset_index(inplace = True,drop=True)\n\ndf_M_W = df[(df.Sex=='M') & (df.Season=='Winter')]\ndf_M_W.reset_index(inplace = True,drop=True)\n\ndf_F_W = df[(df.Sex=='F') & (df.Season=='Winter')]\ndf_F_W.reset_index(inplace = True,drop=True)\n\n\n# Look at the data\n\ndf_M_W.head(10)\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      games_id\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      672\n      672\n      13\n      7\n      391\n      Clarence John Abel\n      M\n      23.0\n      185.0\n      102.0\n      United States\n      USA\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Ice Hockey\n      Ice Hockey Men's Ice Hockey\n      Silver\n    \n    \n      1\n      1791\n      1791\n      205\n      7\n      992\n      Josef Adolf\n      M\n      25.0\n      NaN\n      NaN\n      Czechoslovakia\n      BOH\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Nordic Combined\n      Nordic Combined Men's Individual\n      NaN\n    \n    \n      2\n      1951\n      1951\n      300\n      7\n      1077\n      Xavier Affentranger\n      M\n      26.0\n      NaN\n      NaN\n      Switzerland\n      SUI\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Ski Jumping\n      Ski Jumping Men's Normal Hill, Individual\n      NaN\n    \n    \n      3\n      1952\n      1952\n      385\n      7\n      1077\n      Xavier Affentranger\n      M\n      26.0\n      NaN\n      NaN\n      Switzerland\n      SUI\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Cross Country Skiing\n      Cross Country Skiing Men's 18 kilometres\n      NaN\n    \n    \n      4\n      1953\n      1953\n      205\n      7\n      1077\n      Xavier Affentranger\n      M\n      26.0\n      NaN\n      NaN\n      Switzerland\n      SUI\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Nordic Combined\n      Nordic Combined Men's Individual\n      NaN\n    \n    \n      5\n      2397\n      2397\n      305\n      7\n      1341\n      Johan Petter hln (Andersson-)\n      M\n      44.0\n      NaN\n      NaN\n      Sweden\n      SWE\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Curling\n      Curling Men's Curling\n      Silver\n    \n    \n      6\n      4040\n      4040\n      300\n      7\n      2329\n      Louis Albert\n      M\n      25.0\n      NaN\n      NaN\n      France\n      FRA\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Ski Jumping\n      Ski Jumping Men's Normal Hill, Individual\n      NaN\n    \n    \n      7\n      4249\n      4249\n      472\n      7\n      2431\n      Henri Eugne Aldebert\n      M\n      43.0\n      NaN\n      NaN\n      France-1\n      FRA\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Bobsleigh\n      Bobsleigh Men's Four/Five\n      NaN\n    \n    \n      8\n      5103\n      5103\n      13\n      7\n      2902\n      Karl Ruben Allinger\n      M\n      32.0\n      NaN\n      NaN\n      Sweden\n      SWE\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Ice Hockey\n      Ice Hockey Men's Ice Hockey\n      NaN\n    \n    \n      9\n      5174\n      5174\n      7\n      7\n      2939\n      Ernst Alm\n      M\n      23.0\n      174.0\n      NaN\n      Sweden\n      SWE\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Cross Country Skiing\n      Cross Country Skiing Men's 50 kilometres\n      NaN\n    \n  \n\n\n\n\n\n\n\n\ndf_M_S = df_M_S.drop(columns=['Name','Sex','Season','City','Games','Sport','Event'])\ndf_F_S = df_F_S.drop(columns=['Name','Sex','Season','City','Games','Sport','Event'])\ndf_M_W = df_M_W.drop(columns=['Name','Sex','Season','City','Games','Sport','Event'])\ndf_F_W = df_F_W.drop(columns=['Name','Sex','Season','City','Games','Sport','Event'])\ndf_F_W.head(5)\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      games_id\n      athlete_ID\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Year\n      Medal\n    \n  \n  \n    \n      0\n      30620\n      30620\n      268\n      7\n      15776\n      22.0\n      165.0\n      NaN\n      France\n      FRA\n      1924\n      NaN\n    \n    \n      1\n      30621\n      30621\n      242\n      7\n      15776\n      22.0\n      165.0\n      NaN\n      France-1\n      FRA\n      1924\n      Bronze\n    \n    \n      2\n      63714\n      63714\n      242\n      7\n      32641\n      25.0\n      NaN\n      NaN\n      Austria\n      AUT\n      1924\n      Gold\n    \n    \n      3\n      94058\n      94058\n      268\n      7\n      47618\n      11.0\n      155.0\n      45.0\n      Norway\n      NOR\n      1924\n      NaN\n    \n    \n      4\n      94533\n      94533\n      242\n      7\n      47845\n      NaN\n      NaN\n      NaN\n      Belgium\n      BEL\n      1924\n      NaN\n    \n  \n\n\n\n\n\nSeperate out medals\n\ndf_F_W = pd.get_dummies(df_F_W,columns=['Medal'])\ndf_M_W = pd.get_dummies(df_M_W,columns=['Medal'])\ndf_F_S = pd.get_dummies(df_F_S,columns=['Medal'])\ndf_M_S = pd.get_dummies(df_M_S,columns=['Medal'])\ndf_M_S.head()\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      games_id\n      athlete_ID\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Year\n      Medal_Bronze\n      Medal_Gold\n      Medal_Silver\n    \n  \n  \n    \n      0\n      3079\n      3079\n      191\n      0\n      1724\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896\n      0\n      0\n      0\n    \n    \n      1\n      3080\n      3080\n      92\n      0\n      1724\n      NaN\n      NaN\n      NaN\n      Greece-3\n      CRT\n      1896\n      0\n      0\n      0\n    \n    \n      2\n      3081\n      3081\n      191\n      0\n      1725\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896\n      0\n      0\n      0\n    \n    \n      3\n      3082\n      3082\n      92\n      0\n      1725\n      NaN\n      NaN\n      NaN\n      Greece-3\n      CRT\n      1896\n      0\n      0\n      0\n    \n    \n      4\n      7348\n      7348\n      100\n      0\n      4113\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896\n      0\n      0\n      0"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#save-it",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_createDFs.html#save-it",
    "title": "Olympics data with SQL and pandas- create the tables",
    "section": "Save it",
    "text": "Save it\n\ndf_F_S.to_csv('athlete_F_S')\ndf_F_W.to_csv('athlete_F_W')\ndf_M_S.to_csv('athlete_M_S')\ndf_M_W.to_csv('athlete_M_W')\n\ndf_all_athletes.to_csv('all_athletes')\ndf_country.to_csv('country')\ndf_event.to_csv('event')\ndf_games.to_csv('games')\ndf_population.to_csv('population')"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#introduction",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#introduction",
    "title": "Olympics data with SQL and pandas- GDP and population",
    "section": "Introduction",
    "text": "Introduction\nDue to the global importance of the Olympics, in 2020 there was a broadcast audience of more than 3 billion, I was interested to explore whether countries with the most medals will reflect global politics. And to see if the countries with most influence get more medals.\nThere are two relatively easy to obtain metrics that can be used to define the importance of a nation internationally, GDP and population.\nGross domestic product (GDP) is a monetary measure of the market value of all the final goods and services produced in a specific time period by countries. GDP is often used as a metric for international comparisons as well as a broad measure of economic progress. It is often considered to be the “world’s most powerful statistical indicator of national development and progress”. GDP Wikipedia.\nThe population of a country is an important parameter in assessing the global importance of a nation. Furthermore, the more people in a country the greater the pool of potential athletes.\nIn the final part of this page I will briefly look at how the Cold War was reflected in the Olympics data."
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#pre-analysis",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#pre-analysis",
    "title": "Olympics data with SQL and pandas- GDP and population",
    "section": "Pre-analysis",
    "text": "Pre-analysis\n\nGet medals won by country and year\nWhat we want to end up with is a new table with- - Nation - Number of medals - Event or year of the event - Then the details of nations we’re studying: - GDP - Population - Continent\nTo get a unique medal count for this, we can do a count by grouping on - Nation and Year But also on: - Medal type (Gold, Silver, Bronze) - Event id As we only know if a medal is unique for an athlete if the same medal type does not exist for another athlete in the same event at the same games (year). This is to avoid duplication for team sports. If it is a mixed event then we would need to do the grouping on data of male and female athletes.\nFrom inside out\n\nUse UNION to join the males and female summer athletes\n\nGet NOC, medal types, year, event_id\n\nUse GROUP BY to get unique medals and COUNT\nUse GROUP BY to get medals for countries in each event/year, SUM so we are adding up events\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandasql import sqldf\nimport copy\nimport numpy as np\nimport scipy.stats\n\n\ndf_F_S =pd.read_csv('data/athlete_F_S')\n# df_F_W=pd.read_csv('data/athlete_F_W')\ndf_M_S=pd.read_csv('data/athlete_M_S')\n# df_M_W=pd.read_csv('data/athlete_M_W')\n\ndf_all_athletes= pd.read_csv('data/all_athletes')\ndf_country= pd.read_csv('data/country')\ndf_event= pd.read_csv('data/event')\n# df_games= pd.read_csv('data/games')\n# df_population= pd.read_csv('data/population')\n\ndf_country = df_country.groupby('NOC').max()\ndf_country.head(10)\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      Nation\n      Continent\n      Population\n      GDP\n    \n    \n      NOC\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AFG\n      0\n      Afghanistan\n      Asia\n      32890171\n      19807\n    \n    \n      ALB\n      1\n      Albania\n      Europe\n      2829741\n      14800\n    \n    \n      ALG\n      2\n      Algeria\n      Africa\n      45400000\n      145164\n    \n    \n      AND\n      3\n      Andorra\n      Europe\n      79535\n      3155\n    \n    \n      ANG\n      4\n      Angola\n      Africa\n      33086278\n      62307\n    \n    \n      ANT\n      5\n      Antigua\n      Americas\n      99337\n      1415\n    \n    \n      ANZ\n      7\n      Australia\n      Oceania\n      25921518\n      1330901\n    \n    \n      ARG\n      8\n      Argentina\n      Americas\n      47327407\n      383067\n    \n    \n      ARM\n      9\n      Armenia\n      Asia\n      2963900\n      12645\n    \n    \n      AUT\n      10\n      Austria\n      Europe\n      9027999\n      428965\n    \n  \n\n\n\n\n\ndf_by_year=\\\n     sqldf('SELECT                                                 \\\n              NOC,                                                 \\\n              Year,                                                \\\n              SUM(counta)              AS num_medals               \\\n                FROM(SELECT                                        \\\n                    NOC,                                           \\\n                    Year,                                          \\\n                    event_id,                                      \\\n                    Medal_Bronze, Medal_Gold, Medal_Silver,        \\\n                    COUNT(*) as counta                             \\\n                        FROM(SELECT                                \\\n                            NOC,                                   \\\n                            Year,                                  \\\n                            event_id,                              \\\n                            Medal_Bronze, Medal_Gold, Medal_Silver \\\n                        FROM                                       \\\n                            df_F_S                                 \\\n                        WHERE Medal_Bronze=1 OR Medal_Gold=1 OR Medal_Silver \\\n                        UNION                                      \\\n                        SELECT                                     \\\n                            NOC,                                   \\\n                            Year,                                  \\\n                            event_id,                              \\\n                            Medal_Bronze, Medal_Gold, Medal_Silver \\\n                        FROM                                       \\\n                            df_M_S                                 \\\n                        WHERE Medal_Bronze=1 OR Medal_Gold=1 OR Medal_Silver) as MF                  \\\n                    GROUP BY                                       \\\n                        NOC, Year, event_id, Medal_Bronze, Medal_Gold, Medal_Silver\\\n                    ORDER BY                                       \\\n                        NOC) as inner                              \\\n            GROUP BY                                               \\\n                NOC, Year;',locals()) \n\ndf_by_year[df_by_year.Year==2016].sort_values('num_medals',ascending=False).head(10)\n\n\n\n\n\n  \n    \n      \n      NOC\n      Year\n      num_medals\n    \n  \n  \n    \n      1246\n      USA\n      2016\n      121\n    \n    \n      246\n      CHN\n      2016\n      70\n    \n    \n      527\n      GBR\n      2016\n      67\n    \n    \n      415\n      EUN\n      2016\n      56\n    \n    \n      471\n      FRA\n      2016\n      42\n    \n    \n      497\n      FRG\n      2016\n      42\n    \n    \n      706\n      JPN\n      2016\n      41\n    \n    \n      38\n      ANZ\n      2016\n      29\n    \n    \n      669\n      ITA\n      2016\n      28\n    \n    \n      230\n      CAN\n      2016\n      22\n    \n  \n\n\n\n\n\n\nJoin with the country table\nNow just join to the country table\n\ndf_=\\\n     sqldf('SELECT                              \\\n              NOC,                              \\\n              Nation,                           \\\n              Continent,                        \\\n              SUM(num_medals)  AS number_of_medals,                  \\\n              Population,                       \\\n              GDP                               \\\n            FROM(                               \\\n                SELECT *                        \\\n                FROM                            \\\n                    df_country AS c             \\\n                INNER JOIN                      \\\n                    df_by_year AS d             \\\n                ON                              \\\n                    c.NOC=d.NOC                 \\\n                WHERE                           \\\n                    d.Year>=2008)               \\\n            GROUP BY                            \\\n                NOC,Continent                   \\\n            ORDER BY                            \\\n                num_medals desc;',locals())\n               \ndf_                    \n\n\n\n\n\n  \n    \n      \n      NOC\n      Nation\n      Continent\n      number_of_medals\n      Population\n      GDP\n    \n  \n  \n    \n      0\n      USA\n      USA\n      Americas\n      334\n      332906919\n      20936600\n    \n    \n      1\n      CHN\n      China\n      Asia\n      259\n      1412600000\n      14722731\n    \n    \n      2\n      EUN\n      Russia\n      Europe\n      210\n      147190000\n      1483498\n    \n    \n      3\n      GBR\n      UK\n      Europe\n      180\n      67081234\n      2707744\n    \n    \n      4\n      ANZ\n      Australia\n      Oceania\n      110\n      25921518\n      1330901\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      99\n      TUN\n      Tunisia\n      Africa\n      7\n      11746695\n      39236\n    \n    \n      100\n      UAE\n      United Arab Emirates\n      Asia\n      1\n      9282410\n      421142\n    \n    \n      101\n      UGA\n      Uganda\n      Africa\n      1\n      42885900\n      37372\n    \n    \n      102\n      VEN\n      Venezuela\n      Americas\n      5\n      28705000\n      482359\n    \n    \n      103\n      VIE\n      Vietnam\n      Asia\n      3\n      98505400\n      271158\n    \n  \n\n104 rows × 6 columns"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#correlation-in-population-and-gdp",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#correlation-in-population-and-gdp",
    "title": "Olympics data with SQL and pandas- GDP and population",
    "section": "Correlation in Population and GDP",
    "text": "Correlation in Population and GDP\nFirst create a function to display correlations: - produce scatter plots - find which countries are poor correlation - find some correlation stats\n\ndef modname(string):\n    string=''.join([string[0].upper(),string[1:].lower()])\n    string=string.replace('_',' ')\n    return string\ndef doFigAddOns(nomX,nomY,fontsize):\n        plt.ylabel(modname(nomY), fontsize=fontsize)\n        plt.xlabel(nomX, fontsize=fontsize)\n        plt.grid(True)\n        \ndef scatter_combo(df_temp,xval,yval):\n    \n    df_temp=df_temp.set_index('Nation')\n    fontsize=14\n    \n    df_temp=copy.copy(df_temp)\n    # remove 0 values\n    df_temp=df_temp[df_temp.loc[:,xval]!=0]\n    \n    # drop NaNs \n    df_temp=df_temp.dropna()\n    \n    # values in millions\n    df_temp.loc[:,xval]=df_temp.loc[:,xval]/1e6\n    \n    # the names of the columns\n    nomX=xval#(df_temp.columns[xval])\n    nomY=yval#modname(df_temp.columns[yval])\n    \n    # define the x and y values\n    X=df_temp.loc[:,xval]\n    Y=df_temp.loc[:,yval]\n    \n    # do some plots\n    fig,ax=plt.subplots(figsize=(7,15))\n    plt.rcParams['font.size'] = '13'\n    \n    # Fig A\n    ax1=plt.subplot(3,1,1)\n    ax1.plot(X ,Y,'+b',markeredgewidth=2,ms=10)\n    m,b=np.polyfit(X,Y,1)\n    Ypred=X*m+b\n    plt.plot(X,Ypred, '--k');\n    doFigAddOns(nomX,nomY,fontsize)\n    \n    \n    \n    # Fig B\n    ax3=plt.subplot(3,1,2)\n    ax3.plot(X ,Y,'+b',markeredgewidth=2,ms=10)\n    X=X.sort_values()\n    Ypred=X*m+b\n    plt.plot(X,Ypred, '--k');\n    plt.yscale('log')\n    plt.xscale('log')\n    doFigAddOns(nomX,nomY,fontsize) \n\n    # Fig C\n    diffa = df_temp.loc[:,yval]-Ypred\n    ax2=plt.subplot(3,1,3)\n    ax2.plot(X,diffa, 'xk',markeredgewidth=2,ms=10);\n    plt.xscale('log')\n    doFigAddOns(nomX,'Difference between \\nlinear fit',fontsize)\n\n    plt.subplots_adjust(hspace=0.35)\n    \n    # because sorted x, need to get original x back\n    X=df_temp.loc[:,xval]\n\n    # Get some correlation values, and what are worst countries\n    corr=scipy.stats.pearsonr(X, Y)\n    print('Correlation of  = {:.2f} ({:.0e}) \\n \\\n           And m= {:.3f} b={:.1f}          '.format(corr[0],corr[1],m,b))\n    \n    country_hi_corr=(diffa).sort_values(ascending=False).index[0:10]\n    print('Countries worst correlation where overachive',diffa[country_hi_corr])\n    \n    country_low_corr=(diffa).sort_values().index[0:10]\n    print('Countries worst correlation where unachieve',diffa[country_low_corr])\n\n    d={'Underachieve':country_low_corr,'Overachieve':country_hi_corr}\n    return pd.DataFrame(data=d)\n\ndef getCorr(df_temp, xval,yval):\n    \n    df_temp=copy.copy(df_temp)\n    # remove 0 values\n    df_temp=df_temp[df_temp.loc[:,xval]!=0]\n    \n    # drop NaNs \n    df_temp=df_temp.dropna()\n    \n    # define the x and y values\n    X=df_temp.loc[:,xval]\n    Y=df_temp.loc[:,yval]\n    \n    # Get some correlation values, and what are worst countries\n    corr=scipy.stats.pearsonr(X, Y)\n    print('Pearson Correlation of  = {:.2f} ({:.0e})'.format(corr[0],corr[1]))\n    # Get some correlation values, and what are worst countries\n    corr=scipy.stats.spearmanr(X, Y)\n    print('Spearman Correlation of  = {:.2f} ({:.0e})'.format(corr[0],corr[1]))\n\n\npopCorr=scatter_combo(df_,'GDP','number_of_medals')\npopCorr\n\nCorrelation of  = 0.84 (4e-29) \n            And m= 17.195 b=14.2          \nCountries worst correlation where overachive Nation\nRussia         170.270535\nUK             119.219670\nAustralia       72.894435\nFrance          59.020671\nGermany         47.334168\nUkraine         41.104002\nSouth Korea     37.742411\nItaly           36.341876\nCuba            33.005895\nKazakhstan      26.858922\ndtype: float64\nCountries worst correlation where unachieve Nation\nIndia                  -48.322884\nUSA                    -40.224834\nSaudi Arabia           -25.259275\nIndonesia              -22.420333\nUnited Arab Emirates   -20.462293\nPhilippines            -19.436562\nIsrael                 -18.132356\nMexico                 -17.725355\nAustria                -17.596809\nChile                  -17.570066\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      India\n      Russia\n    \n    \n      1\n      USA\n      UK\n    \n    \n      2\n      Saudi Arabia\n      Australia\n    \n    \n      3\n      Indonesia\n      France\n    \n    \n      4\n      United Arab Emirates\n      Germany\n    \n    \n      5\n      Philippines\n      Ukraine\n    \n    \n      6\n      Israel\n      South Korea\n    \n    \n      7\n      Mexico\n      Italy\n    \n    \n      8\n      Austria\n      Cuba\n    \n    \n      9\n      Chile\n      Kazakhstan\n    \n  \n\n\n\n\n\n\n\n\nGDPCorr=scatter_combo(df_,'Population','number_of_medals')\nGDPCorr\n\nCorrelation of  = 0.42 (7e-06) \n            And m= 0.113 b=20.6          \nCountries worst correlation where overachive Nation\nUSA            275.692534\nRussia         172.705692\nUK             151.769692\nGermany         96.889859\nFrance          89.679993\nAustralia       86.426756\nChina           78.529401\nJapan           69.159606\nItaly           55.694604\nSouth Korea     53.504928\ndtype: float64\nCountries worst correlation where unachieve Nation\nIndia          -165.076115\nIndonesia       -41.444198\nNigeria         -40.164409\nPhilippines     -32.332446\nVietnam         -28.785832\nEgypt           -26.362309\nSudan           -24.687085\nUganda          -24.492699\nSaudi Arabia    -23.601957\nCameroon        -22.395235\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      India\n      USA\n    \n    \n      1\n      Indonesia\n      Russia\n    \n    \n      2\n      Nigeria\n      UK\n    \n    \n      3\n      Philippines\n      Germany\n    \n    \n      4\n      Vietnam\n      France\n    \n    \n      5\n      Egypt\n      Australia\n    \n    \n      6\n      Sudan\n      China\n    \n    \n      7\n      Uganda\n      Japan\n    \n    \n      8\n      Saudi Arabia\n      Italy\n    \n    \n      9\n      Cameroon\n      South Korea\n    \n  \n\n\n\n\n\n\n\n\nscatter_combo(df_[df_['Continent']=='Europe'],'Population','number_of_medals')\n\nCorrelation of  = 0.93 (2e-16) \n            And m= 1.498 b=5.2          \nCountries worst correlation where overachive Nation\nUK                74.302826\nHungary           23.300286\nNetherlands       23.269039\nBelarus           19.808781\nDenmark           17.002417\nFrance            11.114933\nCroatia            9.991807\nCzech Republic     5.060035\nSlovenia           4.658317\nLithuania          4.630427\ndtype: float64\nCountries worst correlation where unachieve Nation\nPoland     -31.142356\nSpain      -24.255647\nPortugal   -16.682378\nRussia     -15.733456\nAustria    -14.709259\nRomania    -12.930475\nBelgium    -11.649525\nItaly      -10.448382\nGreece      -8.813758\nUkraine     -8.812069\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      Poland\n      UK\n    \n    \n      1\n      Spain\n      Hungary\n    \n    \n      2\n      Portugal\n      Netherlands\n    \n    \n      3\n      Russia\n      Belarus\n    \n    \n      4\n      Austria\n      Denmark\n    \n    \n      5\n      Romania\n      France\n    \n    \n      6\n      Belgium\n      Croatia\n    \n    \n      7\n      Italy\n      Czech Republic\n    \n    \n      8\n      Greece\n      Slovenia\n    \n    \n      9\n      Ukraine\n      Lithuania\n    \n  \n\n\n\n\n\n\n\n\nscatter_combo(df_[df_['Continent']!='Europe'],'Population','number_of_medals')\n\nCorrelation of  = 0.49 (2e-05) \n            And m= 0.109 b=14.0          \nCountries worst correlation where overachive Nation\nUSA            283.666410\nAustralia       93.134297\nChina           90.957076\nJapan           76.277923\nSouth Korea     60.318993\nCanada          40.727568\nCuba            33.748715\nKazakhstan      27.859642\nNew Zealand     25.400672\nAzerbaijan      19.852149\ndtype: float64\nCountries worst correlation where unachieve Nation\nIndia          -152.808654\nIndonesia       -33.720543\nNigeria         -32.669700\nPhilippines     -25.269105\nVietnam         -21.778878\nEgypt           -19.334337\nSudan           -17.902477\nUganda          -17.715178\nSaudi Arabia    -16.856911\nCameroon        -15.694183\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      India\n      USA\n    \n    \n      1\n      Indonesia\n      Australia\n    \n    \n      2\n      Nigeria\n      China\n    \n    \n      3\n      Philippines\n      Japan\n    \n    \n      4\n      Vietnam\n      South Korea\n    \n    \n      5\n      Egypt\n      Canada\n    \n    \n      6\n      Sudan\n      Cuba\n    \n    \n      7\n      Uganda\n      Kazakhstan\n    \n    \n      8\n      Saudi Arabia\n      New Zealand\n    \n    \n      9\n      Cameroon\n      Azerbaijan\n    \n  \n\n\n\n\n\n\n\n\nscatter_combo(df_[df_['Continent']=='Europe'],'GDP','number_of_medals')\n\nCorrelation of  = 0.80 (6e-09) \n            And m= 45.027 b=10.1          \nCountries worst correlation where overachive Nation\nRussia            133.114656\nUK                 47.990590\nUkraine            40.906665\nBelarus            26.198814\nHungary            25.932286\nCroatia             8.392025\nCzech Republic      4.946635\nDenmark             4.919196\nNetherlands         3.836572\nSerbia              2.527421\ndtype: float64\nCountries worst correlation where unachieve Nation\nGermany       -54.463232\nSwitzerland   -25.766716\nAustria       -25.402938\nBelgium       -22.291826\nIreland       -18.937224\nPortugal      -16.500704\nSpain         -15.776437\nFinland       -14.300792\nItaly         -12.028820\nSweden        -10.294891\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      Germany\n      Russia\n    \n    \n      1\n      Switzerland\n      UK\n    \n    \n      2\n      Austria\n      Ukraine\n    \n    \n      3\n      Belgium\n      Belarus\n    \n    \n      4\n      Ireland\n      Hungary\n    \n    \n      5\n      Portugal\n      Croatia\n    \n    \n      6\n      Spain\n      Czech Republic\n    \n    \n      7\n      Finland\n      Denmark\n    \n    \n      8\n      Italy\n      Netherlands\n    \n    \n      9\n      Sweden\n      Serbia\n    \n  \n\n\n\n\n\n\n\n\nscatter_combo(df_[df_['Continent']!='Europe'],'GDP','number_of_medals')\n\nCorrelation of  = 0.94 (2e-33) \n            And m= 16.234 b=8.7          \nCountries worst correlation where overachive Nation\nAustralia      79.660038\nSouth Korea    44.796081\nCuba           38.591086\nKazakhstan     32.508245\nKenya          28.660696\nNew Zealand    27.815933\nAzerbaijan     25.573605\nCanada         23.586944\nJamaica        23.041050\nBrazil         19.812142\ndtype: float64\nCountries worst correlation where unachieve Nation\nIndia                  -40.315038\nSaudi Arabia           -19.100124\nIndonesia              -15.916697\nUSA                    -14.609781\nUnited Arab Emirates   -14.571357\nPhilippines            -13.602977\nIsrael                 -12.259868\nChile                  -11.840843\nVenezuela              -11.565125\nMexico                 -11.204664\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      India\n      Australia\n    \n    \n      1\n      Saudi Arabia\n      South Korea\n    \n    \n      2\n      Indonesia\n      Cuba\n    \n    \n      3\n      USA\n      Kazakhstan\n    \n    \n      4\n      United Arab Emirates\n      Kenya\n    \n    \n      5\n      Philippines\n      New Zealand\n    \n    \n      6\n      Israel\n      Azerbaijan\n    \n    \n      7\n      Chile\n      Canada\n    \n    \n      8\n      Venezuela\n      Jamaica\n    \n    \n      9\n      Mexico\n      Brazil\n    \n  \n\n\n\n\n\n\n\n\ndf_GDP=copy.copy(df_[['Nation','Continent','GDP']])\n\ndf_GDP = df_GDP.sort_values('GDP',ascending=False)\ndf_GDP\nrich_list = df_GDP.head(52).index\n# # index_not_rich=[i for i,country in enumerate(df_.index) if (country not in rich_list) and (df_.iloc[i,2]!='Europe') and (df_.index[i]!='India')]\n# # index_rich=[i for i,country in enumerate(df_.index) if ( (df_.iloc[i,2]!='Europe') )]\nindex_rich=[i for i,country in enumerate(df_.index) if (country in rich_list) ]\nindex_not_rich=[i for i,country in enumerate(df_.index) if (country not in rich_list) ]\n\nprint('         Index Rich- Population')\ngetCorr(df_.iloc[index_rich,:],'Population','number_of_medals')\nprint('         Index Not Rich- Population')\ngetCorr(df_.iloc[index_not_rich,:],'Population','number_of_medals')\nprint('         Index Rich- GDP')\ngetCorr(df_.iloc[index_rich,:],'GDP','number_of_medals')\nprint('         Index Not Rich- GDP')\ngetCorr(df_.iloc[index_not_rich,:],'GDP','number_of_medals')\n\n         Index Rich- Population\nPearson Correlation of  = 0.37 (6e-03)\nSpearman Correlation of  = 0.30 (3e-02)\n         Index Not Rich- Population\nPearson Correlation of  = 0.17 (2e-01)\nSpearman Correlation of  = 0.15 (3e-01)\n         Index Rich- GDP\nPearson Correlation of  = 0.84 (7e-15)\nSpearman Correlation of  = 0.50 (2e-04)\n         Index Not Rich- GDP\nPearson Correlation of  = 0.32 (2e-02)\nSpearman Correlation of  = 0.38 (6e-03)\n\n\n\nprint('         Index Europe- GDP')\ngetCorr(df_[df_['Continent']=='Europe'],'GDP','number_of_medals')\nprint('         Index Not Europe- GDP')\ngetCorr(df_[df_['Continent']!='Europe'],'GDP','number_of_medals')\n\nprint('         Index Europe- Population')\ngetCorr(df_[df_['Continent']=='Europe'],'Population','number_of_medals')\nprint('         Index Not Europe- Population')\ngetCorr(df_[df_['Continent']!='Europe'],'Population','number_of_medals')\n\n         Index Europe- GDP\nPearson Correlation of  = 0.80 (6e-09)\nSpearman Correlation of  = 0.71 (1e-06)\n         Index Not Europe- GDP\nPearson Correlation of  = 0.94 (2e-33)\nSpearman Correlation of  = 0.51 (1e-05)\n         Index Europe- Population\nPearson Correlation of  = 0.93 (2e-16)\nSpearman Correlation of  = 0.81 (3e-09)\n         Index Not Europe- Population\nPearson Correlation of  = 0.49 (2e-05)\nSpearman Correlation of  = 0.42 (3e-04)\n\n\n\nprint('GDP'),getCorr(df_,'GDP','number_of_medals')\nprint('Population'),getCorr(df_,'Population','number_of_medals')\n\nGDP\nPearson Correlation of  = 0.84 (4e-29)\nSpearman Correlation of  = 0.60 (2e-11)\nPopulation\nPearson Correlation of  = 0.42 (7e-06)\nSpearman Correlation of  = 0.41 (1e-05)\n\n\n(None, None)"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#overview-of-gdp-and-population",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#overview-of-gdp-and-population",
    "title": "Olympics data with SQL and pandas- GDP and population",
    "section": "Overview of GDP and population",
    "text": "Overview of GDP and population\n\nHypothesis: GDP is correlated with Medals, and Population is too but less so\n\n\nMethods Used\nLooking at number of medals against GDP and population, for a period from 2008-2016 inclusive. Using population and GDP data from ~2020. - scatter plots - to visualize the relationships between medals and GDP, and medals and population. Both show a correlation - Pearson & Spearman correlation - To quatify the correlation seen. Pearson looks for a linear relationship whereas Spearman considers the ordering of the variables. The Pearson results showed a moderate to strong relationship for GDP and a weak to moderate relationship for population. The Spearman results were similar (more correlation for GDP) but the correlation values were lower. - I considered looking at the changes with time, but there were a lot of factors affecting country participation and the data was harder to obtain easily\n\n\nOverview\nResults were mainly as expected and hence PROVED.\n\nGDP\n\n\nALL = strong AND significant\nEurope = strong AND significant\nNOT Europe = very strong AND significant\n\n\nPopulation\n\n\nALL = moderate AND significant\nEurope = very strong AND significant\nNOT Europe = moderate AND significant\n\nUsing a line fit of the data (GDP or Population to Medals) gives an indication of which countries are reducing the correlation. If the country has more medals than the fit then it is overachieve and if it has less it is underachieveing. The table below shows which countries are under and overachieveing for GDP and population.\n\n\nGDPCorr.rename(columns={'Overachieve':'GDP - Overachieve','Underachieve':'GDP - Underachieve'},inplace=True)\npopCorr.rename(columns={'Overachieve':'Population - Overachieve','Underachieve':'Population - Underachieve'},inplace=True)\n\ncorrComb=pd.concat([GDPCorr,popCorr],axis=1)\ncorrComb\n\n\n\n\n\n  \n    \n      \n      GDP - Underachieve\n      GDP - Overachieve\n      Population - Underachieve\n      Population - Overachieve\n    \n  \n  \n    \n      0\n      India\n      USA\n      India\n      Russia\n    \n    \n      1\n      Indonesia\n      Russia\n      USA\n      UK\n    \n    \n      2\n      Nigeria\n      UK\n      Saudi Arabia\n      Australia\n    \n    \n      3\n      Philippines\n      Germany\n      Indonesia\n      France\n    \n    \n      4\n      Vietnam\n      France\n      United Arab Emirates\n      Germany\n    \n    \n      5\n      Egypt\n      Australia\n      Philippines\n      Ukraine\n    \n    \n      6\n      Sudan\n      China\n      Israel\n      South Korea\n    \n    \n      7\n      Uganda\n      Japan\n      Mexico\n      Italy\n    \n    \n      8\n      Saudi Arabia\n      Italy\n      Austria\n      Cuba\n    \n    \n      9\n      Cameroon\n      South Korea\n      Chile\n      Kazakhstan\n    \n  \n\n\n\n\nSo based on the above it may make sense to group countries based on their GDP, into a rich and poor list. But as shown above this doesn’t increase the correlation for either group.\nThe only useful metric to increase the correlation was to group the countries into those from Europe. This is probably due to the similarity of countries within Europe (and outside): size, GDP but also culturally; and it may be because the European countries have much greater participation at the Olympics (both over currently and historically).\n\n\nGuide on Correlation\n\npd.DataFrame({'Correlation':['1','0.8 - 1.0','0.6 - 0.8','0.4 - 0.6','0.2 - 0.4','0 - 0.2'],\\\n   'Interpretation':['Pefect','Strong to Perfect','Moderate to Very Strong','Moderate to strong','Weak to moderate','Zero to weak']})\n\n\n\n\n\n\n  \n    \n      \n      Correlation\n      Interpretation\n    \n  \n  \n    \n      0\n      1\n      Pefect\n    \n    \n      1\n      0.8 - 1.0\n      Strong to Perfect\n    \n    \n      2\n      0.6 - 0.8\n      Moderate to Very Strong\n    \n    \n      3\n      0.4 - 0.6\n      Moderate to strong\n    \n    \n      4\n      0.2 - 0.4\n      Weak to moderate\n    \n    \n      5\n      0 - 0.2\n      Zero to weak\n    \n  \n\n\n\n\nTo determine whether the correlation between variables is significant, compare the p-value to your significance level. Usually, a significance level (denoted as α or alpha) of 0.05 works well. An α of 0.05 (5e-2) indicates that the risk of concluding that a correlation exists—when, actually, no correlation exists—is 5%. The p-value tells you whether the correlation coefficient is significantly different from 0. (A coefficient of 0 indicates that there is no linear relationship.)\n\n- P-value ≤ α (5e-2): The correlation is statistically significant\n    If the p-value is less than or equal to the significance level, then you can conclude that the correlation is different from 0. \n- P-value > α (5e-2): The correlation is not statistically significant\n    If the p-value is greater than the significance level, then you cannot conclude that the correlation is different from 0. \n    \nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6107969/\nhttps://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/correlation/interpret-the-results/"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#number-of-athletes",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#number-of-athletes",
    "title": "Olympics data with SQL and pandas- GDP and population",
    "section": "Number of athletes",
    "text": "Number of athletes\nA metric that would make sense to correlate with medals would be the number of athletes each nation sends to an Olympics. This is because, for the most part, participation is done on merit. That is athletes have to qualify against athletes from other nations.\nSo the metrics we want to look at are: - the number of athletes per nation attending a particular games - the number of medals per nation per games\nNB I will just use male athletes for simplicity\n\nChange in average athletes per continent\nFirst, let us look if the greater number of athletes from Europe is also reflected in the average number of athletes each nation sends within each continent.\nAs shown below European countries send around twice as many athletes per nation as other continents.\n\ntempa= sqldf('SELECT                                     \\\n            Year,                                        \\\n             Continent,                                  \\\n             AVG(numbers)  as ath_per_nation             \\\n        FROM(SELECT                                      \\\n            c.Continent,                                 \\\n            a.Year,\\\n            COUNT(*)           AS numbers                \\\n            FROM                                         \\\n                df_country as c                          \\\n            LEFT JOIN                                    \\\n                df_M_S as a                              \\\n            ON                                           \\\n                a.NOC = c.NOC                            \\\n            GROUP BY                                     \\\n                a.Year,c.Continent,c.Nation              \\\n            ORDER BY                                     \\\n                Year asc) A                              \\\n            GROUP BY                                     \\\n                 Year,Continent;',locals())\n\nplt.subplots(figsize=(8,5))\ncola=['g>--','<r-.','bo-','mv-','kp:']\nfor i,continent in enumerate(tempa.Continent.unique()):\n    x=tempa[tempa.Continent==continent]['Year']\n    y=tempa[tempa.Continent==continent]['ath_per_nation']\n    plt.plot(x,y,cola[i]);\nplt.legend(tempa.Continent.unique());\nplt.ylim([-5,200])\nplt.grid(True)\nplt.xlabel('Year')\nplt.ylabel('Number of male athletes\\n per nation');\n\n\n\n\n\n\nAthletes per nation VS medals per nation\nTo look at this correlation we need to do the following steps: - Join athletes with country tables - Group by Nation and whether they have a medal - Count this, this will give number of events with a medal - Then need to remove nations that didn’t get any medals - Get scatter and correlation of these - Group by continent and do the same\n\ntempa= sqldf('SELECT                                     \\\n             Continent,                                  \\\n             Nation,                                     \\\n             Medal,                                      \\\n             SUM(numbers)   AS numbers                   \\\n        FROM(SELECT                                      \\\n            c.Continent,                                 \\\n            c.Nation,                                    \\\n            a.Medal,                                     \\\n            COUNT(*)           AS numbers                \\\n            FROM                                         \\\n                df_country as c                          \\\n            LEFT JOIN                                    \\\n                df_M_S as a                              \\\n            ON                                           \\\n                a.NOC = c.NOC                            \\\n            WHERE Year>2003                              \\\n            GROUP BY                                     \\\n                c.Continent,c.Nation,a.Medal_Gold,a.Medal_Silver,a.Medal_Bronze) A          \\\n            GROUP BY                                     \\\n                Continent, Nation,Medal;',locals())\n\ntempa2= sqldf('SELECT                                     \\\n             Nation,                                     \\\n             COUNT(numbers)   AS numbers                 \\\n        FROM(SELECT                                      \\\n            a.athlete_ID,                                \\\n            c.Nation,                                    \\\n            COUNT(*)           AS numbers                \\\n            FROM                                         \\\n                df_country as c                          \\\n            LEFT JOIN                                    \\\n                df_F_S as a                              \\\n            ON                                           \\\n                a.NOC = c.NOC                            \\\n            WHERE Year=2016                              \\\n            GROUP BY                                     \\\n                c.NOC,a.athlete_ID,a.Year) A             \\\n            GROUP BY                                     \\\n                Nation;',locals())\n\ntempa3= tempa[tempa.Medal==1]\ntempa4=sqldf('\\\n    SELECT A.Nation,A.numbers as num_medals,B.numbers as num_ath                 \\\n    FROM tempa3 as A                              \\\n    LEFT JOIN tempa2 as B                         \\\n    ON A.Nation=B.Nation                          \\\n;',locals())\ntempa4\n\n\n\n\n\n  \n    \n      \n      Nation\n      num_medals\n      num_ath\n    \n  \n  \n    \n      0\n      Algeria\n      4\n      10.0\n    \n    \n      1\n      Botswana\n      1\n      3.0\n    \n    \n      2\n      Egypt\n      9\n      37.0\n    \n    \n      3\n      Eritrea\n      1\n      1.0\n    \n    \n      4\n      Ethiopia\n      12\n      20.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      UK\n      245\n      159.0\n    \n    \n      96\n      Ukraine\n      51\n      117.0\n    \n    \n      97\n      Australia\n      251\n      212.0\n    \n    \n      98\n      Fiji\n      13\n      17.0\n    \n    \n      99\n      New Zealand\n      44\n      97.0\n    \n  \n\n100 rows × 3 columns\n\n\n\n\ntempa4=tempa4.dropna()\nx=tempa4.num_ath\ny=tempa4.num_medals\n\nplt.subplots(figsize=(8,5))\nplt.scatter(x,y)\na=scipy.stats.spearmanr(x,y)\nb=scipy.stats.pearsonr(x,y)\nprint('Spearman correlation = {:.2f} ({:.0e}) \\nand Pearson correlation= {:.2f} ({:.0e})'\\\n      .format(a[0],a[1],b[0],b[1]))\n\nplt.grid(True)\nplt.xlabel('Athletes per nation')\nplt.ylabel('Medals per nation');\n\np=np.poly1d( np.polyfit(x,y,2) )\nxx=np.arange(0,300,2)\nyy=p(np.arange(0,300,2))\n\nplt.plot(xx,yy);\n\nSpearman correlation = 0.83 (3e-26) \nand Pearson correlation= 0.87 (5e-32)\n\n\n\n\n\n\n\nOverview Medals VS Athletes per nation\nAs was expected there is a good correlation between the number of athletes a nation sends and the number of medals they get\nWhat may also have been expected and shown in the data, is that the relationship is not linear. Instead the more athletes a nation sends the greater the medals/athlete ratio.\ni.e. If a nation sends more athletes it is more likely that a higher proportion of them will win medals"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#cold-war",
    "href": "posts/PROJECTS/Olympic_athletes/OlympicsSQL_GDPpopulation.html#cold-war",
    "title": "Olympics data with SQL and pandas- GDP and population",
    "section": "Cold War",
    "text": "Cold War\nThe Cold War was a period of geopolitical tension between the United States and the Soviet Union and their respective allies, the Western Bloc and the Eastern Bloc, which began following World War II and ended in the early 1990s.\nThe conflict was based around the ideological and geopolitical struggle for global influence by these two superpowers.\nThe Soviet Union competed at the Olympics from 1952-1988. The Russian Empire had previously competed at the 1900, 1908 and 1912 Olympics games. In these games the best they ranked was 12th. In contrast the USA competed from the start of the Olympics and all subsequent games. In 1952 they were the most succesful nation, coming 1st in the medals table in 8 out of the previous 11 games (and second in the other 3).\nThe figures below show how during the Cold War period, The Soviet Union was able to compete with USA and in some cases beat them in the medals table. After this Cold War period the medals obtained by both the USA and the Soviet Union fell with respect to the totals from the European nations. Furthermore, USA reasserted it’s dominance after the Cold War period.\nWikipedia Cold War\n\ndef number_of_athletes_USA_USSR(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                 \\\n        Year,                              \\\n        NOCSMALL,                          \\\n        count(*) AS number_of_athletes,     \\\n        \"F\" AS Sex                          \\\n    FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_F_S                       \\\n         group by athlete_ID,Year               \\\n         order by Year asc) A              \\\n     GROUP BY Year, NOCSMALL               \\\n     UNION ALL                                 \\\n     SELECT                                \\\n        Year,                              \\\n        NOCSMALL,                          \\\n        count(*) AS number_of_athletes,     \\\n        \"M\" AS Sex                          \\\n    FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_M_S                       \\\n         group by athlete_ID,Year          \\\n         order by Year asc) A              \\\n     GROUP BY Year, NOCSMALL;',locals()  )\n    return testa2\n\ndef number_of_medals_USA_USSR(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                 \\\n            COUNT(*) AS number_of_medals,\\\n            Year, Sex, NOCSMALL\\\n        FROM \\\n        (SELECT NOCSMALL,Year,Sex,COUNT(*) AS counta\\\n        FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         event_ID,                          \\\n         \"F\"   AS Sex,                      \\\n         Medal_Gold,Medal_Silver,Medal_Bronze,\\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_F_S                       \\\n         WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1\\\n         UNION ALL                                 \\\n         SELECT                           \\\n         athlete_ID,                        \\\n         event_ID,                          \\\n         \"M\" AS Sex,                       \\\n         Medal_Gold,Medal_Silver,Medal_Bronze,\\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_M_S                       \\\n         WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1\\\n         order by Year asc) A\\\n     GROUP BY \\\n         Year, NOCSMALL,event_id,Medal_Gold,Medal_Silver,Medal_Bronze)  AS B\\\n GROUP BY Year, NOCSMALL, Sex\\\n                 ;',locals()  )                                       \n    return testa2\n\n\nUSA_USSR_medals=number_of_medals_USA_USSR(df_F_S,df_M_S)\nUSA_USSR_athletes=number_of_athletes_USA_USSR(df_F_S,df_M_S)\n\n\ndef yrplot(df__,whatplot= 'avg_weight'): \n    \n    countries=['EST', 'EUN' ,'ROW', 'USA' ,'WES']\n    \n#     df__.NOCSMALL.unique()\n#     countries=np.sort(countries)\n    print(countries)\n    cola=['>','o','+','*','<']\n    colur=[[1,0.6,.6],[1,0,0],[.5,.5,.5],[0,0,1],[.6,.6,1]]\n#     ['EST' 'EUN' 'ROW' 'USA' 'WES']\n#     'EST','USA','WES','ROW','EUN'\n\n    fig,ax1=plt.subplots(figsize=(8,5))\n    \n    for i,country in enumerate(countries):\n        if country!='ROW':\n            ax1.plot(df__[df__.NOCSMALL==country].Year,\\\n                 df__[df__.NOCSMALL==country][whatplot],\\\n                 marker=cola[i],linestyle='None',color=colur[i]\\\n                 ,markersize=10)\n\n\n    def doPlot(df_F,avgNo,whatplot,country,col,lw,ax1):\n        bb = df_F[df__.NOCSMALL==country].Year.rolling(avgNo).mean()\n        cc = df_F[df__.NOCSMALL==country][whatplot]\n        cc = cc.rolling(avgNo).mean()\n        ax1.plot(bb,cc,linewidth=lw,color=col)\n        return ax1\n\n    for i,country in enumerate(countries):\n        if country!='ROW':\n            ax1=doPlot(df__,avgNo=3,whatplot=whatplot,country=country,col=colur[i],lw=3,ax1=ax1)\n    \n    lega = ['East Europe','Russia','USA','West Europe']\n    plt.legend(lega)\n    plt.grid(True)\n    plt.ylabel(modname(whatplot))\n    \n    return ax1\n\n\nyrplot(USA_USSR_medals[USA_USSR_medals.Sex=='F'],whatplot= 'number_of_medals')\n\n\n\nyrplot(USA_USSR_medals[USA_USSR_medals.Sex=='M'],whatplot= 'number_of_medals')"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#overview",
    "href": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#overview",
    "title": "Olympics data with SQL and pandas- home games",
    "section": "Overview",
    "text": "Overview\nThis is part of a project that looks at an Olympics dataset.\nIn this part the hypothesis considered is:\nAt a home Olympic games a nation will on average obtain more medals than at other games\n\nBut can we quantify this effect?\nAre there any residual effects before and after the games?\nWhat about a home continent games?"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#methodology",
    "href": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#methodology",
    "title": "Olympics data with SQL and pandas- home games",
    "section": "Methodology",
    "text": "Methodology\nTo be able to answer the question, the steps taken are as follows. Note the data and tables created in a previous page.\n\nCreate table of medal athletes as athlete\n\nMedals\nYear\nNOC\nOthers? Sex, number_of_athletes\n\nJoin athlete table to country table to get the country added to athlete\n\nNow the next step is trickier. There are several ways we could look at the effect of a home game and the nearness to it. The way I like to do this is to visualise the plot(s) I would like and work back from that.\nThe plot I’d like is: - x-axis = year from games (0 = at the games, +ve after and -ve before) - y-axis = number of medals\nIf we normalise the y-axis we can put all the events together to get an effect of games, before and after. We can also pick out individual games or do the averageing on different time-periods.\nSo to achieve this we need a vector for each games of: - Year from games - Number of medals\nThere are a number of potential problems with this: 1. If a nation holds two games close to each other 1. Normally games are every 4 years but how do we deal with exceptions to this? 1. What do we do when there is a lack of data before or after the games? e.g. games at the start of Olympics or current games, or if a nation stops partipation 1. When looking at the effect of continent, the approach would need to be adjusted based on there being fewer continents and most games being in Europe\n\ncan be solved by reducing the times to +- 20 years, and because we are averageing any exceptions should be covered\na way to solve this is to fit the data across the years/medals data we have with a function then use the function to give us values on a set scale (e.g. -20 to 20 in steps of 4 yrs)\na bit trickier, may we fit values that have positive and negative values up to 20 yrs first. Then if an event has a gap in years fill with the average values below and above 0 yrs\nfor this maybe just look at a partcular game based on recent games that are not in the same continent"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#some-starting-code",
    "href": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#some-starting-code",
    "title": "Olympics data with SQL and pandas- home games",
    "section": "Some Starting Code",
    "text": "Some Starting Code\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandasql import sqldf\nimport copy\nimport numpy as np\nimport scipy.stats\n\n\ndf_F_S =pd.read_csv('data/athlete_F_S')\ndf_F_W=pd.read_csv('data/athlete_F_W')\ndf_M_S=pd.read_csv('data/athlete_M_S')\ndf_M_W=pd.read_csv('data/athlete_M_W')\n\ndf_all_athletes= pd.read_csv('data/all_athletes')\ndf_country= pd.read_csv('data/country')\n# df_event= pd.read_csv('data/event')\ndf_games= pd.read_csv('data/games')\n# df_population= pd.read_csv('data/population')\n\ndf_country = df_country.groupby('NOC').max()\n# df_country.head(10)\n\n\ndf_games.head()\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      games_id\n      City\n      Country\n      Year\n      Region\n      Summer\n      Winter\n      Latitude\n      Longitude\n    \n  \n  \n    \n      0\n      0\n      0\n      Athens\n      Greece\n      1896\n      Europe\n      1\n      0\n      37.9838\n      23.7275\n    \n    \n      1\n      1\n      1\n      Paris\n      France\n      1900\n      Europe\n      1\n      0\n      48.8566\n      2.3522\n    \n    \n      2\n      2\n      2\n      St. Louis\n      USA\n      1904\n      North America\n      1\n      0\n      38.6270\n      90.1994\n    \n    \n      3\n      3\n      3\n      Athens\n      Greece\n      1906\n      Europe\n      1\n      0\n      37.9838\n      23.7275\n    \n    \n      4\n      4\n      4\n      London\n      UK\n      1908\n      Europe\n      1\n      0\n      51.5072\n      0.1276"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#create-a-table-of-country-medals",
    "href": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#create-a-table-of-country-medals",
    "title": "Olympics data with SQL and pandas- home games",
    "section": "Create a table of Country & Medals",
    "text": "Create a table of Country & Medals\nThis first step is to create a table of athletes data that includes both women and men athletes from the summer games, we want the following columns: - The Olympic Year - The Nation - The Continent of the Nation - The number of medals the nation got that year\nBasically just UNION to join the male and female athletes- with some additions so we get the total number of medals per country\nFollowed by a JOIN on the country table to get more information about the countries.\n\ndef number_of_medals(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                                         \\\n            COUNT(*)              AS number_of_medals,                 \\\n            Year, NOC                                                  \\\n        FROM                                                           \\\n        (SELECT NOC,Year,COUNT(*) AS counta                            \\\n           FROM                                                        \\\n             (SELECT                                                   \\\n             athlete_ID,                                               \\\n             event_ID,                                                 \\\n             Medal_Gold,Medal_Silver,Medal_Bronze,                     \\\n             Year,                                                     \\\n             NOC                                                       \\\n             from df_F_S                                               \\\n             WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1    \\\n             UNION ALL                                                 \\\n             SELECT                                                    \\\n             athlete_ID,                                               \\\n             event_ID,                                                 \\\n             Medal_Gold,Medal_Silver,Medal_Bronze,                     \\\n             Year,                                                     \\\n             NOC                                                       \\\n             from df_M_S                                               \\\n             WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1    \\\n             order by Year asc) A                                      \\\n           GROUP BY                                                    \\\n             Year, NOC,event_id,Medal_Gold,Medal_Silver,Medal_Bronze)  AS B\\\n         GROUP BY Year, NOC                                            \\\n                 ;',locals()  )                                       \n    return testa2\n\ndef join_country(df_,df_country):\n    testa2=sqldf('\\\n        SELECT                             \\\n            c.NOC,c.Nation,c.Continent,    \\\n            a.number_of_medals,            \\\n            a.Year                         \\\n        FROM                               \\\n            df_ AS a                       \\\n        INNER JOIN                         \\\n            df_country AS c                \\\n        ON                                 \\\n            c.NOC=a.NOC                    \\\n        GROUP BY                           \\\n            c.NOC,a.Year                   \\\n     ;',locals()  ) \n    return testa2\n\ndf_medals=number_of_medals(df_F_S,df_M_S)\ndf_medals2=join_country(df_medals,df_country)\ndf_medals2.head()\n\n\n\n\n\n  \n    \n      \n      NOC\n      Nation\n      Continent\n      number_of_medals\n      Year\n    \n  \n  \n    \n      0\n      AFG\n      Afghanistan\n      Asia\n      1\n      2008\n    \n    \n      1\n      AFG\n      Afghanistan\n      Asia\n      1\n      2012\n    \n    \n      2\n      ALG\n      Algeria\n      Africa\n      2\n      1984\n    \n    \n      3\n      ALG\n      Algeria\n      Africa\n      2\n      1992\n    \n    \n      4\n      ALG\n      Algeria\n      Africa\n      3\n      1996"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#find-the-change-in-medals-around-a-home-games",
    "href": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#find-the-change-in-medals-around-a-home-games",
    "title": "Olympics data with SQL and pandas- home games",
    "section": "Find the change in medals around a home games",
    "text": "Find the change in medals around a home games\nThe easy solution here would be to take an average of the medals a country obtains obtains at a home games versus non-home games. However, this wouldn’t work mainly due to the changes in medals with time (they increase).\nWe could correct for overall changes in the number of medals by normalising based on the total number of medals in a games. This would be better, but we may need an extra step to account for the lack of diversity of nations in earlier years too.\nBut also we wouldn’t be able to see what effect a home games had before and after the games were held.\nTo observe how medal count is effected before and after a games, and to somewhat reduce the increase in medals with time, the following steps are taken.\n\nScoll through the games table for each summer games\nFor each game add data to the following variables (of length of the number of games) for each particular games\n\nnation the nation hosting the particular games\nmedals the number of medals for each games for the nation hosting the particular games, in all the other games\nyears the difference in years between the particular games and all other games\n\n\nFor example:\nUSA 1984, Los Angeles\n\nnation[20] is ‘USA’\nyears[20] is [-88, -84, -80, -78, -76, -72, -64, -60, -56, -52, -48, -36, -32,-28, -24, -20, -16, -12,  -8,   0,   4,   8,  12,  16,  20,  24, 28,  32]\n\nthe 0 being the 1984 games, and the 32 being the 2016 games\n\nmedals[20] is [ 19,  54, 230,  23,  46,  63,  95,  99,  56, 110,  57,  84,  76, 74,  71,  90, 107,   94,  94, 173,  94, 108, 101,  91, 101, 110, 103, 121]\n\nthe 173 being the number of medals obtained in 1984 and 121 in 2016\n\nCreate a vector for each games of medals against years around the home game.\n\n\nSince not all games are seperated by 4 years and some games can be missed the data needs to be interpolated onto a range in steps of 4 years. Outer bounds of +-28 years ae chosen\nWhen data is missing because the full range of data can’t be obtained (i.e. for recent games or ones near the start of Olympics) replace any missing values with 0\n\n\nAdd up all the vectors for different games\n\n\nignore games where the range isn’t full (-32->32)\nthis gives the average effect of a home games\n\n\n# Step 1 and 2\n\n# Since we just want the summer games\ndf_games=df_games[df_games.Summer==1].reset_index()\n\nmedals=[]\nyears=[]\nnation=[]\nfor i in range(len(df_games)):\n    country=df_games.loc[i,'Country']\n    year=df_games.loc[i,'Year']\n    \n    nation.append(country)\n    medals.append(df_medals2[df_medals2.Nation==country].number_of_medals.values)\n    years.append(df_medals2[df_medals2.Nation==country].Year.values - year)\n    \n\n\n\"\"\"\nStep 3\nFunction to interpolate number of medals in years around a games\nTakes as input x=years and y=number of medals and outputs a new x and y values \nthat have been interpolated between -28 to +28 years in steps of 4 years\nFor games where the full range can't be obtained (e.g. an event close to 2016 \nwill have missing data for years after it) the data is interpolated to the nearest \n4 years and missing data replaced with zeroes.\n\"\"\"\n\ndef do_interp(x,y):\n    from scipy.interpolate import interp1d\n    \n    xx,yy=x,y\n    xhi,xlo=28,-28\n    \n    xnew=np.arange(xlo,xhi+4,4)\n    ynew=np.zeros(np.shape(xnew))\n    # here make adjustments if the whole range doesn't exist to go to nearest 4 yrs\n    # or if inbetween go outside to next one i.e. 11 years->12 years, 8->8,-5->-8\n    # lower years are dealt with separately to later years then combined\n    # and normalised\n    maxx,minx=np.max(x),np.min(x)\n    if maxx<xhi:\n        xhi= 4*(np.ceil(maxx/4))\n        xx=xx[1:]\n        yy=yy[1:]\n    if minx>xlo:\n        xlo= -4*(np.ceil(abs(minx)/4))\n        xx=xx[:-1]\n        yy=yy[:-1]\n        \n    cond =((xnew<=xhi) & (xnew>=xlo))\n    try:\n        f2 = interp1d(x, y, kind='cubic')\n        ynew[cond]=f2(xnew[cond])\n    except:\n        f2 = interp1d(xx, yy, kind='cubic')\n        cond =((xnew<=xhi-4) & (xnew>=xlo+4))\n        ynew[cond]=f2(xnew[cond])\n    \n    ynew=ynew/max(ynew)\n    return xnew,ynew\n\n\n# Step 3\n\nXY=[]\nfor i,year_range in enumerate(years):\n    x=year_range\n    y=medals[i]\n    xnew,ynew=do_interp(x,y)\n    XY.append(np.array(ynew))\n    \n\n\nnp.shape(XY)\n\n(29, 15)\n\n\n\n# If values are less than 0 put as just above zero- can occur when \n\n# make XY a numpy array\nXY = np.array(XY)\n\n# if interpolation is not good\nXY[XY<0]=0\n\n\n\n\n# create vectors for y-data either side of home-event\nyallL = np.zeros((8))\nyallR = np.zeros((8))\n\n# scroll through each games\n# find if the low years or high years have zeros in them\n# if they don't include them in the sum \nfor i,ygames in enumerate(XY):\n    \n    if i>11:\n        if 0 not in ygames[-8:]:\n            yallL[-8:]=yallL[-8:]+ygames[-8:]\n        \n        if 0 not in ygames[0:8]:\n            yallR[0:8]=yallR[0:8]+ygames[0:8]\n            \n\n# normalise\nyallL=yallL/max(yallL)\nyallR=yallR/max(yallR)\n\n# combine low and high years and only use home game year once\nyall=np.concatenate([yallR[0:-1],yallL])\n\n# plot the results\nplt.subplots(figsize=(6,4))\nplt.plot(xnew,yall/max(yall),'ok-')\n\nplt.ylim([0 ,1.05])\nplt.grid(True)\nplt.ylabel('Normalise medals won',fontsize=14)\nplt.xlabel('Years either side of a home games',fontsize=14)\n# plt.plot(xnew,yall2/max(yall2),'m+--')\n\nText(0.5, 0, 'Years either side of a home games')"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#plot-the-effect-of-home-games-for-different-games",
    "href": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#plot-the-effect-of-home-games-for-different-games",
    "title": "Olympics data with SQL and pandas- home games",
    "section": "Plot the effect of home games for different games",
    "text": "Plot the effect of home games for different games\nLook at the individual games plots\n\n\nstartnum=11\n\ncola=['mo--','gs:','bv-.']\nfor i2 in range(6):\n    fig,ax=plt.subplots()\n    vals = np.arange(startnum,startnum+3,1,dtype=int)\n    i1=0\n    for i in vals: \n        plt.plot(xnew,XY[i,:],cola[i1])\n        plt.ylim([-.2 ,1])\n        plt.grid(True)\n        plt.legend([ nation[ii] + ' ' + str(df_games.loc[ii,'Year']) for jj,ii in enumerate(vals)]);\n        plt.ylabel('Normalise medals won')\n        plt.xlabel('Years either side of a home games')\n        i1=i1+1\n    startnum=startnum+3"
  },
  {
    "objectID": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#continent-home-games",
    "href": "posts/PROJECTS/Olympic_athletes/Olympics_HomeEvent.html#continent-home-games",
    "title": "Olympics data with SQL and pandas- home games",
    "section": "Continent home games",
    "text": "Continent home games\nThe Olympics have mainly been held in Europe and North America. Because of this it is not possible to do the same analysis as for home country games.\nInstead we can look at the difference if a games is a home continent or not.\n\ncontinentYorN=sqldf('\\\n    SELECT                                     \\\n    home_continent,                            \\\n    Year,                                      \\\n    COUNT(*)         AS num_countries,         \\\n    AVG(avg_medals)  AS avg_medals             \\\n    FROM                                       \\\n      (SELECT                                  \\\n            Nation,home_continent, Year,       \\\n            AVG(number_of_medals)  AS avg_medals\\\n        FROM                                   \\\n            (SELECT                            \\\n               a.*,                            \\\n               CASE WHEN                       \\\n                  c.Region =a.Continent THEN 1 \\\n               ELSE 0 END AS home_continent    \\\n            FROM                               \\\n                df_medals2 AS a                \\\n            INNER JOIN                         \\\n                df_games AS c                  \\\n            ON                                 \\\n                c.Year=a.Year                  \\\n            WHERE c.Year> 1951) as inner       \\\n        GROUP BY                               \\\n            Nation, Year ) as midder           \\\n    GROUP BY home_continent,Year               \\\n     ;',locals()  ) \n\n\ncontinentYorN.head()\n\n\n\n\n\n  \n    \n      \n      home_continent\n      Year\n      num_countries\n      avg_medals\n    \n  \n  \n    \n      0\n      0\n      1952\n      20\n      7.450000\n    \n    \n      1\n      0\n      1956\n      36\n      11.944444\n    \n    \n      2\n      0\n      1960\n      21\n      7.095238\n    \n    \n      3\n      0\n      1964\n      34\n      13.470588\n    \n    \n      4\n      0\n      1968\n      35\n      11.285714\n    \n  \n\n\n\n\n\nfig,ax=plt.subplots(figsize=(8,5))\n\n\n\nplt.plot(continentYorN[continentYorN.home_continent==1].Year,continentYorN[continentYorN.home_continent==1].avg_medals,'rs--')\nplt.plot(continentYorN[continentYorN.home_continent==0].Year,continentYorN[continentYorN.home_continent==0].avg_medals,'ob--')\n\nplt.grid(True)\nplt.ylabel('Average medals')\nplt.xlabel('Games year')\n\n# plt.plot([df_games[df_games.Region=='Asia'].Year.values,df_games[df_games.Region=='Asia'].Year.values],[0,35],color=[1,.8,.8]);\n\nplt.plot([0,0],'m--');\nplt.plot([0,0],'g-.');\n\nplt.plot([df_games[df_games.Region=='Americas'].Year.values,df_games[df_games.Region=='Americas'].Year.values],[0,35],'m--');\n\n\nplt.plot([df_games[df_games.Region=='Europe'].Year.values,df_games[df_games.Region=='Europe'].Year.values],[0,35],'g-.');\n\n\n# plt.plot([df_games[df_games.Region=='Oceania'].Year.values,df_games[df_games.Region=='Oceania'].Year.values],[0,35],color=[0.7,1,.7]);\n\nplt.xlim([1950,2020])\n\nplt.legend(['Home continent','Another continent','Americas','Europe'])\n\n<matplotlib.legend.Legend at 0x1f4339ed580>\n\n\n\n\n\n\nNot a good measure\nInstead need following columns\n\ntotal or average medals per continent\nHome Continent\nYear\n\n\n\n\"\"\"\nA check on the inner part of the SQL  statement\n\n\"\"\"\n\nsqldf('\\\n    SELECT *   FROM                            \\\n        (SELECT                                \\\n               a.*,                            \\\n               CASE WHEN                       \\\n                  c.Region =a.Continent THEN 1 \\\n               ELSE 0 END AS home_continent    \\\n            FROM                               \\\n                df_medals2 AS a                \\\n            INNER JOIN                         \\\n                df_games AS c                  \\\n            ON                                 \\\n                c.Year=a.Year                  \\\n            WHERE c.Year> 1951) as inner       \\\n     ;',locals()  ) \n\n\n\n\n\n\n  \n    \n      \n      NOC\n      Nation\n      Continent\n      number_of_medals\n      Year\n      home_continent\n    \n  \n  \n    \n      0\n      ANZ\n      Australia\n      Oceania\n      11\n      1952\n      0\n    \n    \n      1\n      ARG\n      Argentina\n      Americas\n      5\n      1952\n      0\n    \n    \n      2\n      AUT\n      Austria\n      Europe\n      2\n      1952\n      1\n    \n    \n      3\n      BEL\n      Belgium\n      Europe\n      4\n      1952\n      1\n    \n    \n      4\n      BOH\n      Czech Republic\n      Europe\n      13\n      1952\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      960\n      UKR\n      Ukraine\n      Europe\n      11\n      2016\n      0\n    \n    \n      961\n      USA\n      USA\n      Americas\n      121\n      2016\n      0\n    \n    \n      962\n      UZB\n      Uzbekistan\n      Asia\n      13\n      2016\n      0\n    \n    \n      963\n      VEN\n      Venezuela\n      Americas\n      3\n      2016\n      0\n    \n    \n      964\n      VIE\n      Vietnam\n      Asia\n      2\n      2016\n      0\n    \n  \n\n965 rows × 6 columns\n\n\n\n\n\"\"\"\nThe complete SQL statement\n\n\"\"\"\n\ncontinentYorN2=sqldf('\\\n    SELECT \\\n      Year, sum(number_of_medals) AS num_medals, Continent,home_continent\\\n          FROM                                 \\\n        (SELECT                                \\\n               a.*,                            \\\n               CASE WHEN                       \\\n                  c.Region =a.Continent THEN 1 \\\n               ELSE 0 END AS home_continent    \\\n            FROM                               \\\n                df_medals2 AS a                \\\n            INNER JOIN                         \\\n                df_games AS c                  \\\n            ON                                 \\\n                c.Year=a.Year                  \\\n            WHERE c.Year> 1951) as inner       \\\n        GROUP BY Continent,Year, home_continent\\\n        ORDER BY Year\\\n     ;',locals()  ) \n\ncontinentYorN2.head()\n\n\n\n\n\n  \n    \n      \n      Year\n      num_medals\n      Continent\n      home_continent\n    \n  \n  \n    \n      0\n      1952\n      11\n      Africa\n      0\n    \n    \n      1\n      1952\n      100\n      Americas\n      0\n    \n    \n      2\n      1952\n      24\n      Asia\n      0\n    \n    \n      3\n      1952\n      308\n      Europe\n      1\n    \n    \n      4\n      1952\n      14\n      Oceania\n      0\n    \n  \n\n\n\n\n\nplt.subplots(figsize=(8,5))\nregion='Asia'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'or',markersize=10)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,':or')\n\nregion='Europe'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'bo',markersize=10)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'b--o')\n\nregion='Americas'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'m<',markersize=10)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'m-o')\n\nregion='Oceania'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'cv',markersize=10)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'c-o')\n\nplt.legend(['Asia','','Europe','','Americas','','Oceania',''])\nplt.grid(True)\n\n\n\n\n\nregion='Europe'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nasum=np.average(continentYorN2[cond].num_medals)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nbsum=np.average(continentYorN2[cond].num_medals)\n\nprint('For {} the average medals at home continent = {:.0f} and for away continent = {:.0f}\\n \\\n      With a ratio of {:.2f}'.format(region,asum,bsum,asum/bsum))\n\n\nregion='Asia'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nasum=np.average(continentYorN2[cond].num_medals)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nbsum=np.average(continentYorN2[cond].num_medals)\n\nprint('For {} the average medals at home continent = {:.0f} and for away continent = {:.0f}\\n \\\n      With a ratio of {:.2f}'.format(region,asum,bsum,asum/bsum))\n\nregion='Americas'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nasum=np.average(continentYorN2[cond].num_medals)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nbsum=np.average(continentYorN2[cond].num_medals)\n\nprint('For {} the average medals at home continent = {:.0f} and for away continent = {:.0f}\\n \\\n      With a ratio of {:.2f}'.format(region,asum,bsum,asum/bsum))\n\nregion='Oceania'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nasum=np.average(continentYorN2[cond].num_medals)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nbsum=np.average(continentYorN2[cond].num_medals)\n\nprint('For {} the average medals at home continent = {:.0f} and for away continent = {:.0f}\\n \\\n      With a ratio of {:.2f}'.format(region,asum,bsum,asum/bsum))\n\nFor Europe the average medals at home continent = 420 and for away continent = 396\n       With a ratio of 1.06\nFor Asia the average medals at home continent = 121 and for away continent = 103\n       With a ratio of 1.18\nFor Americas the average medals at home continent = 177 and for away continent = 130\n       With a ratio of 1.36\nFor Oceania the average medals at home continent = 50 and for away continent = 32\n       With a ratio of 1.57\n\n\nAgain the above stats are not really great as\n\ndon’t take account of changes in the average number of medals with time for a nation\ngames in Oceania and Americas are often also home games\n\nThe best metric uses Europe and suggests a less than 6% increase for a home continent"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/ChicagoBikes.html#introduction",
    "href": "posts/PROJECTS/Other_projects/ChicagoBikes.html#introduction",
    "title": "How Does a Bike-Share Navigate Speedy Success",
    "section": "Introduction",
    "text": "Introduction\nSome quick analysis on Cycle bike-share data from Chicago\nWelcome to the Cyclistic bike-share analysis case study! In this case study, you will perform many real-world tasks of a junior data analyst. You will work for a fictional company, Cyclistic, and meet different characters and team members. In order to answer the key business questions, you will follow the steps of the data analysis process: ask, prepare, process, analyze, share, and act. Along the way, the Case Study Roadmap tables — including guiding questions and key tasks — will help you stay on the right path. By the end of this lesson, you will have a portfolio-ready case study. Download the packet and reference the details of this case study anytime. Then, when you begin your job hunt, your case study will be a tangible way to demonstrate your knowledge and skills to potential employers.\n\nSome imports\n\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport numpy as np\nimport requests\n# from datetime import datetime, timezone\nimport os\nimport geopandas as gpd\n\n#get the current working directory\nowd=os.getcwd()"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/ChicagoBikes.html#a-function-to-extract-web-zip-files-and-save-to-dat-folder",
    "href": "posts/PROJECTS/Other_projects/ChicagoBikes.html#a-function-to-extract-web-zip-files-and-save-to-dat-folder",
    "title": "How Does a Bike-Share Navigate Speedy Success",
    "section": "A function to extract web zip files and save to /dat folder",
    "text": "A function to extract web zip files and save to /dat folder\n\nWe’ll just look at Q1 for 2020 data\nThe data for 2020 is split into Q1 and the rest is for each month. So we need to download and convert each to a data frame and then combine them together\n\ndef extractStuff(url):\n    import requests, zipfile, io\n    import os\n    owd=os.getcwd()\n    r = requests.get(url)\n    z = zipfile.ZipFile(io.BytesIO(r.content))\n    z.extractall(owd+\"/dat/\")\nURL=\"https://divvy-tripdata.s3.amazonaws.com/\"\nnoma =[['202004-divvy-tripdata'],\n['202005-divvy-tripdata'],\n['202006-divvy-tripdata'],\n['202007-divvy-tripdata'],\n['202008-divvy-tripdata'],\n['202009-divvy-tripdata'],\n['202010-divvy-tripdata'],\n['202011-divvy-tripdata'],\n['202012-divvy-tripdata']]\n    \n\n\nfor nom in noma:\n    extractStuff(URL+ nom[0]+\".zip\")\n\n\n\nLoad files, put in pandas data frame and have a look\n\nLets load each csv and combine them\n\nfor i,nom in enumerate(noma):\n    if i>0:\n        df=pd.read_csv(owd+\"/dat/\"+nom[0]+'.csv')\n        dfAll=pd.concat([df,dfAll])    \n        print('1 ',nom[0])\n    else:\n        dfAll=pd.read_csv(owd+\"/dat/\"+nom[0]+'.csv')\n        print('2',nom[0])\n\n2 202004-divvy-tripdata\n1  202005-divvy-tripdata\n1  202006-divvy-tripdata\n1  202007-divvy-tripdata\n1  202008-divvy-tripdata\n1  202009-divvy-tripdata\n1  202010-divvy-tripdata\n1  202011-divvy-tripdata\n1  202012-divvy-tripdata\n\n\n\n\n\nHow many NaN stations?\n\nprint('The percentage start stations NaN = {}'.format(100*np.shape(dfAll[dfAll['start_station_id'].isna()])[0] / np.shape(dfAll)[0]) )#95 282 3 114 796\n\nprint('The percentage end stations NaN = {}'.format(100*np.shape(dfAll[dfAll['end_station_id'].isna()])[0] / np.shape(dfAll)[0]) )#95 282 3 114 796\n\nbothNa=dfAll[dfAll['start_station_id'].isna() | dfAll['end_station_id'].isna()] \nprint('The percentage start stations NaN = {}'.format(100*np.shape(bothNa)[0] / np.shape(dfAll)[0]) )#95 282 3 114 796\n\nThe percentage start stations NaN = 3.059012532441932\nThe percentage end stations NaN = 3.5745840177013197\nThe percentage start stations NaN = 4.889597906251324\n\n\n\nimport copy\ndfUse=copy.copy(dfAll[dfAll['start_station_id'].notnull() & dfAll['end_station_id'].notnull()])\ndfUse.describe(include='all')\n\n\n\n\n\n  \n    \n      \n      ride_id\n      rideable_type\n      started_at\n      ended_at\n      start_station_name\n      start_station_id\n      end_station_name\n      end_station_id\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      count\n      2962495\n      2962495\n      2962495\n      2962495\n      2962495\n      2962495.0\n      2962495\n      2962495.0\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2962495\n    \n    \n      unique\n      2962287\n      3\n      2568216\n      2556286\n      689\n      1301.0\n      690\n      1304.0\n      NaN\n      NaN\n      NaN\n      NaN\n      2\n    \n    \n      top\n      C4EC57564F928A97\n      docked_bike\n      2020-09-07 15:19:26\n      2020-07-11 15:35:03\n      Streeter Dr & Grand Ave\n      35.0\n      Streeter Dr & Grand Ave\n      35.0\n      NaN\n      NaN\n      NaN\n      NaN\n      member\n    \n    \n      freq\n      2\n      2535257\n      12\n      13\n      32629\n      32192.0\n      34905\n      34467.0\n      NaN\n      NaN\n      NaN\n      NaN\n      1710201\n    \n    \n      mean\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.190534e+01\n      -8.764452e+01\n      4.190559e+01\n      -8.764481e+01\n      NaN\n    \n    \n      std\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.157203e-02\n      2.446731e-02\n      4.169299e-02\n      2.460637e-02\n      NaN\n    \n    \n      min\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.164850e+01\n      -8.777470e+01\n      4.164850e+01\n      -8.777470e+01\n      NaN\n    \n    \n      25%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.188316e+01\n      -8.765840e+01\n      4.188338e+01\n      -8.765862e+01\n      NaN\n    \n    \n      50%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.190096e+01\n      -8.764117e+01\n      4.190096e+01\n      -8.764182e+01\n      NaN\n    \n    \n      75%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.193120e+01\n      -8.762773e+01\n      4.193125e+01\n      -8.762775e+01\n      NaN\n    \n    \n      max\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.206490e+01\n      -8.752823e+01\n      4.206501e+01\n      -8.752823e+01\n      NaN\n    \n  \n\n\n\n\n\n\nNow we need to convert the dates from object (i.e. string) to date format\n\nnext add a new column as time for hire in hours\n\ndfUse.loc[:,'started_at']=pd.to_datetime(dfUse['started_at'],infer_datetime_format=True)\ndfUse.loc[:,'ended_at']=pd.to_datetime(dfUse['ended_at'],infer_datetime_format=True)\n\ndelta=dfUse.iloc[:,3]-dfUse.iloc[:,2]\ndd=delta.dt.total_seconds()/(60*60)\ndfUse.insert(2,\"hire_time_h\",dd)\ndfUse.head()\n\n\n\n\n\n  \n    \n      \n      ride_id\n      rideable_type\n      hire_time_h\n      started_at\n      ended_at\n      start_station_name\n      start_station_id\n      end_station_name\n      end_station_id\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      70B6A9A437D4C30D\n      classic_bike\n      0.176944\n      2020-12-27 12:44:29\n      2020-12-27 12:55:06\n      Aberdeen St & Jackson Blvd\n      13157\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.877726\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      39\n      15F369FDAED4E8E3\n      electric_bike\n      0.130556\n      2020-12-18 13:53:56\n      2020-12-18 14:01:46\n      Larrabee St & Armitage Ave\n      TA1309000006\n      Wells St & Walton St\n      TA1306000011\n      41.918112\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      50\n      0CFD61DFE00E6043\n      electric_bike\n      0.030000\n      2020-12-28 17:10:25\n      2020-12-28 17:12:13\n      Kingsbury St & Kinzie St\n      KA1503000043\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.889193\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      87\n      244CB936487039B7\n      docked_bike\n      1.013056\n      2020-12-10 13:36:16\n      2020-12-10 14:37:03\n      Clark St & Leland Ave\n      TA1309000014\n      Clark St & Leland Ave\n      TA1309000014\n      41.967096\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      88\n      B7AD5038F79637F9\n      classic_bike\n      0.101111\n      2020-12-20 13:09:04\n      2020-12-20 13:15:08\n      Dearborn St & Monroe St\n      TA1305000006\n      Kingsbury St & Kinzie St\n      KA1503000043\n      41.881320\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n  \n\n\n\n\n\n\nMaybe we want the day of the week?\nThe day of the week with Monday=0, Sunday=6.\n\ndfUse.insert(3,'day_week',dfUse.loc[:,'started_at'].dt.dayofweek)\ndfUse.head()\n\n\n\n\n\n  \n    \n      \n      ride_id\n      rideable_type\n      hire_time_h\n      day_week\n      started_at\n      ended_at\n      start_station_name\n      start_station_id\n      end_station_name\n      end_station_id\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      70B6A9A437D4C30D\n      classic_bike\n      0.176944\n      6\n      2020-12-27 12:44:29\n      2020-12-27 12:55:06\n      Aberdeen St & Jackson Blvd\n      13157\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.877726\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      39\n      15F369FDAED4E8E3\n      electric_bike\n      0.130556\n      4\n      2020-12-18 13:53:56\n      2020-12-18 14:01:46\n      Larrabee St & Armitage Ave\n      TA1309000006\n      Wells St & Walton St\n      TA1306000011\n      41.918112\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      50\n      0CFD61DFE00E6043\n      electric_bike\n      0.030000\n      0\n      2020-12-28 17:10:25\n      2020-12-28 17:12:13\n      Kingsbury St & Kinzie St\n      KA1503000043\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.889193\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      87\n      244CB936487039B7\n      docked_bike\n      1.013056\n      3\n      2020-12-10 13:36:16\n      2020-12-10 14:37:03\n      Clark St & Leland Ave\n      TA1309000014\n      Clark St & Leland Ave\n      TA1309000014\n      41.967096\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      88\n      B7AD5038F79637F9\n      classic_bike\n      0.101111\n      6\n      2020-12-20 13:09:04\n      2020-12-20 13:15:08\n      Dearborn St & Monroe St\n      TA1305000006\n      Kingsbury St & Kinzie St\n      KA1503000043\n      41.881320\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n  \n\n\n\n\n\n\n\nLets also get the time on its own\n\ndfUse.insert(4,'time_day',dfUse.loc[:,'started_at'].dt.hour + dfUse.loc[:,'started_at'].dt.minute/60)\ndfUse.head()\n\n\n\n\n\n  \n    \n      \n      ride_id\n      rideable_type\n      hire_time_h\n      day_week\n      time_day\n      started_at\n      ended_at\n      start_station_name\n      start_station_id\n      end_station_name\n      end_station_id\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      70B6A9A437D4C30D\n      classic_bike\n      0.176944\n      6\n      12.733333\n      2020-12-27 12:44:29\n      2020-12-27 12:55:06\n      Aberdeen St & Jackson Blvd\n      13157\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.877726\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      39\n      15F369FDAED4E8E3\n      electric_bike\n      0.130556\n      4\n      13.883333\n      2020-12-18 13:53:56\n      2020-12-18 14:01:46\n      Larrabee St & Armitage Ave\n      TA1309000006\n      Wells St & Walton St\n      TA1306000011\n      41.918112\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      50\n      0CFD61DFE00E6043\n      electric_bike\n      0.030000\n      0\n      17.166667\n      2020-12-28 17:10:25\n      2020-12-28 17:12:13\n      Kingsbury St & Kinzie St\n      KA1503000043\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.889193\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      87\n      244CB936487039B7\n      docked_bike\n      1.013056\n      3\n      13.600000\n      2020-12-10 13:36:16\n      2020-12-10 14:37:03\n      Clark St & Leland Ave\n      TA1309000014\n      Clark St & Leland Ave\n      TA1309000014\n      41.967096\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      88\n      B7AD5038F79637F9\n      classic_bike\n      0.101111\n      6\n      13.150000\n      2020-12-20 13:09:04\n      2020-12-20 13:15:08\n      Dearborn St & Monroe St\n      TA1305000006\n      Kingsbury St & Kinzie St\n      KA1503000043\n      41.881320\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n  \n\n\n\n\n\n\nAnd the distance travelled\n\ndef distanceLatLong(lat1,lon1,lat2,lon2):\n    \n    import numpy as np\n\n    def deg2rad(deg):\n        return deg * np.pi/180\n\n    R = 6371; # Radius of the earth in km\n    dLat = deg2rad(lat2-lat1)  # deg2rad below\n    dLon = deg2rad(lon2-lon1)\n    a = np.sin(dLat/2) * np.sin(dLat/2) + \\\n    np.cos(deg2rad(lat1)) * np.cos(deg2rad(lat2)) * \\\n    np.sin(dLon/2) * np.sin(dLon/2)\n\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    d = R * c ## Distance in km\n \n    return d\n\n\nd=distanceLatLong(dfUse[\"start_lat\"].values,dfUse[\"start_lng\"].values,dfUse[\"end_lat\"].values,dfUse[\"end_lng\"].values)\ndfUse.insert(11,'distance',d)\ndfUse.describe()\n\n\n\n\n\n  \n    \n      \n      hire_time_h\n      day_week\n      time_day\n      distance\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n    \n  \n  \n    \n      count\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n    \n    \n      mean\n      4.291666e-01\n      3.262215e+00\n      1.485441e+01\n      2.240406e+00\n      4.190534e+01\n      -8.764452e+01\n      4.190559e+01\n      -8.764481e+01\n    \n    \n      std\n      6.640800e+00\n      1.973614e+00\n      4.595529e+00\n      2.029178e+00\n      4.157203e-02\n      2.446731e-02\n      4.169299e-02\n      2.460637e-02\n    \n    \n      min\n      -4.841661e+02\n      0.000000e+00\n      0.000000e+00\n      0.000000e+00\n      4.164850e+01\n      -8.777470e+01\n      4.164850e+01\n      -8.777470e+01\n    \n    \n      25%\n      1.377778e-01\n      2.000000e+00\n      1.188333e+01\n      8.598642e-01\n      4.188316e+01\n      -8.765840e+01\n      4.188338e+01\n      -8.765862e+01\n    \n    \n      50%\n      2.525000e-01\n      3.000000e+00\n      1.550000e+01\n      1.713410e+00\n      4.190096e+01\n      -8.764117e+01\n      4.190096e+01\n      -8.764182e+01\n    \n    \n      75%\n      4.577778e-01\n      5.000000e+00\n      1.820000e+01\n      3.098683e+00\n      4.193120e+01\n      -8.762773e+01\n      4.193125e+01\n      -8.762775e+01\n    \n    \n      max\n      9.786672e+02\n      6.000000e+00\n      2.398333e+01\n      4.837080e+01\n      4.206490e+01\n      -8.752823e+01\n      4.206501e+01\n      -8.752823e+01\n    \n  \n\n\n\n\n\n\nSome issues arose above\n\nhire_time_h max and min values\n\nLooks like the error is there from the start, so lets delete them\ndo the same for long times\n\ndfUse=dfUse[dfUse.hire_time_h>=0]\n\ndfUse=dfUse[dfUse.hire_time_h<24]\n\n\n\nLets drop some columns for space\n\ndfUse.drop(columns=[\"ride_id\", \"started_at\",\"ended_at\",\"start_station_name\",\"end_station_name\"],inplace=True)\n#,\"start_station_id\",\"end_station_id\"]\n\n\n\nsave\n\ndfUse.to_csv('/data/df_2020.csv')\ndf=copy.copy(dfUse)\n\n\ndf = pd.read_csv('/data/df_2020.csv')\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      rideable_type\n      hire_time_h\n      day_week\n      time_day\n      start_station_id\n      end_station_id\n      distance\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      0\n      classic_bike\n      0.176944\n      6\n      12.733333\n      13157\n      TA1306000003\n      1.491984\n      41.877726\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      1\n      39\n      electric_bike\n      0.130556\n      4\n      13.883333\n      TA1309000006\n      TA1306000011\n      2.144117\n      41.918112\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      2\n      50\n      electric_bike\n      0.030000\n      0\n      17.166667\n      KA1503000043\n      TA1306000003\n      0.323238\n      41.889193\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      3\n      87\n      docked_bike\n      1.013056\n      3\n      13.600000\n      TA1309000014\n      TA1309000014\n      0.000000\n      41.967096\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      4\n      88\n      classic_bike\n      0.101111\n      6\n      13.150000\n      TA1305000006\n      KA1503000043\n      1.147392\n      41.881320\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2949984\n      84771\n      docked_bike\n      0.215278\n      3\n      16.166667\n      140.0\n      140.0\n      0.000000\n      41.899000\n      -87.629900\n      41.899000\n      -87.629900\n      member\n    \n    \n      2949985\n      84772\n      docked_bike\n      0.319167\n      3\n      17.933333\n      322.0\n      351.0\n      1.056377\n      41.799600\n      -87.594700\n      41.803000\n      -87.606600\n      casual\n    \n    \n      2949986\n      84773\n      docked_bike\n      1.886111\n      4\n      19.950000\n      236.0\n      182.0\n      0.604983\n      41.907600\n      -87.638600\n      41.903200\n      -87.634300\n      casual\n    \n    \n      2949987\n      84774\n      docked_bike\n      0.708611\n      3\n      17.983333\n      310.0\n      310.0\n      0.000000\n      41.920100\n      -87.677900\n      41.920100\n      -87.677900\n      casual\n    \n    \n      2949988\n      84775\n      docked_bike\n      0.100000\n      5\n      1.516667\n      138.0\n      138.0\n      0.000000\n      41.904600\n      -87.640600\n      41.904600\n      -87.640600\n      casual\n    \n  \n\n2949989 rows × 13 columns\n\n\n\n\n\nPut frequency location onto a map\n\nimport folium\nfrom folium import plugins\nfrom folium.plugins import HeatMap\n\nlat=df['start_lat'].values\nlon=df['start_lng'].values\nlatlon = [lat, lon]\n\nmaps = folium.Map(location=[lat[0],lon[0]],\n                    zoom_start = 11)\n\nlatlon=np.transpose(latlon)\n\n# Plot it on the map\nHeatMap(latlon).add_to(maps)\n\n# Display the map\nmaps\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nBit of a mess, grouping by region may be better"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/ChicagoBikes.html#plot-some-choroplots",
    "href": "posts/PROJECTS/Other_projects/ChicagoBikes.html#plot-some-choroplots",
    "title": "How Does a Bike-Share Navigate Speedy Success",
    "section": "Plot some choroplots",
    "text": "Plot some choroplots\nopen and modify the geojson file- seems to make life easier later\n\nimport geopandas as gpd\nfname='Chicago.geojson'\nchicago = gpd.read_file(fname)\n\n# neighborhoods aren't unique so lets use the index and call it ID\nchicago.reset_index(inplace=True)\nchicago.rename(columns={'index':'ID'},inplace=True)\n\nchicago.drop(columns=['sec_neigh','shape_area','shape_len'],inplace=True)\nchicago.to_file(\"Chi_.json\", driver=\"GeoJSON\")\nchicago.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      pri_neigh\n      geometry\n    \n  \n  \n    \n      0\n      0\n      Grand Boulevard\n      MULTIPOLYGON (((-87.60671 41.81681, -87.60670 ...\n    \n    \n      1\n      1\n      Printers Row\n      MULTIPOLYGON (((-87.62761 41.87437, -87.62760 ...\n    \n    \n      2\n      2\n      United Center\n      MULTIPOLYGON (((-87.66707 41.88885, -87.66707 ...\n    \n    \n      3\n      3\n      Sheffield & DePaul\n      MULTIPOLYGON (((-87.65833 41.92166, -87.65835 ...\n    \n    \n      4\n      4\n      Humboldt Park\n      MULTIPOLYGON (((-87.74060 41.88782, -87.74060 ...\n    \n  \n\n\n\n\n\nNow we want to convert each station to a region within the json file\n\nFirst let’s create a variable for each station, with location and station_id\n\n#use mean here just in case some slight differences- big ones lets hope not!\ndfStat=df.groupby(by=['start_station_id']).mean()\n\ndfStat=dfStat.drop(columns=['Unnamed: 0','hire_time_h','day_week','time_day','distance','end_lat','end_lng'])\ndfStat.reset_index(inplace=True)\ndfStat\n\n\n\n\n\n  \n    \n      \n      start_station_id\n      start_lat\n      start_lng\n    \n  \n  \n    \n      0\n      2.0\n      41.876505\n      -87.620535\n    \n    \n      1\n      3.0\n      41.867228\n      -87.615357\n    \n    \n      2\n      4.0\n      41.856268\n      -87.613345\n    \n    \n      3\n      5.0\n      41.874050\n      -87.627709\n    \n    \n      4\n      6.0\n      41.886974\n      -87.612813\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1877\n      TA1309000066\n      41.969101\n      -87.674234\n    \n    \n      1878\n      TA1309000067\n      41.803034\n      -87.606613\n    \n    \n      1879\n      WL-008\n      41.867122\n      -87.641071\n    \n    \n      1880\n      WL-011\n      41.880395\n      -87.642727\n    \n    \n      1881\n      WL-012\n      41.883364\n      -87.641203\n    \n  \n\n1882 rows × 3 columns\n\n\n\n\n\nNow for each station we want a JSON-area code\nThis is slightly convoluted - scroll through each station - for each station find if it’s inside a Chigao_JSON region - if not we assign if a value 1000 - for those with no region find the nearest station that has a JSON-region (done in tab after this)\nwhatChoro = json ID whatwhat = station ID\n\nfrom shapely.geometry import shape, Point\n\n\nwhatChoro=[]\nwhatwhat=[]\n# check each polygon to see if it contains the point\ni=0\n# scroll through each station\nfor istat in range(np.shape(dfStat)[0]):\n    i=0\n    #create a point for the station\n    point=Point(dfStat.loc[istat,'start_lng'],dfStat.loc[istat,'start_lat'])\n    \n    #scroll through each geometery\n    for feature in chicago.ID:\n        polygon = shape(chicago.loc[i,'geometry'])\n        if polygon.contains(point):\n            #this gives the json region ID\n            whatChoro.append(chicago.loc[i,'ID'])\n            #this give the station id\n            whatwhat.append(dfStat.loc[istat,'start_station_id'])\n            break \n        \n        #if we don't get a match!!\n        if feature==chicago['ID'].iloc[-1]:\n            \n            import copy\n            # find distances lat2/lng2 this location\n            # lat1/lng1 all locations\n            lat1_=copy.copy(dfStat['start_lat'])\n            lon1_=copy.copy(dfStat['start_lng'])\n            lat2_=dfStat.loc[istat,'start_lat']\n            lon2_=dfStat.loc[istat,'start_lng']\n\n            \n            #this gives the json region ID\n            whatChoro.append(1000)\n            #this give the station id\n            whatwhat.append(dfStat.loc[istat,'start_station_id'])\n            \n            \n        i=i+1\n\n\n\nThis does the cleaning up if they don’t have a json id\nThis will handle when we don’t get a match—> a reuse of the distance function with slight mods\n\ndef distanceLatLong_v2(lat1_,lon1_,lat2_,lon2_):\n    \n    import numpy as np\n    import math\n    def deg2rad(deg):\n        return deg * np.pi/180\n    def inner(lat1,lon1,lat2,lon2):\n        R = 6371; # Radius of the earth in km\n        dLat = deg2rad(lat2-lat1)  # deg2rad below\n        dLon = deg2rad(lon2-lon1)\n        a = np.sin(dLat/2) * np.sin(dLat/2) + \\\n        np.cos(deg2rad(lat1)) * np.cos(deg2rad(lat2)) * \\\n        np.sin(dLon/2) * np.sin(dLon/2)\n\n        c = 2 * math.atan2(np.sqrt(a), np.sqrt(1-a))\n        d = R * c ## Distance in km\n        if d==0:\n            d=1000\n        return d\n    if np.shape(lat1_)[0]>1:\n        d=[]\n        for i in range(np.shape(lat1_)[0]):\n            d.append(inner(lat1_[i],lon1_[i],lat2_,lon2_))\n        \n    else:\n        d=inner(lat1_,lon1_,lat2_,lon2_)   \n    \n    return d\n\nthis scrolls through ones we didn’t match and finds nearest JSON-id we did match\n\nfor i in range(np.shape(dfStat)[0]):\n    if whatChoro[i]==1000:\n             \n        #find distances lat2/lng2 this location\n        # lat1/lng1 all locations\n        lat1_=copy.copy(dfStat['start_lat'])\n        lon1_=copy.copy(dfStat['start_lng'])\n        lat2_=dfStat.loc[i,'start_lat']\n        lon2_=dfStat.loc[i,'start_lng']\n        ind=[idx for idx, element in enumerate(whatChoro) if element==1000]\n        lat1_[ind]=0\n        lon1_[ind]=0\n        d=distanceLatLong_v2(lat1_,lon1_,lat2_,lon2_)\n        indamin=d.index(min(d))\n#         whatwhat[i]=whatwhat[indamin]\n        whatChoro[i]=whatChoro[indamin]\n        \n        print(i,indamin,whatChoro[i],whatChoro[indamin],min(d))\n\n554 474 48 48 3.218616605981318\n555 474 48 48 1.5436541433245226\n556 474 48 48 0.7244340745224377\n557 554 48 48 1.618989106320433\n558 557 48 48 0.9589393666816851\n559 558 48 48 1.703490590200107\n560 559 48 48 1.0394756465095663\n561 554 48 48 0.5321339843549502\n562 561 48 48 0.8611490298165934\n563 561 48 48 0.4535879672825213\n570 554 48 48 0.7620712283526319\n603 562 48 48 0.7657516801324228\n604 1355 55 55 0.9398603094768803\n605 559 48 48 1.3757808765327746\n1441 554 48 48 0.0009191040374285816\n1442 1441 48 48 0.003706303019684898\n1443 555 48 48 0.006456249041029345\n1444 556 48 48 4.9908562509422157e-05\n1445 1444 48 48 0.002230404415936471\n1446 557 48 48 0.0012372240336437155\n1447 1446 48 48 0.003412919018808641\n1450 558 48 48 0.005285184511373336\n1451 1450 48 48 0.011408782497315317\n1452 559 48 48 0.027327480291422585\n1453 560 48 48 0.0012042612006966005\n1454 561 48 48 0.0010429138707679156\n1455 562 48 48 0.0017205826064828574\n1456 1455 48 48 0.0034819520850311483\n1457 563 48 48 0.0025804458419044335\n1458 563 48 48 0.009202498604403178\n1470 570 48 48 0.004764480272445732\n1513 603 48 48 0.0008354495738933785\n1514 603 48 48 0.0011940325501674988\n1515 604 55 55 0.006060872681823562\n1516 1515 55 55 0.012603279140811706\n1517 605 48 48 0.009833621616663023\n1582 555 48 48 0.0011726503764087032\n1583 559 48 48 0.0038048094986119284\n1584 1453 48 48 0.0005568291527966493\n1585 561 48 48 0.0005786222457187065\n1586 1447 48 48 0.5069880704727254\n1587 605 48 48 0.0032438412454957833\n\n\n\n\n\nNow we can insert a new column in df with the json ID\n\nchicID=[]\nfor stat in df['start_station_id']:\n#     chicID.append(stat)\n    ind=[idx for idx, element in enumerate(whatwhat) if element==stat]\n    try:\n        chicID.append(whatChoro[ind[0]])\n    except:\n        continue\n\n\ndf.insert(0,'ID',chicID)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      Unnamed: 0\n      rideable_type\n      hire_time_h\n      day_week\n      time_day\n      start_station_id\n      end_station_id\n      distance\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      40\n      0\n      classic_bike\n      0.176944\n      6\n      12.733333\n      13157\n      TA1306000003\n      1.491984\n      41.877726\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      1\n      92\n      39\n      electric_bike\n      0.130556\n      4\n      13.883333\n      TA1309000006\n      TA1306000011\n      2.144117\n      41.918112\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      2\n      97\n      50\n      electric_bike\n      0.030000\n      0\n      17.166667\n      KA1503000043\n      TA1306000003\n      0.323238\n      41.889193\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      3\n      56\n      87\n      docked_bike\n      1.013056\n      3\n      13.600000\n      TA1309000014\n      TA1309000014\n      0.000000\n      41.967096\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      4\n      26\n      88\n      classic_bike\n      0.101111\n      6\n      13.150000\n      TA1305000006\n      KA1503000043\n      1.147392\n      41.881320\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n  \n\n\n\n\n\n\nAnd represent each JSON region by how many times they’re used\nWe’ll take the count and divide it by the total- and because of the distribution we’ll also take the log- basically hires are highly focussed on a few regions with many having low %\n\ndfG=df.groupby('ID').count()\ndfG.reset_index(inplace=True)\ndfG=dfG[['ID','rideable_type']]\ndfG.rename(columns={'rideable_type':'Frequency'})\ndfG.rideable_type=np.log(dfG.rideable_type/sum(dfG.rideable_type))\ndfG.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      rideable_type\n    \n  \n  \n    \n      0\n      0\n      -5.835124\n    \n    \n      1\n      1\n      -5.124845\n    \n    \n      2\n      2\n      -6.001956\n    \n    \n      3\n      3\n      -3.718336\n    \n    \n      4\n      4\n      -4.965188\n    \n  \n\n\n\n\n\ndf.to_csv('/data/dfChoro_2020.csv')\n\n\ndf = pd.read_csv('/data/dfChoro_2020.csv')\n\n\n\nNow the plotting\nWe first read in the json file, add the df with our frequency values to it then we can plot the data\n\n\nLets put this in a function to look at differences\n\ndef bigChoro(dfIN,colname,choi):\n    import folium \n    \n    LEGNOM=colname\n    if choi=='count':\n        dfG=dfIN.groupby('ID').count()\n        dfG[colname]=dfG[colname]/(100*274/7)\n        myscale = (dfG[colname].quantile((0,0.25,0.5,0.75,0.9,0.95,.97,1))).tolist()\n#         np.linspace(dfG[colname].min(),dfG[colname].max(),10)\n        LEGNOM='Number of journeys 100s per week'\n    elif choi=='mean':\n        dfG=dfIN.groupby('ID').mean()\n        myscale = np.linspace(dfG[colname].min(),dfG[colname].max(),10)\n    elif choi=='sum':\n        dfG=dfIN.groupby('ID').sum()\n        myscale = np.linspace(dfG[colname].min(),dfG[colname].max(),10)\n    elif choi=='dayofweek':\n        dfIN=dfIN[['ID',colname]]\n        dfG=dfIN.groupby(['ID']).agg(lambda x:x.value_counts().index[0])\n        dfG[dfG[colname]>4]=5-dfG[dfG[colname]>4]\n        myscale = np.array([-2.,0.,1.,2.,3.,4.])\n        LEGNOM='Day of week (-2 to -1 weekend, 0-4 Monday to Friday)'\n    elif choi=='mode':\n        dfIN=dfIN[['ID',colname]]\n        dfIN[colname].astype('int32')\n        dfG=dfIN.groupby(['ID']).agg(lambda x:x.value_counts().index[0])\n        myscale = np.linspace(dfG[colname].min(),dfG[colname].max(),10)\n        \n    dfG.reset_index(inplace=True)\n    dfG=dfG[['ID',colname]]\n\n\n    nil=gpd.read_file(\"Chi_.json\")\n    nil=nil[['ID','geometry']]\n\n    # merge data frames\n    nilpop=nil.merge(dfG,on=\"ID\")\n\n    #initial map\n    m = folium.Map(location=[41.884,-87.6247], zoom_start=10,\\\n       control_scale=True,tiles=\"Stamen Toner\")#,tiles = t_list[1])\n\n    folium.TileLayer('CartoDB positron',name=\"Light Map\",control=False).add_to(m)\n\n   \n    # (dfG['rideable_type'].quantile((0,.02,0.1,.25,0.5,0.75,0.9,0.95,0.98,1))).tolist()\n    choropleth =folium.Choropleth(\n        geo_data=\"Chi_.json\", \n        data=nilpop,\n        threshold_scale=myscale,\n        columns=['ID',colname],\n        name='choropleth',\n        fill_color='BuPu',#PuBuGn YlGn PuBuGn YlGnBu RdYlBu\n        key_on= \"feature.properties.ID\",\n        fill_opacity=0.7,\n        line_opacity=0.2,\n        nan_fill_color='gray',\n        legend_name=LEGNOM, \n        nan_fill_opacity =.5,\n        ).add_to(m)\n    folium.LayerControl().add_to(m)\n    choropleth.geojson.add_child(\n        folium.features.GeoJsonTooltip(['pri_neigh'],labels=False)\n        )\n    return m\n\n\ndfIN.columns\n\nIndex(['ID', 'Unnamed: 0', 'rideable_type', 'hire_time_h', 'day_week',\n       'time_day', 'start_station_id', 'end_station_id', 'start_lat',\n       'distance', 'start_lng', 'end_lat', 'end_lng', 'member_casual'],\n      dtype='object')\n\n\n\ncolname='distance'#end_station_id\ndfIN= df[df.member_casual=='member']\nm=bigChoro(dfIN,colname,'mean')\nm\n\n\n\ncolname='day_week'#end_station_id\ndfIN= df[df.member_casual=='member']\nm=bigChoro(dfIN,colname,'dayofweek')\nm\n\n\n\ncolname='time_day'#end_station_id\ndfIN= df[df.member_casual=='member']\nm=bigChoro(dfIN,colname,'mode')\nm\n\n\n\ncolname='time_day'#end_station_id\ndfIN= df[df.member_casual=='member']\nm=bigChoro(dfIN,colname,'count')\nm\n\n\n\ncolname='time_day'#end_station_id\ndfIN= df[df.member_casual=='casual']\nm=bigChoro(dfIN,colname,'count')\nm\n\n\n\nnp.linspace(-2,4,7)\nnp.array([-2.,0.,1.,2.,3.,4.])\n\narray([-2.,  0.,  1.,  2.,  3.,  4.])\n\n\n\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n\nsns.set_theme(style=\"ticks\")\n\nf, ax = plt.subplots(figsize=(7, 5))\nsns.despine(f)\n\n# Draw a nested boxplot to show bills by day and time\nsns.histplot(df,hue=\"member_casual\", x=\"time_day\",\n            multiple=\"stack\",\n            palette=\"dark:b_r\",\n            edgecolor=\".3\",\n            linewidth=.5,)\nsns.despine(offset=10, trim=True)\n\n\n\n\n\nfrom matplotlib.ticker import PercentFormatter\ndf_=df[df.hire_time_h<5]\ndf_=df_[df_.hire_time_h>0]\nsns.set_theme(style=\"ticks\")\n\nbinwidth = 5\n\nf, ax1 = plt.subplots(figsize=(10, 7))\nsns.despine(f)\ndf2_=df_[df_.member_casual=='member']\n# Draw a nested boxplot to show bills by day and time\nsns.histplot(df2_, x=\"hire_time_h\",\n            multiple=\"stack\",\n            palette=\"light:m_r\",\n            edgecolor=\".3\",\n            linewidth=.5,\n            stat='probability',\n            log_scale=True,\n            ax=ax1,\n            label='member')\n\nax2=ax1.twinx()\n\ndf2_=df_[df_.member_casual=='casual']\n# Draw a nested boxplot to show bills by day and time\nsns.histplot(df2_, x=\"hire_time_h\",\n             element=\"step\",fill=False,\n             color='red',\n            linewidth=.8,\n            stat='probability',\n            log_scale=True,\n            ax=ax2,\n            label='casual')\n\nax1.legend(loc='upper left')\nax2.legend(loc='upper right')\nsns.despine(offset=10, trim=True)\n# ax.legend('Member','Casual')\n\n\n\n\n\nsns.set_theme(style=\"ticks\")\n\nf, ax = plt.subplots(figsize=(10, 8))\nsns.despine(f)\ndf_=df[ df[\"distance\"]>0.1 ]\ndf_= df_[df_[\"distance\"]<20]\ndf_=df_[df_.member_casual=='member']\n# Draw a nested boxplot to show bills by day and time\nsns.histplot(data=df_, x=\"distance\",\n            edgecolor=\".3\",\n            linewidth=.5,\n            stat='probability',\n             label='member')\nsns.despine(offset=10, trim=True)\ndf_=df[df[\"distance\"]>0.1]\ndf_= df_[df_[\"distance\"]<20]\ndf_=df_[df_.member_casual=='casual']\nsns.histplot(data=df_, x=\"distance\",\n            linewidth=.8,\n            color='r',\n            stat='probability',\n             label='casual',\n            fill=False,\n            element='step')\n\nax.legend(loc='upper right')\n\n<matplotlib.legend.Legend at 0x2f212cc0be0>\n\n\n\n\n\n\n# f, ax = plt.subplots(figsize=(7, 5))\nsns.set_theme(style=\"whitegrid\")\n\n# Draw a nested boxplot to show bills by day and time\nax=sns.histplot(df,hue=\"member_casual\", \n             x=\"day_week\",palette=\"dark:b_r\",\n             multiple=\"dodge\",\n             bins=[0 ,1 ,2 ,3, 4, 5, 6,7],\n             shrink=.9\n            )\nsns.despine(offset=20, trim=True)\naa=np.array([0,1,2,3,4,5,6])+.5\nax.set_xticks(aa)\nax.set_xlim([0, 7.5])\nlab=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\nax.set_xticklabels(lab,rotation='vertical')\nax.set_xlabel('Day of the week')\n\nText(0.5, 0, 'Day of the week')\n\n\n\n\n\n\n\nSo after a quick look at the data (*maybe some plots need mods) some clear trends:\n\nCasuals use bikes more on weekends, members more on weekdays\nMembers tend to use bikes in commuting times 7-9 am and 4-7 pm. Whereas casuals more spread but focussed later\nCasuals tend to use the bikes for longer and travel further from initial location"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches-PrepareTheData.html#introduction",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches-PrepareTheData.html#introduction",
    "title": "Predicting Premier League Matches- Prepare the data",
    "section": "Introduction",
    "text": "Introduction\nThe aim of this page is to prepare data for modelling to predict the results.\n\nSource of the data\nThe data was downloaded with this code which uses the wesbite FBREF.\nThe data from the following seasons were used (season = year competition started), as earlier years had a different format: - 2017 - 2018 - 2019 - 2020 - 2021\nFurther down the data in each column downloaded is shown.\n\n\nMethodology\nThe data gives details of a given match along with the result. Details such as shots on goal, possession etc. But I don’t want to predict the results of a match given the data of that match. Instead I want to predict the result based on data from previous matches.\n\nSo the data for a match needs to come from data from previous matches, with preferance to matches that are near\n\nThe second important step with this data is to combine results of the home and away team to allow predictions for one match.\n#collapse-hide"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches-PrepareTheData.html#the-data",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches-PrepareTheData.html#the-data",
    "title": "Predicting Premier League Matches- Prepare the data",
    "section": "The data",
    "text": "The data\n\nOverall match details\n\nDate – Date listed is local to the match\nTime – Time listed is local to the match venue\n\nTime is written in the 24-hour notation -Your local time is in (·)\n\nComp – Competition\nNumber next to competition states which level in the country’s league pyramid this league occupies.\nRound – Round or Phase of Competition\nDay – Day of week\nGF – Goals For\nGA – Goals Against\nopponent\n\n\n\nScores & Fixtures\n\nDay – Day of week\nxG – Expected Goals\n\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nxGA – Expected Goals Allowed\n\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nPoss – Possession\n\nCalculated as the percentage of passes attempted\n\nFormation – Number of players in each row from defenders to forwards, not including the goalkeeper.\n\nFormations provided by Data Sports Group and StatsBomb.\n\n\n\n\nShooting\n\nStandard\n\nGls – Goals scored or allowed\nSh – Shots Total -Does not include penalty kicks\nSoT – Shots on target -Note: Shots on target do not include penalty kicks\nSoT% – Percentage of shots that are on target\n\nMinimum .395 shots per squad game to qualify as a leader -Note: Shots on target do not include penalty kicks\n\nG/Sh – Goals per shot\n\nMinimum .395 shots per squad game to qualify as a leader\n\nG/SoT – Goals per shot on target\n\nMinimum .111 shots on target per squad game to qualify as a leader\nNote: Shots on target do not include penalty kicks\n\nDist – Average distance, in yards, from goal of all shots taken\n\nMinimum .395 shots per squad game to qualify as a leader\nDoes not include penalty kicks\n\nFK – Shots from free kicks\nPK – Penalty Kicks Made\nPKatt – Penalty Kicks Attempted #### Expected\nxG – Expected Goals\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\n\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nnpxG – Non-Penalty Expected Goals\n\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nnpxG/Sh – Non-Penalty Expected Goals per shot\n\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\nMinimum .395 shots per squad game to qualify as a leader\n\nG-xG – Goals minus Expected Goals\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\n\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nnp:G-xG – Non-Penalty Goals minus Non-Penalty Expected Goals\n\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\n\n\n\n\nGoalkeeping\n\nPerformance\n\nSoTA – Shots on Target Against\nGA – Goals Against\nSave% – Save Percentage\n\n(Shots on Target Against - Goals Against)/Shots on Target Against\nNote that not all shots on target are stopped by the keeper, many will be stopped by defenders\nDoes not include penalty kicks\n\nCS – Clean Sheets\n\nFull matches by goalkeeper where no goals are allowed.\n\nPSxG – Post-Shot Expected Goals\n\nPSxG is expected goals based on how likely the goalkeeper is to save the shot\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nPSxG+/- – Post-Shot Expected Goals minus Goals Allowed\n\nPositive numbers suggest better luck or an above average ability to stop shots\nPSxG is expected goals based on how likely the goalkeeper is to save the shot\nNote: Does not include own goals\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available. #### Penalty Kicks\n\nPKatt – Penalty Kicks Attempted\nPKA– Penalty Kicks Allowed\nPKsv – Penalty Kicks Saved\nPKm– Penalty Kicks Missed #### Launched\nCmp – Passes Completed\n\nPasses` longer than 40 yards\n\nAtt – Passes Attempted\n\nPasses longer than 40 yards\n\nCmp% – Pass Completion Percentage\n\nPasses longer than 40 yards #### Passes\n\nAtt – Passes Attempted\n\nNot including goal kicks\n\nThr – Throws Attempted\nLaunch% – Percentage of Passes that were Launched\n\nNot including goal kicks\nPasses longer than 40 yards\n\nAvgLen – Average length of passes, in yards\n\nNot including goal kicks #### Goal Kicks\n\nAtt – Goal Kicks Attempted\nLaunch% – Percentage of Goal Kicks that were Launched\n\nPasses longer than 40 yards\n\nAvgLen – Average length of goal kicks, in yards #### Crosses\nOpp – Opponent’s attempted crosses into penalty area\nStp – Number of crosses into penalty area which were successfully stopped by the goalkeeper\nStp% – Percentage of crosses into penalty area which were successfully stopped by the goalkeeper #### Sweeper\n#OPA – # of defensive actions outside of penalty area\nAvgDist – Average distance from goal (in yards) of all defensive actions\n\n\n\n\nPassing\n\nTotal\n\nCmp – Passes Completed\nAtt – Passes Attempted\nCmp% – Pass Completion Percentage\n\nMinimum 30 minutes played per squad game to qualify as a leader\n\nTotDist – Total distance, in yards, that completed passes have traveled in any direction\nPrgDist – Progressive Distance\n\nTotal distance, in yards, that completed passes have traveled towards the opponent’s goal. Note: Passes away from opponent’s goal are counted as zero progressive yards. #### Short\n\nCmp – Passes Completed\n\nPasses between 5 and 15 yards\n\nAtt – Passes Attempted\n\nPasses between 5 and 15 yards\n\nCmp% – Pass Completion Percentage\n\nPasses between 5 and 15 yards\nMinimum 30 minutes played per squad game to qualify as a leader #### Medium\n\nCmp – Passes Completed\n\nPasses between 15 and 30 yards\n\nAtt – Passes Attempted\n\nPasses between 15 and 30 yards\n\nCmp% – Pass Completion Percentage\n\nPasses between 15 and 30 yards\nMinimum 30 minutes played per squad game to qualify as a leader #### Long\n\nCmp – Passes Completed\n\nPasses longer than 30 yards\n\nAtt – Passes Attempted\n\nPasses longer than 30 yards\n\nCmp% – Pass Completion Percentage\n\nPasses longer than 30 yards\nMinimum 30 minutes played per squad game to qualify as a leader #### Others\n\nAst – Assists\nxA – xG Assisted\n\nxG which follows a pass that assists a shot\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nKP – Passes that directly lead to a shot (assisted shots)\n1/3 – Completed passes that enter the 1/3 of the pitch closest to the goal\n\nNot including set pieces\n\nPPA – Completed passes into the 18-yard box\n\nNot including set pieces\n\nCrsPA – Completed crosses into the 18-yard box\n\nNot including set pieces\n\nProg – Progressive Passes\n\nCompleted passes that move the ball towards the opponent’s goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area. Excludes passes from the defending 40% of the pitch\n\n\n\n\n\nPass Types\n\nTotal\n\nAtt – Passes Attempted #### Pass Types\nLive – Live-ball passes\nDead – Dead-ball passes\n\nIncludes free kicks, corner kicks, kick offs, throw-ins and goal kicks\n\nFK – Passes attempted from free kicks\nTB – Completed pass sent between back defenders into open space\nPress – Passes made while under pressure from opponent\nSw – Passes that travel more than 40 yards of the width of the pitch\nCrs – Crosses\nCK – Corner Kicks\n\n\n\nCorner Kicks\n\nIn – Inswinging Corner Kicks\nOut – Outswinging Corner Kicks\nStr – Straight Corner Kicks #### Height\nGround – Ground passes\nLow – Passes that leave the ground, but stay below shoulder-level\nHigh – Passes that are above shoulder-level at the peak height #### Body Parts\nLeft – Passes attempted using left foot\nRight – Passes attempted using right foot\nHead – Passes attempted using head\nTI – Throw-Ins taken\nOther – Passes attempted using body parts other than the player’s head or feet #### Outcomes\nCmp – Passes Completed\nOff – Offsides\nOut – Out of bounds\nInt – Intercepted\nBlocks – Blocked by the opponent who was standing it the path\n\n\n\n\nGoal and Shot Creation\n\nSCA Types\n\nSCA – Shot-Creating Actions\n\nThe two offensive actions directly leading to a shot, such as passes, dribbles and drawing fouls. Note: A single player can receive credit for multiple actions and the shot-taker can also receive credit.\n\nPassLive – Completed live-ball passes that lead to a shot attempt\nPassDead – Completed dead-ball passes that lead to a shot attempt.\n\nIncludes free kicks, corner kicks, kick offs, throw-ins and goal kicks\n\nDrib – Successful dribbles that lead to a shot attempt\nSh – Shots that lead to another shot attempt\nFld – Fouls drawn that lead to a shot attempt\nDef – Defensive actions that lead to a shot attempt #### GCA Types\nGCA – Goal-Creating Actions\n\nThe two offensive actions directly leading to a goal, such as passes, dribbles and drawing fouls. Note: A single player can receive credit for multiple actions and the shot-taker can also receive credit.\n\nPassLive – Completed live-ball passes that lead to a goal\nPassDead – Completed dead-ball passes that lead to a goal. Includes free kicks, corner kicks, kick offs, throw-ins and goal kicks\nDrib – Successful dribbles that lead to a goal\nSh – Shots that lead to another goal-scoring shot\nFld – Fouls drawn that lead to a goal\nDef – Defensive actions that lead to a goal\n\n\n\n\nDefensive Actions\n\n\nTackles\n\nTkl – Number of players tackled\nTklW – Tackles in which the tackler’s team won possession of the ball\nDef 3rd – Tackles in defensive 1/3\nMid 3rd – Tackles in middle 1/3\nAtt 3rd – Tackles in attacking 1/3\n\n\nVs Dribbles\n\nTkl – Number of dribblers tackled\nAtt – Number of times dribbled past plus number of tackles\nTkl% – Percentage of dribblers tackled\n\nDribblers tackled divided by dribblers tackled plus times dribbled past\nMinimum .625 dribblers contested per squad game to qualify as a leader\n\nPast – Number of times dribbled past by an opposing player\n\n\n\nPressures\n\nPress – Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball\nSucc – Number of times the squad gained possession withing five seconds of applying pressure\n% – Successful Pressure Percentage\n\nPercentage of time the squad gained possession withing five seconds of applying pressure\nMinimum 6.44 pressures per squad game to qualify as a leader\n\nDef 3rd – Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the defensive 1/3\nMid 3rd – Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the middle 1/3\nAtt 3rd – Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the attacking 1/3\n\n\n\nBlocks\n\nBlocks – Number of times blocking the ball by standing in its path\nSh – Number of times blocking a shot by standing in its path\nShSv – Number of times blocking a shot that was on target, by standing in its path\nPass – Number of times blocking a pass by standing in its path\nInt – Interceptions\nTkl+Int – Number of players tackled plus number of interceptions\nClr – Clearances\nErr – Mistakes leading to an opponent’s shot\n\n\n\n\nPossession\n\nPoss – Possession\n\nCalculated as the percentage of passes attempted #### Touches\n\nTouches – Number of times a player touched the ball. Note: Receiving a pass, then dribbling, then sending a pass counts as one touch\nDef Pen – Touches in defensive penalty area\nDef 3rd – Touches in defensive 1/3\nMid 3rd – Touches in middle 1/3\nAtt 3rd – Touches in attacking 1/3\nAtt Pen – Touches in attacking penalty area\nLive – Live-ball touches. Does not include corner kicks, free kicks, throw-ins, kick-offs, goal kicks or penalty kicks #### Dribbles\nSucc – Dribbles Completed Successfully\nAtt – Dribbles Attempted\nSucc% – Percentage of Dribbles Completed Successfully\n\nMinimum .5 dribbles per squad game to qualify as a leader\n\n#Pl – Number of Players Dribbled Past\nMegs – Number of times a player dribbled the ball through an opposing player’s legs\n\n\nCarries\n\nCarries – Number of times the player controlled the ball with their feet\nTotDist – Total distance, in yards, a player moved the ball while controlling - it with their feet, in any direction\nPrgDist – Progressive Distance\n\nTotal distance, in yards, a player moved the ball while controlling it with - their feet towards the opponent’s goal\n\nProg – Carries that move the ball towards the opponent’s goal at least 5 - yards, or any carry into the penalty area. Excludes carries from the defending 40% of the pitch\n1/3 – Carries that enter the 1/3 of the pitch closest to the goal\nCPA – Carries into the 18-yard box\nMis – Number of times a player failed when attempting to gain control of a ball\nDis – Number of times a player loses control of the ball after being tackled - by an opposing player. Does not include attempted dribbles\n\n\n\nReceiving\n\nTarg – Number of times a player was the target of an attempted pass\nRec – Number of times a player successfully received a pass\nRec% – Passes Received Percentage\n\nPercentage of time a player successfully received a pass\nMinimum 30 minutes played per squad game to qualify as a leader\n\nProg – Progressive Passes Received\n\nCompleted passes that move the ball towards the opponent’s goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area. Excludes passes from the defending 40% of the pitch\n\n\n\n\n\nMiscellaneous Stats\n\nPerformance\n\nCrdY– Yellow Cards\nCrdR– Red Cards\n2CrdY – Second Yellow Card\nFls- Fouls Committed\nFld – Fouls Drawn\nOff – Offsides\nCrs – Crosses\nInt – Interceptions\nTklW– Tackles in which the tackler’s team won possession of the ball\nPKwon – Penalty Kicks Won\nPKcon – Penalty Kicks Conceded\nOG -- Own Goals\nRecov – Number of loose balls recovered #### Aerial Duels\nWon – Aerials won\nLost – Aerials lost\nWon% – Percentage of aerials won Minimum .97 aerial duels per squad game to qualify as a leader"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches-PrepareTheData.html#prepare-the-data",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches-PrepareTheData.html#prepare-the-data",
    "title": "Predicting Premier League Matches- Prepare the data",
    "section": "Prepare the data",
    "text": "Prepare the data\n\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ncwd=os.getcwd()\n\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\ndira\n\n['dfEPL_2017.csv',\n 'dfEPL_2018.csv',\n 'dfEPL_2019.csv',\n 'dfEPL_2020.csv',\n 'dfEPL_2021.csv',\n 'epl2017-2021.csv',\n 'epl2017-2021_wivnetscore.csv',\n 'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv',\n 'epl2017-2021_wivnetscoreAndGFGA_both-HA_modPC.csv',\n 'epl2017-2021_wivnetscore_both-HA.csv',\n 'epl_beforeAVG_HA.csv']\n\n\nLoad the data and combine in one big DataFrame\n\n#collapse-output\ni=0\nfor d in dira:\n    if d[0]=='d':\n        df = pd.read_csv(folda+d,index_col=0)\n        df['Season']=int(d.split('.')[0].split('_')[-1]) \n        if i==0:\n            dfAll=df\n            i=i+1\n        else:\n            dfAll=pd.concat([dfAll,df])\n        \nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll)\n\n\n\n\n\n  \n    \n      \n      Date\n      Time\n      Comp\n      Round\n      Day\n      Venue\n      Result\n      GF\n      GA\n      Opponent\n      Gls\n      Sh_shooting\n      SoT\n      SoT%\n      G/Sh\n      G/SoT\n      Dist\n      FK_shooting\n      PK\n      PKatt_shooting\n      xG\n      npxG\n      npxG/Sh\n      G-xG\n      np:G-xG\n      Match Report\n      SoTA\n      Saves\n      Save%\n      CS\n      PSxG\n      PSxG+/-\n      PKatt_keeper\n      PKA\n      PKsv\n      PKm\n      Cmp_keeper\n      Att_keeper\n      Cmp%_keeper\n      Att_keeper.1\n      Thr\n      Launch%\n      AvgLen\n      Att_keeper.2\n      Launch%.1\n      AvgLen.1\n      Opp\n      Stp\n      Stp%\n      #OPA\n      AvgDist\n      Cmp_passing\n      Att_passing\n      Cmp%_passing\n      TotDist_passing\n      PrgDist_passing\n      Cmp_passing.1\n      Att_passing.1\n      Cmp%_passing.1\n      Cmp_passing.2\n      Att_passing.2\n      Cmp%_passing.2\n      Cmp_passing.3\n      Att_passing.3\n      Cmp%_passing.3\n      Ast\n      xA\n      KP\n      1/3_passing\n      PPA\n      CrsPA\n      Prog_passing\n      Att_passing_types\n      Live_passing_types\n      Dead\n      FK_passing_types\n      TB\n      Press_passing_types\n      Sw\n      Crs_passing_types\n      CK\n      In\n      Out\n      Str\n      Ground\n      Low\n      High\n      Left\n      Right\n      Head\n      TI\n      Other\n      Cmp_passing_types\n      Off_passing_types\n      Out.1\n      Int_passing_types\n      Blocks_passing_types\n      SCA\n      PassLive\n      PassDead\n      Drib\n      Sh_gca\n      Fld_gca\n      Def\n      GCA\n      PassLive.1\n      PassDead.1\n      Drib.1\n      Sh_gca.1\n      Fld_gca.1\n      Def.1\n      Tkl\n      TklW_defense\n      Def 3rd_defense\n      Mid 3rd_defense\n      Att 3rd_defense\n      Tkl.1\n      Att_defense\n      Tkl%\n      Past\n      Press_defense\n      Succ_defense\n      %\n      Def 3rd_defense.1\n      Mid 3rd_defense.1\n      Att 3rd_defense.1\n      Blocks_defense\n      Sh_defense\n      ShSv\n      Pass\n      Int_defense\n      Tkl+Int\n      Clr\n      Err\n      Poss\n      Touches\n      Def Pen\n      Def 3rd_possession\n      Mid 3rd_possession\n      Att 3rd_possession\n      Att Pen\n      Live_possession\n      Succ_possession\n      Att_possession\n      Succ%\n      #Pl\n      Megs\n      Carries\n      TotDist_possession\n      PrgDist_possession\n      Prog_possession\n      1/3_possession\n      CPA\n      Mis\n      Dis\n      Targ\n      Rec\n      Rec%\n      Prog_possession.1\n      CrdY\n      CrdR\n      2CrdY\n      Fls\n      Fld_misc\n      Off_misc\n      Crs_misc\n      Int_misc\n      TklW_misc\n      PKwon\n      PKcon\n      OG\n      Recov\n      Won\n      Lost\n      Won%\n      team\n      Season\n    \n  \n  \n    \n      0\n      2017-08-12\n      17:30\n      Premier League\n      Matchweek 1\n      Sat\n      Away\n      W\n      2\n      0\n      Brighton\n      1.0\n      14.0\n      4.0\n      28.6\n      0.07\n      0.25\n      19.4\n      2.0\n      0.0\n      0.0\n      1.8\n      1.8\n      0.14\n      -0.8\n      -0.8\n      Match Report\n      2.0\n      2.0\n      100.0\n      1.0\n      0.4\n      0.4\n      0.0\n      0.0\n      0.0\n      0.0\n      2.0\n      5.0\n      40.0\n      20.0\n      7.0\n      10.0\n      22.5\n      4.0\n      75.0\n      56.8\n      3.0\n      0.0\n      0.0\n      1.0\n      24.2\n      712.0\n      808.0\n      88.1\n      13422.0\n      3465.0\n      297.0\n      320.0\n      92.8\n      315.0\n      346.0\n      91.0\n      89.0\n      117.0\n      76.1\n      1.0\n      1.1\n      9.0\n      69.0\n      15.0\n      1.0\n      60.0\n      808.0\n      766.0\n      42.0\n      10.0\n      2.0\n      63.0\n      28.0\n      16.0\n      10.0\n      1.0\n      5.0\n      0.0\n      612.0\n      105.0\n      91.0\n      182.0\n      570.0\n      20.0\n      17.0\n      10.0\n      712.0\n      1.0\n      8.0\n      19.0\n      17.0\n      22.0\n      17.0\n      1.0\n      0.0\n      1.0\n      2.0\n      1.0\n      2.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      4.0\n      5.0\n      6.0\n      0.0\n      4.0\n      14.0\n      28.6\n      10.0\n      104.0\n      28.0\n      26.9\n      25.0\n      42.0\n      37.0\n      7.0\n      2.0\n      0.0\n      5.0\n      13.0\n      NaN\n      15.0\n      0.0\n      77.0\n      902.0\n      30.0\n      146.0\n      484.0\n      329.0\n      31.0\n      858.0\n      8.0\n      15.0\n      53.3\n      9.0\n      1.0\n      646.0\n      3346.0\n      1924.0\n      91.0\n      27.0\n      3.0\n      15.0\n      4.0\n      794.0\n      712.0\n      89.7\n      60.0\n      2.0\n      0.0\n      0.0\n      9.0\n      8.0\n      1.0\n      16.0\n      13.0\n      4.0\n      0.0\n      0.0\n      0.0\n      85.0\n      19.0\n      17.0\n      52.8\n      ManchesterCity\n      2017\n    \n    \n      1\n      2017-08-21\n      20:00\n      Premier League\n      Matchweek 2\n      Mon\n      Home\n      D\n      1\n      1\n      Everton\n      1.0\n      20.0\n      6.0\n      30.0\n      0.05\n      0.17\n      18.9\n      1.0\n      0.0\n      0.0\n      1.2\n      1.2\n      0.06\n      -0.2\n      -0.2\n      Match Report\n      2.0\n      1.0\n      50.0\n      0.0\n      0.8\n      -0.2\n      0.0\n      0.0\n      0.0\n      0.0\n      7.0\n      10.0\n      70.0\n      27.0\n      5.0\n      25.9\n      33.5\n      6.0\n      50.0\n      46.0\n      3.0\n      2.0\n      66.7\n      1.0\n      16.0\n      497.0\n      611.0\n      81.3\n      9615.0\n      3476.0\n      199.0\n      228.0\n      87.3\n      217.0\n      254.0\n      85.4\n      72.0\n      110.0\n      65.5\n      0.0\n      1.0\n      16.0\n      39.0\n      16.0\n      0.0\n      67.0\n      611.0\n      556.0\n      55.0\n      11.0\n      2.0\n      135.0\n      24.0\n      14.0\n      7.0\n      0.0\n      6.0\n      0.0\n      389.0\n      113.0\n      109.0\n      158.0\n      370.0\n      22.0\n      29.0\n      10.0\n      497.0\n      0.0\n      13.0\n      10.0\n      14.0\n      33.0\n      27.0\n      3.0\n      0.0\n      1.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      15.0\n      10.0\n      9.0\n      5.0\n      1.0\n      7.0\n      14.0\n      50.0\n      7.0\n      127.0\n      42.0\n      33.1\n      42.0\n      51.0\n      34.0\n      13.0\n      0.0\n      0.0\n      13.0\n      13.0\n      NaN\n      18.0\n      0.0\n      63.0\n      732.0\n      47.0\n      190.0\n      374.0\n      227.0\n      42.0\n      678.0\n      6.0\n      15.0\n      40.0\n      7.0\n      0.0\n      447.0\n      2863.0\n      1715.0\n      77.0\n      25.0\n      9.0\n      12.0\n      16.0\n      580.0\n      497.0\n      85.7\n      67.0\n      2.0\n      1.0\n      1.0\n      8.0\n      13.0\n      0.0\n      14.0\n      13.0\n      10.0\n      0.0\n      0.0\n      0.0\n      108.0\n      28.0\n      14.0\n      66.7\n      ManchesterCity\n      2017\n    \n    \n      2\n      2017-08-26\n      12:30\n      Premier League\n      Matchweek 3\n      Sat\n      Away\n      W\n      2\n      1\n      Bournemouth\n      2.0\n      18.0\n      8.0\n      44.4\n      0.11\n      0.25\n      16.4\n      1.0\n      0.0\n      0.0\n      1.6\n      1.6\n      0.09\n      0.4\n      0.4\n      Match Report\n      3.0\n      2.0\n      66.7\n      0.0\n      1.1\n      0.1\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      3.0\n      33.3\n      17.0\n      6.0\n      11.8\n      26.9\n      1.0\n      100.0\n      98.0\n      7.0\n      1.0\n      14.3\n      0.0\n      18.6\n      568.0\n      676.0\n      84.0\n      10625.0\n      3119.0\n      243.0\n      268.0\n      90.7\n      240.0\n      280.0\n      85.7\n      78.0\n      107.0\n      72.9\n      2.0\n      1.3\n      12.0\n      47.0\n      14.0\n      2.0\n      48.0\n      676.0\n      621.0\n      55.0\n      12.0\n      1.0\n      96.0\n      16.0\n      17.0\n      5.0\n      2.0\n      2.0\n      0.0\n      445.0\n      126.0\n      105.0\n      201.0\n      377.0\n      30.0\n      35.0\n      7.0\n      568.0\n      3.0\n      7.0\n      7.0\n      22.0\n      26.0\n      18.0\n      3.0\n      1.0\n      2.0\n      2.0\n      0.0\n      4.0\n      3.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      8.0\n      6.0\n      5.0\n      1.0\n      2.0\n      1.0\n      11.0\n      9.1\n      10.0\n      91.0\n      29.0\n      31.9\n      15.0\n      38.0\n      38.0\n      13.0\n      4.0\n      0.0\n      9.0\n      8.0\n      NaN\n      23.0\n      0.0\n      71.0\n      802.0\n      54.0\n      191.0\n      403.0\n      268.0\n      41.0\n      748.0\n      11.0\n      17.0\n      64.7\n      13.0\n      0.0\n      566.0\n      2875.0\n      1691.0\n      77.0\n      25.0\n      5.0\n      25.0\n      15.0\n      653.0\n      568.0\n      87.0\n      56.0\n      5.0\n      1.0\n      1.0\n      14.0\n      16.0\n      3.0\n      17.0\n      8.0\n      6.0\n      0.0\n      0.0\n      0.0\n      119.0\n      30.0\n      11.0\n      73.2\n      ManchesterCity\n      2017\n    \n    \n      3\n      2017-09-09\n      12:30\n      Premier League\n      Matchweek 4\n      Sat\n      Home\n      W\n      5\n      0\n      Liverpool\n      5.0\n      13.0\n      10.0\n      76.9\n      0.38\n      0.50\n      14.2\n      0.0\n      0.0\n      0.0\n      2.7\n      2.7\n      0.21\n      2.3\n      2.3\n      Match Report\n      3.0\n      3.0\n      100.0\n      2.0\n      0.5\n      0.5\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      8.0\n      62.5\n      30.0\n      5.0\n      23.3\n      33.6\n      3.0\n      33.3\n      50.3\n      0.0\n      0.0\n      NaN\n      1.0\n      16.0\n      694.0\n      773.0\n      89.8\n      13656.0\n      3583.0\n      254.0\n      268.0\n      94.8\n      338.0\n      365.0\n      92.6\n      94.0\n      122.0\n      77.0\n      5.0\n      2.6\n      11.0\n      32.0\n      8.0\n      5.0\n      44.0\n      773.0\n      729.0\n      44.0\n      11.0\n      2.0\n      111.0\n      22.0\n      20.0\n      8.0\n      0.0\n      3.0\n      0.0\n      631.0\n      73.0\n      69.0\n      241.0\n      475.0\n      20.0\n      21.0\n      6.0\n      694.0\n      5.0\n      6.0\n      18.0\n      11.0\n      23.0\n      17.0\n      3.0\n      1.0\n      0.0\n      1.0\n      1.0\n      10.0\n      9.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      20.0\n      14.0\n      9.0\n      7.0\n      4.0\n      7.0\n      21.0\n      33.3\n      14.0\n      135.0\n      43.0\n      31.9\n      33.0\n      62.0\n      40.0\n      10.0\n      2.0\n      0.0\n      8.0\n      16.0\n      NaN\n      18.0\n      0.0\n      65.0\n      878.0\n      51.0\n      182.0\n      588.0\n      152.0\n      26.0\n      835.0\n      3.0\n      12.0\n      25.0\n      5.0\n      2.0\n      678.0\n      2392.0\n      1341.0\n      54.0\n      17.0\n      7.0\n      10.0\n      9.0\n      754.0\n      694.0\n      92.0\n      44.0\n      2.0\n      0.0\n      0.0\n      12.0\n      11.0\n      5.0\n      20.0\n      16.0\n      14.0\n      0.0\n      0.0\n      0.0\n      62.0\n      12.0\n      8.0\n      60.0\n      ManchesterCity\n      2017\n    \n    \n      4\n      2017-09-13\n      20:45\n      Champions Lg\n      Group stage\n      Wed\n      Away\n      W\n      4\n      0\n      nl Feyenoord\n      4.0\n      11.0\n      8.0\n      72.7\n      0.36\n      0.50\n      NaN\n      NaN\n      0.0\n      0.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Match Report\n      1.0\n      1.0\n      100.0\n      1.0\n      NaN\n      NaN\n      0.0\n      0.0\n      0.0\n      0.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      3.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      22.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      6.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      9.0\n      NaN\n      NaN\n      NaN\n      72.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      0.0\n      0.0\n      10.0\n      12.0\n      6.0\n      22.0\n      9.0\n      6.0\n      0.0\n      0.0\n      0.0\n      NaN\n      NaN\n      NaN\n      NaN\n      ManchesterCity\n      2017\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      39\n      2022-05-08\n      14:00\n      Premier League\n      Matchweek 36\n      Sun\n      Home\n      L\n      0\n      4\n      West Ham\n      0.0\n      8.0\n      2.0\n      25.0\n      0.00\n      0.00\n      21.5\n      1.0\n      0.0\n      0.0\n      0.7\n      0.7\n      0.08\n      -0.7\n      -0.7\n      Match Report\n      4.0\n      1.0\n      25.0\n      0.0\n      2.3\n      -1.7\n      1.0\n      1.0\n      0.0\n      0.0\n      4.0\n      10.0\n      40.0\n      25.0\n      4.0\n      28.0\n      31.3\n      5.0\n      60.0\n      52.0\n      10.0\n      0.0\n      0.0\n      0.0\n      11.3\n      335.0\n      412.0\n      81.3\n      6189.0\n      2105.0\n      140.0\n      158.0\n      88.6\n      146.0\n      162.0\n      90.1\n      42.0\n      72.0\n      58.3\n      0.0\n      0.5\n      5.0\n      19.0\n      6.0\n      1.0\n      25.0\n      412.0\n      375.0\n      37.0\n      10.0\n      4.0\n      36.0\n      11.0\n      12.0\n      9.0\n      7.0\n      0.0\n      0.0\n      306.0\n      37.0\n      69.0\n      102.0\n      275.0\n      12.0\n      8.0\n      8.0\n      335.0\n      3.0\n      4.0\n      11.0\n      14.0\n      12.0\n      8.0\n      0.0\n      1.0\n      0.0\n      2.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      6.0\n      3.0\n      5.0\n      3.0\n      3.0\n      14.0\n      21.4\n      11.0\n      161.0\n      32.0\n      19.9\n      64.0\n      65.0\n      32.0\n      16.0\n      6.0\n      0.0\n      10.0\n      12.0\n      NaN\n      21.0\n      1.0\n      37.0\n      499.0\n      66.0\n      188.0\n      215.0\n      132.0\n      19.0\n      462.0\n      7.0\n      8.0\n      87.5\n      7.0\n      1.0\n      310.0\n      1933.0\n      1122.0\n      55.0\n      19.0\n      4.0\n      8.0\n      7.0\n      374.0\n      335.0\n      89.6\n      25.0\n      1.0\n      0.0\n      0.0\n      15.0\n      12.0\n      2.0\n      12.0\n      12.0\n      6.0\n      0.0\n      1.0\n      0.0\n      57.0\n      12.0\n      13.0\n      48.0\n      NorwichCity\n      2021\n    \n    \n      40\n      2022-05-11\n      19:45\n      Premier League\n      Matchweek 21\n      Wed\n      Away\n      L\n      0\n      3\n      Leicester City\n      0.0\n      9.0\n      5.0\n      55.6\n      0.00\n      0.00\n      16.2\n      0.0\n      0.0\n      0.0\n      1.2\n      1.2\n      0.15\n      -1.2\n      -1.2\n      Match Report\n      8.0\n      5.0\n      62.5\n      0.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      3.0\n      20.0\n      15.0\n      26.0\n      3.0\n      50.0\n      38.9\n      9.0\n      77.8\n      57.4\n      10.0\n      1.0\n      10.0\n      0.0\n      8.0\n      295.0\n      367.0\n      80.4\n      5864.0\n      2054.0\n      132.0\n      148.0\n      89.2\n      119.0\n      133.0\n      89.5\n      41.0\n      74.0\n      55.4\n      0.0\n      0.8\n      5.0\n      16.0\n      7.0\n      1.0\n      22.0\n      367.0\n      323.0\n      44.0\n      11.0\n      0.0\n      58.0\n      18.0\n      7.0\n      2.0\n      2.0\n      0.0\n      0.0\n      250.0\n      46.0\n      71.0\n      90.0\n      238.0\n      11.0\n      18.0\n      4.0\n      295.0\n      0.0\n      6.0\n      9.0\n      11.0\n      12.0\n      8.0\n      1.0\n      1.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      20.0\n      9.0\n      9.0\n      9.0\n      2.0\n      7.0\n      16.0\n      43.8\n      9.0\n      264.0\n      56.0\n      21.2\n      102.0\n      124.0\n      38.0\n      19.0\n      8.0\n      0.0\n      11.0\n      16.0\n      NaN\n      26.0\n      0.0\n      36.0\n      511.0\n      95.0\n      242.0\n      194.0\n      99.0\n      19.0\n      468.0\n      6.0\n      15.0\n      40.0\n      7.0\n      0.0\n      310.0\n      1330.0\n      723.0\n      26.0\n      9.0\n      1.0\n      13.0\n      17.0\n      307.0\n      295.0\n      96.1\n      22.0\n      0.0\n      0.0\n      0.0\n      10.0\n      12.0\n      0.0\n      7.0\n      16.0\n      9.0\n      0.0\n      0.0\n      0.0\n      71.0\n      8.0\n      14.0\n      36.4\n      NorwichCity\n      2021\n    \n    \n      41\n      2022-05-15\n      14:00\n      Premier League\n      Matchweek 37\n      Sun\n      Away\n      D\n      1\n      1\n      Wolves\n      1.0\n      11.0\n      2.0\n      18.2\n      0.09\n      0.50\n      13.4\n      0.0\n      0.0\n      0.0\n      1.3\n      1.3\n      0.12\n      -0.3\n      -0.3\n      Match Report\n      4.0\n      3.0\n      75.0\n      0.0\n      1.1\n      0.1\n      0.0\n      0.0\n      0.0\n      0.0\n      10.0\n      22.0\n      45.5\n      25.0\n      4.0\n      60.0\n      40.9\n      14.0\n      50.0\n      40.6\n      15.0\n      0.0\n      0.0\n      1.0\n      14.0\n      275.0\n      363.0\n      75.8\n      4915.0\n      1856.0\n      125.0\n      143.0\n      87.4\n      112.0\n      131.0\n      85.5\n      31.0\n      73.0\n      42.5\n      1.0\n      1.2\n      9.0\n      12.0\n      2.0\n      0.0\n      14.0\n      363.0\n      320.0\n      43.0\n      5.0\n      2.0\n      40.0\n      6.0\n      4.0\n      3.0\n      3.0\n      0.0\n      0.0\n      243.0\n      47.0\n      73.0\n      120.0\n      199.0\n      13.0\n      19.0\n      7.0\n      275.0\n      0.0\n      10.0\n      15.0\n      6.0\n      19.0\n      8.0\n      4.0\n      3.0\n      0.0\n      1.0\n      3.0\n      2.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      24.0\n      15.0\n      16.0\n      6.0\n      2.0\n      8.0\n      22.0\n      36.4\n      14.0\n      180.0\n      41.0\n      22.8\n      99.0\n      58.0\n      23.0\n      10.0\n      5.0\n      0.0\n      5.0\n      22.0\n      NaN\n      23.0\n      0.0\n      37.0\n      465.0\n      96.0\n      250.0\n      173.0\n      72.0\n      14.0\n      423.0\n      12.0\n      16.0\n      75.0\n      13.0\n      2.0\n      275.0\n      1615.0\n      844.0\n      29.0\n      6.0\n      5.0\n      4.0\n      5.0\n      340.0\n      275.0\n      80.9\n      14.0\n      3.0\n      0.0\n      0.0\n      11.0\n      6.0\n      0.0\n      4.0\n      22.0\n      15.0\n      0.0\n      0.0\n      0.0\n      53.0\n      11.0\n      16.0\n      40.7\n      NorwichCity\n      2021\n    \n    \n      42\n      2022-05-22\n      16:00\n      Premier League\n      Matchweek 38\n      Sun\n      Home\n      L\n      0\n      5\n      Tottenham\n      0.0\n      9.0\n      0.0\n      0.0\n      0.00\n      NaN\n      17.1\n      0.0\n      0.0\n      0.0\n      0.3\n      0.3\n      0.04\n      -0.3\n      -0.3\n      Match Report\n      12.0\n      7.0\n      58.3\n      0.0\n      4.6\n      -0.4\n      0.0\n      0.0\n      0.0\n      0.0\n      4.0\n      14.0\n      28.6\n      28.0\n      7.0\n      39.3\n      39.1\n      4.0\n      75.0\n      59.3\n      5.0\n      0.0\n      0.0\n      0.0\n      11.0\n      335.0\n      422.0\n      79.4\n      7435.0\n      1726.0\n      99.0\n      114.0\n      86.8\n      163.0\n      184.0\n      88.6\n      71.0\n      116.0\n      61.2\n      0.0\n      0.2\n      5.0\n      18.0\n      4.0\n      1.0\n      21.0\n      422.0\n      383.0\n      39.0\n      9.0\n      0.0\n      57.0\n      24.0\n      12.0\n      3.0\n      2.0\n      1.0\n      0.0\n      299.0\n      42.0\n      81.0\n      136.0\n      244.0\n      12.0\n      17.0\n      8.0\n      335.0\n      0.0\n      9.0\n      16.0\n      8.0\n      12.0\n      6.0\n      2.0\n      1.0\n      1.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      5.0\n      9.0\n      2.0\n      0.0\n      3.0\n      16.0\n      18.8\n      13.0\n      117.0\n      32.0\n      27.4\n      44.0\n      40.0\n      33.0\n      8.0\n      4.0\n      1.0\n      4.0\n      16.0\n      NaN\n      7.0\n      1.0\n      40.0\n      505.0\n      61.0\n      206.0\n      222.0\n      101.0\n      17.0\n      466.0\n      6.0\n      13.0\n      46.2\n      8.0\n      2.0\n      344.0\n      1648.0\n      875.0\n      42.0\n      9.0\n      4.0\n      11.0\n      4.0\n      417.0\n      335.0\n      80.3\n      21.0\n      3.0\n      0.0\n      0.0\n      17.0\n      8.0\n      0.0\n      12.0\n      16.0\n      5.0\n      0.0\n      0.0\n      0.0\n      58.0\n      9.0\n      13.0\n      40.9\n      NorwichCity\n      2021\n    \n    \n      43\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      8-7-28\n      32\n      89\n      NaN\n      30.0\n      426.0\n      131.0\n      30.8\n      0.06\n      0.21\n      18.1\n      18.0\n      3.0\n      4.0\n      33.3\n      31.0\n      0.09\n      -3.3\n      -4.0\n      NaN\n      224.0\n      142.0\n      64.3\n      9.0\n      78.7\n      -3.3\n      13.0\n      9.0\n      2.0\n      2.0\n      250.0\n      649.0\n      38.5\n      1046.0\n      194.0\n      46.6\n      39.6\n      309.0\n      52.4\n      44.1\n      350.0\n      17.0\n      4.9\n      17.0\n      12.9\n      11974.0\n      15658.0\n      76.5\n      242050.0\n      81553.0\n      4705.0\n      5440.0\n      86.5\n      5095.0\n      6038.0\n      84.4\n      1985.0\n      3585.0\n      55.4\n      24.0\n      22.7\n      254.0\n      705.0\n      230.0\n      47.0\n      922.0\n      15658.0\n      13820.0\n      1838.0\n      475.0\n      27.0\n      2280.0\n      518.0\n      411.0\n      164.0\n      87.0\n      61.0\n      4.0\n      10004.0\n      2064.0\n      3590.0\n      4770.0\n      8734.0\n      721.0\n      767.0\n      253.0\n      11974.0\n      48.0\n      315.0\n      518.0\n      399.0\n      546.0\n      368.0\n      59.0\n      30.0\n      29.0\n      40.0\n      20.0\n      32.0\n      25.0\n      2.0\n      1.0\n      0.0\n      2.0\n      2.0\n      678.0\n      429.0\n      358.0\n      256.0\n      64.0\n      256.0\n      643.0\n      39.8\n      387.0\n      6146.0\n      1570.0\n      25.5\n      2410.0\n      2488.0\n      1248.0\n      639.0\n      207.0\n      5.0\n      432.0\n      673.0\n      NaN\n      840.0\n      9.0\n      42.7\n      20165.0\n      3068.0\n      8529.0\n      8372.0\n      4463.0\n      692.0\n      18371.0\n      289.0\n      576.0\n      50.2\n      317.0\n      35.0\n      11712.0\n      62580.0\n      33620.0\n      1194.0\n      384.0\n      115.0\n      415.0\n      388.0\n      14702.0\n      11974.0\n      81.4\n      922.0\n      72.0\n      1.0\n      1.0\n      524.0\n      548.0\n      71.0\n      411.0\n      673.0\n      429.0\n      2.0\n      12.0\n      2.0\n      2883.0\n      585.0\n      669.0\n      46.7\n      NorwichCity\n      2021\n    \n  \n\n4884 rows × 177 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      Date\n      Time\n      Comp\n      Round\n      Day\n      Venue\n      Result\n      GF\n      GA\n      Opponent\n      Gls\n      Sh_shooting\n      SoT\n      SoT%\n      G/Sh\n      G/SoT\n      Dist\n      FK_shooting\n      PK\n      PKatt_shooting\n      xG\n      npxG\n      npxG/Sh\n      G-xG\n      np:G-xG\n      Match Report\n      SoTA\n      Saves\n      Save%\n      CS\n      PSxG\n      PSxG+/-\n      PKatt_keeper\n      PKA\n      PKsv\n      PKm\n      Cmp_keeper\n      Att_keeper\n      Cmp%_keeper\n      Att_keeper.1\n      Thr\n      Launch%\n      AvgLen\n      Att_keeper.2\n      Launch%.1\n      AvgLen.1\n      Opp\n      Stp\n      Stp%\n      #OPA\n      AvgDist\n      Cmp_passing\n      Att_passing\n      Cmp%_passing\n      TotDist_passing\n      PrgDist_passing\n      Cmp_passing.1\n      Att_passing.1\n      Cmp%_passing.1\n      Cmp_passing.2\n      Att_passing.2\n      Cmp%_passing.2\n      Cmp_passing.3\n      Att_passing.3\n      Cmp%_passing.3\n      Ast\n      xA\n      KP\n      1/3_passing\n      PPA\n      CrsPA\n      Prog_passing\n      Att_passing_types\n      Live_passing_types\n      Dead\n      FK_passing_types\n      TB\n      Press_passing_types\n      Sw\n      Crs_passing_types\n      CK\n      In\n      Out\n      Str\n      Ground\n      Low\n      High\n      Left\n      Right\n      Head\n      TI\n      Other\n      Cmp_passing_types\n      Off_passing_types\n      Out.1\n      Int_passing_types\n      Blocks_passing_types\n      SCA\n      PassLive\n      PassDead\n      Drib\n      Sh_gca\n      Fld_gca\n      Def\n      GCA\n      PassLive.1\n      PassDead.1\n      Drib.1\n      Sh_gca.1\n      Fld_gca.1\n      Def.1\n      Tkl\n      TklW_defense\n      Def 3rd_defense\n      Mid 3rd_defense\n      Att 3rd_defense\n      Tkl.1\n      Att_defense\n      Tkl%\n      Past\n      Press_defense\n      Succ_defense\n      %\n      Def 3rd_defense.1\n      Mid 3rd_defense.1\n      Att 3rd_defense.1\n      Blocks_defense\n      Sh_defense\n      ShSv\n      Pass\n      Int_defense\n      Tkl+Int\n      Clr\n      Err\n      Poss\n      Touches\n      Def Pen\n      Def 3rd_possession\n      Mid 3rd_possession\n      Att 3rd_possession\n      Att Pen\n      Live_possession\n      Succ_possession\n      Att_possession\n      Succ%\n      #Pl\n      Megs\n      Carries\n      TotDist_possession\n      PrgDist_possession\n      Prog_possession\n      1/3_possession\n      CPA\n      Mis\n      Dis\n      Targ\n      Rec\n      Rec%\n      Prog_possession.1\n      CrdY\n      CrdR\n      2CrdY\n      Fls\n      Fld_misc\n      Off_misc\n      Crs_misc\n      Int_misc\n      TklW_misc\n      PKwon\n      PKcon\n      OG\n      Recov\n      Won\n      Lost\n      Won%\n      team\n      Season\n    \n  \n  \n    \n      count\n      4784\n      4784\n      4784\n      4784\n      4784\n      4784\n      4884\n      4884\n      4884\n      4784\n      4882.000000\n      4855.000000\n      4855.000000\n      4852.000000\n      4852.000000\n      4702.000000\n      4183.000000\n      4186.000000\n      4882.000000\n      4882.000000\n      4186.000000\n      4186.000000\n      4183.000000\n      4186.000000\n      4186.000000\n      4784\n      4855.000000\n      4855.000000\n      4665.000000\n      4872.000000\n      4186.000000\n      4186.000000\n      4882.000000\n      4882.000000\n      4882.000000\n      4882.000000\n      4186.000000\n      4186.000000\n      4180.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4174.000000\n      4174.000000\n      4186.000000\n      4186.000000\n      4167.000000\n      4186.000000\n      4152.00000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.00000\n      4186.000000\n      4880.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4855.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4855.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4855.000000\n      0.0\n      4186.000000\n      4186.000000\n      4853.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4185.000000\n      4185.000000\n      4185.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4882.000000\n      4882.000000\n      4882.000000\n      4855.000000\n      4855.000000\n      4851.000000\n      4855.000000\n      4855.000000\n      4855.000000\n      4429.000000\n      4429.000000\n      4882.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4884\n      4884.000000\n    \n    \n      unique\n      932\n      55\n      8\n      57\n      7\n      3\n      102\n      100\n      79\n      196\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n    \n    \n      top\n      2020-07-26\n      15:00\n      Premier League\n      Group stage\n      Sat\n      Away\n      W\n      1\n      1\n      Chelsea\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Match Report\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Chelsea\n      NaN\n    \n    \n      freq\n      20\n      1304\n      3800\n      204\n      1955\n      2379\n      2024\n      1458\n      1530\n      223\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4784\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      302\n      NaN\n    \n    \n      mean\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2.807046\n      25.024099\n      8.454377\n      34.208780\n      0.107178\n      0.302303\n      17.016161\n      0.916866\n      0.212618\n      0.265465\n      2.650358\n      2.447611\n      0.102305\n      0.325991\n      0.297731\n      NaN\n      7.774253\n      5.405973\n      69.542851\n      0.599343\n      2.554754\n      0.007215\n      0.244982\n      0.191315\n      0.038918\n      0.014748\n      12.899188\n      33.093168\n      41.963493\n      47.056856\n      7.976589\n      49.877926\n      41.947181\n      14.445294\n      65.545208\n      51.673766\n      16.774009\n      1.260870\n      7.495824\n      1.270425\n      14.44039\n      778.702819\n      979.663641\n      77.703321\n      15260.310081\n      5068.769231\n      318.322026\n      361.893454\n      86.891519\n      330.830387\n      384.102246\n      84.293048\n      115.584329\n      197.11419\n      57.708624\n      2.017623\n      1.808576\n      17.715719\n      58.741042\n      16.486861\n      3.909221\n      64.507883\n      979.663641\n      886.577162\n      93.086479\n      22.768275\n      1.907788\n      146.339226\n      28.565217\n      25.307930\n      10.187769\n      4.153846\n      3.428571\n      0.769231\n      646.799331\n      132.541806\n      200.322504\n      271.279025\n      588.523650\n      39.738175\n      41.058290\n      12.734353\n      778.702819\n      3.241280\n      17.334448\n      22.790731\n      23.553751\n      38.194458\n      27.595318\n      3.312470\n      2.381749\n      1.967511\n      2.090301\n      0.847109\n      4.365504\n      2.998567\n      0.281892\n      0.305781\n      0.356904\n      0.320115\n      0.102246\n      34.440038\n      20.515345\n      17.107023\n      13.040134\n      4.292881\n      11.609651\n      31.862398\n      36.524319\n      20.252747\n      294.902054\n      85.661252\n      29.545485\n      100.644052\n      128.161968\n      66.096034\n      30.767320\n      7.319637\n      0.153846\n      23.447683\n      23.006797\n      NaN\n      47.913521\n      0.542284\n      51.159242\n      1213.857143\n      127.489250\n      388.689441\n      576.553273\n      322.073101\n      47.647396\n      1122.888677\n      19.130435\n      32.597707\n      58.473340\n      20.764931\n      1.397516\n      763.685141\n      3891.837076\n      2095.075490\n      85.597611\n      25.697013\n      8.394265\n      23.881032\n      23.030100\n      923.780698\n      778.700430\n      82.872934\n      68.917821\n      3.081934\n      0.107743\n      0.046293\n      23.768486\n      22.819773\n      3.692022\n      25.307930\n      23.006797\n      20.515345\n      0.222624\n      0.245202\n      0.081934\n      175.380315\n      36.778309\n      36.482083\n      50.300263\n      NaN\n      2018.999795\n    \n    \n      std\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      10.633434\n      88.799785\n      30.533485\n      15.894195\n      0.106387\n      0.260790\n      2.956683\n      3.218861\n      0.931731\n      1.123947\n      8.894023\n      8.208661\n      0.045897\n      3.151378\n      3.001137\n      NaN\n      26.650273\n      18.596239\n      27.910813\n      2.295011\n      8.196880\n      1.103346\n      0.979508\n      0.793245\n      0.237192\n      0.134986\n      41.759788\n      107.882512\n      17.911863\n      150.427337\n      26.089799\n      23.767444\n      11.250174\n      45.771924\n      31.433860\n      17.035460\n      53.173125\n      4.175571\n      10.930395\n      4.553672\n      4.93127\n      2605.489763\n      3208.035980\n      7.414447\n      50630.636493\n      16299.172616\n      1068.855698\n      1202.422025\n      4.805741\n      1123.135331\n      1282.943241\n      6.690822\n      377.078549\n      624.91629\n      11.307517\n      7.763338\n      6.131791\n      58.080111\n      197.829053\n      55.986741\n      12.654073\n      214.622704\n      3208.035980\n      2925.037009\n      292.535663\n      72.090205\n      7.136800\n      470.335604\n      93.135721\n      88.390685\n      33.119199\n      13.731657\n      12.164358\n      2.915172\n      2207.910917\n      423.589872\n      630.932794\n      917.313240\n      1963.754151\n      125.726147\n      129.347165\n      40.881764\n      2605.489763\n      10.552076\n      54.773459\n      75.022925\n      74.970220\n      125.518394\n      91.755801\n      10.691361\n      8.137498\n      6.618276\n      6.873735\n      2.885309\n      15.374347\n      10.847460\n      1.038030\n      1.256439\n      1.326036\n      1.209979\n      0.497602\n      108.322327\n      70.287520\n      54.061008\n      41.315181\n      13.986381\n      36.726989\n      100.519999\n      14.096407\n      64.120993\n      927.776033\n      270.289930\n      6.137151\n      318.495026\n      404.369150\n      212.614304\n      96.855501\n      23.584690\n      0.649772\n      73.919927\n      80.317731\n      NaN\n      152.214124\n      1.913732\n      12.765971\n      3922.818669\n      401.789918\n      1232.300695\n      1895.667845\n      1063.463054\n      158.530092\n      3643.085181\n      62.084728\n      104.776235\n      14.357941\n      67.270208\n      4.731968\n      2539.014612\n      12895.247448\n      7030.655371\n      293.742138\n      86.595433\n      29.033431\n      75.264289\n      73.034432\n      3043.493873\n      2605.477967\n      6.643909\n      228.821950\n      10.680582\n      0.491127\n      0.269891\n      81.167475\n      78.675002\n      13.030748\n      88.390685\n      80.317731\n      70.287520\n      0.936620\n      0.944928\n      0.389166\n      552.150279\n      116.590220\n      116.000905\n      10.049628\n      NaN\n      1.414431\n    \n    \n      min\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.020000\n      -10.300000\n      -9.700000\n      NaN\n      0.000000\n      0.000000\n      -100.000000\n      0.000000\n      0.000000\n      -11.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      5.000000\n      0.000000\n      0.000000\n      15.800000\n      0.000000\n      0.000000\n      6.700000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      2.00000\n      97.000000\n      179.000000\n      49.100000\n      2201.000000\n      931.000000\n      34.000000\n      54.000000\n      60.700000\n      22.000000\n      41.000000\n      53.700000\n      11.000000\n      46.00000\n      20.400000\n      0.000000\n      0.000000\n      0.000000\n      3.000000\n      0.000000\n      0.000000\n      2.000000\n      179.000000\n      130.000000\n      21.000000\n      0.000000\n      0.000000\n      5.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      56.000000\n      12.000000\n      41.000000\n      26.000000\n      92.000000\n      2.000000\n      3.000000\n      0.000000\n      97.000000\n      0.000000\n      0.000000\n      0.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      3.000000\n      0.000000\n      0.000000\n      39.000000\n      10.000000\n      11.500000\n      4.000000\n      11.000000\n      3.000000\n      2.000000\n      0.000000\n      0.000000\n      1.000000\n      0.000000\n      NaN\n      1.000000\n      0.000000\n      17.000000\n      299.000000\n      16.000000\n      56.000000\n      91.000000\n      25.000000\n      0.000000\n      261.000000\n      0.000000\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      105.000000\n      446.000000\n      188.000000\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      150.000000\n      97.000000\n      55.000000\n      2.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      37.000000\n      1.000000\n      1.000000\n      10.000000\n      NaN\n      2017.000000\n    \n    \n      25%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      0.000000\n      9.000000\n      2.000000\n      23.800000\n      0.000000\n      0.000000\n      15.100000\n      0.000000\n      0.000000\n      0.000000\n      0.800000\n      0.700000\n      0.070000\n      -0.600000\n      -0.600000\n      NaN\n      2.000000\n      1.000000\n      50.000000\n      0.000000\n      0.600000\n      -0.400000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      10.000000\n      30.000000\n      19.000000\n      2.000000\n      30.800000\n      33.000000\n      5.000000\n      42.900000\n      38.600000\n      5.000000\n      0.000000\n      0.000000\n      0.000000\n      11.30000\n      289.250000\n      395.000000\n      73.000000\n      5805.250000\n      2197.000000\n      117.000000\n      139.000000\n      84.100000\n      114.000000\n      141.000000\n      80.625000\n      45.000000\n      88.00000\n      49.600000\n      0.000000\n      0.500000\n      6.000000\n      20.000000\n      5.000000\n      1.000000\n      23.000000\n      395.000000\n      346.250000\n      42.000000\n      9.000000\n      0.000000\n      54.000000\n      10.000000\n      8.000000\n      3.000000\n      1.000000\n      0.000000\n      0.000000\n      224.000000\n      53.000000\n      86.000000\n      99.000000\n      220.000000\n      15.000000\n      17.000000\n      4.000000\n      289.250000\n      1.000000\n      7.000000\n      7.000000\n      9.000000\n      13.000000\n      9.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      14.000000\n      8.000000\n      6.000000\n      5.000000\n      1.000000\n      4.000000\n      12.000000\n      27.300000\n      7.000000\n      122.000000\n      35.000000\n      25.400000\n      36.000000\n      51.000000\n      25.000000\n      12.000000\n      2.000000\n      0.000000\n      9.000000\n      7.000000\n      NaN\n      16.000000\n      0.000000\n      42.000000\n      521.000000\n      53.000000\n      171.000000\n      227.000000\n      120.000000\n      16.000000\n      473.000000\n      7.000000\n      12.000000\n      50.000000\n      7.000000\n      0.000000\n      289.000000\n      1457.500000\n      743.000000\n      27.000000\n      8.000000\n      2.000000\n      9.000000\n      9.000000\n      365.000000\n      289.250000\n      78.700000\n      25.000000\n      1.000000\n      0.000000\n      0.000000\n      9.000000\n      9.000000\n      1.000000\n      8.000000\n      7.000000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      78.000000\n      13.000000\n      13.000000\n      44.000000\n      NaN\n      2018.000000\n    \n    \n      50%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.000000\n      12.000000\n      4.000000\n      33.300000\n      0.090000\n      0.290000\n      16.900000\n      0.000000\n      0.000000\n      0.000000\n      1.300000\n      1.100000\n      0.090000\n      -0.100000\n      -0.100000\n      NaN\n      4.000000\n      3.000000\n      71.400000\n      0.000000\n      1.200000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.000000\n      17.000000\n      40.000000\n      23.000000\n      4.000000\n      50.000000\n      40.900000\n      7.000000\n      71.400000\n      54.300000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      14.00000\n      384.000000\n      491.000000\n      78.600000\n      7600.500000\n      2575.000000\n      155.500000\n      178.000000\n      87.700000\n      162.000000\n      189.000000\n      85.600000\n      58.000000\n      100.00000\n      57.800000\n      1.000000\n      0.800000\n      9.000000\n      28.000000\n      8.000000\n      2.000000\n      32.000000\n      491.000000\n      441.000000\n      48.000000\n      12.000000\n      1.000000\n      72.000000\n      14.000000\n      12.000000\n      5.000000\n      2.000000\n      1.000000\n      0.000000\n      315.000000\n      66.000000\n      102.000000\n      129.000000\n      290.000000\n      20.000000\n      21.000000\n      6.000000\n      384.000000\n      1.000000\n      9.000000\n      11.000000\n      12.000000\n      19.000000\n      13.000000\n      2.000000\n      1.000000\n      1.000000\n      1.000000\n      0.000000\n      2.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.000000\n      10.000000\n      8.000000\n      6.000000\n      2.000000\n      6.000000\n      16.000000\n      36.250000\n      10.000000\n      148.000000\n      43.000000\n      29.300000\n      49.000000\n      64.000000\n      33.000000\n      15.000000\n      3.000000\n      0.000000\n      12.000000\n      11.000000\n      NaN\n      23.000000\n      0.000000\n      51.000000\n      611.000000\n      64.000000\n      198.000000\n      288.000000\n      155.000000\n      23.000000\n      564.000000\n      9.000000\n      16.000000\n      58.800000\n      10.000000\n      0.000000\n      379.000000\n      1935.500000\n      1024.500000\n      40.000000\n      12.000000\n      4.000000\n      12.000000\n      12.000000\n      460.500000\n      384.000000\n      83.800000\n      34.000000\n      1.000000\n      0.000000\n      0.000000\n      12.000000\n      12.000000\n      2.000000\n      12.000000\n      11.000000\n      10.000000\n      0.000000\n      0.000000\n      0.000000\n      89.000000\n      18.000000\n      18.000000\n      50.000000\n      NaN\n      2019.000000\n    \n    \n      75%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2.000000\n      16.000000\n      6.000000\n      43.800000\n      0.170000\n      0.500000\n      18.700000\n      1.000000\n      0.000000\n      0.000000\n      1.900000\n      1.700000\n      0.120000\n      0.600000\n      0.600000\n      NaN\n      6.000000\n      4.000000\n      100.000000\n      1.000000\n      1.900000\n      0.400000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      9.000000\n      24.000000\n      50.000000\n      29.000000\n      6.000000\n      68.400000\n      50.400000\n      10.000000\n      100.000000\n      66.000000\n      11.000000\n      1.000000\n      12.500000\n      1.000000\n      16.90000\n      502.000000\n      605.000000\n      83.300000\n      9785.250000\n      3022.750000\n      203.000000\n      228.000000\n      90.300000\n      223.000000\n      252.000000\n      89.400000\n      73.000000\n      114.00000\n      66.100000\n      2.000000\n      1.300000\n      12.000000\n      39.000000\n      11.000000\n      3.000000\n      43.000000\n      605.000000\n      557.000000\n      53.750000\n      14.000000\n      2.000000\n      93.000000\n      19.000000\n      17.000000\n      7.000000\n      3.000000\n      3.000000\n      1.000000\n      433.000000\n      82.000000\n      119.000000\n      169.000000\n      379.000000\n      25.000000\n      25.000000\n      9.000000\n      502.000000\n      3.000000\n      11.000000\n      16.000000\n      15.000000\n      26.000000\n      19.000000\n      3.000000\n      2.000000\n      2.000000\n      2.000000\n      1.000000\n      4.000000\n      2.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      21.000000\n      13.000000\n      11.000000\n      9.000000\n      3.000000\n      8.000000\n      20.000000\n      45.500000\n      13.000000\n      179.000000\n      53.000000\n      33.500000\n      65.000000\n      80.000000\n      43.000000\n      20.000000\n      5.000000\n      0.000000\n      15.000000\n      16.000000\n      NaN\n      32.000000\n      0.000000\n      61.000000\n      723.000000\n      77.000000\n      226.000000\n      358.000000\n      206.000000\n      32.000000\n      676.000000\n      13.000000\n      21.000000\n      68.150000\n      14.000000\n      1.000000\n      491.000000\n      2538.000000\n      1391.750000\n      58.000000\n      17.000000\n      6.000000\n      15.000000\n      15.000000\n      578.000000\n      502.000000\n      87.800000\n      45.000000\n      2.000000\n      0.000000\n      0.000000\n      15.000000\n      14.000000\n      3.000000\n      17.000000\n      16.000000\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      102.000000\n      24.000000\n      24.000000\n      56.700000\n      NaN\n      2020.000000\n    \n    \n      max\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      162.000000\n      1140.000000\n      418.000000\n      100.000000\n      1.000000\n      1.000000\n      34.900000\n      50.000000\n      18.000000\n      22.000000\n      115.600000\n      107.600000\n      0.370000\n      59.200000\n      57.500000\n      NaN\n      246.000000\n      184.000000\n      100.000000\n      33.000000\n      78.700000\n      11.900000\n      13.000000\n      13.000000\n      3.000000\n      3.000000\n      435.000000\n      1122.000000\n      100.000000\n      1702.000000\n      290.000000\n      100.000000\n      78.000000\n      417.000000\n      100.000000\n      106.000000\n      464.000000\n      53.000000\n      100.000000\n      80.000000\n      85.00000\n      32015.000000\n      37015.000000\n      93.000000\n      597272.000000\n      176070.000000\n      14699.000000\n      16107.000000\n      97.700000\n      14051.000000\n      15205.000000\n      96.400000\n      4291.000000\n      6303.00000\n      89.000000\n      127.000000\n      82.600000\n      676.000000\n      2552.000000\n      734.000000\n      135.000000\n      2578.000000\n      37015.000000\n      34410.000000\n      2728.000000\n      751.000000\n      136.000000\n      5062.000000\n      1145.000000\n      1035.000000\n      398.000000\n      170.000000\n      267.000000\n      51.000000\n      28713.000000\n      4655.000000\n      5891.000000\n      14393.000000\n      27064.000000\n      1190.000000\n      1223.000000\n      419.000000\n      32015.000000\n      110.000000\n      509.000000\n      962.000000\n      744.000000\n      1471.000000\n      1128.000000\n      130.000000\n      119.000000\n      97.000000\n      81.000000\n      39.000000\n      216.000000\n      164.000000\n      14.000000\n      19.000000\n      22.000000\n      17.000000\n      10.000000\n      901.000000\n      670.000000\n      476.000000\n      377.000000\n      168.000000\n      373.000000\n      916.000000\n      100.000000\n      585.000000\n      8089.000000\n      2429.000000\n      53.800000\n      2948.000000\n      3705.000000\n      2388.000000\n      867.000000\n      251.000000\n      9.000000\n      688.000000\n      846.000000\n      NaN\n      1486.000000\n      29.000000\n      85.000000\n      43032.000000\n      3617.000000\n      12063.000000\n      22515.000000\n      13154.000000\n      2090.000000\n      40508.000000\n      695.000000\n      1086.000000\n      100.000000\n      743.000000\n      70.000000\n      31423.000000\n      154478.000000\n      89994.000000\n      4119.000000\n      1150.000000\n      463.000000\n      697.000000\n      735.000000\n      35814.000000\n      32015.000000\n      99.600000\n      2725.000000\n      110.000000\n      7.000000\n      4.000000\n      836.000000\n      889.000000\n      170.000000\n      1035.000000\n      846.000000\n      670.000000\n      16.000000\n      12.000000\n      5.000000\n      5087.000000\n      1155.000000\n      1193.000000\n      90.900000\n      NaN\n      2021.000000\n    \n  \n\n\n\n\n\n#collapse-output\n[ (x,dfAll[x].dtype) for x in dfAll]\n\n[('Date', dtype('O')),\n ('Time', dtype('O')),\n ('Comp', dtype('O')),\n ('Round', dtype('O')),\n ('Day', dtype('O')),\n ('Venue', dtype('O')),\n ('Result', dtype('O')),\n ('GF', dtype('O')),\n ('GA', dtype('O')),\n ('Opponent', dtype('O')),\n ('Gls', dtype('float64')),\n ('Sh_shooting', dtype('float64')),\n ('SoT', dtype('float64')),\n ('SoT%', dtype('float64')),\n ('G/Sh', dtype('float64')),\n ('G/SoT', dtype('float64')),\n ('Dist', dtype('float64')),\n ('FK_shooting', dtype('float64')),\n ('PK', dtype('float64')),\n ('PKatt_shooting', dtype('float64')),\n ('xG', dtype('float64')),\n ('npxG', dtype('float64')),\n ('npxG/Sh', dtype('float64')),\n ('G-xG', dtype('float64')),\n ('np:G-xG', dtype('float64')),\n ('Match Report', dtype('O')),\n ('SoTA', dtype('float64')),\n ('Saves', dtype('float64')),\n ('Save%', dtype('float64')),\n ('CS', dtype('float64')),\n ('PSxG', dtype('float64')),\n ('PSxG+/-', dtype('float64')),\n ('PKatt_keeper', dtype('float64')),\n ('PKA', dtype('float64')),\n ('PKsv', dtype('float64')),\n ('PKm', dtype('float64')),\n ('Cmp_keeper', dtype('float64')),\n ('Att_keeper', dtype('float64')),\n ('Cmp%_keeper', dtype('float64')),\n ('Att_keeper.1', dtype('float64')),\n ('Thr', dtype('float64')),\n ('Launch%', dtype('float64')),\n ('AvgLen', dtype('float64')),\n ('Att_keeper.2', dtype('float64')),\n ('Launch%.1', dtype('float64')),\n ('AvgLen.1', dtype('float64')),\n ('Opp', dtype('float64')),\n ('Stp', dtype('float64')),\n ('Stp%', dtype('float64')),\n ('#OPA', dtype('float64')),\n ('AvgDist', dtype('float64')),\n ('Cmp_passing', dtype('float64')),\n ('Att_passing', dtype('float64')),\n ('Cmp%_passing', dtype('float64')),\n ('TotDist_passing', dtype('float64')),\n ('PrgDist_passing', dtype('float64')),\n ('Cmp_passing.1', dtype('float64')),\n ('Att_passing.1', dtype('float64')),\n ('Cmp%_passing.1', dtype('float64')),\n ('Cmp_passing.2', dtype('float64')),\n ('Att_passing.2', dtype('float64')),\n ('Cmp%_passing.2', dtype('float64')),\n ('Cmp_passing.3', dtype('float64')),\n ('Att_passing.3', dtype('float64')),\n ('Cmp%_passing.3', dtype('float64')),\n ('Ast', dtype('float64')),\n ('xA', dtype('float64')),\n ('KP', dtype('float64')),\n ('1/3_passing', dtype('float64')),\n ('PPA', dtype('float64')),\n ('CrsPA', dtype('float64')),\n ('Prog_passing', dtype('float64')),\n ('Att_passing_types', dtype('float64')),\n ('Live_passing_types', dtype('float64')),\n ('Dead', dtype('float64')),\n ('FK_passing_types', dtype('float64')),\n ('TB', dtype('float64')),\n ('Press_passing_types', dtype('float64')),\n ('Sw', dtype('float64')),\n ('Crs_passing_types', dtype('float64')),\n ('CK', dtype('float64')),\n ('In', dtype('float64')),\n ('Out', dtype('float64')),\n ('Str', dtype('float64')),\n ('Ground', dtype('float64')),\n ('Low', dtype('float64')),\n ('High', dtype('float64')),\n ('Left', dtype('float64')),\n ('Right', dtype('float64')),\n ('Head', dtype('float64')),\n ('TI', dtype('float64')),\n ('Other', dtype('float64')),\n ('Cmp_passing_types', dtype('float64')),\n ('Off_passing_types', dtype('float64')),\n ('Out.1', dtype('float64')),\n ('Int_passing_types', dtype('float64')),\n ('Blocks_passing_types', dtype('float64')),\n ('SCA', dtype('float64')),\n ('PassLive', dtype('float64')),\n ('PassDead', dtype('float64')),\n ('Drib', dtype('float64')),\n ('Sh_gca', dtype('float64')),\n ('Fld_gca', dtype('float64')),\n ('Def', dtype('float64')),\n ('GCA', dtype('float64')),\n ('PassLive.1', dtype('float64')),\n ('PassDead.1', dtype('float64')),\n ('Drib.1', dtype('float64')),\n ('Sh_gca.1', dtype('float64')),\n ('Fld_gca.1', dtype('float64')),\n ('Def.1', dtype('float64')),\n ('Tkl', dtype('float64')),\n ('TklW_defense', dtype('float64')),\n ('Def 3rd_defense', dtype('float64')),\n ('Mid 3rd_defense', dtype('float64')),\n ('Att 3rd_defense', dtype('float64')),\n ('Tkl.1', dtype('float64')),\n ('Att_defense', dtype('float64')),\n ('Tkl%', dtype('float64')),\n ('Past', dtype('float64')),\n ('Press_defense', dtype('float64')),\n ('Succ_defense', dtype('float64')),\n ('%', dtype('float64')),\n ('Def 3rd_defense.1', dtype('float64')),\n ('Mid 3rd_defense.1', dtype('float64')),\n ('Att 3rd_defense.1', dtype('float64')),\n ('Blocks_defense', dtype('float64')),\n ('Sh_defense', dtype('float64')),\n ('ShSv', dtype('float64')),\n ('Pass', dtype('float64')),\n ('Int_defense', dtype('float64')),\n ('Tkl+Int', dtype('float64')),\n ('Clr', dtype('float64')),\n ('Err', dtype('float64')),\n ('Poss', dtype('float64')),\n ('Touches', dtype('float64')),\n ('Def Pen', dtype('float64')),\n ('Def 3rd_possession', dtype('float64')),\n ('Mid 3rd_possession', dtype('float64')),\n ('Att 3rd_possession', dtype('float64')),\n ('Att Pen', dtype('float64')),\n ('Live_possession', dtype('float64')),\n ('Succ_possession', dtype('float64')),\n ('Att_possession', dtype('float64')),\n ('Succ%', dtype('float64')),\n ('#Pl', dtype('float64')),\n ('Megs', dtype('float64')),\n ('Carries', dtype('float64')),\n ('TotDist_possession', dtype('float64')),\n ('PrgDist_possession', dtype('float64')),\n ('Prog_possession', dtype('float64')),\n ('1/3_possession', dtype('float64')),\n ('CPA', dtype('float64')),\n ('Mis', dtype('float64')),\n ('Dis', dtype('float64')),\n ('Targ', dtype('float64')),\n ('Rec', dtype('float64')),\n ('Rec%', dtype('float64')),\n ('Prog_possession.1', dtype('float64')),\n ('CrdY', dtype('float64')),\n ('CrdR', dtype('float64')),\n ('2CrdY', dtype('float64')),\n ('Fls', dtype('float64')),\n ('Fld_misc', dtype('float64')),\n ('Off_misc', dtype('float64')),\n ('Crs_misc', dtype('float64')),\n ('Int_misc', dtype('float64')),\n ('TklW_misc', dtype('float64')),\n ('PKwon', dtype('float64')),\n ('PKcon', dtype('float64')),\n ('OG', dtype('float64')),\n ('Recov', dtype('float64')),\n ('Won', dtype('float64')),\n ('Lost', dtype('float64')),\n ('Won%', dtype('float64')),\n ('team', dtype('O')),\n ('Season', dtype('int64'))]\n\n\n\nChange some columns\n\nAdd the predictor column as Win from result\nChange time to an int of the time eg 16:30 goes to 16.5\nChange date to day, month, year and day of week weekday\nConvert result to int of 2, 1, 0 for W/D/L\nChange round to just an int of the matchweek\nConvert some columns to int\nSort the DataFrame by season and then round\nMake sure team names are consistent (sometimes name in opponent column differ from team column\ndrop columns won’t be using\nselect matches from Premier league only\ncreate a new DataFrame not lined to old one in case we want old details\n\n\nimport re\n# Some date time functions\ndef just_time(time):\n    return time.time().hour+time.time().minute/60\ndef just_datesDay(time):\n    return time.day\ndef just_datesMonth(time):\n    return time.month\ndef just_datesYear(time):\n    return time.year\ndef just_datesWeekDay(time):\n    return time.weekday()\n\n# Mods to target result\ndef Result(string):\n    if string=='W':\n        return 2\n    elif string=='D':\n        return 1\n    else:\n        return 0\n    \ndef columnMods(matches):\n    \n    cols= matches.columns\n    cols=[x.lower() for x in cols]\n    matches.columns = cols\n    \n    # Misc\n    \n    matches = matches.astype({'gf': 'int'})\n    matches = matches.astype({'ga': 'int'})\n    \n    \n    # some adjustments to time/dates\n    \n    matches=matches.astype({'date': 'datetime64[ns]'})\n    matches = matches.astype({'time': 'datetime64[ns]'})\n    \n    matches['day'] = matches['date'].apply(just_datesDay)\n    matches['month'] = matches['date'].apply(just_datesMonth)\n    matches['year'] = matches['date'].apply(just_datesYear)\n    matches['weekday'] = matches['date'].apply(just_datesWeekDay)\n\n    # target and results\n    matches['Win']=matches['result']\n    \n    matches['NetScore']=matches['gf']-matches['ga']\n    matches['GoalsFor']=matches['gf']\n    matches['GoalsAgainst']=matches['ga']\n\n    matches['result'] = matches['NetScore']#matches['result'].apply(Result)\n    \n    # Change round to an int\n    matches['round']=matches['round'].str.replace('Matchweek ','').astype('int')\n    \n    # drop some columns\n    \n    matches.drop(columns=['comp','match report','date','time','tkl+int'],inplace=True)\n    \n    try:\n        matches = matches.drop(columns='index')\n    except:\n        pass\n        \n    try:\n        matches = matches.drop(columns='unnamed: 0')\n    except:\n        pass\n    \n    \n    #order by date\n    matches=matches.sort_values(['season','round']).reset_index(drop=True)\n\n    \n    # team name changes\n    changeTeamName={'Brighton':'Brighton and Hove Albion',\n                'Manchester Utd':'Manchester United',\n                'Newcastle Utd':'Newcastle United',\n                'Sheffield Utd' : 'Sheffield United',\n                'Huddersfield' : 'Huddersfield Town',\n                'Tottenham' : 'Tottenham Hotspur',\n                'West Brom' : 'West Bromwich Albion',\n                'West Ham' : 'West Ham United',\n                'Wolves' : 'Wolverhampton Wanderers'}\n    matches['opponent']=matches['opponent'].replace(changeTeamName)\n    matches['team']=matches['team'].replace(changeTeamName)\n\n    noms=pd.concat([matches.team,matches.opponent]).sort_values().unique()\n\n    teamDict={}\n    for team in noms:\n\n        x= re.sub(r\"([a-z])([A-Z])\",r\"\\1 \\2\",team) \n        teamout =  re.sub(r\"(and)\\s\",r\" \\1 \",x).strip().replace('  ',' ')    \n        teamDict[team]=teamout\n        \n    matches['team']=matches['team'].replace(teamDict)\n    matches['opponent']=matches['opponent'].replace(teamDict)\n    \n    return matches\n\nimport copy\nmatches=copy.copy(dfAll)\nmatches=matches[matches.Comp=='Premier League']\n\nmatches = columnMods(matches)\nmatches[matches.season==2019]\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue\n      result\n      gf\n      ga\n      opponent\n      gls\n      sh_shooting\n      sot\n      ...\n      won%\n      team\n      season\n      month\n      year\n      weekday\n      Win\n      NetScore\n      GoalsFor\n      GoalsAgainst\n    \n  \n  \n    \n      1520\n      1\n      9\n      Home\n      3\n      4\n      1\n      Norwich City\n      3.0\n      15.0\n      7.0\n      ...\n      77.8\n      Liverpool\n      2019\n      8\n      2019\n      4\n      W\n      3\n      4\n      1\n    \n    \n      1521\n      1\n      10\n      Away\n      5\n      5\n      0\n      West Ham United\n      5.0\n      13.0\n      8.0\n      ...\n      50.0\n      Manchester City\n      2019\n      8\n      2019\n      5\n      W\n      5\n      5\n      0\n    \n    \n      1522\n      1\n      11\n      Home\n      4\n      4\n      0\n      Chelsea\n      4.0\n      10.0\n      4.0\n      ...\n      70.6\n      Manchester United\n      2019\n      8\n      2019\n      6\n      W\n      4\n      4\n      0\n    \n    \n      1523\n      1\n      11\n      Away\n      -4\n      0\n      4\n      Manchester United\n      0.0\n      18.0\n      7.0\n      ...\n      29.4\n      Chelsea\n      2019\n      8\n      2019\n      6\n      L\n      -4\n      0\n      4\n    \n    \n      1524\n      1\n      11\n      Home\n      0\n      0\n      0\n      Wolverhampton Wanderers\n      0.0\n      17.0\n      1.0\n      ...\n      56.8\n      Leicester City\n      2019\n      8\n      2019\n      6\n      D\n      0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2275\n      38\n      26\n      Home\n      0\n      1\n      1\n      Aston Villa\n      1.0\n      10.0\n      1.0\n      ...\n      61.0\n      West Ham United\n      2019\n      7\n      2020\n      6\n      D\n      0\n      1\n      1\n    \n    \n      2276\n      38\n      26\n      Away\n      0\n      1\n      1\n      West Ham United\n      1.0\n      13.0\n      4.0\n      ...\n      39.0\n      Aston Villa\n      2019\n      7\n      2020\n      6\n      D\n      0\n      1\n      1\n    \n    \n      2277\n      38\n      26\n      Away\n      2\n      3\n      1\n      Everton\n      3.0\n      12.0\n      6.0\n      ...\n      46.3\n      Bournemouth\n      2019\n      7\n      2020\n      6\n      W\n      2\n      3\n      1\n    \n    \n      2278\n      38\n      26\n      Away\n      -1\n      2\n      3\n      Arsenal\n      2.0\n      18.0\n      5.0\n      ...\n      56.1\n      Watford\n      2019\n      7\n      2020\n      6\n      L\n      -1\n      2\n      3\n    \n    \n      2279\n      38\n      26\n      Away\n      -5\n      0\n      5\n      Manchester City\n      0.0\n      5.0\n      4.0\n      ...\n      40.0\n      Norwich City\n      2019\n      7\n      2020\n      6\n      L\n      -5\n      0\n      5\n    \n  \n\n760 rows × 179 columns\n\n\n\n\ncluster_features_shootingAll = [\n    \"gls_x\",\"sh_shooting_x\",\n    \"sot_x\",\"sot%_x\",\"g/sh_x\",\"g/sot_x\",\n    \"dist_x\",'fk_shooting_x',\"pk_x\",\"pkatt_shooting_x\",\n    'xg_x','npxg_x','npxg/sh_x','g-xg_x','np:g-xg_x'\n]\n\ncluster_features_keeperAll=[\n    'sota_x','saves_x','save%_x','cs_x',\n 'psxg_x','psxg+/-_x','pkatt_keeper_x','pka_x',\n 'pksv_x','pkm_x','cmp_keeper_x','att_keeper_x','cmp%_keeper_x',\n'cmp%_keeper_x','att_keeper.1_x','thr_x','launch%_x','avglen_x',\n'att_keeper.2_x','launch%.1_x','avglen.1_x','opp_x','stp_x','stp%_x',\n    '#opa_x','avgdist_x'\n]\n\ncluster_features_passingAll=[\n 'cmp_passing_x', 'att_passing_x', 'cmp%_passing_x', 'totdist_passing_x', 'prgdist_passing_x', 'cmp_passing.1_x', 'att_passing.1_x', 'cmp%_passing.1_x',\n 'cmp_passing.2_x', 'att_passing.2_x', 'cmp%_passing.2_x', 'cmp_passing.3_x', 'att_passing.3_x', 'cmp%_passing.3_x', 'ast_x', 'xa_x', 'kp_x', '1/3_passing_x',\n 'ppa_x', 'crspa_x', 'prog_passing_x']\n\ncluster_features_passtypeAll=[\n 'att_passing_types_x', 'live_passing_types_x', 'dead_x', 'fk_passing_types_x', 'tb_x', 'press_passing_types_x', 'sw_x', 'crs_passing_types_x',\n 'ck_x', 'in_x', 'out_x', 'str_x', 'ground_x', 'low_x', 'high_x', 'left_x', 'right_x', 'head_x', 'ti_x', 'other_x', 'cmp_passing_types_x', 'off_passing_types_x', 'out.1_x', 'int_passing_types_x', 'blocks_passing_types_x']\n\ncluster_features_shotcreateAll=[\n 'sca_x', 'passlive_x', 'passdead_x', 'drib_x', 'sh_gca_x', 'fld_gca_x', 'def_x', 'gca_x', 'passlive.1_x', 'passdead.1_x', 'drib.1_x', 'sh_gca.1_x',\n 'fld_gca.1_x', 'def.1_x']\n\ncluster_features_tackleAll=[ 'tkl_x', 'tklw_defense_x', 'def 3rd_defense_x', 'mid 3rd_defense_x', 'att 3rd_defense_x', 'tkl.1_x', 'att_defense_x',\n 'tkl%_x', 'past_x', 'press_defense_x', 'succ_defense_x', '%_x', 'def 3rd_defense.1_x', 'mid 3rd_defense.1_x', 'att 3rd_defense.1_x', 'blocks_defense_x',\n 'sh_defense_x', 'shsv_x', 'pass_x', 'tkl+int_x','int_defense_x', 'clr_x', 'err_x']\n\ncluster_features_possessionAll=[\n 'poss_x', 'touches_x', 'def pen_x', 'def 3rd_possession_x', 'mid 3rd_possession_x', 'att 3rd_possession_x', 'att pen_x', 'live_possession_x', 'succ_possession_x', 'att_possession_x', 'succ%_x',\n '#pl_x', 'megs_x', 'carries_x', 'totdist_possession_x', 'prgdist_possession_x', 'prog_possession_x', '1/3_possession_x', 'cpa_x', 'mis_x', 'dis_x', 'targ_x', 'rec_x',\n 'rec%_x', 'prog_possession.1_x']\n\ncluster_features_miscAll=[ 'crdy_x', 'crdr_x', '2crdy_x', 'fls_x', 'fld_misc_x', 'off_misc_x', 'crs_misc_x', 'int_misc_x', 'tklw_misc_x', 'pkwon_x', 'pkcon_x', 'og_x', 'recov_x', 'won_x', 'lost_x', 'won%_x']\n\n\n# [x for x in df]\n\n\nimport re\n\ndef do_dict_col_names(dict1,string,col_names):\n    regexp=string\n    \n    for x in col_names:\n        x=re.sub('(_x$)','',x)\n        if not re.search(regexp,x):\n            x2=string+'_'+x\n#             print(x2)\n            dict1[x]=x2\n        else:\n            x2=re.sub(regexp,'',x)\n            x2=string+'_'+x2\n            x2=x2.strip('_')\n            dict1[x]=x2\n#             print(x,'---',x2)\n    return dict1\n\ndict1={}\ndict1=do_dict_col_names(dict1,r'shooting',cluster_features_shootingAll)\ndict1=do_dict_col_names(dict1,r'keeper',cluster_features_keeperAll)\ndict1=do_dict_col_names(dict1,r'passing',cluster_features_passingAll)\ndict1=do_dict_col_names(dict1,r'passing_types',cluster_features_passtypeAll)\ndict1=do_dict_col_names(dict1,r'shotcreate',cluster_features_shotcreateAll)\ndict1=do_dict_col_names(dict1,r'tackle',cluster_features_tackleAll)\ndict1=do_dict_col_names(dict1,r'possession',cluster_features_possessionAll)\ndict1=do_dict_col_names(dict1,r'misc',cluster_features_miscAll)\n\n\ndictall=dict1.copy()\n\nmatches.columns=matches.columns.str.lower()\n    \ncols=[]\nfor x in matches:\n    try:\n        cols.append(dictall[x])\n#         print('---')\n    except:\n        cols.append(x)\n        \n# for i,x in enumerate(cols):\n#     if re.search(r'^passing_types',x):\n#         x=re.sub(r'(^passing_types)','passingtypes',x)\n#         cols[i]=x\nmatches.columns=cols\nmatches.columns=matches.columns.str.replace('passing_types','passingtypes')\n\n\nnoms=pd.concat([matches.team,matches.opponent]).sort_values().unique()\nnoms\n\narray(['Arsenal', 'Aston Villa', 'Bournemouth', 'Brentford',\n       'Brighton and Hove Albion', 'Burnley', 'Cardiff City', 'Chelsea',\n       'Crystal Palace', 'Everton', 'Fulham', 'Huddersfield Town',\n       'Leeds United', 'Leicester City', 'Liverpool', 'Manchester City',\n       'Manchester United', 'Newcastle United', 'Norwich City',\n       'Sheffield United', 'Southampton', 'Stoke City', 'Swansea City',\n       'Tottenham Hotspur', 'Watford', 'West Bromwich Albion',\n       'West Ham United', 'Wolverhampton Wanderers'], dtype=object)\n\n\n\n\nI want to make some columns percentages\ni.e. number of passes in final 3rd -> pc of passes in final 3rd\n\ndef change_to_pc(col,col_tot,df_matches):\n    df_matches.loc[:,col]=df_matches.loc[:,col].div(df_matches.loc[:,col_tot])*100\n    col_new=re.sub(r'(^[a-z]*_)',r\"\\1PC_\",col)\n\n    df_matches.rename(columns={col:col_new},inplace=True)\n    return df_matches\n\n\n# drop columns 'attempts' but keep the % one after it\ncols_to_drop=[x for x in matches if re.search(r'^passing_',x) and re.search(r'att',x)]\nprint(cols_to_drop)\nmatches = matches.drop(columns=cols_to_drop)\n\n['passing_att', 'passing_att_.1', 'passing_att_.2', 'passing_att_.3']\n\n\n\ncols_to_pc=[x for x in matches if re.search(r'passing_',x) and not re.search(r'passing_ty',x) and not re.search(r'%',x)\\\nand not re.search(r'xa',x) and not re.search(r'kp',x) and not re.search(r'ast',x)\\\nand not re.search(r'dist',x) and not re.search(r'passing_cmp$',x) ]\n\nprint(cols_to_pc)\ncol_tot='passing_cmp'\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n    \n\n\n   \nmatches = change_to_pc('passing_prgdist','passing_cmp',matches)\nmatches = change_to_pc('passing_totdist','passing_cmp',matches)\n\n['passing_cmp_.1', 'passing_cmp_.2', 'passing_cmp_.3', 'passing_1/3', 'passing_ppa', 'passing_crspa', 'passing_prog']\n\n\n\nmatches=matches.rename(columns={'passing_cmp': 'passing_pass_complete',\n 'passing_PCcmp_.1': 'passing_pass_complete.shortPC',\n 'passing_PCcmp_.2': 'passing_pass_complete.mediumPC',\n 'passing_PCcmp_.3': 'passing_pass_complete.longPC',\n})\n\n\n\ncols_to_pc=[x for x in matches if re.search(r'passingtype',x) and not re.search(r'passingtypes_att',x)]\nprint(cols_to_pc)\ncol_tot='passingtypes_att'\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n   \nmatches=matches.drop(columns='passingtypes_att')\n\n\n['passingtypes_live', 'passingtypes_dead', 'passingtypes_fk', 'passingtypes_tb', 'passingtypes_press', 'passingtypes_sw', 'passingtypes_crs', 'passingtypes_ck', 'passingtypes_in', 'passingtypes_out', 'passingtypes_str', 'passingtypes_ground', 'passingtypes_low', 'passingtypes_high', 'passingtypes_left', 'passingtypes_right', 'passingtypes_head', 'passingtypes_ti', 'passingtypes_other', 'passingtypes_cmp', 'passingtypes_off', 'passingtypes_out.1', 'passingtypes_int', 'passingtypes_blocks']\n\n\n\n\nmatches=matches.rename(columns={'tackle_tkl.1':'tackle_tkl_dribble',\n                      'tackle_tkl%' : 'tackle_dribble%',\n                      'tackle_past' : 'tackle_dribllepast',\n                       'tackle_def 3rd_defense.1':'tackle_press_def3rd',\n                       'tackle_mid 3rd_defense.1':'tackle_press_mid3rd',    \n                       'tackle_att 3rd_defense.1':'tackle_press_att3rd',\n                     })\nmatches=matches.drop(columns='tackle_att_defense')\nmatches=matches.drop(columns='tackle_succ_defense')\n\n\n## this makes tackles as % for first 6 values\ncols_to_pc=[x for x in matches if re.search(r'tackle',x) \\\n            and not re.search(r'passingtypes_att',x)]\ncol_tot=cols_to_pc[0]\ncols_to_pc = cols_to_pc[1:6]\n\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n    \n\ncols_to_pc=['tackle_press_def3rd',\n'tackle_press_mid3rd',    \n'tackle_press_att3rd']\ncol_tot='tackle_press_defense'\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n    \ncol_tot='tackle_blocks_defense'\ncols_to_pc=['tackle_sh_defense','tackle_shsv' ,'tackle_pass']\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n\n\n## possession touches\ncols_to_pc=[x for x in matches if re.search(r'possession',x)  ]\n\n\ncol_tot=cols_to_pc[1]\ncols_to_pc=cols_to_pc[2:8]\nprint(cols_to_pc, col_tot)\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n\n['possession_def pen', 'possession_def 3rd', 'possession_mid 3rd', 'possession_att 3rd', 'possession_att pen', 'possession_live'] possession_touches\n\n\n\nmatches=matches.rename(columns={'possession_succ':'possession_dribblesucc',\n'possession_att':'possession_dribbleatt',\n'possession_succ%':'possession_dribblesucc%',\n'possession_#pl':'possession_dribblepast'})\n\n\ncol_tot='possession_totdist'\ncol='possession_prgdist'\nmatches = change_to_pc(col,col_tot,matches)\n\ncol_tot='possession_carries'\ncols_to_pc=['possession_prog','possession_1/3','possession_cpa','possession_mis','possession_dis']\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n    \n\n\n\ncol_tot='shooting_sh'\ncol='shooting_dist'\nmatches = change_to_pc(col,col_tot,matches)\n\n\nmatches.to_csv(folda+'epl_beforeAVG_HA.csv')\n\n\n\nI want to predict the results without knowing details of the game\n\nso some mods\n\nSo as a first step I will give each gameweek stats for the previous gameweek and the average of the last 5 gameweeks\nThese stats are everything EXCEPT:\n\nround\nday\nvenue\nopponent\nteam\nmonth\nyear\nweekday\nWin\n\n\n#collapse-output\nno_change=['round','day','venue','opponent','team',\\\n 'month','year','weekday','season','Win','NetScore','GoalsFor','GoalsAgainst']\ncolRepeat = [x for x in matches.columns if x not in no_change]\n[x for x in colRepeat]\n\n['result',\n 'gf',\n 'ga',\n 'shooting_gls',\n 'shooting_sh',\n 'shooting_sot',\n 'shooting_sot%',\n 'shooting_g/sh',\n 'shooting_g/sot',\n 'shooting_PC_dist',\n 'shooting_fk',\n 'shooting_pk',\n 'shooting_pkatt',\n 'shooting_xg',\n 'shooting_npxg',\n 'shooting_npxg/sh',\n 'shooting_g-xg',\n 'shooting_np:g-xg',\n 'keeper_sota',\n 'keeper_saves',\n 'keeper_save%',\n 'keeper_cs',\n 'keeper_psxg',\n 'keeper_psxg+/-',\n 'keeper_pkatt',\n 'keeper_pka',\n 'keeper_pksv',\n 'keeper_pkm',\n 'keeper_cmp',\n 'keeper_att',\n 'keeper_cmp%',\n 'keeper_att_.1',\n 'keeper_thr',\n 'keeper_launch%',\n 'keeper_avglen',\n 'keeper_att_.2',\n 'keeper_launch%.1',\n 'keeper_avglen.1',\n 'keeper_opp',\n 'keeper_stp',\n 'keeper_stp%',\n 'keeper_#opa',\n 'keeper_avgdist',\n 'passing_pass_complete',\n 'passing_cmp%',\n 'passing_PC_totdist',\n 'passing_PC_prgdist',\n 'passing_PC_cmp_.1',\n 'passing_cmp%_.1',\n 'passing_PC_cmp_.2',\n 'passing_cmp%_.2',\n 'passing_PC_cmp_.3',\n 'passing_cmp%_.3',\n 'passing_ast',\n 'passing_xa',\n 'passing_kp',\n 'passing_PC_1/3',\n 'passing_PC_ppa',\n 'passing_PC_crspa',\n 'passing_PC_prog',\n 'passingtypes_PC_live',\n 'passingtypes_PC_dead',\n 'passingtypes_PC_fk',\n 'passingtypes_PC_tb',\n 'passingtypes_PC_press',\n 'passingtypes_PC_sw',\n 'passingtypes_PC_crs',\n 'passingtypes_PC_ck',\n 'passingtypes_PC_in',\n 'passingtypes_PC_out',\n 'passingtypes_PC_str',\n 'passingtypes_PC_ground',\n 'passingtypes_PC_low',\n 'passingtypes_PC_high',\n 'passingtypes_PC_left',\n 'passingtypes_PC_right',\n 'passingtypes_PC_head',\n 'passingtypes_PC_ti',\n 'passingtypes_PC_other',\n 'passingtypes_PC_cmp',\n 'passingtypes_PC_off',\n 'passingtypes_PC_out.1',\n 'passingtypes_PC_int',\n 'passingtypes_PC_blocks',\n 'shotcreate_sca',\n 'shotcreate_passlive',\n 'shotcreate_passdead',\n 'shotcreate_drib',\n 'shotcreate_sh_gca',\n 'shotcreate_fld_gca',\n 'shotcreate_def',\n 'shotcreate_gca',\n 'shotcreate_passlive.1',\n 'shotcreate_passdead.1',\n 'shotcreate_drib.1',\n 'shotcreate_sh_gca.1',\n 'shotcreate_fld_gca.1',\n 'shotcreate_def.1',\n 'tackle_tkl',\n 'tackle_PC_tklw_defense',\n 'tackle_PC_def 3rd_defense',\n 'tackle_PC_mid 3rd_defense',\n 'tackle_PC_att 3rd_defense',\n 'tackle_PC_tkl_dribble',\n 'tackle_dribble%',\n 'tackle_dribllepast',\n 'tackle_press_defense',\n 'tackle_%',\n 'tackle_PC_press_def3rd',\n 'tackle_PC_press_mid3rd',\n 'tackle_PC_press_att3rd',\n 'tackle_blocks_defense',\n 'tackle_PC_sh_defense',\n 'tackle_PC_shsv',\n 'tackle_PC_pass',\n 'tackle_int_defense',\n 'tackle_clr',\n 'tackle_err',\n 'possession_poss',\n 'possession_touches',\n 'possession_PC_def pen',\n 'possession_PC_def 3rd',\n 'possession_PC_mid 3rd',\n 'possession_PC_att 3rd',\n 'possession_PC_att pen',\n 'possession_PC_live',\n 'possession_dribblesucc',\n 'possession_dribbleatt',\n 'possession_dribblesucc%',\n 'possession_dribblepast',\n 'possession_megs',\n 'possession_carries',\n 'possession_totdist',\n 'possession_PC_prgdist',\n 'possession_PC_prog',\n 'possession_PC_1/3',\n 'possession_PC_cpa',\n 'possession_PC_mis',\n 'possession_PC_dis',\n 'possession_targ',\n 'possession_rec',\n 'possession_rec%',\n 'possession_prog_.1',\n 'misc_crdy',\n 'misc_crdr',\n 'misc_2crdy',\n 'misc_fls',\n 'misc_fld',\n 'misc_off',\n 'misc_crs',\n 'misc_int',\n 'misc_tklw',\n 'misc_pkwon',\n 'misc_pkcon',\n 'misc_og',\n 'misc_recov',\n 'misc_won',\n 'misc_lost',\n 'misc_won%',\n 'win',\n 'netscore',\n 'goalsfor',\n 'goalsagainst']\n\n\n\n\nConverts data into rolling average of previous matches\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html\n\nwindowint, offset, or BaseIndexer subclass\n\nSize of the moving window.\nIf an integer, the fixed number of observations used for each window.\nIf an offset, the time period of each window. Each window will be a variable sized based on the observations included in the time-period. This is only valid for datetimelike indexes. To learn more about the offsets & frequency strings, please see this link.\nIf a BaseIndexer subclass, the window boundaries based on the defined get_window_bounds method. Additional rolling keyword arguments, namely min_periods, center, and closed will be passed to get_window_bounds.\n\n\n\nmin_periodsint, default None\n\nMinimum number of observations in window required to have a value; otherwise, result is np.nan.\nFor a window that is specified by an offset, min_periods will default to 1.\nFor a window that is specified by an integer, min_periods will default to the size of the window.\n\n\n\nclosed : str, default None\n\nIf ‘right’, the first point in the window is excluded from calculations.\nIf ‘left’, the last point in the window is excluded from calculations.\nIf ‘both’, the no points in the window are excluded from calculations.\nIf ‘neither’, the first and last points in the window are excluded from calculations.\nDefault None (‘right’).\n\n\n#collapse-output\nmatches_=matches.copy()\nfor x in matches_.team.unique():\n    matches_.loc[matches_.team==x,colRepeat] = matches_.loc[matches_.team==x,colRepeat].rolling(window=3,closed='left',min_periods=1).mean()\n\nmatches_.loc[matches_['round']>10].head()\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue\n      result\n      gf\n      ga\n      opponent\n      shooting_gls\n      shooting_sh\n      shooting_sot\n      ...\n      misc_won%\n      team\n      season\n      month\n      year\n      weekday\n      win\n      netscore\n      goalsfor\n      goalsagainst\n    \n  \n  \n    \n      200\n      11\n      5\n      Home\n      3.000000\n      4.333333\n      1.333333\n      Arsenal\n      4.333333\n      16.666667\n      8.666667\n      ...\n      63.633333\n      Manchester City\n      2017\n      11\n      2017\n      6\n      NaN\n      3.000000\n      4.333333\n      1.333333\n    \n    \n      201\n      11\n      5\n      Away\n      0.000000\n      0.666667\n      0.666667\n      Chelsea\n      0.666667\n      9.000000\n      2.666667\n      ...\n      54.000000\n      Manchester United\n      2017\n      11\n      2017\n      6\n      NaN\n      0.000000\n      0.666667\n      0.666667\n    \n    \n      202\n      11\n      5\n      Home\n      1.000000\n      1.666667\n      0.666667\n      Crystal Palace\n      1.666667\n      14.666667\n      5.000000\n      ...\n      51.466667\n      Tottenham Hotspur\n      2017\n      11\n      2017\n      6\n      NaN\n      1.000000\n      1.666667\n      0.666667\n    \n    \n      203\n      11\n      4\n      Away\n      0.000000\n      1.333333\n      1.333333\n      West Ham United\n      1.333333\n      16.000000\n      6.333333\n      ...\n      46.800000\n      Liverpool\n      2017\n      11\n      2017\n      5\n      NaN\n      0.000000\n      1.333333\n      1.333333\n    \n    \n      204\n      11\n      5\n      Home\n      0.666667\n      2.000000\n      1.333333\n      Manchester United\n      2.000000\n      16.000000\n      5.666667\n      ...\n      63.433333\n      Chelsea\n      2017\n      11\n      2017\n      6\n      NaN\n      0.666667\n      2.000000\n      1.333333\n    \n  \n\n5 rows × 172 columns\n\n\n\n\nmatches_.loc[(matches.team=='Arsenal'),['round',]]\n\n\n\n\n\n  \n    \n      \n      round\n    \n  \n  \n    \n      5\n      1\n    \n    \n      25\n      2\n    \n    \n      45\n      3\n    \n    \n      65\n      4\n    \n    \n      85\n      5\n    \n    \n      ...\n      ...\n    \n    \n      3704\n      34\n    \n    \n      3724\n      35\n    \n    \n      3744\n      36\n    \n    \n      3764\n      37\n    \n    \n      3784\n      38\n    \n  \n\n190 rows × 1 columns\n\n\n\n\nmatches.loc[(matches.team=='Arsenal')]\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue\n      result\n      gf\n      ga\n      opponent\n      shooting_gls\n      shooting_sh\n      shooting_sot\n      ...\n      misc_won%\n      team\n      season\n      month\n      year\n      weekday\n      win\n      netscore\n      goalsfor\n      goalsagainst\n    \n  \n  \n    \n      5\n      1\n      11\n      Home\n      1\n      4\n      3\n      Leicester City\n      4.0\n      27.0\n      10.0\n      ...\n      50.0\n      Arsenal\n      2017\n      8\n      2017\n      4\n      W\n      1\n      4\n      3\n    \n    \n      25\n      2\n      19\n      Away\n      -1\n      0\n      1\n      Stoke City\n      0.0\n      19.0\n      7.0\n      ...\n      40.0\n      Arsenal\n      2017\n      8\n      2017\n      5\n      L\n      -1\n      0\n      1\n    \n    \n      45\n      3\n      27\n      Away\n      -4\n      0\n      4\n      Liverpool\n      0.0\n      8.0\n      0.0\n      ...\n      54.5\n      Arsenal\n      2017\n      8\n      2017\n      6\n      L\n      -4\n      0\n      4\n    \n    \n      65\n      4\n      9\n      Home\n      3\n      3\n      0\n      Bournemouth\n      3.0\n      17.0\n      9.0\n      ...\n      51.1\n      Arsenal\n      2017\n      9\n      2017\n      5\n      W\n      3\n      3\n      0\n    \n    \n      85\n      5\n      17\n      Away\n      0\n      0\n      0\n      Chelsea\n      0.0\n      11.0\n      2.0\n      ...\n      48.8\n      Arsenal\n      2017\n      9\n      2017\n      6\n      D\n      0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3704\n      34\n      23\n      Home\n      2\n      3\n      1\n      Manchester United\n      3.0\n      13.0\n      6.0\n      ...\n      19.0\n      Arsenal\n      2021\n      4\n      2022\n      5\n      W\n      2\n      3\n      1\n    \n    \n      3724\n      35\n      1\n      Away\n      1\n      2\n      1\n      West Ham United\n      2.0\n      13.0\n      7.0\n      ...\n      51.5\n      Arsenal\n      2021\n      5\n      2022\n      6\n      W\n      1\n      2\n      1\n    \n    \n      3744\n      36\n      8\n      Home\n      1\n      2\n      1\n      Leeds United\n      2.0\n      19.0\n      9.0\n      ...\n      42.9\n      Arsenal\n      2021\n      5\n      2022\n      6\n      W\n      1\n      2\n      1\n    \n    \n      3764\n      37\n      16\n      Away\n      -2\n      0\n      2\n      Newcastle United\n      0.0\n      11.0\n      2.0\n      ...\n      45.0\n      Arsenal\n      2021\n      5\n      2022\n      0\n      L\n      -2\n      0\n      2\n    \n    \n      3784\n      38\n      22\n      Home\n      4\n      5\n      1\n      Everton\n      5.0\n      25.0\n      8.0\n      ...\n      48.4\n      Arsenal\n      2021\n      5\n      2022\n      6\n      W\n      4\n      5\n      1\n    \n  \n\n190 rows × 172 columns\n\n\n\n\n\n\nCombine results for both home and away teams\ni.e. combine team/opponent combos for a particular match. Will have different data for team/opponent\n\n#collapse-output\nmatchesC=matches_.copy()\n\n\nmatchesC=matches_.merge(matches_, left_on = [\"month\",'year','weekday',\"round\",\"day\",'season', \"team\"], \\\n                       right_on= [\"month\",'year','weekday',\"round\",\"day\",'season', \"opponent\"])\nmatchesC\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      shooting_gls_x\n      shooting_sh_x\n      shooting_sot_x\n      ...\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      team_y\n      win_y\n      netscore_y\n      goalsfor_y\n      goalsagainst_y\n    \n  \n  \n    \n      0\n      1\n      12\n      Away\n      NaN\n      NaN\n      NaN\n      Brighton and Hove Albion\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Brighton and Hove Albion\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      1\n      13\n      Home\n      NaN\n      NaN\n      NaN\n      West Ham United\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      West Ham United\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      1\n      13\n      Away\n      NaN\n      NaN\n      NaN\n      Newcastle United\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Newcastle United\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      1\n      12\n      Away\n      NaN\n      NaN\n      NaN\n      Watford\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Watford\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      1\n      12\n      Home\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      38\n      22\n      Away\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n      Arsenal\n      NaN\n      0.000000\n      1.333333\n      1.333333\n    \n    \n      3796\n      38\n      22\n      Away\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n      Brentford\n      NaN\n      0.333333\n      2.000000\n      1.666667\n    \n    \n      3797\n      38\n      22\n      Home\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n      NaN\n      -1.333333\n      0.666667\n      2.000000\n    \n    \n      3798\n      38\n      22\n      Away\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n      Chelsea\n      NaN\n      -0.333333\n      1.000000\n      1.333333\n    \n    \n      3799\n      38\n      22\n      Home\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n      NaN\n      1.000000\n      1.666667\n      0.666667\n    \n  \n\n3800 rows × 338 columns\n\n\n\n\nSave the data\n\nwhatsave=1\n\nif whatsave==0:\n    matchesOut=matchesC.copy()\n    matchesOut=matchesOut.drop(columns=['venue_x','venue_y','win_y','netscore_y','goalsfor_x','goalsfor_y',\n                                        'goalsagainst_x','goalsagainst_y'])\n    matchesOut.to_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\nelif whatsave==1:\n    matchesOut=matchesC.copy()\n    matchesOut=matchesOut.drop(columns=['venue_y','win_y','netscore_y','goalsfor_y','goalsagainst_y'])\n    matchesOut.to_csv(folda+'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv')\n#    \n\n# matchesC=matchesC.drop(columns=['opponent_x','opponent_y'])\n# matchesC=matchesC.loc[matchesC['venue_x']=='Home']\n\n\nmatchesC[['venue_x','venue_y','win_y','netscore_y','goalsfor_x','goalsfor_y',\n          'goalsagainst_x','goalsagainst_y']]\n\n\n\n\n\n  \n    \n      \n      venue_x\n      venue_y\n      win_y\n      netscore_y\n      goalsfor_x\n      goalsfor_y\n      goalsagainst_x\n      goalsagainst_y\n    \n  \n  \n    \n      0\n      Away\n      Home\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      Home\n      Away\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      Away\n      Home\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      Away\n      Home\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      Home\n      Away\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      Away\n      Home\n      NaN\n      0.000000\n      1.666667\n      1.333333\n      1.333333\n      1.333333\n    \n    \n      3796\n      Away\n      Home\n      NaN\n      0.333333\n      0.666667\n      2.000000\n      2.333333\n      1.666667\n    \n    \n      3797\n      Home\n      Away\n      NaN\n      -1.333333\n      1.000000\n      0.666667\n      1.666667\n      2.000000\n    \n    \n      3798\n      Away\n      Home\n      NaN\n      -0.333333\n      0.666667\n      1.000000\n      2.666667\n      1.333333\n    \n    \n      3799\n      Home\n      Away\n      NaN\n      1.000000\n      0.333333\n      1.666667\n      2.333333\n      0.666667\n    \n  \n\n3800 rows × 8 columns\n\n\n\n\n## SANITY CHECKS\nteamName='Manchester United'\nyear=2017\nmc=matchesC.loc[((  (matchesC.team_x==teamName) ))][['round','team_x','team_y','result_x','season']]\n\nmraw=matches.loc[((  matches.team==teamName  ))][['round','team','opponent','result','season']]\n\n\n\nplt.subplots(figsize=(15,5))\nplt.plot( (mc['round']+(mc['season']-2017)*38)/38, mraw['result'] ,'.-')\nplt.plot( (mc['round']+(mc['season']-2017)*38)/38, mc['result_x'] ,'.-')\nplt.legend(['raw','running average']);\nplt.grid(True)\n\n\n\n\n\nmg = matchesC.groupby('team_x').mean()\nmg\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      shooting_gls_x\n      shooting_sh_x\n      shooting_sot_x\n      shooting_sot%_x\n      shooting_g/sh_x\n      ...\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      netscore_y\n      goalsfor_y\n      goalsagainst_y\n    \n    \n      team_x\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Arsenal\n      19.5\n      15.210526\n      0.421517\n      1.675485\n      1.253968\n      1.633157\n      13.111111\n      4.514109\n      35.496473\n      0.126499\n      ...\n      0.112589\n      0.136525\n      0.042553\n      91.012411\n      19.406915\n      19.757979\n      49.480762\n      -0.061170\n      1.287234\n      1.348404\n    \n    \n      Aston Villa\n      19.5\n      15.903509\n      -0.181416\n      1.286136\n      1.467552\n      1.233038\n      12.609145\n      4.261062\n      33.371829\n      0.092640\n      ...\n      0.102339\n      0.122807\n      0.052632\n      89.173977\n      17.751462\n      18.026316\n      49.695760\n      0.114035\n      1.388889\n      1.274854\n    \n    \n      Bournemouth\n      19.5\n      15.868421\n      -0.500000\n      1.218289\n      1.718289\n      1.191740\n      11.336283\n      3.691740\n      32.124926\n      0.095973\n      ...\n      0.093093\n      0.123123\n      0.030030\n      93.247748\n      20.250751\n      20.214715\n      50.193544\n      0.057057\n      1.409910\n      1.352853\n    \n    \n      Brentford\n      19.5\n      15.394737\n      -0.189189\n      1.234234\n      1.423423\n      1.198198\n      11.297297\n      3.549550\n      31.855405\n      0.092117\n      ...\n      0.114035\n      0.140351\n      0.061404\n      82.771930\n      16.850877\n      16.429825\n      51.121930\n      0.052632\n      1.394737\n      1.342105\n    \n    \n      Brighton and Hove Albion\n      19.5\n      16.052632\n      -0.388007\n      0.978836\n      1.366843\n      0.936508\n      11.276014\n      3.218695\n      30.280688\n      0.080811\n      ...\n      0.095238\n      0.127866\n      0.040564\n      89.408289\n      19.255732\n      19.731041\n      49.229630\n      0.059965\n      1.424162\n      1.364198\n    \n    \n      Burnley\n      19.5\n      16.168421\n      -0.375661\n      1.016755\n      1.392416\n      0.974427\n      10.093474\n      3.194004\n      31.874427\n      0.103527\n      ...\n      0.095238\n      0.128748\n      0.038801\n      88.843034\n      18.495591\n      18.074074\n      50.651764\n      -0.073192\n      1.338624\n      1.411817\n    \n    \n      Cardiff City\n      19.5\n      15.921053\n      -1.018018\n      0.828829\n      1.846847\n      0.819820\n      10.761261\n      2.842342\n      29.641441\n      0.074865\n      ...\n      0.078947\n      0.149123\n      0.026316\n      91.561404\n      19.140351\n      18.307018\n      51.198246\n      0.026316\n      1.412281\n      1.385965\n    \n    \n      Chelsea\n      19.5\n      15.963158\n      0.668430\n      1.728395\n      1.059965\n      1.691358\n      15.545855\n      5.257496\n      34.136684\n      0.103307\n      ...\n      0.121693\n      0.126984\n      0.052028\n      91.537919\n      20.075838\n      19.852734\n      50.077778\n      -0.105820\n      1.294533\n      1.400353\n    \n    \n      Crystal Palace\n      19.5\n      16.310526\n      -0.296296\n      1.142857\n      1.439153\n      1.100529\n      10.937390\n      3.427690\n      32.483686\n      0.100838\n      ...\n      0.109929\n      0.143617\n      0.028369\n      90.376773\n      19.329787\n      19.449468\n      49.848493\n      0.152482\n      1.443262\n      1.290780\n    \n    \n      Everton\n      19.5\n      14.710526\n      -0.194885\n      1.216931\n      1.411817\n      1.174603\n      11.298060\n      3.654321\n      32.695414\n      0.100979\n      ...\n      0.093972\n      0.126773\n      0.057624\n      89.239362\n      18.835993\n      18.802305\n      49.994415\n      -0.075355\n      1.358156\n      1.433511\n    \n    \n      Fulham\n      19.5\n      15.289474\n      -0.964444\n      0.802222\n      1.766667\n      0.775556\n      11.673333\n      3.460000\n      29.526667\n      0.058756\n      ...\n      0.118421\n      0.184211\n      0.043860\n      88.429825\n      18.258772\n      18.456140\n      49.566228\n      -0.188596\n      1.381579\n      1.570175\n    \n    \n      Huddersfield Town\n      19.5\n      16.026316\n      -1.062222\n      0.680000\n      1.742222\n      0.602222\n      10.044444\n      2.935556\n      30.048889\n      0.055511\n      ...\n      0.146667\n      0.142222\n      0.044444\n      91.108889\n      21.348889\n      21.073333\n      50.432222\n      -0.233333\n      1.282222\n      1.515556\n    \n    \n      Leeds United\n      19.5\n      16.078947\n      -0.404444\n      1.388889\n      1.793333\n      1.362222\n      13.184444\n      4.442222\n      35.603778\n      0.110378\n      ...\n      0.114035\n      0.162281\n      0.048246\n      84.732456\n      18.061404\n      17.293860\n      51.365789\n      0.008772\n      1.364035\n      1.355263\n    \n    \n      Leicester City\n      19.5\n      15.889474\n      0.212522\n      1.582892\n      1.370370\n      1.519400\n      12.416226\n      4.320106\n      35.845767\n      0.121587\n      ...\n      0.121693\n      0.111111\n      0.045855\n      88.839506\n      18.775132\n      19.029101\n      49.624868\n      -0.096120\n      1.342152\n      1.438272\n    \n    \n      Liverpool\n      19.5\n      16.289474\n      1.357143\n      2.211640\n      0.854497\n      2.158730\n      16.320106\n      5.810406\n      36.395767\n      0.129691\n      ...\n      0.096257\n      0.126560\n      0.048128\n      89.806595\n      19.374332\n      19.647950\n      49.776827\n      0.067736\n      1.356506\n      1.288770\n    \n    \n      Manchester City\n      19.5\n      15.947368\n      1.804233\n      2.544092\n      0.739859\n      2.474427\n      17.603175\n      6.336861\n      36.914815\n      0.140406\n      ...\n      0.134039\n      0.121693\n      0.046737\n      91.272487\n      19.769841\n      19.767196\n      50.053086\n      0.152557\n      1.456790\n      1.304233\n    \n    \n      Manchester United\n      19.5\n      16.047368\n      0.615520\n      1.758377\n      1.142857\n      1.726631\n      13.648148\n      5.078483\n      38.115608\n      0.119489\n      ...\n      0.097002\n      0.116402\n      0.040564\n      90.966490\n      19.932981\n      19.534392\n      50.678660\n      0.007937\n      1.358907\n      1.350970\n    \n    \n      Newcastle United\n      19.5\n      16.042105\n      -0.373016\n      1.088183\n      1.461199\n      1.054674\n      11.138448\n      3.601411\n      32.866755\n      0.095344\n      ...\n      0.119929\n      0.125220\n      0.047619\n      90.180776\n      18.980600\n      19.029982\n      49.676367\n      0.069665\n      1.417989\n      1.348325\n    \n    \n      Norwich City\n      19.5\n      15.973684\n      -1.411111\n      0.662222\n      2.073333\n      0.622222\n      10.364444\n      3.097778\n      30.114889\n      0.054400\n      ...\n      0.092105\n      0.144737\n      0.043860\n      89.100877\n      18.320175\n      18.162281\n      50.484211\n      -0.127193\n      1.271930\n      1.399123\n    \n    \n      Sheffield United\n      19.5\n      15.657895\n      -0.580000\n      0.782222\n      1.362222\n      0.728889\n      8.780000\n      2.657778\n      30.685556\n      0.083556\n      ...\n      0.129386\n      0.164474\n      0.039474\n      90.660088\n      16.978070\n      17.546053\n      49.354605\n      -0.109649\n      1.361842\n      1.471491\n    \n    \n      Southampton\n      19.5\n      16.231579\n      -0.466490\n      1.173721\n      1.640212\n      1.152557\n      12.388007\n      4.113757\n      34.837654\n      0.090088\n      ...\n      0.125220\n      0.121693\n      0.045855\n      89.746914\n      19.088183\n      18.665785\n      50.723016\n      0.035273\n      1.398589\n      1.363316\n    \n    \n      Stoke City\n      19.5\n      16.394737\n      -0.918919\n      0.878378\n      1.797297\n      0.851351\n      10.432432\n      3.184685\n      33.167117\n      0.087342\n      ...\n      0.081081\n      0.072072\n      0.009009\n      94.153153\n      21.887387\n      23.333333\n      48.231532\n      0.450450\n      1.522523\n      1.072072\n    \n    \n      Swansea City\n      19.5\n      16.868421\n      -0.720721\n      0.729730\n      1.450450\n      0.702703\n      8.189189\n      2.193694\n      28.216667\n      0.092162\n      ...\n      0.099099\n      0.081081\n      0.031532\n      95.824324\n      24.725225\n      22.824324\n      52.114414\n      0.216216\n      1.459459\n      1.243243\n    \n    \n      Tottenham Hotspur\n      19.5\n      15.394737\n      0.676367\n      1.771605\n      1.095238\n      1.675485\n      13.314815\n      4.734568\n      36.830423\n      0.129233\n      ...\n      0.093972\n      0.125887\n      0.035461\n      90.899823\n      19.563830\n      19.655142\n      49.633688\n      0.017730\n      1.366135\n      1.348404\n    \n    \n      Watford\n      19.5\n      16.184211\n      -0.620309\n      1.107064\n      1.727373\n      1.073951\n      11.065121\n      3.399558\n      31.508940\n      0.089536\n      ...\n      0.099338\n      0.116998\n      0.038631\n      90.599338\n      19.486755\n      19.296909\n      50.105740\n      -0.099338\n      1.304636\n      1.403974\n    \n    \n      West Bromwich Albion\n      19.5\n      16.421053\n      -0.817778\n      0.866667\n      1.684444\n      0.840000\n      9.457778\n      2.793333\n      31.112000\n      0.083800\n      ...\n      0.111111\n      0.151111\n      0.057778\n      89.895556\n      20.335556\n      20.268889\n      50.009333\n      0.017778\n      1.380000\n      1.362222\n    \n    \n      West Ham United\n      19.5\n      16.157895\n      -0.078483\n      1.416226\n      1.494709\n      1.389771\n      11.238095\n      3.870370\n      35.340388\n      0.120414\n      ...\n      0.125220\n      0.114638\n      0.047619\n      90.360670\n      19.217813\n      19.444444\n      49.579894\n      0.006173\n      1.402116\n      1.395944\n    \n    \n      Wolverhampton Wanderers\n      19.5\n      15.559211\n      -0.048565\n      1.134658\n      1.183223\n      1.081678\n      11.768212\n      3.706402\n      31.860706\n      0.091347\n      ...\n      0.118421\n      0.120614\n      0.067982\n      89.114035\n      17.844298\n      17.971491\n      49.912939\n      -0.085526\n      1.357456\n      1.442982\n    \n  \n\n28 rows × 330 columns\n\n\n\n\nX\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      shooting_gls_x\n      shooting_sh_x\n      shooting_sot_x\n      shooting_sot%_x\n      shooting_g/sh_x\n      ...\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      netscore_y\n      goalsfor_y\n      goalsagainst_y\n    \n  \n  \n    \n      round\n      1.000000\n      -0.101106\n      -0.000427\n      -0.032829\n      -0.033619\n      -0.031728\n      -0.033182\n      -0.031253\n      -0.012582\n      -0.005572\n      ...\n      -0.026473\n      -0.039209\n      -0.016878\n      0.053467\n      0.027972\n      0.028820\n      0.000147\n      -0.000427\n      -0.032829\n      -0.033619\n    \n    \n      day\n      -0.101106\n      1.000000\n      0.001526\n      0.012942\n      0.011046\n      0.017277\n      0.018508\n      0.013796\n      0.011117\n      0.013813\n      ...\n      0.017057\n      -0.014209\n      -0.019603\n      0.000052\n      0.011315\n      0.008934\n      0.007511\n      0.001526\n      0.012942\n      0.011046\n    \n    \n      result_x\n      -0.000427\n      0.001526\n      1.000000\n      0.804871\n      -0.784386\n      0.796159\n      0.489624\n      0.598669\n      0.302810\n      0.553999\n      ...\n      -0.008706\n      -0.020023\n      0.015524\n      0.000158\n      -0.003279\n      -0.004667\n      0.006454\n      0.020826\n      0.017049\n      -0.016039\n    \n    \n      gf_x\n      -0.032829\n      0.012942\n      0.804871\n      1.000000\n      -0.263228\n      0.988970\n      0.489024\n      0.682367\n      0.418380\n      0.724261\n      ...\n      0.010279\n      -0.026590\n      0.016782\n      0.015622\n      0.005549\n      0.006301\n      0.001188\n      0.017049\n      0.011392\n      -0.015809\n    \n    \n      ga_x\n      -0.033619\n      0.011046\n      -0.784386\n      -0.263228\n      1.000000\n      -0.260595\n      -0.284823\n      -0.260010\n      -0.054968\n      -0.143603\n      ...\n      0.024876\n      0.004775\n      -0.007703\n      0.016053\n      0.011122\n      0.014161\n      -0.009246\n      -0.016039\n      -0.015809\n      0.009557\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      misc_lost_y\n      0.028820\n      0.008934\n      -0.004667\n      0.006301\n      0.014161\n      0.007396\n      0.001735\n      0.012405\n      0.009634\n      0.014438\n      ...\n      -0.119425\n      -0.028281\n      0.011898\n      0.373947\n      0.694807\n      1.000000\n      -0.398785\n      -0.222763\n      -0.280020\n      0.069455\n    \n    \n      misc_won%_y\n      0.000147\n      0.007511\n      0.006454\n      0.001188\n      -0.009246\n      -0.000937\n      -0.002138\n      0.005459\n      0.010180\n      0.009635\n      ...\n      0.058702\n      -0.067979\n      -0.029776\n      0.040269\n      0.327227\n      -0.398785\n      1.000000\n      0.202235\n      0.155459\n      -0.166274\n    \n    \n      netscore_y\n      -0.000427\n      0.001526\n      0.020826\n      0.017049\n      -0.016039\n      0.018878\n      -0.000026\n      0.013563\n      0.023359\n      0.019314\n      ...\n      0.189385\n      -0.197948\n      -0.164797\n      0.084513\n      -0.111881\n      -0.222763\n      0.202235\n      1.000000\n      0.804871\n      -0.784386\n    \n    \n      goalsfor_y\n      -0.032829\n      0.012942\n      0.017049\n      0.011392\n      -0.015809\n      0.012763\n      0.007157\n      0.006324\n      0.017994\n      0.014789\n      ...\n      0.253819\n      -0.045267\n      -0.062638\n      0.016541\n      -0.197868\n      -0.280020\n      0.155459\n      0.804871\n      1.000000\n      -0.263228\n    \n    \n      goalsagainst_y\n      -0.033619\n      0.011046\n      -0.016039\n      -0.015809\n      0.009557\n      -0.017349\n      0.007515\n      -0.015435\n      -0.019168\n      -0.015943\n      ...\n      -0.042581\n      0.274478\n      0.202431\n      -0.120098\n      -0.024934\n      0.069455\n      -0.166274\n      -0.784386\n      -0.263228\n      1.000000\n    \n  \n\n330 rows × 330 columns\n\n\n\n\nplt.plot(mg.netscore_x,mg.shooting_sh_x,'ok')\n\n# plt.plot(matchesC.gf_x,matchesC.NetScore_x,'ok')\n\nX=matchesC.corr()\ncorrnetscore=X.sort_values(by=\"netscore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\ncorrnetscore\n\n\n\n\n\n  \n    \n      \n      category\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      shooting_gls_x\n      shooting_sh_x\n      shooting_sot_x\n      shooting_sot%_x\n      ...\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      netscore_y\n      goalsfor_y\n      goalsagainst_y\n    \n  \n  \n    \n      0\n      ga_x\n      -0.033619\n      0.011046\n      -0.784386\n      -0.263228\n      1.000000\n      -0.260595\n      -0.284823\n      -0.260010\n      -0.054968\n      ...\n      0.024876\n      0.004775\n      -0.007703\n      0.016053\n      0.011122\n      0.014161\n      -0.009246\n      -0.016039\n      -0.015809\n      0.009557\n    \n    \n      1\n      goalsagainst_x\n      -0.033619\n      0.011046\n      -0.784386\n      -0.263228\n      1.000000\n      -0.260595\n      -0.284823\n      -0.260010\n      -0.054968\n      ...\n      0.024876\n      0.004775\n      -0.007703\n      0.016053\n      0.011122\n      0.014161\n      -0.009246\n      -0.016039\n      -0.015809\n      0.009557\n    \n    \n      2\n      keeper_psxg_x\n      -0.020151\n      0.004270\n      -0.689039\n      -0.288664\n      0.818415\n      -0.285579\n      -0.342578\n      -0.292562\n      -0.040214\n      ...\n      0.016138\n      0.005909\n      0.004696\n      0.022612\n      0.008525\n      0.021666\n      -0.019468\n      -0.026014\n      -0.025878\n      0.015252\n    \n    \n      3\n      keeper_sota_x\n      -0.027422\n      0.009134\n      -0.585212\n      -0.306845\n      0.630628\n      -0.303735\n      -0.390630\n      -0.326298\n      -0.029044\n      ...\n      -0.003544\n      0.019901\n      -0.012280\n      0.008879\n      0.015911\n      0.029753\n      -0.018988\n      -0.016977\n      -0.017976\n      0.008819\n    \n    \n      4\n      passingtypes_PC_dead_x\n      -0.020593\n      0.025862\n      -0.428442\n      -0.400000\n      0.278412\n      -0.400698\n      -0.520973\n      -0.469203\n      -0.092371\n      ...\n      -0.022421\n      0.000464\n      -0.011870\n      -0.003227\n      0.015526\n      0.010683\n      0.004033\n      -0.001923\n      -0.001384\n      0.001681\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      325\n      shooting_gls_x\n      -0.031728\n      0.017277\n      0.796159\n      0.988970\n      -0.260595\n      1.000000\n      0.489307\n      0.687750\n      0.424698\n      ...\n      0.008137\n      -0.028288\n      0.015246\n      0.016248\n      0.005333\n      0.007396\n      -0.000937\n      0.018878\n      0.012763\n      -0.017349\n    \n    \n      326\n      gf_x\n      -0.032829\n      0.012942\n      0.804871\n      1.000000\n      -0.263228\n      0.988970\n      0.489024\n      0.682367\n      0.418380\n      ...\n      0.010279\n      -0.026590\n      0.016782\n      0.015622\n      0.005549\n      0.006301\n      0.001188\n      0.017049\n      0.011392\n      -0.015809\n    \n    \n      327\n      goalsfor_x\n      -0.032829\n      0.012942\n      0.804871\n      1.000000\n      -0.263228\n      0.988970\n      0.489024\n      0.682367\n      0.418380\n      ...\n      0.010279\n      -0.026590\n      0.016782\n      0.015622\n      0.005549\n      0.006301\n      0.001188\n      0.017049\n      0.011392\n      -0.015809\n    \n    \n      328\n      result_x\n      -0.000427\n      0.001526\n      1.000000\n      0.804871\n      -0.784386\n      0.796159\n      0.489624\n      0.598669\n      0.302810\n      ...\n      -0.008706\n      -0.020023\n      0.015524\n      0.000158\n      -0.003279\n      -0.004667\n      0.006454\n      0.020826\n      0.017049\n      -0.016039\n    \n    \n      329\n      netscore_x\n      -0.000427\n      0.001526\n      1.000000\n      0.804871\n      -0.784386\n      0.796159\n      0.489624\n      0.598669\n      0.302810\n      ...\n      -0.008706\n      -0.020023\n      0.015524\n      0.000158\n      -0.003279\n      -0.004667\n      0.006454\n      0.020826\n      0.017049\n      -0.016039\n    \n  \n\n330 rows × 331 columns"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#overview",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#overview",
    "title": "Predicting Premier League Matches",
    "section": "Overview",
    "text": "Overview\n\nIntroduction\nPredicting results of English Premier League using random forests for the 2017 to 2021 seasons. I will predict whether a result is a win, loss or draw, and then simplify as a binary question- is it a win?\nFrom an article about pundit versus gambling company Pinnacle vs. Mark Lawrenson we have a benchmark to aim for from the 2012 season: - Mark Lawrenson = 52.6% accuracy - Pinnacle traders = 55.3% accuracy - Random guess = 33.3% accuracy\n\n\nMethod\nIn this data there are various parameters that can be used. The most important step is to not use data about a current match as a predictor, but for a prediction to be based on stats from previous matches. (A couple of slight exceptions to this are below like who is playing who and where)\nThe predictors used here include: - date of match - home or away - stats from previous matches - results - goals scored/conceded - possession/expected goals etc - who is playing who\nSome details on the machine learning:\n\nNotebook on kaggle is here\nSeveral models were used:\n\nA Random Forest model\nGradient boosting models XGBoost\nRidge model\nNeural networks\n\nRegression and classification models were used\nData is trained on years 2017 to 2020 with season 2021 used as validation\n\n20% validation / 80% training\n\nSome data cleaning methods were performed and shown in the code\n\n\n\nResults\n\nModel accuracy = 52% (+-1%)\n\nSo the model is comparable with the results of Mark Lawrenson\n\nThe model is okay as it matches the accuracy from an expert pundit. But it does underperform gambing predictions.\nDraws are under-represented by the model\n\ndraws predicted was increased by adjusting the input parameter class_weight but the issue was only reduced\n\nChanging input parameters was done in a semi-manual manner, obtaining the best input parameters was not easy\nThe more parameters the better,\n\nbut the increase from just using a basic four parameter fit to one with 300+ columns is relatively small (a difference of ~1-2% (based on values 50-65%))\n\nBy searching for the best hyper parameters the results of a random forest (RF) model were increased from 49% accuracy to 52%\nRF, XG boost and grad boost methods all performed similar\n\nRidge model was the worst performing\nNeural networks with fastai tabular data also performed poorly. NN analysis of EPL\n\nSimilar results were obtained by using classification and regression methods\n\nRegression on the net score performed the best\nRegression methods performed worse on predicting draws though\n\nEnsembling (combining results from different methods by adding them) can increase the overall results. The accuracy would need to be comparable and the results different enough for their to be a benefit\n\nA summary of the results is shown below\n\n\n\n\n\n\n\n\n\nAccuracy W/L/D\nAccuracy Win\nClassification/Regression\nDetails\n\n\n\n\n0.489\n0.669\nClassification\nRF with all parameters\n\n\n0.479\n0.661\nClassification\nRF with 43 parameters from feature imp\n\n\n0.487\n0.666\nClassification\nRF as above with basic features\n\n\n0.484\n0.656\nClassification\nRF with 4 basic features\n\n\n0.479\n-\nClassification\nRF with 4 basic ones + balanced\n\n\n0.485\n0.656\nClassification\nRF with 23 correlation parameters plus basic\n\n\n0.451\n0.678\nRegression\nRF with all parameters on net score\n\n\n-\n0.657\nRegression\nXGB with all parameters on net score\n\n\n-\n0.639\nRegression\nRidge with all parameters on net score\n\n\n-\n0.666\nRegression\nGrad boost with all parameters on net score\n\n\n0.427\n0.670\nRegression\nRF with all parameters on GF/GA\n\n\n-\n0.670\nRegression\nXGB with all parameters on GF/GA score\n\n\n-\n0.665\nRegression\nRF+XGB+Grad boost on netscore\n\n\n-\n0.678\nRegression\nRF on netscore + RF on GF/GA"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#load-data-and-libraries",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#load-data-and-libraries",
    "title": "Predicting Premier League Matches",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\n#collapse-hide\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks\n\n# from sklearn.tree import DecisionTreeClassifier\n# from dtreeviz.trees import *\n# from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n# from fastai.tabular.all import *\n\n# from sklearn.experimental import enable_halving_search_cv  # noqa\n# from sklearn.model_selection import HalvingRandomSearchCV\n\n\n# from sklearn.metrics import precision_score\nfrom xgboost import XGBClassifier\n\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\n\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscoreAndGFGA_both-HA_modPC.csv',index_col=0)\ndfAll=dfAll.iloc[20:,:]\ndfAll\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      shooting_gls_x\n      shooting_sh__x\n      shooting_sot_x\n      ...\n      misc_int__y\n      misc_tklw__y\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      team_y\n    \n  \n  \n    \n      44\n      3\n      27\n      Home\n      0.000000\n      2.000000\n      2.000000\n      Everton\n      2.000000\n      14.500000\n      4.000000\n      ...\n      13.000000\n      12.000000\n      0.000000\n      0.000000\n      0.000000\n      94.500000\n      19.500000\n      27.000000\n      41.150000\n      Everton\n    \n    \n      45\n      3\n      27\n      Away\n      0.000000\n      2.000000\n      2.000000\n      Liverpool\n      2.000000\n      23.000000\n      8.500000\n      ...\n      16.000000\n      12.000000\n      0.500000\n      0.000000\n      0.000000\n      114.000000\n      28.500000\n      20.500000\n      57.450000\n      Liverpool\n    \n    \n      46\n      3\n      27\n      Away\n      0.000000\n      1.500000\n      1.500000\n      Tottenham Hotspur\n      1.500000\n      15.000000\n      3.000000\n      ...\n      8.500000\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      21.000000\n      22.500000\n      48.600000\n      Tottenham Hotspur\n    \n    \n      47\n      3\n      27\n      Away\n      0.500000\n      1.000000\n      0.500000\n      Chelsea\n      1.000000\n      8.000000\n      3.000000\n      ...\n      7.000000\n      14.000000\n      0.000000\n      0.000000\n      0.500000\n      92.000000\n      23.500000\n      26.000000\n      47.850000\n      Chelsea\n    \n    \n      48\n      3\n      26\n      Away\n      0.500000\n      2.500000\n      2.000000\n      Manchester United\n      2.500000\n      10.000000\n      3.500000\n      ...\n      16.000000\n      10.500000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      21.500000\n      19.500000\n      50.300000\n      Manchester United\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      38\n      22\n      Away\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      10.000000\n      9.666667\n      0.000000\n      0.000000\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n      Arsenal\n    \n    \n      3796\n      38\n      22\n      Away\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      11.666667\n      6.666667\n      0.000000\n      0.666667\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n      Brentford\n    \n    \n      3797\n      38\n      22\n      Home\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n    \n    \n      3798\n      38\n      22\n      Away\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      11.666667\n      11.666667\n      0.333333\n      0.000000\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n      Chelsea\n    \n    \n      3799\n      38\n      22\n      Home\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n    \n  \n\n3740 rows × 333 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      shooting_gls_x\n      shooting_sh__x\n      shooting_sot_x\n      shooting_sot%_x\n      shooting_g/sh_x\n      shooting_g/sot_x\n      shooting_PC_dist_x\n      shooting_fk__x\n      shooting_pk_x\n      shooting_pkatt__x\n      shooting_xg_x\n      shooting_npxg_x\n      shooting_npxg/sh_x\n      shooting_g-xg_x\n      shooting_np:g-xg_x\n      keeper_sota_x\n      keeper_saves_x\n      keeper_save%_x\n      keeper_cs_x\n      keeper_psxg_x\n      keeper_psxg+/-_x\n      keeper_pkatt__x\n      keeper_pka_x\n      keeper_pksv_x\n      keeper_pkm_x\n      keeper_cmp__x\n      keeper_att__x\n      keeper_cmp%__x\n      keeper_att_.1_x\n      keeper_thr_x\n      keeper_launch%_x\n      keeper_avglen_x\n      keeper_att_.2_x\n      keeper_launch%.1_x\n      keeper_avglen.1_x\n      keeper_opp_x\n      keeper_stp_x\n      keeper_stp%_x\n      keeper_#opa_x\n      keeper_avgdist_x\n      passing_pass_complete_x\n      passing_cmp%__x\n      passing_PC_totdist__x\n      passing_PC_prgdist__x\n      passing_PC_cmp_.1_x\n      passing_cmp%_.1_x\n      passing_PC_cmp_.2_x\n      passing_cmp%_.2_x\n      passing_PC_cmp_.3_x\n      passing_cmp%_.3_x\n      passing_ast_x\n      passing_xa_x\n      passing_kp_x\n      passing_PC_1/3__x\n      passing_PC_ppa_x\n      passing_PC_crspa_x\n      passing_PC_prog__x\n      passing_PC_types_live__x\n      passing_PC_types_dead_x\n      passing_PC_types_fk__x\n      passing_PC_types_tb_x\n      passing_PC_types_press__x\n      passing_PC_types_sw_x\n      passing_PC_types_crs__x\n      passing_PC_types_ck_x\n      passing_PC_types_in_x\n      passing_PC_types_out_x\n      passing_PC_types_str_x\n      passing_PC_types_ground_x\n      passing_PC_types_low_x\n      passing_PC_types_high_x\n      passing_PC_types_left_x\n      passing_PC_types_right_x\n      passing_PC_types_head_x\n      passing_PC_types_ti_x\n      passing_PC_types_other_x\n      passing_PC_types_cmp__x\n      passing_PC_types_off__x\n      passing_PC_types_out.1_x\n      passing_PC_types_int__x\n      passing_PC_types_blocks__x\n      shotcreate_sca_x\n      shotcreate_passlive_x\n      shotcreate_passdead_x\n      shotcreate_drib_x\n      shotcreate_sh_gca_x\n      shotcreate_fld_gca_x\n      shotcreate_def_x\n      shotcreate_gca_x\n      shotcreate_passlive.1_x\n      shotcreate_passdead.1_x\n      shotcreate_drib.1_x\n      shotcreate_sh_gca.1_x\n      shotcreate_fld_gca.1_x\n      shotcreate_def.1_x\n      tackle_tkl_x\n      tackle_PC_tklw_defense_x\n      tackle_PC_def 3rd_defense_x\n      tackle_PC_mid 3rd_defense_x\n      tackle_PC_att 3rd_defense_x\n      tackle_PC_tkl_dribble_x\n      tackle_dribble%_x\n      tackle_dribllepast_x\n      tackle_press_defense_x\n      tackle_%_x\n      tackle_PC_press_def3rd_x\n      tackle_PC_press_mid3rd_x\n      tackle_PC_press_att3rd_x\n      tackle_blocks_defense_x\n      tackle_PC_sh_defense_x\n      tackle_PC_shsv_x\n      tackle_PC_pass_x\n      tackle_int_defense_x\n      tackle_clr_x\n      tackle_err_x\n      possession_poss_x\n      possession_touches_x\n      possession_PC_def pen_x\n      possession_PC_def 3rd__x\n      possession_PC_mid 3rd__x\n      possession_PC_att 3rd__x\n      possession_PC_att pen_x\n      possession_PC_live__x\n      possession_dribblesucc__x\n      possession_dribbleatt__x\n      possession_dribblesucc%_x\n      possession_dribblepast_x\n      possession_megs_x\n      possession_carries_x\n      possession_totdist__x\n      possession_PC_prgdist__x\n      possession_PC_prog__x\n      possession_PC_1/3__x\n      possession_PC_cpa_x\n      possession_PC_mis_x\n      possession_PC_dis_x\n      possession_targ_x\n      possession_rec_x\n      possession_rec%_x\n      possession_prog_.1_x\n      misc_crdy_x\n      misc_crdr_x\n      misc_2crdy_x\n      misc_fls_x\n      misc_fld__x\n      misc_off__x\n      misc_crs__x\n      misc_int__x\n      misc_tklw__x\n      misc_pkwon_x\n      misc_pkcon_x\n      misc_og_x\n      misc_recov_x\n      misc_won_x\n      misc_lost_x\n      misc_won%_x\n      team_x\n      season\n      month\n      year\n      weekday\n      Win_x\n      NetScore_x\n      GoalsFor_x\n      GoalsAgainst_x\n      result_y\n      gf_y\n      ga_y\n      opponent_y\n      shooting_gls_y\n      shooting_sh__y\n      shooting_sot_y\n      shooting_sot%_y\n      shooting_g/sh_y\n      shooting_g/sot_y\n      shooting_PC_dist_y\n      shooting_fk__y\n      shooting_pk_y\n      shooting_pkatt__y\n      shooting_yg_y\n      shooting_npxg_y\n      shooting_npxg/sh_y\n      shooting_g-xg_y\n      shooting_np:g-xg_y\n      keeper_sota_y\n      keeper_saves_y\n      keeper_save%_y\n      keeper_cs_y\n      keeper_psxg_y\n      keeper_psxg+/-_y\n      keeper_pkatt__y\n      keeper_pka_y\n      keeper_pksv_y\n      keeper_pkm_y\n      keeper_cmp__y\n      keeper_att__y\n      keeper_cmp%__y\n      keeper_att_.1_y\n      keeper_thr_y\n      keeper_launch%_y\n      keeper_avglen_y\n      keeper_att_.2_y\n      keeper_launch%.1_y\n      keeper_avglen.1_y\n      keeper_opp_y\n      keeper_stp_y\n      keeper_stp%_y\n      keeper_#opa_y\n      keeper_avgdist_y\n      passing_pass_complete_y\n      passing_cmp%__y\n      passing_PC_totdist__y\n      passing_PC_prgdist__y\n      passing_PC_cmp_.1_y\n      passing_cmp%_.1_y\n      passing_PC_cmp_.2_y\n      passing_cmp%_.2_y\n      passing_PC_cmp_.3_y\n      passing_cmp%_.3_y\n      passing_ast_y\n      passing_ya_y\n      passing_kp_y\n      passing_PC_1/3__y\n      passing_PC_ppa_y\n      passing_PC_crspa_y\n      passing_PC_prog__y\n      passing_PC_types_live__y\n      passing_PC_types_dead_y\n      passing_PC_types_fk__y\n      passing_PC_types_tb_y\n      passing_PC_types_press__y\n      passing_PC_types_sw_y\n      passing_PC_types_crs__y\n      passing_PC_types_ck_y\n      passing_PC_types_in_y\n      passing_PC_types_out_y\n      passing_PC_types_str_y\n      passing_PC_types_ground_y\n      passing_PC_types_low_y\n      passing_PC_types_high_y\n      passing_PC_types_left_y\n      passing_PC_types_right_y\n      passing_PC_types_head_y\n      passing_PC_types_ti_y\n      passing_PC_types_other_y\n      passing_PC_types_cmp__y\n      passing_PC_types_off__y\n      passing_PC_types_out.1_y\n      passing_PC_types_int__y\n      passing_PC_types_blocks__y\n      shotcreate_sca_y\n      shotcreate_passlive_y\n      shotcreate_passdead_y\n      shotcreate_drib_y\n      shotcreate_sh_gca_y\n      shotcreate_fld_gca_y\n      shotcreate_def_y\n      shotcreate_gca_y\n      shotcreate_passlive.1_y\n      shotcreate_passdead.1_y\n      shotcreate_drib.1_y\n      shotcreate_sh_gca.1_y\n      shotcreate_fld_gca.1_y\n      shotcreate_def.1_y\n      tackle_tkl_y\n      tackle_PC_tklw_defense_y\n      tackle_PC_def 3rd_defense_y\n      tackle_PC_mid 3rd_defense_y\n      tackle_PC_att 3rd_defense_y\n      tackle_PC_tkl_dribble_y\n      tackle_dribble%_y\n      tackle_dribllepast_y\n      tackle_press_defense_y\n      tackle_%_y\n      tackle_PC_press_def3rd_y\n      tackle_PC_press_mid3rd_y\n      tackle_PC_press_att3rd_y\n      tackle_blocks_defense_y\n      tackle_PC_sh_defense_y\n      tackle_PC_shsv_y\n      tackle_PC_pass_y\n      tackle_int_defense_y\n      tackle_clr_y\n      tackle_err_y\n      possession_poss_y\n      possession_touches_y\n      possession_PC_def pen_y\n      possession_PC_def 3rd__y\n      possession_PC_mid 3rd__y\n      possession_PC_att 3rd__y\n      possession_PC_att pen_y\n      possession_PC_live__y\n      possession_dribblesucc__y\n      possession_dribbleatt__y\n      possession_dribblesucc%_y\n      possession_dribblepast_y\n      possession_megs_y\n      possession_carries_y\n      possession_totdist__y\n      possession_PC_prgdist__y\n      possession_PC_prog__y\n      possession_PC_1/3__y\n      possession_PC_cpa_y\n      possession_PC_mis_y\n      possession_PC_dis_y\n      possession_targ_y\n      possession_rec_y\n      possession_rec%_y\n      possession_prog_.1_y\n      misc_crdy_y\n      misc_crdr_y\n      misc_2crdy_y\n      misc_fls_y\n      misc_fld__y\n      misc_off__y\n      misc_crs__y\n      misc_int__y\n      misc_tklw__y\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      team_y\n    \n  \n  \n    \n      count\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n    \n    \n      unique\n      NaN\n      NaN\n      2\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      3\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n    \n    \n      top\n      NaN\n      NaN\n      Away\n      NaN\n      NaN\n      NaN\n      Newcastle United\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      NaN\n      L\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Newcastle United\n    \n    \n      freq\n      NaN\n      NaN\n      1871\n      NaN\n      NaN\n      NaN\n      188\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      188\n      NaN\n      NaN\n      NaN\n      NaN\n      1444\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      188\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      188\n    \n    \n      mean\n      19.789305\n      15.910160\n      NaN\n      -0.003342\n      1.367870\n      1.371212\n      NaN\n      1.324242\n      12.318806\n      4.082620\n      33.666230\n      0.103205\n      0.295620\n      151.814870\n      0.457487\n      0.104055\n      0.131684\n      1.320134\n      1.220357\n      0.100935\n      0.004109\n      -0.000169\n      4.084715\n      2.817513\n      68.905134\n      0.285829\n      1.332852\n      0.005624\n      0.134447\n      0.104768\n      0.022103\n      0.007576\n      6.711765\n      17.383601\n      41.413993\n      24.147148\n      4.075178\n      51.061034\n      42.502959\n      7.459848\n      66.906448\n      52.437215\n      8.755080\n      0.661631\n      7.543382\n      0.649643\n      14.412273\n      390.931194\n      77.247553\n      1979.363069\n      687.824335\n      40.897515\n      86.660709\n      41.792130\n      83.940147\n      15.411750\n      57.009621\n      0.942959\n      0.897821\n      8.928030\n      7.547074\n      2.120160\n      0.545131\n      8.387274\n      89.802235\n      10.197765\n      2.484955\n      0.183265\n      15.459547\n      2.967840\n      2.486263\n      1.061565\n      0.467084\n      0.350791\n      0.082297\n      63.555635\n      14.102166\n      22.342199\n      27.469285\n      59.267074\n      4.388067\n      4.484950\n      1.347329\n      77.794521\n      0.354085\n      1.919054\n      2.424604\n      2.519446\n      19.230080\n      13.878342\n      1.687032\n      1.185428\n      0.992647\n      1.057353\n      0.429278\n      2.148217\n      1.469563\n      0.141355\n      0.147816\n      0.180793\n      0.159358\n      0.049332\n      17.782130\n      60.717652\n      50.005406\n      37.636636\n      12.357958\n      33.790802\n      36.547767\n      10.469430\n      150.873797\n      29.555771\n      34.517406\n      43.220499\n      22.262095\n      15.869519\n      23.681976\n      0.506995\n      76.318024\n      12.285829\n      25.121970\n      0.274911\n      49.998217\n      615.295811\n      11.131009\n      33.164347\n      46.679487\n      26.100825\n      3.856162\n      92.155582\n      9.629144\n      16.482531\n      58.265330\n      10.457442\n      0.714572\n      383.570811\n      1960.431774\n      53.252857\n      10.944362\n      3.339541\n      1.091207\n      3.437701\n      3.274796\n      465.705749\n      390.931194\n      82.527647\n      34.576738\n      1.634715\n      0.058289\n      0.023886\n      12.389394\n      11.971569\n      1.868182\n      12.004590\n      12.285829\n      10.759091\n      0.110116\n      0.128832\n      0.044251\n      90.116667\n      19.210250\n      19.209581\n      49.993079\n      NaN\n      2019.023529\n      6.763636\n      2019.533690\n      4.360963\n      NaN\n      -0.001872\n      1.371390\n      1.373262\n      -0.001471\n      1.368672\n      1.370143\n      NaN\n      1.324777\n      12.322950\n      4.084759\n      33.665749\n      0.103174\n      0.295648\n      151.783431\n      0.457888\n      0.104189\n      0.131818\n      1.320963\n      1.221092\n      0.100949\n      0.003815\n      -0.000504\n      4.081640\n      2.815374\n      68.919652\n      0.286364\n      1.331836\n      0.005677\n      0.134447\n      0.104768\n      0.022103\n      0.007576\n      6.709358\n      17.376381\n      41.415183\n      24.147549\n      4.076114\n      51.039416\n      42.493012\n      7.457843\n      66.902732\n      52.430985\n      8.752540\n      0.662701\n      7.562781\n      0.649777\n      14.412968\n      391.065285\n      77.252794\n      1979.240478\n      687.729735\n      40.898842\n      86.663770\n      41.792418\n      83.941805\n      15.409745\n      57.018378\n      0.943093\n      0.898075\n      8.930303\n      7.547489\n      2.119949\n      0.544611\n      8.387497\n      89.804963\n      10.195037\n      2.483827\n      0.183429\n      15.457410\n      2.966877\n      2.485392\n      1.061554\n      0.466670\n      0.351048\n      0.082452\n      63.562637\n      14.102245\n      22.335118\n      27.463310\n      59.275168\n      4.386860\n      4.484425\n      1.347030\n      77.799389\n      0.353852\n      1.918207\n      2.423601\n      2.519481\n      19.238102\n      13.884492\n      1.687299\n      1.185963\n      0.993182\n      1.058021\n      0.429144\n      2.149020\n      1.470766\n      0.141087\n      0.147683\n      0.180526\n      0.159759\n      0.049198\n      17.784135\n      60.719894\n      50.000323\n      37.647136\n      12.352541\n      33.783894\n      36.543182\n      10.470232\n      150.897059\n      29.560998\n      34.512083\n      43.224267\n      22.263651\n      15.867112\n      23.665236\n      0.506995\n      76.334764\n      12.288636\n      25.107932\n      0.274777\n      50.007442\n      615.434180\n      11.127372\n      33.157686\n      46.683163\n      26.103830\n      3.856597\n      92.157298\n      9.633021\n      16.488681\n      58.268097\n      10.461988\n      0.714840\n      383.703164\n      1960.965196\n      53.255401\n      10.945468\n      3.339802\n      1.091572\n      3.436512\n      3.274502\n      465.841176\n      391.065285\n      82.532513\n      34.589305\n      1.635918\n      0.058422\n      0.024020\n      12.391800\n      11.971836\n      1.866979\n      12.004055\n      12.288636\n      10.760561\n      0.110250\n      0.128832\n      0.044251\n      90.128164\n      19.211854\n      19.208779\n      49.995499\n      NaN\n    \n    \n      std\n      10.812190\n      9.082985\n      NaN\n      1.260926\n      0.808001\n      0.774004\n      NaN\n      0.794644\n      3.597818\n      1.608375\n      9.614793\n      0.063311\n      0.160978\n      54.846307\n      0.401409\n      0.189608\n      0.213964\n      0.539431\n      0.499269\n      0.028063\n      0.548592\n      0.545514\n      1.536609\n      1.192484\n      17.268237\n      0.271639\n      0.620853\n      0.426968\n      0.218550\n      0.189411\n      0.089500\n      0.052022\n      2.673514\n      6.831725\n      11.779479\n      5.578168\n      1.668569\n      20.032654\n      9.608195\n      2.134183\n      24.745854\n      13.899819\n      2.799294\n      0.530528\n      6.377266\n      0.567336\n      3.132228\n      119.477131\n      6.127586\n      108.661242\n      122.423021\n      3.621674\n      3.653049\n      3.620413\n      5.360235\n      2.776097\n      8.948543\n      0.660216\n      0.400746\n      2.878542\n      1.266651\n      0.599713\n      0.297163\n      1.457260\n      2.574413\n      2.574413\n      0.758481\n      0.151459\n      3.983513\n      0.780574\n      0.691667\n      0.342776\n      0.294596\n      0.231719\n      0.116260\n      9.270781\n      2.990125\n      7.202335\n      6.437151\n      7.071222\n      1.538933\n      1.257358\n      0.410721\n      6.000126\n      0.218160\n      0.703913\n      0.971685\n      0.625166\n      6.158332\n      5.057429\n      0.842449\n      0.768469\n      0.696029\n      0.600697\n      0.406695\n      1.383549\n      1.122031\n      0.214337\n      0.251428\n      0.253063\n      0.238379\n      0.133121\n      3.479814\n      7.282239\n      9.782546\n      7.986327\n      5.688972\n      8.586122\n      8.484729\n      2.904268\n      27.877080\n      3.933526\n      6.492833\n      3.781661\n      5.400574\n      3.425881\n      8.158337\n      1.101893\n      8.158337\n      4.887549\n      7.802474\n      0.332278\n      9.573898\n      112.341294\n      3.073200\n      5.869180\n      4.246802\n      4.196696\n      0.939337\n      1.639189\n      2.899335\n      4.097558\n      8.885281\n      3.039749\n      0.565743\n      109.013451\n      560.207630\n      3.728944\n      1.931172\n      0.714923\n      0.444086\n      1.165160\n      1.051011\n      119.023950\n      119.477131\n      5.138379\n      10.830988\n      0.746549\n      0.138407\n      0.089291\n      2.524250\n      2.591855\n      0.956812\n      3.444791\n      4.887549\n      2.295753\n      0.195497\n      0.211274\n      0.118976\n      11.267654\n      5.659847\n      5.813950\n      6.294121\n      NaN\n      1.407382\n      3.969227\n      1.520015\n      1.798241\n      NaN\n      1.947079\n      1.269421\n      1.269820\n      1.262519\n      0.808628\n      0.774343\n      NaN\n      0.795351\n      3.597067\n      1.608762\n      9.614106\n      0.063220\n      0.160880\n      54.850292\n      0.401701\n      0.189711\n      0.214038\n      0.540175\n      0.499985\n      0.028062\n      0.548811\n      0.545793\n      1.537276\n      1.192771\n      17.264720\n      0.271814\n      0.621129\n      0.426749\n      0.218550\n      0.189411\n      0.089500\n      0.052022\n      2.672028\n      6.828191\n      11.780052\n      5.577480\n      1.669308\n      20.034401\n      9.606079\n      2.134818\n      24.737701\n      13.894690\n      2.800754\n      0.530705\n      6.392757\n      0.567242\n      3.129257\n      119.515735\n      6.128051\n      108.609872\n      122.401336\n      3.621302\n      3.653428\n      3.620178\n      5.359233\n      2.775348\n      8.950187\n      0.660886\n      0.400693\n      2.874659\n      1.266934\n      0.599507\n      0.297272\n      1.457096\n      2.574378\n      2.574378\n      0.758191\n      0.151427\n      3.984765\n      0.780327\n      0.691138\n      0.342928\n      0.294658\n      0.231838\n      0.116712\n      9.267060\n      2.989201\n      7.200972\n      6.427083\n      7.065863\n      1.538999\n      1.256937\n      0.410498\n      6.000922\n      0.218247\n      0.704214\n      0.971906\n      0.625276\n      6.153878\n      5.053910\n      0.842469\n      0.768861\n      0.697474\n      0.601022\n      0.406260\n      1.385009\n      1.123701\n      0.213889\n      0.251374\n      0.252460\n      0.238531\n      0.132919\n      3.477123\n      7.276880\n      9.780540\n      7.986417\n      5.689568\n      8.581289\n      8.469441\n      2.904276\n      27.861281\n      3.935946\n      6.495629\n      3.784094\n      5.401501\n      3.426921\n      8.160210\n      1.101893\n      8.160210\n      4.886419\n      7.791726\n      0.332288\n      9.576615\n      112.388551\n      3.076070\n      5.875037\n      4.250795\n      4.198132\n      0.939326\n      1.639047\n      2.902260\n      4.103303\n      8.886728\n      3.042843\n      0.565759\n      109.038437\n      560.266760\n      3.730208\n      1.932012\n      0.714515\n      0.443880\n      1.164719\n      1.050918\n      119.069075\n      119.515735\n      5.138246\n      10.836724\n      0.746286\n      0.138592\n      0.089629\n      2.523003\n      2.591213\n      0.956610\n      3.445064\n      4.886419\n      2.293386\n      0.195592\n      0.211274\n      0.118976\n      11.274286\n      5.658357\n      5.813577\n      6.295669\n      NaN\n    \n    \n      min\n      1.000000\n      1.000000\n      NaN\n      -5.333333\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.333333\n      2.766667\n      0.000000\n      0.000000\n      55.061728\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.033333\n      -1.966667\n      -1.700000\n      0.333333\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      157.000000\n      58.200000\n      1690.290290\n      421.044850\n      28.197674\n      68.133333\n      31.100478\n      63.566667\n      8.301527\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      3.724138\n      0.126263\n      0.000000\n      3.750000\n      78.957169\n      3.957997\n      0.732601\n      0.000000\n      5.770965\n      1.133948\n      0.632911\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      32.774674\n      6.373355\n      6.699548\n      12.052117\n      37.898687\n      1.231423\n      1.332795\n      0.264901\n      58.153846\n      0.000000\n      0.455581\n      0.293255\n      0.691017\n      4.666667\n      2.500000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      36.170213\n      11.627907\n      12.500000\n      0.000000\n      8.333333\n      9.166667\n      2.000000\n      66.000000\n      13.700000\n      13.606911\n      29.111842\n      8.041237\n      6.000000\n      0.000000\n      0.000000\n      45.161290\n      1.333333\n      6.333333\n      0.000000\n      24.666667\n      361.666667\n      3.639121\n      14.908854\n      33.405172\n      10.754098\n      1.246334\n      85.822785\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      157.000000\n      778.000000\n      41.276202\n      5.420561\n      1.097695\n      0.000000\n      0.894188\n      0.889193\n      219.333333\n      157.000000\n      61.866667\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.333333\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n      2017.000000\n      1.000000\n      2017.000000\n      0.000000\n      NaN\n      -9.000000\n      0.000000\n      0.000000\n      -5.333333\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.333333\n      2.766667\n      0.000000\n      0.000000\n      55.061728\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.033333\n      -1.966667\n      -1.700000\n      0.333333\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      157.000000\n      58.200000\n      1690.290290\n      421.044850\n      28.197674\n      68.133333\n      31.100478\n      63.566667\n      8.301527\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      3.724138\n      0.126263\n      0.000000\n      3.750000\n      78.957169\n      3.957997\n      0.732601\n      0.000000\n      5.770965\n      1.133948\n      0.632911\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      32.774674\n      6.373355\n      6.699548\n      12.052117\n      37.898687\n      1.231423\n      1.332795\n      0.264901\n      58.153846\n      0.000000\n      0.455581\n      0.293255\n      0.691017\n      4.666667\n      2.500000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      36.170213\n      11.627907\n      12.500000\n      0.000000\n      8.333333\n      9.166667\n      2.000000\n      66.000000\n      13.700000\n      13.606911\n      29.111842\n      8.041237\n      6.000000\n      0.000000\n      0.000000\n      45.161290\n      1.333333\n      6.333333\n      0.000000\n      24.666667\n      361.666667\n      3.639121\n      14.908854\n      33.405172\n      10.754098\n      1.246334\n      85.822785\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      157.000000\n      778.000000\n      41.276202\n      5.420561\n      1.097695\n      0.000000\n      0.894188\n      0.889193\n      219.333333\n      157.000000\n      61.866667\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.333333\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n    \n    \n      25%\n      10.000000\n      8.000000\n      NaN\n      -1.000000\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.200000\n      0.060000\n      0.176667\n      114.758929\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.258333\n      20.333333\n      3.000000\n      34.625000\n      34.666667\n      6.000000\n      48.000000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      73.000000\n      1904.671024\n      597.184442\n      38.330073\n      84.366667\n      39.180032\n      80.466667\n      13.442505\n      50.300000\n      0.333333\n      0.600000\n      7.000000\n      6.676949\n      1.706103\n      0.329083\n      7.358874\n      88.052077\n      8.321893\n      1.936060\n      0.073233\n      12.539702\n      2.435745\n      1.990478\n      0.825466\n      0.251375\n      0.176815\n      0.000000\n      57.131288\n      12.020757\n      16.761444\n      22.619711\n      54.337558\n      3.223610\n      3.572207\n      1.058524\n      73.703910\n      0.198840\n      1.395349\n      1.681482\n      2.083333\n      15.000000\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      55.769231\n      43.181818\n      32.142857\n      8.333333\n      27.906977\n      30.633333\n      8.333333\n      131.000000\n      26.925000\n      30.194872\n      40.625000\n      18.408045\n      13.333333\n      17.987179\n      0.000000\n      70.833333\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.666667\n      8.961050\n      29.345463\n      43.868450\n      23.254724\n      3.223858\n      91.025962\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.333333\n      50.769548\n      9.595724\n      2.845528\n      0.782841\n      2.597991\n      2.543108\n      377.333333\n      302.000000\n      79.166667\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.250000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.000000\n      15.000000\n      45.933333\n      NaN\n      2018.000000\n      3.000000\n      2018.000000\n      4.000000\n      NaN\n      -1.000000\n      0.000000\n      0.000000\n      -1.000000\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.200000\n      0.060000\n      0.176667\n      114.708333\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.233333\n      20.333333\n      3.000000\n      34.625000\n      34.666667\n      6.000000\n      48.000000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      73.000000\n      1904.671024\n      597.103658\n      38.327718\n      84.366667\n      39.180032\n      80.466667\n      13.441365\n      50.325000\n      0.333333\n      0.600000\n      7.000000\n      6.676949\n      1.706103\n      0.328192\n      7.358874\n      88.054636\n      8.307964\n      1.935807\n      0.073300\n      12.535171\n      2.435630\n      1.990167\n      0.824997\n      0.250117\n      0.176815\n      0.000000\n      57.140011\n      12.020757\n      16.756203\n      22.619711\n      54.346396\n      3.221214\n      3.573929\n      1.058127\n      73.710308\n      0.198282\n      1.394568\n      1.681230\n      2.083333\n      15.000000\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      55.769231\n      43.181818\n      32.142857\n      8.333333\n      27.906977\n      30.633333\n      8.333333\n      131.000000\n      26.933333\n      30.183981\n      40.625000\n      18.408045\n      13.333333\n      17.948718\n      0.000000\n      70.909091\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.916667\n      8.957279\n      29.333138\n      43.868450\n      23.260019\n      3.225334\n      91.027006\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.583333\n      50.772488\n      9.595724\n      2.845528\n      0.783429\n      2.597186\n      2.543108\n      377.333333\n      302.000000\n      79.166667\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.000000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.000000\n      15.000000\n      45.933333\n      NaN\n    \n    \n      50%\n      20.000000\n      16.000000\n      NaN\n      0.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.000000\n      4.000000\n      33.266667\n      0.096667\n      0.276667\n      141.126984\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.666667\n      40.133333\n      23.666667\n      4.000000\n      51.233333\n      41.983333\n      7.333333\n      70.883333\n      53.866667\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.666667\n      77.533333\n      1973.385792\n      674.276172\n      40.893394\n      87.033333\n      41.918119\n      84.733333\n      15.218688\n      56.616667\n      1.000000\n      0.833333\n      8.666667\n      7.505258\n      2.080172\n      0.499085\n      8.344460\n      89.793788\n      10.206212\n      2.440634\n      0.155159\n      15.109299\n      2.891967\n      2.444716\n      1.030131\n      0.415153\n      0.326624\n      0.052673\n      64.038769\n      13.965784\n      21.682644\n      27.017143\n      59.389146\n      4.180029\n      4.393993\n      1.312780\n      78.137796\n      0.312337\n      1.835510\n      2.419147\n      2.476006\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      60.606061\n      50.000000\n      37.500000\n      11.764706\n      33.333333\n      36.333333\n      10.333333\n      148.666667\n      29.500000\n      34.422759\n      43.166562\n      21.661238\n      16.000000\n      23.076923\n      0.000000\n      76.923077\n      12.333333\n      24.333333\n      0.333333\n      49.333333\n      598.000000\n      10.956981\n      33.231956\n      46.543912\n      25.917296\n      3.799952\n      92.101589\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1888.333333\n      53.271144\n      10.804122\n      3.312019\n      1.046910\n      3.311880\n      3.151388\n      447.000000\n      369.666667\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.866667\n      NaN\n      2019.000000\n      7.000000\n      2020.000000\n      5.000000\n      NaN\n      0.000000\n      1.000000\n      1.000000\n      0.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.000000\n      4.000000\n      33.266667\n      0.096667\n      0.276667\n      141.096096\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.500000\n      40.133333\n      23.666667\n      4.000000\n      51.216667\n      41.966667\n      7.333333\n      70.833333\n      53.866667\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.666667\n      77.533333\n      1973.299213\n      674.203472\n      40.902674\n      87.033333\n      41.918119\n      84.733333\n      15.216435\n      56.633333\n      1.000000\n      0.833333\n      8.666667\n      7.505258\n      2.080172\n      0.499002\n      8.344641\n      89.807127\n      10.192873\n      2.438150\n      0.155280\n      15.107914\n      2.891076\n      2.442379\n      1.030131\n      0.414938\n      0.326731\n      0.052673\n      64.054440\n      13.965784\n      21.676691\n      27.017143\n      59.397669\n      4.179519\n      4.393352\n      1.312062\n      78.145767\n      0.312215\n      1.833579\n      2.418674\n      2.476006\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      60.606061\n      50.000000\n      37.500000\n      11.764706\n      33.333333\n      36.333333\n      10.333333\n      148.666667\n      29.500000\n      34.416938\n      43.190925\n      21.661853\n      16.000000\n      23.076923\n      0.000000\n      76.923077\n      12.333333\n      24.333333\n      0.333333\n      49.333333\n      598.166667\n      10.955386\n      33.229361\n      46.543912\n      25.917765\n      3.800716\n      92.104505\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1889.166667\n      53.272788\n      10.807099\n      3.312348\n      1.047120\n      3.311526\n      3.150893\n      447.000000\n      369.666667\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.866667\n      NaN\n    \n    \n      75%\n      29.000000\n      23.000000\n      NaN\n      0.666667\n      1.666667\n      2.000000\n      NaN\n      1.666667\n      14.333333\n      5.000000\n      39.833333\n      0.136667\n      0.400000\n      174.814815\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.600000\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.608333\n      49.875000\n      9.000000\n      88.900000\n      63.800000\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      462.666667\n      81.866667\n      2046.497928\n      761.944411\n      43.321740\n      89.300000\n      44.501404\n      88.008333\n      17.192269\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      8.377245\n      2.488849\n      0.704380\n      9.353610\n      91.678107\n      11.947923\n      2.967121\n      0.259875\n      18.066159\n      3.434564\n      2.904000\n      1.275412\n      0.628931\n      0.495488\n      0.121175\n      70.360031\n      16.085472\n      27.074844\n      31.353094\n      64.326950\n      5.348022\n      5.296737\n      1.594533\n      82.279813\n      0.464769\n      2.369317\n      3.088833\n      2.916504\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      65.724070\n      56.818182\n      43.083554\n      15.733083\n      39.404609\n      42.108333\n      12.333333\n      168.083333\n      32.166667\n      38.637570\n      45.792658\n      25.485027\n      18.000000\n      29.166667\n      0.000000\n      82.012821\n      15.666667\n      29.666667\n      0.333333\n      56.666667\n      684.416667\n      13.116066\n      37.014643\n      49.525891\n      28.669936\n      4.423012\n      93.340426\n      11.333333\n      19.000000\n      64.233333\n      12.333333\n      1.000000\n      450.541667\n      2321.083333\n      55.817291\n      12.157871\n      3.783117\n      1.351732\n      4.127864\n      3.906409\n      537.666667\n      462.666667\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      NaN\n      2020.000000\n      11.000000\n      2021.000000\n      6.000000\n      NaN\n      1.000000\n      2.000000\n      2.000000\n      0.666667\n      1.666667\n      2.000000\n      NaN\n      1.666667\n      14.333333\n      5.000000\n      39.833333\n      0.136667\n      0.400000\n      174.685847\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.600000\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.600000\n      49.866667\n      9.000000\n      88.900000\n      63.800000\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      463.000000\n      81.875000\n      2046.262466\n      761.837938\n      43.322443\n      89.300000\n      44.500754\n      88.008333\n      17.189260\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      8.378284\n      2.488688\n      0.704225\n      9.352675\n      91.692036\n      11.945364\n      2.965807\n      0.259898\n      18.066159\n      3.433541\n      2.902260\n      1.275691\n      0.628931\n      0.496003\n      0.121230\n      70.360031\n      16.080614\n      27.056263\n      31.353094\n      64.338108\n      5.347347\n      5.295715\n      1.594285\n      82.292768\n      0.464563\n      2.369200\n      3.087634\n      2.916504\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      65.714286\n      56.756757\n      43.103448\n      15.733083\n      39.393939\n      42.100000\n      12.333333\n      168.083333\n      32.166667\n      38.637570\n      45.795794\n      25.485027\n      18.000000\n      29.090909\n      0.000000\n      82.051282\n      15.666667\n      29.666667\n      0.333333\n      56.666667\n      684.750000\n      13.116066\n      37.014643\n      49.526726\n      28.669936\n      4.423812\n      93.342347\n      11.333333\n      19.000000\n      64.233333\n      12.333333\n      1.000000\n      450.666667\n      2322.416667\n      55.825288\n      12.158055\n      3.783784\n      1.351732\n      4.125392\n      3.905096\n      538.000000\n      463.000000\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      NaN\n    \n    \n      max\n      38.000000\n      31.000000\n      NaN\n      5.333333\n      5.666667\n      5.666667\n      NaN\n      5.666667\n      27.666667\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      708.000000\n      2.333333\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      18.666667\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      91.066667\n      2398.063380\n      1296.830986\n      54.207263\n      95.100000\n      52.490660\n      94.633333\n      25.879917\n      83.633333\n      5.000000\n      2.833333\n      21.666667\n      13.935970\n      4.793757\n      2.348066\n      14.285714\n      96.042003\n      21.042831\n      5.673759\n      1.083032\n      30.942092\n      6.671900\n      5.632716\n      2.524698\n      2.195390\n      1.541002\n      0.920680\n      84.874640\n      26.916376\n      47.310513\n      49.404117\n      78.316327\n      11.080836\n      10.986965\n      3.247863\n      91.125642\n      2.006689\n      5.189189\n      6.269113\n      4.973822\n      46.333333\n      38.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      1.333333\n      1.666667\n      1.000000\n      32.000000\n      91.666667\n      79.487179\n      62.790698\n      42.857143\n      71.428571\n      66.266667\n      25.333333\n      268.333333\n      45.566667\n      58.685446\n      56.675063\n      48.812095\n      30.666667\n      54.838710\n      7.894737\n      100.000000\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      25.899281\n      55.932203\n      63.639323\n      44.711111\n      8.444444\n      96.594982\n      24.333333\n      36.333333\n      87.166667\n      25.666667\n      4.666667\n      746.333333\n      4209.000000\n      64.982456\n      18.909306\n      6.168549\n      3.206651\n      9.473684\n      9.362280\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      1.000000\n      0.666667\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      NaN\n      2021.000000\n      12.000000\n      2022.000000\n      6.000000\n      NaN\n      9.000000\n      9.000000\n      9.000000\n      5.333333\n      5.666667\n      5.666667\n      NaN\n      5.666667\n      27.666667\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      708.000000\n      2.333333\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      18.666667\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      91.066667\n      2398.063380\n      1296.830986\n      54.207263\n      95.100000\n      52.490660\n      94.633333\n      25.879917\n      83.633333\n      5.000000\n      2.833333\n      21.666667\n      13.935970\n      4.793757\n      2.348066\n      14.285714\n      96.042003\n      21.042831\n      5.673759\n      1.083032\n      30.942092\n      6.671900\n      5.632716\n      2.524698\n      2.195390\n      1.541002\n      0.920680\n      84.874640\n      26.916376\n      47.310513\n      49.404117\n      78.316327\n      11.080836\n      10.986965\n      3.247863\n      91.125642\n      2.006689\n      5.189189\n      6.269113\n      4.973822\n      46.333333\n      38.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      1.333333\n      1.666667\n      1.000000\n      32.000000\n      91.666667\n      79.487179\n      62.790698\n      42.857143\n      71.428571\n      66.266667\n      25.333333\n      268.333333\n      45.566667\n      58.685446\n      56.675063\n      48.812095\n      30.666667\n      54.838710\n      7.894737\n      100.000000\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      25.899281\n      55.932203\n      63.639323\n      44.711111\n      8.444444\n      96.594982\n      24.333333\n      36.333333\n      87.166667\n      25.666667\n      4.666667\n      746.333333\n      4209.000000\n      64.982456\n      18.909306\n      6.168549\n      3.206651\n      9.473684\n      9.362280\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      1.000000\n      0.666667\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      NaN"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#prepare-the-data",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#prepare-the-data",
    "title": "Predicting Premier League Matches",
    "section": "Prepare the data",
    "text": "Prepare the data\nBasically just make numerical data normalised, categorical data encoded and split into train and validation sets\n\n#toggle-hide\ndef do_pre_proc(dfAll,target = 'NetScore_x'):\n    \n    dfAll=dfAll.iloc[20:,:]\n\n    if target == 'NetScore_x':\n        dfAll=dfAll.drop(columns=['Win_x','opponent_y','team_y','GoalsAgainst_x','GoalsFor_x'])\n    elif target=='Win_x':\n        dfAll=dfAll.drop(columns=['NetScore_x','opponent_y','team_y','GoalsAgainst_x','GoalsFor_x'])\n        dfAll[target]=dfAll[target].map({'W':2,'D':1,'L':0})\n    else:\n        return 'error'\n    \n    \n    dfAll=dfAll[[c for c in dfAll if c!=target]+[target]]\n    \n    features_cat=[x for x in dfAll if dfAll[x].dtype=='O']\n    features_num = [x for x in dfAll.columns if x != target and dfAll[x].dtype!='O' ]\n    \n    preprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n    (OneHotEncoder(), features_cat),\n    )\n      \n    dfAll=dfAll.fillna(0)\n    cond = dfAll.season<2021\n    \n    predictors = [x for x in dfAll.columns if x != target ]\n    X=dfAll.copy()\n    \n    y=X.pop(target)\n    X = preprocessor.fit_transform(X)\n    \n    \n    X_train=X[cond]\n    X_valid=X[~cond]\n    y_train = y[cond]\n    y_valid = y[~cond]\n\n    return X_train, X_valid, y_train, y_valid\n\n\nX_train, X_valid, y_train, y_valid = do_pre_proc(dfAll,'Win_x')"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#xgboost",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#xgboost",
    "title": "Predicting Premier League Matches",
    "section": "XGBoost",
    "text": "XGBoost\nGradient Boosting\nGradient boosting is a method that goes through cycles to iteratively add models into an ensemble.\nIt begins by initializing the ensemble with a single model, whose predictions can be pretty naive. (Even if its predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.)\nThen, we start the cycle:\n\nFirst, we use the current ensemble to generate predictions for each observation in the dataset. To make a prediction, we add the predictions from all models in the ensemble.\nThese predictions are used to calculate a loss function (like mean squared error, for instance).\nThen, we use the loss function to fit a new model that will be added to the ensemble. Specifically, we determine model parameters so that adding this new model to the ensemble will reduce the loss. (Side note: The “gradient” in “gradient boosting” refers to the fact that we’ll use gradient descent on the loss function to determine the parameters in this new model.)\nFinally, we add the new model to ensemble, and …\n… repeat!\n\nGBoost stands for extreme gradient boosting, which is an implementation of gradient boosting with several additional features focused on performance and speed\n\nmodel_rf = RandomForestClassifier()\nmodel_rf.fit(X_train,y_train)\n\naccuracy_score(y_train,model_rf.predict(X_train)),accuracy_score(y_valid,model_rf.predict(X_valid))\n\n(1.0, 0.49868073878627966)\n\n\n\nmodel_XGB = XGBClassifier()\nmodel_XGB.fit(X_train,y_train)\n\naccuracy_score(y_train,model_XGB.predict(X_train)),accuracy_score(y_valid,model_XGB.predict(X_valid))\n\n(1.0, 0.5092348284960422)\n\n\n\nParameter tuning\nn_estimators specifies how many times to go through the modeling cycle described above. It is equal to the number of models that we include in the ensemble.\n\nToo low a value causes underfitting, which leads to inaccurate predictions on both training data and test data.\nToo high a value causes overfitting, which causes accurate predictions on training data, but inaccurate predictions on test data (which is what we care about).\n\nTypical values range from 100-1000\nearly_stopping_rounds offers a way to automatically find the ideal value for n_estimators. Early stopping causes the model to stop iterating when the validation score stops improving, even if we aren’t at the hard stop for n_estimators. Setting early_stopping_rounds=5 is a reasonable choice. In this case, we stop after 5 straight rounds of deteriorating validation scores.\nlearning_rate\nInstead of getting predictions by simply adding up the predictions from each component model, we can multiply the predictions from each model by a small number (known as the learning rate) before adding them in.\nThis means each tree we add to the ensemble helps us less. So, we can set a higher value for n_estimators without overfitting. If we use early stopping, the appropriate number of trees will be determined automatically.\nIn general, a small learning rate and large number of estimators will yield more accurate XGBoost models, though it will also take the model longer to train since it does more iterations through the cycle. As default, XGBoost sets learning_rate=0.1\n\ndef do_model(n_estimators,learning_rate):\n    model_XGB = XGBClassifier(n_estimators=n_estimators,\n             learning_rate=learning_rate,\n             early_stopping_rounds=10,\n             )\n    \n    model_XGB.fit(X_train,y_train,\n             eval_set=[(X_valid, y_valid)],\n             verbose=False)\n\n    acc_train=accuracy_score(y_train,model_XGB.predict(X_train))\n    acc_valid=accuracy_score(y_valid,model_XGB.predict(X_valid))\n    \n    return acc_train, acc_valid\n\nlearning_rate=1e-4\nn_estimators=[100,250,500,1_000,1500,2_500,5_000,10_000]\n\nscore=[]\nfor n in n_estimators:\n    score.append( do_model(n,learning_rate) )\n\n\nscore=np.array(score)\nplt.plot(n_estimators,score,'o-')\nplt.legend(['train','validation'])\nnp.max(score[:,1])\n\n0.5290237467018469\n\n\n\n\n\n\nn_estimator=n_estimators[np.argmax(score[:,1])]\nmodel_XGB = XGBClassifier(n_estimators=n_estimator,\n             learning_rate=learning_rate,\n             early_stopping_rounds=10,\n             )\n    \nmodel_XGB.fit(X_train,y_train,\n         eval_set=[(X_valid, y_valid)],\n         verbose=False)\n\npred_XGB=model_XGB.predict(X_valid)\npred_XGB=[np.argmax(x) for x in pred_XGB ]"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#deep-learning",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#deep-learning",
    "title": "Predicting Premier League Matches",
    "section": "Deep Learning",
    "text": "Deep Learning\nThis dataset is prone to lots of overfitting (bias) and also has a high ratio of numberof parameters to number of data points.\nTo get around the 2 issues: - model has a high dropout rate - a relatively high number of units (i.e. a wide neural network)\nFor more information see the kaggle notebook of keras binary EPL which goes over this in more detail for the binary issue.\n\ny_valid=pd.get_dummies(y_valid)\ny_train=pd.get_dummies(y_train)\n\ndrop_pc=0.8\nunits=512*2\nmodel=keras.Sequential([\n        layers.Dense(units,activation='relu',input_shape=[np.shape(X_train)[1]]),\n        layers.Dropout(drop_pc),\n        layers.Dense(units,activation='relu'),\n        layers.Dropout(drop_pc),\n        layers.Dense(units,activation='relu'),\n        layers.Dropout(drop_pc),\n        layers.Dense(3,activation='softmax')\n        ])\n\nopt = keras.optimizers.Adam(learning_rate=0.0005)\nmodel.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    #loss='binary_crossentropy',#for binary classification 0-1\n    metrics=['accuracy'],\n)\n\n\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.0001, # minimium amount of change to count as an improvement\n    patience=40, # how many epochs to wait before stopping\n    restore_best_weights=True,\n    monitor='val_accuracy',\n)\n\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=len(X_valid),\n    epochs=700,\n    callbacks=[early_stopping],\n    verbose=0, # hide the output because we have so many epochs\n)\n\n\nhistory_df = pd.DataFrame(history.history)\n\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['val_loss'].min(), \n              history_df['val_accuracy'].max()))\n\nBest Validation Loss: 1.0254\nBest Validation Accuracy: 0.5369\n\n\n\n\n\n\n\n\n\nepochs=history_df['val_accuracy'].argmax()\nmodel=keras.Sequential([\n        layers.Dense(units,activation='relu',input_shape=[np.shape(X_train)[1]]),\n        layers.Dropout(drop_pc),\n        layers.Dense(units,activation='relu'),\n        layers.Dropout(drop_pc),\n        layers.Dense(units,activation='relu'),\n        layers.Dropout(drop_pc),\n        layers.Dense(3,activation='softmax')\n        ])\n\nopt = keras.optimizers.Adam(learning_rate=0.0005)\nmodel.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    #loss='binary_crossentropy',#for binary classification 0-1\n    metrics=['accuracy'],\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=len(X_valid),\n    epochs=epochs,\n    verbose=0, # hide the output because we have so many epochs\n)\n\n\npreds=model.predict(X_valid).argmax(axis=1)\ny_valid_=[np.argmax(y_valid.iloc[i,:]) for i in range(len(y_valid))]\nacc_nn=accuracy_score(y_valid_,preds)\n\nprint(f\"accuracy of nn model = {acc_nn:.3f}\")\n\naccuracy of nn model = 0.516"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#ensembling",
    "href": "posts/PROJECTS/Other_projects/PredictingPremierLeagueMatches.html#ensembling",
    "title": "Predicting Premier League Matches",
    "section": "Ensembling",
    "text": "Ensembling\nCombine the results of the two models\n\npreds_combo=(model.predict(X_valid)+ model_XGB.predict_proba(X_valid)).argmax(axis=1)\n\nacc_combo=accuracy_score(y_valid_,preds_combo)\n\nprint(f\"accuracy of combined model = {acc_combo:.3f}\")\n\naccuracy of combined model = 0.534"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePriceApp.html#overview",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePriceApp.html#overview",
    "title": "Creating a property prediction App",
    "section": "Overview",
    "text": "Overview\nThis is an app for predicting house prices in Swansea using Streamlit https://streamlit.io/\nThe app uses the following for predictions:\n\nHouse price sales (price and date)\nName of street and number\nLocation of property (Lattitude and Longitude)\nData on Census regions\n\nMore details of the prediction side of the app, using Random Forrests and neural networks, is dealt with here https://thomashsimm.com/jupyter/python/randomforests/tabulardata/sklearn/2022/02/17/SwanseaHousePrices_Part2.html.\nA video of the app is shown below or can be accessed via https://share.streamlit.io/dmaterialia/propertystreamlit/main/PropertyApp.py\nThe intention of the app is to provide a simple user interface to allow price predictions\n{{< video https://youtu.be/IGykZUeZqRA}}"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePriceApp.html#the-python-script-for-the-app",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePriceApp.html#the-python-script-for-the-app",
    "title": "Creating a property prediction App",
    "section": "The Python Script for the App",
    "text": "The Python Script for the App\n\nLoading the data\nThe following function is used to load the data.\nThe data consists of 4 parts: 1. m = the model (this is by far the biggest part in terms of data size) 1. to = a data frame object of the house data 1. xsAll = this is a form of ‘to’ used by the model (the input values of the model) 1. yAll = a form of ‘to’ the values the model is trying to predict (house price values)\nThe data is saved as a pickle file in a Jupyter Notebook, then uploaded to googledrive as filesize has to be less than 100 Mb on GitHub.\ngdown.download(url, output) downloads the data from GoogleDrive\n@st.cache(allow_output_mutation=True) This line at the top of the python file means the data is cached and don’t need to keep loading it\n\n@st.cache(allow_output_mutation=True)\ndef load_data():\n    \"\"\"\n    Loads the data\n    \"\"\"\n    import gdown\n    url = 'https://drive.google.com/uc?id=1OD2l7ynVzLlqY92gYiCx5xq32-D1wJMe'\n    output = 'one1.pkl'\n    gdown.download(url, output)\n\n    cda = os.getcwd()\n    with open('one1.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n    return m2, to2, xsAll2, yAll2\ndata_load_state = st.text('Loading data...')\nm1, to1, xsAll1, yAll1=load_data()\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\n\n\nUpdating data so prediction is for today\nThe following function changes the date of sale details for each property so that they are today’s date\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n\n\nGetting the predictions\nThe following function takes the address selected and outputs the predicted property price\nget_predTodayNotExact(m,address,toTEMP,xs_final,y)\n\n\nHelp with reducing code for selecting data\nThe following function is used to allow to select different details from the dataframes. Really just a function to get around the slightly unusual way data is selected in ‘to’ and dataFrames\ndef doSelect(typee,option2,typeeOut,toTEMP):\n\n\nThe user interface parts of the app\noptionSELECT = st.sidebar.selectbox(     'Select how to search',      choice)\nThis is a select box loacted in the LHS sidebar. The options for the user are as follows and choice dictates what boxes they see:\nchoice=['Post Code','Region', 'Street']\nFor example if ‘Post code’ is selected the folowing selectbox is shown with all post code options for first part of the postcode:\noption2 = st.sidebar.selectbox(         'Select Postcode',         indexPCSA)\nWhatever option selected the individual address must be selected:\naddress = st.sidebar.selectbox(     'Select Address',     AdSel)\n\n\nPredictions and Output\nOnce the address is selected, teh predictions are found by calling the prediction function:\nPri1, Pri2, typa=get_predTodayNotExact(m,address,(to),(xsAll),(yAll))\nAnd then displayed in the main screen with the following code:\n'You selected: ', option2, 'and', address\n'Property type is ',typa\nstra = 'The predicted price is: ' st.subheader(stra) st.header('£'+ str(Pri1[0])+'k')"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePriceApp.html#creating-the-app",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePriceApp.html#creating-the-app",
    "title": "Creating a property prediction App",
    "section": "Creating the App",
    "text": "Creating the App\nThe Python .py file along with a requirements file are uploaded to a GitHub repository. The one for this is at https://github.com/dMaterialia/PropertyStreamlit\nThe requirements file includes all the modules not included in python that need to be loaded. For this function the file is as follows:\nnumpy\npandas\nmatplotlib\ngdown\nscikit-learn\nfastai\nThen simply log into Streamlit select the repository and the python file and hit go to get the app working\n\nFull Python function\n\nimport streamlit as st\n# To make things easier later, we're also importing numpy and pandas for\n# working with sample data.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport pickle\nimport copy\nfrom sklearn.ensemble import RandomForestRegressor\n\nst.title('Swansea Property Price Predictor')\n\n@st.cache(allow_output_mutation=True)\ndef load_data():\n    \"\"\"\n    Loads the data\n    \"\"\"\n    import gdown\n    url = 'https://drive.google.com/uc?id=1OD2l7ynVzLlqY92gYiCx5xq32-D1wJMe'\n    output = 'one1.pkl'\n    gdown.download(url, output)\n\n    cda = os.getcwd()\n    with open('one1.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n    return m2, to2, xsAll2, yAll2\ndata_load_state = st.text('Loading data...')\nm1, to1, xsAll1, yAll1=load_data()\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n    import re\n    import pandas as pd\n    import numpy as np\n    \n    def ifnone(a, b):\n        \"`b` if `a` is None else `a`\"\n        return b if a is None else a\n    \n    def make_date(df, date_field):\n        \"Make sure `df[date_field]` is of the right date type.\"\n        \n        field_dtype = df[date_field].dtype\n        if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n            field_dtype = np.datetime64\n        if not np.issubdtype(field_dtype, np.datetime64):\n            df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n    \n    \n    make_date(df, field_name)\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    # Pandas removed `dt.week` in v1.1.10\n    week = field.dt.isocalendar().week.astype(field.dt.day.dtype) if hasattr(field.dt, 'isocalendar') else field.dt.week\n    for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) if n != 'Week' else week\n    mask = ~field.isna()\n    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,np.nan)\n    if drop: df.drop(field_name, axis=1, inplace=True)\n    return df\n\ndef get_predTodayNotExact(m,address,toTEMP,xs_final,y):\n    \"\"\"\n    Given model m, address, initial pd of houses to, and adjusted pd xs_final\n    output is house price prediction\n    \"\"\"\n    import copy\n    # convert to current date\n    colsAll=xs_final.columns\n    colsNoDate=['Type', 'Index of Multiple Deprivation', 'Latitude',\n                'Average Income', 'Longitude', 'Postcode', 'Introduced', 'Address',\n           'Altitude']\n    xsNoDate=copy.copy(xs_final.drop(columns=['Elapsed','Year']))\n    \n    xsNoDate['Date'] = pd.to_datetime(\"today\")\n    xsNoDate = add_datepart(xsNoDate, 'Date')\n    xs_finalTEMP=xsNoDate.loc[:,colsAll]\n\n    # each address has a unique number\n    aa=toTEMP.classes['Address']\n    # findwhich number is address give (take 1st if more than 1)\n    try:\n        ii=[ii for ii,aa1 in enumerate(aa) if aa1== address][0]\n        # 1 address can have multiple sales so we need index in dataframes\n        ii=toTEMP[toTEMP['Address']==ii].index[0]\n\n        preda = np.round( np.exp( m.predict(xs_finalTEMP.loc[ii:ii]) )/1000 ,1)\n        prev = np.round( np.exp(y.loc[ii])/1000 ,1)\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xs_finalTEMP.loc[ii:ii,'Type']][0]\n    \n    except:\n        aa=toTEMP.classes['Address']\n        aaStreet=toTEMP.classes['Street']\n        ii=[ii for ii,aa1 in enumerate(aaStreet) if aa1== Street][0]\n        xsTemp=copy.copy( xs_finalTEMP[xs_finalTEMP['Street']==ii] )\n        xsTemp.reset_index(inplace=True,drop=True)\n        # find nearest house by houseno\n        No=np.array(xsTemp['HouseNo'])\n\n        yo=(np.abs(No-HouseNo))\n        yo1=np.min(yo)\n        # get index of the nearest house\n        yo=No[yo==yo1][0]  \n\n        ii=[ii for ii,aa1 in enumerate(xsTemp.HouseNo) if aa1== yo][0]\n        xsTemp.loc[ii:ii,'HouseNo']=HouseNo\n        # If want to change house type\n        \n#         xsTemp.loc[ii:ii,'Type']=2\n#         print(xsTemp.loc[ii:ii,'Type'])\n#         print(xsTemp.loc[ii:ii])\n        \n        preda = np.round( np.exp( m.predict(xsTemp.loc[ii:ii]) )/1000 ,1)[0]\n        prev=0\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xsTemp.loc[ii:ii,'Type']][0]\n        \n        \n    return preda, prev, typa\n\n\ndef doSelect(typee,option2,typeeOut,toTEMP):\n        streetAll=toTEMP.classes[typee]\n        AdAll=toTEMP.classes[typeeOut]\n        # this finds index of postcode for example SA1 0EA = 62\n        indexPC1=[ita for ita,ij in enumerate(streetAll) if ij==option2][0]\n\n        # finds all indexes of addresses with given post code index \n        indexAdds=[ita for ita, ij in enumerate(toTEMP[typee]) if ij==indexPC1]\n\n        # Find address index numbers for those given above\n        indexAddSel=toTEMP.iloc[indexAdds][typeeOut]\n\n        # Convert these to actual addresses\n        AdSel=AdAll[indexAddSel]\n        \n        # unique values\n        AdSel=np.unique(AdSel)\n        return AdSel\n    \n\npcodesSA=['SA1', 'SA2', 'SA3', 'SA4', 'SA5', 'SA6', 'SA7', 'SA8',          \n          'SA9', 'SA10' ,'SA11', 'SA12', 'SA13', 'SA14','SA15','SA18']\n\nchoice=['Post Code','Region', 'Street']\n\nto=copy.copy(to1)\nm=copy.copy(m1)\nxsAll=copy.copy(xsAll1)\nyAll=copy.copy(yAll1)\n# These are the list of all addresses etc by actual name\nAdAll=(to.classes['Address'])\npcAll=(to.classes['Postcode'])\nregionAll=(to.classes['Region'])\nstreetAll=(to.classes['Street'])\n\n# An optionbox- Select How search\noptionSELECT = st.sidebar.selectbox(\n    'Select how to search',\n     choice)\n\nif optionSELECT=='Post Code':\n    # An optionbox- Select Postcode Start e.g. SA1\n    option = st.sidebar.selectbox(\n        'Select Area',\n         pcodesSA)\n\n\n    # Select Postcode All\n\n    # This finds a set of postcodes given by optionbox\n    indexPCSA=[ij for ij in pcAll if ij.split(' ')[0]==option]\n\n    # optionbox to select particular postcode \n    # Outcome e.g. SA1 0EA\n    option2 = st.sidebar.selectbox(\n        'Select Postcode',\n        indexPCSA)\n\n    AdSel = doSelect(typee='Postcode',option2=option2,typeeOut='Address',toTEMP=(to))\n    \n\nelif optionSELECT=='Region':\n\n    \n    option2 = st.sidebar.selectbox(\n         'Select Region',\n         regionAll)\n    \n    StreetSel = doSelect(typee='Region',option2=option2,typeeOut='Street',toTEMP=(to))\n       \n        \n    option3 = st.sidebar.selectbox(\n         'Select Street',\n         StreetSel)\n    \n    AdSel = doSelect(typee='Street',option2=option3,typeeOut='Address',toTEMP=(to))\n        \n    \n\nelif optionSELECT=='Street':\n\n    \n    option2 = st.sidebar.selectbox(\n         'Select Street',\n         streetAll)\n    \n    AdSel = doSelect(typee='Street',option2=option2,typeeOut='Address',toTEMP=(to))\n    \n    \n\naddress = st.sidebar.selectbox(\n    'Select Address',\n    AdSel)\n\nPri1, Pri2, typa=get_predTodayNotExact(m,address,(to),(xsAll),(yAll))\n\n#tell user what they selected\n'You selected: ', option2, 'and', address\n'Property type is ',typa\n\nstra = 'The predicted price is: '\nst.subheader(stra)\nst.header('£'+ str(Pri1[0])+'k')"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#overview",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#overview",
    "title": "Swansea House Prices- Part 2",
    "section": "Overview",
    "text": "Overview\nIn part 1 (https://thomashsimm.com/2021/08/04/Swansea-House-Price-Report.html) house price predictions were done using Census regions and information about the locations.\nWhereas, in this part the main focus is on using property sales data to obtain price predictions."
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#import-modules-and-prepare-the-data",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#import-modules-and-prepare-the-data",
    "title": "Swansea House Prices- Part 2",
    "section": "Import modules and prepare the data",
    "text": "Import modules and prepare the data\n\nSome imports\n\nimport os\nimport requests\nimport wget\nimport pandas as pd\n\nfrom fastbook import *\nfrom kaggle import api\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom dtreeviz.trees import *\nfrom IPython.display import Image, display_svg, SVG\n\npd.options.display.max_rows = 20\npd.options.display.max_columns = 8\n\nCreate a local path\n\npath = URLs.path('SwansProp')\nPath.BASE_PATH = path\npath\n\nPath('.')\n\n\n\nif not path.exists():\n    path.mkdir(parents=true)\n\n\n\nDownload the data\n\nGet the property sales from https://www.doogal.co.uk/PropertySalesCSV.ashx?area=\nAnd then the postcode details from https://www.doogal.co.uk/UKPostcodesCSV.ashx?Search=SA for\n\n\nlattitude and longitude\nCensus data and related data\n\nAvg income\nDeprivation index\netc\n\n\nUnique postcode starts SA1 SA2 SA3 SA4 SA5 SA6 SA7 SA8 SA9 SA10 SA11 SA12 SA13 SA80 SA99\n\ntry:\n    os.mkdir('data')\nexcept:\n    pass\n\npcodesSA=['SA1', 'SA2', 'SA3', 'SA4', 'SA5', 'SA6', 'SA7', 'SA8',\n          'SA9', 'SA10' ,'SA11', 'SA12', 'SA13', 'SA14','SA15','SA18']\n\n\n‘A’ Property Sales Data\nDownload the data\n\n\nurl='https://www.doogal.co.uk/PropertySalesCSV.ashx?area='\n\n\nfor pc in pcodesSA:\n    patha=path/'{}.csv'.format(pc)\n    wget.download(url+pc, str(patha))\n\n100% [............................................................................] 935424 / 935424\n\n\nCreate a dataframe from the downloaded csv files\n\nfor i,pc in enumerate(pcodesSA):\n    patha=path/'{}.csv'.format(pc)\n    dfTemp=pd.read_csv(str(patha))\n    \n    if i==0:\n        df=dfTemp\n        print(i)\n    else:\n        df=df.append(dfTemp)\n    print(df.shape[0])\n\ndf.reset_index(drop=True, inplace=True)\n\n0\n19432\n35015\n47639\n67896\n79210\n92148\n99680\n104480\n109669\n122570\n136404\n147937\n155697\n169021\n183674\n195094\n\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Date\n      Address\n      Postcode\n      Price\n      Type\n      Ownership\n      NewBuild\n    \n  \n  \n    \n      0\n      2021-10-22\n      60 Danygraig Road, Port Tennant\n      SA1 8LZ\n      192000\n      Terraced\n      Freehold\n      No\n    \n    \n      1\n      2021-10-01\n      2 Camona Drive, Maritime Quarter\n      SA1 1YJ\n      179950\n      Flat\n      Leasehold\n      No\n    \n    \n      2\n      2021-09-24\n      36 Balaclava Street, St Thomas\n      SA1 8BR\n      140000\n      Terraced\n      Freehold\n      No\n    \n    \n      3\n      2021-09-21\n      7 Abernethy Square, Maritime Quarter\n      SA1 1UH\n      133000\n      Flat\n      Leasehold\n      No\n    \n    \n      4\n      2021-09-17\n      6 Brynffordd, Townhill\n      SA1 6RA\n      176000\n      Semi-detached\n      Freehold\n      No\n    \n  \n\n\n\n\n\nimport copy\ndfOrig = copy.copy(df)\n\n\n\n‘B’ The PostCode data\nDwonload the data\n\nurl=\"https://www.doogal.co.uk/UKPostcodesCSV.ashx?Search=SA\"\npatha = path/'SA.csv'\nwget.download(url, str(patha))\n\nhttps://www.doogal.co.uk/PostcodeCsvFields.php\n\nLatitude\nLongitude\nIntroduced\nRural/urban\nAltitude\nIndex of Multiple Deprivation\nAverage income\n\n[‘Latitude’,‘Longitude’,‘Introduced’,‘Rural/urban’,‘’Altitude’,‘Index of Multiple Deprivation’,‘Average income’]\nCreate a dataFrame from the data\n\ndfCensus=pd.read_csv(str(patha),usecols=[\"Postcode\",\"Ward Code\",\"District Code\",'Latitude','Longitude','Introduced','Rural/urban','Altitude','Index of Multiple Deprivation','Average Income'])\ndfCensus\n\n\n\n\n\n  \n    \n      \n      Postcode\n      Latitude\n      Longitude\n      District Code\n      ...\n      Rural/urban\n      Altitude\n      Index of Multiple Deprivation\n      Average Income\n    \n  \n  \n    \n      0\n      SA1 1AA\n      51.647984\n      -3.923586\n      W06000011\n      ...\n      Urban city and town\n      16.0\n      355\n      29200.0\n    \n    \n      1\n      SA1 1AB\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      2\n      SA1 1AD\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      3\n      SA1 1AE\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      4\n      SA1 1AF\n      51.619766\n      -3.939424\n      W06000011\n      ...\n      Urban city and town\n      13.0\n      36\n      28600.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      29399\n      SA99 1ZU\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29400\n      SA99 1ZW\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29401\n      SA99 1ZX\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29402\n      SA99 1ZY\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29403\n      SA99 1ZZ\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n  \n\n29404 rows × 10 columns\n\n\n\n\n\n\nMerge the two data frames\n\ndf=pd.merge(df,dfCensus)\ndf.columns\n\nIndex(['Date', 'Address', 'Postcode', 'Price', 'Type', 'Ownership', 'NewBuild',\n       'Latitude', 'Longitude', 'District Code', 'Ward Code', 'Introduced',\n       'Rural/urban', 'Altitude', 'Index of Multiple Deprivation',\n       'Average Income'],\n      dtype='object')\n\n\n\ndf.dtypes\n\nDate                              object\nAddress                           object\nPostcode                          object\nPrice                              int64\nType                              object\nOwnership                         object\nNewBuild                          object\nLatitude                         float64\nLongitude                        float64\nDistrict Code                     object\nWard Code                         object\nIntroduced                        object\nRural/urban                       object\nAltitude                         float64\nIndex of Multiple Deprivation      int64\nAverage Income                   float64\ndtype: object\n\n\n\ndfOrig=dfOrig.iloc[df.index]"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#modify-data-ready-for-model",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#modify-data-ready-for-model",
    "title": "Swansea House Prices- Part 2",
    "section": "Modify data ready for model",
    "text": "Modify data ready for model\n\nAdd date details\nFrom date get Year, Month, Week etc\n\ndf = add_datepart(df, 'Date')\ndf.columns\n\nIndex(['Address', 'Postcode', 'Price', 'Type', 'Ownership', 'NewBuild',\n       'Latitude', 'Longitude', 'District Code', 'Ward Code', 'Introduced',\n       'Rural/urban', 'Altitude', 'Index of Multiple Deprivation',\n       'Average Income', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n       'Dayofyear', 'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n       'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Elapsed'],\n      dtype='object')\n\n\n\n\nSeperate details of address out\nWant to sepaerate details of address so that\nchx='Flat 30, Henllys, Wind Street, Swansea'\ngives modAdd(chx)=('Swansea', 900, 'Henllys')\nOr\nchx='15A Bethania Road, Upper Tumble'\ngives modAdd(chx)=('Upper Tumble', 15, 'Bethania Road')\n\ndef modAdd(address):\n    import re\n\n    split1 = address.split(',')\n    if len(split1)<2:\n        split1 = address.split(' ')\n        print('####',split1 ) \n    \n    FirstLine=split1[0]\n    Region = split1[-1]\n    \n    try:\n        Region=re.search(\"[A-Za-z][A-Za-z\\s]*\",Region)[0]\n    except:\n        Region=Region\n    \n    \n    try:\n        HouseNo=re.search(\"[0-9]*\",FirstLine)\n#         print(HouseNo)\n        HouseNo =int(HouseNo[0])\n        \n    except:\n        FirstLine=split1[1]\n        HouseNo=re.search(\"[\\s0-9]*\",FirstLine)\n        try:\n            HouseNo =int(HouseNo[0])\n        except:\n            HouseNo=900\n        \n    try:    \n        Street=re.search(\"\\s[A-Za-z][A-Za-z\\s]*\",FirstLine)\n        Street=Street[0]\n        Street=Street[1:]\n    except:\n        try:\n            Street=split1[1]\n            Street=re.search(\"\\s[A-Za-z][A-Za-z\\s]*\",Street)[0]\n            Street=Street[1:]\n        except:\n            Street='NA'\n#         print(FirstLine)\n        \n#     print('Region {}\\n Number {} \\n Street {} '.format(Region,HouseNo,Street))\n\n    return Region,HouseNo,Street\n    \ndef addAdddets_df(df):\n    Street,HouseNo,Region=[],[],[]\n    for ita,oo in enumerate(df.index):\n        \n        addTemp=df.iloc[ita].Address\n        RegionTemp,HouseNoTemp,StreetTemp=modAdd(addTemp)\n        Region.append(RegionTemp)\n        HouseNo.append(HouseNoTemp)\n        Street.append(StreetTemp)\n    df.insert(1,'Street',Street)\n    df.insert(1,'HouseNo',HouseNo)    \n    df.insert(1,'Region',Region)\n    return df\n\n\ntry:\n    df.drop(columns=['Street','HouseNo','Region'],inplace=True)\nexcept:\n    pass\ndf=addAdddets_df(df)\n\n\n\nCreate train and validation sets\nDo this randomly in this case 97:3 split\n\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=3\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/train_idx.shape[0]\n\nSpecify which column we are fitting to\n\ndep_var = 'Price'\n\n# for this fit to the log of it\ndf[dep_var] = np.log(df[dep_var])\n\nSplit into test and validation and convert to TabularPandas\n\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\nWhat are the columns?\n\n#hide\nimport os\nimport pickle\n\ncda = 'C:\\\\Users\\\\44781\\\\Documents\\\\GitHub\\\\SwanseaProperty'\ncda = cda + '\\\\pickles\\\\'\nwith open(cda+'RFrand_to.pkl', 'rb')as f: \n    to = pickle.load(f)\n    \nwith open(cda+'RFrand_xs_final.pkl', 'rb')as f: \n    xs = pickle.load(f)\n    \nwith open(cda+'RFrand_y.pkl', 'rb')as f: \n    y = pickle.load(f)\n\n\n[ii for ii in to.all_col_names]\n\n['Address',\n 'Region',\n 'Street',\n 'Postcode',\n 'Type',\n 'Ownership',\n 'NewBuild',\n 'District Code',\n 'Ward Code',\n 'Introduced',\n 'Rural/urban',\n 'Is_month_end',\n 'Is_month_start',\n 'Is_quarter_end',\n 'Is_quarter_start',\n 'Is_year_end',\n 'Is_year_start',\n 'HouseNo',\n 'Latitude',\n 'Longitude',\n 'Altitude',\n 'Index of Multiple Deprivation',\n 'Average Income',\n 'Year',\n 'Month',\n 'Week',\n 'Day',\n 'Dayofweek',\n 'Dayofyear',\n 'Elapsed',\n 'Price']\n\n\n\n\nSome functions to fit or get results of fit\n\ndef r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)\n\ndef r_abs(pred,y): return round( (np.abs( np.exp(pred)-np.exp(y) ).mean()), 0)\ndef m_abs(m, xs, y): return r_abs(m.predict(xs), y)/1000\n\ndef rf(xs, y, n_estimators=400, max_samples=100_000,\n       max_features=0.5, min_samples_leaf=5, **kwargs):\n    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#fit-the-model-and-optimise",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#fit-the-model-and-optimise",
    "title": "Swansea House Prices- Part 2",
    "section": "Fit the model and optimise",
    "text": "Fit the model and optimise\nBasic model with 4 nodes\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y);\n\n\nm_rmse(m, xs, y),m_rmse(m, valid_xs, valid_y)\n\n(0.511491, 0.503983)\n\n\nIncrease the number of leafs, reduces the errors\n\nm = DecisionTreeRegressor(min_samples_leaf=25)\nm.fit(to.train.xs, to.train.y)\nm_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)\n\n(0.338283, 0.370846)\n\n\nUsing the modified function above\n\nm = rf(xs, y)\nm_rmse(m, xs_imp, y), m_rmse(m, valid_xs_imp, valid_y)\n\n(0.287589, 0.335017)\n\n\n\nLook at which columns are important\n\ncluster_columns(xs)\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n\nfi = rf_feat_importance(m, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n\nplot_fi(fi[:30]);\n\n\n\nKeep ones with most importance\nReduces columns to use from 30 to 17\n\nto_keep = fi[fi.imp>0.01].cols\nlen(to_keep),len(fi.cols)\n\n(13, 30)\n\n\n\n# Get rid of the address one- is a number for each address\nto_keep=to_keep[to_keep!='Address']\n\n\nxs_imp = xs[to_keep]\nvalid_xs_imp = valid_xs[to_keep]\nm_imp = rf(xs_imp, y)\nm_rmse(m_imp, xs_imp, y), m_rmse(m_imp, valid_xs_imp, valid_y)\n\n(0.296979, 0.335829)\n\n\n\nfi2 = rf_feat_importance(m_imp, xs_imp)\n\ndef plot_fi(fi2):\n    return fi2.plot('cols', 'imp', 'barh', figsize=(10,6), legend=False)\n\nplot_fi(fi2[:30]);"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#save-the-results",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#save-the-results",
    "title": "Swansea House Prices- Part 2",
    "section": "Save the results",
    "text": "Save the results\nCombine the test and valid datasets\n\nxsAll=pd.concat([xs_imp,valid_xs_imp])\nyAll = pd.concat([y, valid_y])\n\n\nimport os\nimport pickle\n\ncda = os.getcwd()\ncda = cda + '\\\\pickles\\\\'\n\n# Saving the objects:\nwith open(cda+'RFrand_New4varB.pkl', 'wb') as f:\n    pickle.dump([m_imp, to, xsAll, yAll], f)\n\n\nnp.exp(0.335829)\n\n1.3990997582955578"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#get-the-predictions",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#get-the-predictions",
    "title": "Swansea House Prices- Part 2",
    "section": "Get the Predictions",
    "text": "Get the Predictions\nReload the data saved\n\nimport os\nimport pickle\n\nwith open(cda+'RFrand_New4varB.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n\n\nFirst need a way to convert sale date to today’s date\nFunction takes the dataFrame and changes ‘Date’ features to today’s date Taken from fastai functions\n\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n    import re\n    import pandas as pd\n    import numpy as np\n    \n    def ifnone(a, b):\n        \"`b` if `a` is None else `a`\"\n        return b if a is None else a\n    \n    def make_date(df, date_field):\n        \"Make sure `df[date_field]` is of the right date type.\"\n        \n        field_dtype = df[date_field].dtype\n        if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n            field_dtype = np.datetime64\n        if not np.issubdtype(field_dtype, np.datetime64):\n            df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n            \n    make_date(df, field_name)\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    # Pandas removed `dt.week` in v1.1.10\n    week = field.dt.isocalendar().week.astype(field.dt.day.dtype) if hasattr(field.dt, 'isocalendar') else field.dt.week\n    for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) if n != 'Week' else week\n    mask = ~field.isna()\n    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,np.nan)\n    if drop: df.drop(field_name, axis=1, inplace=True)\n    return df\n\nThe next function uses the above function to update the date details.\nThen looks up the address given so that predictions can be made. This is because address are not in xsAll2 dataFrame\n\nxsAll2.columns\n\nIndex(['Elapsed', 'Type', 'Year', 'Index of Multiple Deprivation', 'Latitude',\n       'Average Income', 'Longitude', 'Introduced', 'Postcode', 'Altitude',\n       'HouseNo', 'Street'],\n      dtype='object')\n\n\n\n# seperate columns into those related to date and those not\ncolsNoDate=[ 'Type',  'Index of Multiple Deprivation', 'Latitude',\n       'Average Income', 'Longitude', 'Introduced', 'Postcode', 'Altitude',\n       'HouseNo', 'Street']\ncolsDate=['Elapsed','Year']\n    \n\n\ndef get_predTodayNotExact(m,address,toTEMP,xs_final,y):\n    \"\"\"\n    Given model m, address, initial pd of houses to, and adjusted pd xs_final\n    output is house price prediction\n    \"\"\"\n    import copy\n\n    colsAll=xs_final.columns\n\n    #columns with dates need to remove\n    colsDate=['Elapsed','Year']\n    xsNoDate=copy.copy(xs_final.drop(columns=colsDate))\n    \n    # add date part to dataframe\n    xsNoDate['Date'] = pd.to_datetime(\"today\")\n    xsNoDate = add_datepart(xsNoDate, 'Date')\n    xs_finalTEMP=xsNoDate.loc[:,colsAll]\n\n    # each address has a unique number\n    aa=toTEMP.classes['Address']\n    # findwhich number is address give (take 1st if more than 1)\n    try:\n        ii=[ii for ii,aa1 in enumerate(aa) if aa1== address][0]\n        # 1 address can have multiple sales so we need index in dataframes\n        ii=toTEMP[toTEMP['Address']==ii].index[0]\n\n        preda = np.round( np.exp( m.predict(xs_finalTEMP.loc[ii:ii]) )/1000 ,1)\n        prev = np.round( np.exp(y.loc[ii])/1000 ,1)\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xs_finalTEMP.loc[ii:ii,'Type']][0]\n    \n    except:\n        aa=toTEMP.classes['Address']\n        aaStreet=toTEMP.classes['Street']\n        ii=[ii for ii,aa1 in enumerate(aaStreet) if aa1== Street][0]\n        xsTemp=copy.copy( xs_finalTEMP[xs_finalTEMP['Street']==ii] )\n        xsTemp.reset_index(inplace=True,drop=True)\n        # find nearest house by houseno\n        No=np.array(xsTemp['HouseNo'])\n\n        yo=(np.abs(No-HouseNo))\n        yo1=np.min(yo)\n        # get index of the nearest house\n        yo=No[yo==yo1][0]  \n\n        ii=[ii for ii,aa1 in enumerate(xsTemp.HouseNo) if aa1== yo][0]\n        xsTemp.loc[ii:ii,'HouseNo']=HouseNo\n        \n        # If want to change house type\n        \n#         xsTemp.loc[ii:ii,'Type']=2\n#         print(xsTemp.loc[ii:ii,'Type'])\n#         print(xsTemp.loc[ii:ii])\n        \n        preda = np.round( np.exp( m.predict(xsTemp.loc[ii:ii]) )/1000 ,1)[0]\n        prev=0\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xsTemp.loc[ii:ii,'Type']][0]\n        \n        \n    return preda, prev, typa\n\n\naddress='20 Malvern Terrace, Brynmill'\nget_predTodayNotExact(m2,address,to2,xsAll2,yAll2)\n\n(array([180.1]), 54.5, 'Terraced')"
  },
  {
    "objectID": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#summary",
    "href": "posts/PROJECTS/Other_projects/SwanseaHousePrices_Part2.html#summary",
    "title": "Swansea House Prices- Part 2",
    "section": "Summary",
    "text": "Summary\n\ndef r_abs(pred,y): return round( (np.abs( np.exp(pred)-np.exp(y) ).mean()), 0)\ndef m_abs(m, xs, y): return r_abs(m.predict(xs), y)/1000\n\nm_abs(m2, xsAll2, yAll2)#, m_abs(m, valid_xs_final, valid_y)\n\n23.159\n\n\nThe average error in price predictions is £23,000\nWhich is comparable to values seen with regions and fairly good given the details of the houses used in the model are limited\nThis model is put into an app here https://thomashsimm.com/streamlit/randomforrests/houseprices/python/2022/02/23/SwanseaHousePriceApp.html\n{{< video https://youtu.be/IGykZUeZqRA}}"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePriceApp.html#overview",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePriceApp.html#overview",
    "title": "Creating a property prediction App",
    "section": "Overview",
    "text": "Overview\nThis is an app for predicting house prices in Swansea using Streamlit https://streamlit.io/\nThe app uses the following for predictions:\n\nHouse price sales (price and date)\nName of street and number\nLocation of property (Lattitude and Longitude)\nData on Census regions\n\nMore details of the prediction side of the app, using Random Forrests and neural networks, is dealt with here https://thomashsimm.com/jupyter/python/randomforests/tabulardata/sklearn/2022/02/17/SwanseaHousePrices_Part2.html.\nA video of the app is shown below or can be accessed via https://share.streamlit.io/dmaterialia/propertystreamlit/main/PropertyApp.py\nThe intention of the app is to provide a simple user interface to allow price predictions"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePriceApp.html#the-python-script-for-the-app",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePriceApp.html#the-python-script-for-the-app",
    "title": "Creating a property prediction App",
    "section": "The Python Script for the App",
    "text": "The Python Script for the App\n\nLoading the data\nThe following function is used to load the data.\nThe data consists of 4 parts: 1. m = the model (this is by far the biggest part in terms of data size) 1. to = a data frame object of the house data 1. xsAll = this is a form of ‘to’ used by the model (the input values of the model) 1. yAll = a form of ‘to’ the values the model is trying to predict (house price values)\nThe data is saved as a pickle file in a Jupyter Notebook, then uploaded to googledrive as filesize has to be less than 100 Mb on GitHub.\ngdown.download(url, output) downloads the data from GoogleDrive\n@st.cache(allow_output_mutation=True) This line at the top of the python file means the data is cached and don’t need to keep loading it\n\n@st.cache(allow_output_mutation=True)\ndef load_data():\n    \"\"\"\n    Loads the data\n    \"\"\"\n    import gdown\n    url = 'https://drive.google.com/uc?id=1OD2l7ynVzLlqY92gYiCx5xq32-D1wJMe'\n    output = 'one1.pkl'\n    gdown.download(url, output)\n\n    cda = os.getcwd()\n    with open('one1.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n    return m2, to2, xsAll2, yAll2\ndata_load_state = st.text('Loading data...')\nm1, to1, xsAll1, yAll1=load_data()\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\n\n\nUpdating data so prediction is for today\nThe following function changes the date of sale details for each property so that they are today’s date\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n\n\nGetting the predictions\nThe following function takes the address selected and outputs the predicted property price\nget_predTodayNotExact(m,address,toTEMP,xs_final,y)\n\n\nHelp with reducing code for selecting data\nThe following function is used to allow to select different details from the dataframes. Really just a function to get around the slightly unusual way data is selected in ‘to’ and dataFrames\ndef doSelect(typee,option2,typeeOut,toTEMP):\n\n\nThe user interface parts of the app\noptionSELECT = st.sidebar.selectbox(     'Select how to search',      choice)\nThis is a select box loacted in the LHS sidebar. The options for the user are as follows and choice dictates what boxes they see:\nchoice=['Post Code','Region', 'Street']\nFor example if ‘Post code’ is selected the folowing selectbox is shown with all post code options for first part of the postcode:\noption2 = st.sidebar.selectbox(         'Select Postcode',         indexPCSA)\nWhatever option selected the individual address must be selected:\naddress = st.sidebar.selectbox(     'Select Address',     AdSel)\n\n\nPredictions and Output\nOnce the address is selected, teh predictions are found by calling the prediction function:\nPri1, Pri2, typa=get_predTodayNotExact(m,address,(to),(xsAll),(yAll))\nAnd then displayed in the main screen with the following code:\n'You selected: ', option2, 'and', address\n'Property type is ',typa\nstra = 'The predicted price is: ' st.subheader(stra) st.header('£'+ str(Pri1[0])+'k')"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePriceApp.html#creating-the-app",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePriceApp.html#creating-the-app",
    "title": "Creating a property prediction App",
    "section": "Creating the App",
    "text": "Creating the App\nThe Python .py file along with a requirements file are uploaded to a GitHub repository. The one for this is at https://github.com/dMaterialia/PropertyStreamlit\nThe requirements file includes all the modules not included in python that need to be loaded. For this function the file is as follows:\nnumpy\npandas\nmatplotlib\ngdown\nscikit-learn\nfastai\nThen simply log into Streamlit select the repository and the python file and hit go to get the app working\n\nFull Python function\n\nimport streamlit as st\n# To make things easier later, we're also importing numpy and pandas for\n# working with sample data.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport pickle\nimport copy\nfrom sklearn.ensemble import RandomForestRegressor\n\nst.title('Swansea Property Price Predictor')\n\n@st.cache(allow_output_mutation=True)\ndef load_data():\n    \"\"\"\n    Loads the data\n    \"\"\"\n    import gdown\n    url = 'https://drive.google.com/uc?id=1OD2l7ynVzLlqY92gYiCx5xq32-D1wJMe'\n    output = 'one1.pkl'\n    gdown.download(url, output)\n\n    cda = os.getcwd()\n    with open('one1.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n    return m2, to2, xsAll2, yAll2\ndata_load_state = st.text('Loading data...')\nm1, to1, xsAll1, yAll1=load_data()\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n    import re\n    import pandas as pd\n    import numpy as np\n    \n    def ifnone(a, b):\n        \"`b` if `a` is None else `a`\"\n        return b if a is None else a\n    \n    def make_date(df, date_field):\n        \"Make sure `df[date_field]` is of the right date type.\"\n        \n        field_dtype = df[date_field].dtype\n        if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n            field_dtype = np.datetime64\n        if not np.issubdtype(field_dtype, np.datetime64):\n            df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n    \n    \n    make_date(df, field_name)\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    # Pandas removed `dt.week` in v1.1.10\n    week = field.dt.isocalendar().week.astype(field.dt.day.dtype) if hasattr(field.dt, 'isocalendar') else field.dt.week\n    for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) if n != 'Week' else week\n    mask = ~field.isna()\n    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,np.nan)\n    if drop: df.drop(field_name, axis=1, inplace=True)\n    return df\n\ndef get_predTodayNotExact(m,address,toTEMP,xs_final,y):\n    \"\"\"\n    Given model m, address, initial pd of houses to, and adjusted pd xs_final\n    output is house price prediction\n    \"\"\"\n    import copy\n    # convert to current date\n    colsAll=xs_final.columns\n    colsNoDate=['Type', 'Index of Multiple Deprivation', 'Latitude',\n                'Average Income', 'Longitude', 'Postcode', 'Introduced', 'Address',\n           'Altitude']\n    xsNoDate=copy.copy(xs_final.drop(columns=['Elapsed','Year']))\n    \n    xsNoDate['Date'] = pd.to_datetime(\"today\")\n    xsNoDate = add_datepart(xsNoDate, 'Date')\n    xs_finalTEMP=xsNoDate.loc[:,colsAll]\n\n    # each address has a unique number\n    aa=toTEMP.classes['Address']\n    # findwhich number is address give (take 1st if more than 1)\n    try:\n        ii=[ii for ii,aa1 in enumerate(aa) if aa1== address][0]\n        # 1 address can have multiple sales so we need index in dataframes\n        ii=toTEMP[toTEMP['Address']==ii].index[0]\n\n        preda = np.round( np.exp( m.predict(xs_finalTEMP.loc[ii:ii]) )/1000 ,1)\n        prev = np.round( np.exp(y.loc[ii])/1000 ,1)\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xs_finalTEMP.loc[ii:ii,'Type']][0]\n    \n    except:\n        aa=toTEMP.classes['Address']\n        aaStreet=toTEMP.classes['Street']\n        ii=[ii for ii,aa1 in enumerate(aaStreet) if aa1== Street][0]\n        xsTemp=copy.copy( xs_finalTEMP[xs_finalTEMP['Street']==ii] )\n        xsTemp.reset_index(inplace=True,drop=True)\n        # find nearest house by houseno\n        No=np.array(xsTemp['HouseNo'])\n\n        yo=(np.abs(No-HouseNo))\n        yo1=np.min(yo)\n        # get index of the nearest house\n        yo=No[yo==yo1][0]  \n\n        ii=[ii for ii,aa1 in enumerate(xsTemp.HouseNo) if aa1== yo][0]\n        xsTemp.loc[ii:ii,'HouseNo']=HouseNo\n        # If want to change house type\n        \n#         xsTemp.loc[ii:ii,'Type']=2\n#         print(xsTemp.loc[ii:ii,'Type'])\n#         print(xsTemp.loc[ii:ii])\n        \n        preda = np.round( np.exp( m.predict(xsTemp.loc[ii:ii]) )/1000 ,1)[0]\n        prev=0\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xsTemp.loc[ii:ii,'Type']][0]\n        \n        \n    return preda, prev, typa\n\n\ndef doSelect(typee,option2,typeeOut,toTEMP):\n        streetAll=toTEMP.classes[typee]\n        AdAll=toTEMP.classes[typeeOut]\n        # this finds index of postcode for example SA1 0EA = 62\n        indexPC1=[ita for ita,ij in enumerate(streetAll) if ij==option2][0]\n\n        # finds all indexes of addresses with given post code index \n        indexAdds=[ita for ita, ij in enumerate(toTEMP[typee]) if ij==indexPC1]\n\n        # Find address index numbers for those given above\n        indexAddSel=toTEMP.iloc[indexAdds][typeeOut]\n\n        # Convert these to actual addresses\n        AdSel=AdAll[indexAddSel]\n        \n        # unique values\n        AdSel=np.unique(AdSel)\n        return AdSel\n    \n\npcodesSA=['SA1', 'SA2', 'SA3', 'SA4', 'SA5', 'SA6', 'SA7', 'SA8',          \n          'SA9', 'SA10' ,'SA11', 'SA12', 'SA13', 'SA14','SA15','SA18']\n\nchoice=['Post Code','Region', 'Street']\n\nto=copy.copy(to1)\nm=copy.copy(m1)\nxsAll=copy.copy(xsAll1)\nyAll=copy.copy(yAll1)\n# These are the list of all addresses etc by actual name\nAdAll=(to.classes['Address'])\npcAll=(to.classes['Postcode'])\nregionAll=(to.classes['Region'])\nstreetAll=(to.classes['Street'])\n\n# An optionbox- Select How search\noptionSELECT = st.sidebar.selectbox(\n    'Select how to search',\n     choice)\n\nif optionSELECT=='Post Code':\n    # An optionbox- Select Postcode Start e.g. SA1\n    option = st.sidebar.selectbox(\n        'Select Area',\n         pcodesSA)\n\n\n    # Select Postcode All\n\n    # This finds a set of postcodes given by optionbox\n    indexPCSA=[ij for ij in pcAll if ij.split(' ')[0]==option]\n\n    # optionbox to select particular postcode \n    # Outcome e.g. SA1 0EA\n    option2 = st.sidebar.selectbox(\n        'Select Postcode',\n        indexPCSA)\n\n    AdSel = doSelect(typee='Postcode',option2=option2,typeeOut='Address',toTEMP=(to))\n    \n\nelif optionSELECT=='Region':\n\n    \n    option2 = st.sidebar.selectbox(\n         'Select Region',\n         regionAll)\n    \n    StreetSel = doSelect(typee='Region',option2=option2,typeeOut='Street',toTEMP=(to))\n       \n        \n    option3 = st.sidebar.selectbox(\n         'Select Street',\n         StreetSel)\n    \n    AdSel = doSelect(typee='Street',option2=option3,typeeOut='Address',toTEMP=(to))\n        \n    \n\nelif optionSELECT=='Street':\n\n    \n    option2 = st.sidebar.selectbox(\n         'Select Street',\n         streetAll)\n    \n    AdSel = doSelect(typee='Street',option2=option2,typeeOut='Address',toTEMP=(to))\n    \n    \n\naddress = st.sidebar.selectbox(\n    'Select Address',\n    AdSel)\n\nPri1, Pri2, typa=get_predTodayNotExact(m,address,(to),(xsAll),(yAll))\n\n#tell user what they selected\n'You selected: ', option2, 'and', address\n'Property type is ',typa\n\nstra = 'The predicted price is: '\nst.subheader(stra)\nst.header('£'+ str(Pri1[0])+'k')"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#overview",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#overview",
    "title": "Swansea House Prices- Part 2",
    "section": "Overview",
    "text": "Overview\nIn part 1 (https://thomashsimm.com/2021/08/04/Swansea-House-Price-Report.html) house price predictions were done using Census regions and information about the locations.\nWhereas, in this part the main focus is on using property sales data to obtain price predictions."
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#import-modules-and-prepare-the-data",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#import-modules-and-prepare-the-data",
    "title": "Swansea House Prices- Part 2",
    "section": "Import modules and prepare the data",
    "text": "Import modules and prepare the data\n\nSome imports\n\nimport os\nimport requests\nimport wget\nimport pandas as pd\n\nfrom fastbook import *\nfrom kaggle import api\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom dtreeviz.trees import *\nfrom IPython.display import Image, display_svg, SVG\n\npd.options.display.max_rows = 20\npd.options.display.max_columns = 8\n\nCreate a local path\n\npath = URLs.path('SwansProp')\nPath.BASE_PATH = path\npath\n\nPath('.')\n\n\n\nif not path.exists():\n    path.mkdir(parents=true)\n\n\n\nDownload the data\n\nGet the property sales from https://www.doogal.co.uk/PropertySalesCSV.ashx?area=\nAnd then the postcode details from https://www.doogal.co.uk/UKPostcodesCSV.ashx?Search=SA for\n\n\nlattitude and longitude\nCensus data and related data\n\nAvg income\nDeprivation index\netc\n\n\nUnique postcode starts SA1 SA2 SA3 SA4 SA5 SA6 SA7 SA8 SA9 SA10 SA11 SA12 SA13 SA80 SA99\n\ntry:\n    os.mkdir('data')\nexcept:\n    pass\n\npcodesSA=['SA1', 'SA2', 'SA3', 'SA4', 'SA5', 'SA6', 'SA7', 'SA8',\n          'SA9', 'SA10' ,'SA11', 'SA12', 'SA13', 'SA14','SA15','SA18']\n\n\n‘A’ Property Sales Data\nDownload the data\n\n\nurl='https://www.doogal.co.uk/PropertySalesCSV.ashx?area='\n\n\nfor pc in pcodesSA:\n    patha=path/'{}.csv'.format(pc)\n    wget.download(url+pc, str(patha))\n\n100% [............................................................................] 935424 / 935424\n\n\nCreate a dataframe from the downloaded csv files\n\nfor i,pc in enumerate(pcodesSA):\n    patha=path/'{}.csv'.format(pc)\n    dfTemp=pd.read_csv(str(patha))\n    \n    if i==0:\n        df=dfTemp\n        print(i)\n    else:\n        df=df.append(dfTemp)\n    print(df.shape[0])\n\ndf.reset_index(drop=True, inplace=True)\n\n0\n19432\n35015\n47639\n67896\n79210\n92148\n99680\n104480\n109669\n122570\n136404\n147937\n155697\n169021\n183674\n195094\n\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Date\n      Address\n      Postcode\n      Price\n      Type\n      Ownership\n      NewBuild\n    \n  \n  \n    \n      0\n      2021-10-22\n      60 Danygraig Road, Port Tennant\n      SA1 8LZ\n      192000\n      Terraced\n      Freehold\n      No\n    \n    \n      1\n      2021-10-01\n      2 Camona Drive, Maritime Quarter\n      SA1 1YJ\n      179950\n      Flat\n      Leasehold\n      No\n    \n    \n      2\n      2021-09-24\n      36 Balaclava Street, St Thomas\n      SA1 8BR\n      140000\n      Terraced\n      Freehold\n      No\n    \n    \n      3\n      2021-09-21\n      7 Abernethy Square, Maritime Quarter\n      SA1 1UH\n      133000\n      Flat\n      Leasehold\n      No\n    \n    \n      4\n      2021-09-17\n      6 Brynffordd, Townhill\n      SA1 6RA\n      176000\n      Semi-detached\n      Freehold\n      No\n    \n  \n\n\n\n\n\nimport copy\ndfOrig = copy.copy(df)\n\n\n\n‘B’ The PostCode data\nDwonload the data\n\nurl=\"https://www.doogal.co.uk/UKPostcodesCSV.ashx?Search=SA\"\npatha = path/'SA.csv'\nwget.download(url, str(patha))\n\nhttps://www.doogal.co.uk/PostcodeCsvFields.php\n\nLatitude\nLongitude\nIntroduced\nRural/urban\nAltitude\nIndex of Multiple Deprivation\nAverage income\n\n[‘Latitude’,‘Longitude’,‘Introduced’,‘Rural/urban’,‘’Altitude’,‘Index of Multiple Deprivation’,‘Average income’]\nCreate a dataFrame from the data\n\ndfCensus=pd.read_csv(str(patha),usecols=[\"Postcode\",\"Ward Code\",\"District Code\",'Latitude','Longitude','Introduced','Rural/urban','Altitude','Index of Multiple Deprivation','Average Income'])\ndfCensus\n\n\n\n\n\n  \n    \n      \n      Postcode\n      Latitude\n      Longitude\n      District Code\n      ...\n      Rural/urban\n      Altitude\n      Index of Multiple Deprivation\n      Average Income\n    \n  \n  \n    \n      0\n      SA1 1AA\n      51.647984\n      -3.923586\n      W06000011\n      ...\n      Urban city and town\n      16.0\n      355\n      29200.0\n    \n    \n      1\n      SA1 1AB\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      2\n      SA1 1AD\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      3\n      SA1 1AE\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      4\n      SA1 1AF\n      51.619766\n      -3.939424\n      W06000011\n      ...\n      Urban city and town\n      13.0\n      36\n      28600.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      29399\n      SA99 1ZU\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29400\n      SA99 1ZW\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29401\n      SA99 1ZX\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29402\n      SA99 1ZY\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29403\n      SA99 1ZZ\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n  \n\n29404 rows × 10 columns\n\n\n\n\n\n\nMerge the two data frames\n\ndf=pd.merge(df,dfCensus)\ndf.columns\n\nIndex(['Date', 'Address', 'Postcode', 'Price', 'Type', 'Ownership', 'NewBuild',\n       'Latitude', 'Longitude', 'District Code', 'Ward Code', 'Introduced',\n       'Rural/urban', 'Altitude', 'Index of Multiple Deprivation',\n       'Average Income'],\n      dtype='object')\n\n\n\ndf.dtypes\n\nDate                              object\nAddress                           object\nPostcode                          object\nPrice                              int64\nType                              object\nOwnership                         object\nNewBuild                          object\nLatitude                         float64\nLongitude                        float64\nDistrict Code                     object\nWard Code                         object\nIntroduced                        object\nRural/urban                       object\nAltitude                         float64\nIndex of Multiple Deprivation      int64\nAverage Income                   float64\ndtype: object\n\n\n\ndfOrig=dfOrig.iloc[df.index]"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#modify-data-ready-for-model",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#modify-data-ready-for-model",
    "title": "Swansea House Prices- Part 2",
    "section": "Modify data ready for model",
    "text": "Modify data ready for model\n\nAdd date details\nFrom date get Year, Month, Week etc\n\ndf = add_datepart(df, 'Date')\ndf.columns\n\nIndex(['Address', 'Postcode', 'Price', 'Type', 'Ownership', 'NewBuild',\n       'Latitude', 'Longitude', 'District Code', 'Ward Code', 'Introduced',\n       'Rural/urban', 'Altitude', 'Index of Multiple Deprivation',\n       'Average Income', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n       'Dayofyear', 'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n       'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Elapsed'],\n      dtype='object')\n\n\n\n\nSeperate details of address out\nWant to sepaerate details of address so that\nchx='Flat 30, Henllys, Wind Street, Swansea'\ngives modAdd(chx)=('Swansea', 900, 'Henllys')\nOr\nchx='15A Bethania Road, Upper Tumble'\ngives modAdd(chx)=('Upper Tumble', 15, 'Bethania Road')\n\ndef modAdd(address):\n    import re\n\n    split1 = address.split(',')\n    if len(split1)<2:\n        split1 = address.split(' ')\n        print('####',split1 ) \n    \n    FirstLine=split1[0]\n    Region = split1[-1]\n    \n    try:\n        Region=re.search(\"[A-Za-z][A-Za-z\\s]*\",Region)[0]\n    except:\n        Region=Region\n    \n    \n    try:\n        HouseNo=re.search(\"[0-9]*\",FirstLine)\n#         print(HouseNo)\n        HouseNo =int(HouseNo[0])\n        \n    except:\n        FirstLine=split1[1]\n        HouseNo=re.search(\"[\\s0-9]*\",FirstLine)\n        try:\n            HouseNo =int(HouseNo[0])\n        except:\n            HouseNo=900\n        \n    try:    \n        Street=re.search(\"\\s[A-Za-z][A-Za-z\\s]*\",FirstLine)\n        Street=Street[0]\n        Street=Street[1:]\n    except:\n        try:\n            Street=split1[1]\n            Street=re.search(\"\\s[A-Za-z][A-Za-z\\s]*\",Street)[0]\n            Street=Street[1:]\n        except:\n            Street='NA'\n#         print(FirstLine)\n        \n#     print('Region {}\\n Number {} \\n Street {} '.format(Region,HouseNo,Street))\n\n    return Region,HouseNo,Street\n    \ndef addAdddets_df(df):\n    Street,HouseNo,Region=[],[],[]\n    for ita,oo in enumerate(df.index):\n        \n        addTemp=df.iloc[ita].Address\n        RegionTemp,HouseNoTemp,StreetTemp=modAdd(addTemp)\n        Region.append(RegionTemp)\n        HouseNo.append(HouseNoTemp)\n        Street.append(StreetTemp)\n    df.insert(1,'Street',Street)\n    df.insert(1,'HouseNo',HouseNo)    \n    df.insert(1,'Region',Region)\n    return df\n\n\ntry:\n    df.drop(columns=['Street','HouseNo','Region'],inplace=True)\nexcept:\n    pass\ndf=addAdddets_df(df)\n\n\n\nCreate train and validation sets\nDo this randomly in this case 97:3 split\n\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=3\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/train_idx.shape[0]\n\nSpecify which column we are fitting to\n\ndep_var = 'Price'\n\n# for this fit to the log of it\ndf[dep_var] = np.log(df[dep_var])\n\nSplit into test and validation and convert to TabularPandas\n\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\nWhat are the columns?\n\n#hide\nimport os\nimport pickle\n\ncda = 'C:\\\\Users\\\\44781\\\\Documents\\\\GitHub\\\\SwanseaProperty'\ncda = cda + '\\\\pickles\\\\'\nwith open(cda+'RFrand_to.pkl', 'rb')as f: \n    to = pickle.load(f)\n    \nwith open(cda+'RFrand_xs_final.pkl', 'rb')as f: \n    xs = pickle.load(f)\n    \nwith open(cda+'RFrand_y.pkl', 'rb')as f: \n    y = pickle.load(f)\n\n\n[ii for ii in to.all_col_names]\n\n['Address',\n 'Region',\n 'Street',\n 'Postcode',\n 'Type',\n 'Ownership',\n 'NewBuild',\n 'District Code',\n 'Ward Code',\n 'Introduced',\n 'Rural/urban',\n 'Is_month_end',\n 'Is_month_start',\n 'Is_quarter_end',\n 'Is_quarter_start',\n 'Is_year_end',\n 'Is_year_start',\n 'HouseNo',\n 'Latitude',\n 'Longitude',\n 'Altitude',\n 'Index of Multiple Deprivation',\n 'Average Income',\n 'Year',\n 'Month',\n 'Week',\n 'Day',\n 'Dayofweek',\n 'Dayofyear',\n 'Elapsed',\n 'Price']\n\n\n\n\nSome functions to fit or get results of fit\n\ndef r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)\n\ndef r_abs(pred,y): return round( (np.abs( np.exp(pred)-np.exp(y) ).mean()), 0)\ndef m_abs(m, xs, y): return r_abs(m.predict(xs), y)/1000\n\ndef rf(xs, y, n_estimators=400, max_samples=100_000,\n       max_features=0.5, min_samples_leaf=5, **kwargs):\n    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#fit-the-model-and-optimise",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#fit-the-model-and-optimise",
    "title": "Swansea House Prices- Part 2",
    "section": "Fit the model and optimise",
    "text": "Fit the model and optimise\nBasic model with 4 nodes\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y);\n\n\nm_rmse(m, xs, y),m_rmse(m, valid_xs, valid_y)\n\n(0.511491, 0.503983)\n\n\nIncrease the number of leafs, reduces the errors\n\nm = DecisionTreeRegressor(min_samples_leaf=25)\nm.fit(to.train.xs, to.train.y)\nm_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)\n\n(0.338283, 0.370846)\n\n\nUsing the modified function above\n\nm = rf(xs, y)\nm_rmse(m, xs_imp, y), m_rmse(m, valid_xs_imp, valid_y)\n\n(0.287589, 0.335017)\n\n\n\nLook at which columns are important\n\ncluster_columns(xs)\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n\nfi = rf_feat_importance(m, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n\nplot_fi(fi[:30]);\n\n\n\nKeep ones with most importance\nReduces columns to use from 30 to 17\n\nto_keep = fi[fi.imp>0.01].cols\nlen(to_keep),len(fi.cols)\n\n(13, 30)\n\n\n\n# Get rid of the address one- is a number for each address\nto_keep=to_keep[to_keep!='Address']\n\n\nxs_imp = xs[to_keep]\nvalid_xs_imp = valid_xs[to_keep]\nm_imp = rf(xs_imp, y)\nm_rmse(m_imp, xs_imp, y), m_rmse(m_imp, valid_xs_imp, valid_y)\n\n(0.296979, 0.335829)\n\n\n\nfi2 = rf_feat_importance(m_imp, xs_imp)\n\ndef plot_fi(fi2):\n    return fi2.plot('cols', 'imp', 'barh', figsize=(10,6), legend=False)\n\nplot_fi(fi2[:30]);"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#save-the-results",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#save-the-results",
    "title": "Swansea House Prices- Part 2",
    "section": "Save the results",
    "text": "Save the results\nCombine the test and valid datasets\n\nxsAll=pd.concat([xs_imp,valid_xs_imp])\nyAll = pd.concat([y, valid_y])\n\n\nimport os\nimport pickle\n\ncda = os.getcwd()\ncda = cda + '\\\\pickles\\\\'\n\n# Saving the objects:\nwith open(cda+'RFrand_New4varB.pkl', 'wb') as f:\n    pickle.dump([m_imp, to, xsAll, yAll], f)\n\n\nnp.exp(0.335829)\n\n1.3990997582955578"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#get-the-predictions",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#get-the-predictions",
    "title": "Swansea House Prices- Part 2",
    "section": "Get the Predictions",
    "text": "Get the Predictions\nReload the data saved\n\nimport os\nimport pickle\n\nwith open(cda+'RFrand_New4varB.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n\n\nFirst need a way to convert sale date to today’s date\nFunction takes the dataFrame and changes ‘Date’ features to today’s date Taken from fastai functions\n\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n    import re\n    import pandas as pd\n    import numpy as np\n    \n    def ifnone(a, b):\n        \"`b` if `a` is None else `a`\"\n        return b if a is None else a\n    \n    def make_date(df, date_field):\n        \"Make sure `df[date_field]` is of the right date type.\"\n        \n        field_dtype = df[date_field].dtype\n        if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n            field_dtype = np.datetime64\n        if not np.issubdtype(field_dtype, np.datetime64):\n            df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n            \n    make_date(df, field_name)\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    # Pandas removed `dt.week` in v1.1.10\n    week = field.dt.isocalendar().week.astype(field.dt.day.dtype) if hasattr(field.dt, 'isocalendar') else field.dt.week\n    for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) if n != 'Week' else week\n    mask = ~field.isna()\n    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,np.nan)\n    if drop: df.drop(field_name, axis=1, inplace=True)\n    return df\n\nThe next function uses the above function to update the date details.\nThen looks up the address given so that predictions can be made. This is because address are not in xsAll2 dataFrame\n\nxsAll2.columns\n\nIndex(['Elapsed', 'Type', 'Year', 'Index of Multiple Deprivation', 'Latitude',\n       'Average Income', 'Longitude', 'Introduced', 'Postcode', 'Altitude',\n       'HouseNo', 'Street'],\n      dtype='object')\n\n\n\n# seperate columns into those related to date and those not\ncolsNoDate=[ 'Type',  'Index of Multiple Deprivation', 'Latitude',\n       'Average Income', 'Longitude', 'Introduced', 'Postcode', 'Altitude',\n       'HouseNo', 'Street']\ncolsDate=['Elapsed','Year']\n    \n\n\ndef get_predTodayNotExact(m,address,toTEMP,xs_final,y):\n    \"\"\"\n    Given model m, address, initial pd of houses to, and adjusted pd xs_final\n    output is house price prediction\n    \"\"\"\n    import copy\n\n    colsAll=xs_final.columns\n\n    #columns with dates need to remove\n    colsDate=['Elapsed','Year']\n    xsNoDate=copy.copy(xs_final.drop(columns=colsDate))\n    \n    # add date part to dataframe\n    xsNoDate['Date'] = pd.to_datetime(\"today\")\n    xsNoDate = add_datepart(xsNoDate, 'Date')\n    xs_finalTEMP=xsNoDate.loc[:,colsAll]\n\n    # each address has a unique number\n    aa=toTEMP.classes['Address']\n    # findwhich number is address give (take 1st if more than 1)\n    try:\n        ii=[ii for ii,aa1 in enumerate(aa) if aa1== address][0]\n        # 1 address can have multiple sales so we need index in dataframes\n        ii=toTEMP[toTEMP['Address']==ii].index[0]\n\n        preda = np.round( np.exp( m.predict(xs_finalTEMP.loc[ii:ii]) )/1000 ,1)\n        prev = np.round( np.exp(y.loc[ii])/1000 ,1)\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xs_finalTEMP.loc[ii:ii,'Type']][0]\n    \n    except:\n        aa=toTEMP.classes['Address']\n        aaStreet=toTEMP.classes['Street']\n        ii=[ii for ii,aa1 in enumerate(aaStreet) if aa1== Street][0]\n        xsTemp=copy.copy( xs_finalTEMP[xs_finalTEMP['Street']==ii] )\n        xsTemp.reset_index(inplace=True,drop=True)\n        # find nearest house by houseno\n        No=np.array(xsTemp['HouseNo'])\n\n        yo=(np.abs(No-HouseNo))\n        yo1=np.min(yo)\n        # get index of the nearest house\n        yo=No[yo==yo1][0]  \n\n        ii=[ii for ii,aa1 in enumerate(xsTemp.HouseNo) if aa1== yo][0]\n        xsTemp.loc[ii:ii,'HouseNo']=HouseNo\n        \n        # If want to change house type\n        \n#         xsTemp.loc[ii:ii,'Type']=2\n#         print(xsTemp.loc[ii:ii,'Type'])\n#         print(xsTemp.loc[ii:ii])\n        \n        preda = np.round( np.exp( m.predict(xsTemp.loc[ii:ii]) )/1000 ,1)[0]\n        prev=0\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xsTemp.loc[ii:ii,'Type']][0]\n        \n        \n    return preda, prev, typa\n\n\naddress='20 Malvern Terrace, Brynmill'\nget_predTodayNotExact(m2,address,to2,xsAll2,yAll2)\n\n(array([180.1]), 54.5, 'Terraced')"
  },
  {
    "objectID": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#summary",
    "href": "posts/PROJECTS/Swansea_property/SwanseaHousePrices_Part2.html#summary",
    "title": "Swansea House Prices- Part 2",
    "section": "Summary",
    "text": "Summary\n\ndef r_abs(pred,y): return round( (np.abs( np.exp(pred)-np.exp(y) ).mean()), 0)\ndef m_abs(m, xs, y): return r_abs(m.predict(xs), y)/1000\n\nm_abs(m2, xsAll2, yAll2)#, m_abs(m, valid_xs_final, valid_y)\n\n23.159\n\n\nThe average error in price predictions is £23,000\nWhich is comparable to values seen with regions and fairly good given the details of the houses used in the model are limited\nThis model is put into an app here https://thomashsimm.com/streamlit/randomforrests/houseprices/python/2022/02/23/SwanseaHousePriceApp.html"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#content",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#content",
    "title": "Overview: Communicating code and data",
    "section": "Content",
    "text": "Content\n\nNotebooks overview\nConverting Notebooks\nExample useage of notebooks"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#jupyter-notebooks",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#jupyter-notebooks",
    "title": "Overview: Communicating code and data",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nFrom TalkPython: Awesome Jupyter Libraries and Extensions\n\nJupyter is an amazing environment for exploring data and generating executable reports with Python. But there are many external tools, extensions, and libraries to make it so much better and make you more productive.\n\n\nA notebook consists of two parts\n\nmarkdown part where we can:\n\nwrite text, add images, links, html, LaTeX etc\n\ncode part which runs and displays output of code\n\n\nSome links:\n\nJupyter Book\nA curated list of awesome Jupyter projects\nCode Documentation QA of Code\nFastAI guide for better blogs"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-of-a-notebook",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-of-a-notebook",
    "title": "Overview: Communicating code and data",
    "section": "Example of a notebook",
    "text": "Example of a notebook\nAn example notebook"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-of-a-notebook-output",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-of-a-notebook-output",
    "title": "Overview: Communicating code and data",
    "section": "Example of a notebook: output",
    "text": "Example of a notebook: output\n\nimport matplotlib.pyplot as plt\nplt.plot(df2['date_of_sampling'])"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-of-a-notebook-output-2",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-of-a-notebook-output-2",
    "title": "Overview: Communicating code and data",
    "section": "Example of a notebook: output 2",
    "text": "Example of a notebook: output 2\n\nimport altair as alt\nfrom vega_datasets import data\n\nmovies = alt.UrlData(\n    data.movies.url,\n    format=alt.DataFormat(parse={\"Release_Date\":\"date\"})\n)\nratings = ['G', 'NC-17', 'PG', 'PG-13', 'R']\ngenres = ['Action', 'Adventure', 'Black Comedy', 'Comedy',\n       'Concert/Performance', 'Documentary', 'Drama', 'Horror', 'Musical',\n       'Romantic Comedy', 'Thriller/Suspense', 'Western']\n\nbase = alt.Chart(movies, width=200, height=200).mark_point(filled=True).transform_calculate(\n    Rounded_IMDB_Rating = \"floor(datum.IMDB_Rating)\",\n    Hundred_Million_Production =  \"datum.Production_Budget > 100000000.0 ? 100 : 10\",\n    Release_Year = \"year(datum.Release_Date)\"\n).transform_filter(\n    alt.datum.IMDB_Rating > 0\n).transform_filter(\n    alt.FieldOneOfPredicate(field='MPAA_Rating', oneOf=ratings)\n).encode(\n    x=alt.X('Worldwide_Gross:Q', scale=alt.Scale(domain=(100000,10**9), clamp=True)),\n    y='IMDB_Rating:Q',\n    tooltip=\"Title:N\"\n)\n\n# A slider filter\nyear_slider = alt.binding_range(min=1969, max=2018, step=1)\nslider_selection = alt.selection_single(bind=year_slider, fields=['Release_Year'], name=\"Release Year_\")\n\n\nfilter_year = base.add_selection(\n    slider_selection\n).transform_filter(\n    slider_selection\n).properties(title=\"Slider Filtering\")\n\n# A dropdown filter\ngenre_dropdown = alt.binding_select(options=genres)\ngenre_select = alt.selection_single(fields=['Major_Genre'], bind=genre_dropdown, name=\"Genre\")\n\nfilter_genres = base.add_selection(\n    genre_select\n).transform_filter(\n    genre_select\n).properties(title=\"Dropdown Filtering\")\n\n#color changing marks\nrating_radio = alt.binding_radio(options=ratings)\n\nrating_select = alt.selection_single(fields=['MPAA_Rating'], bind=rating_radio, name=\"Rating\")\nrating_color_condition = alt.condition(rating_select,\n                      alt.Color('MPAA_Rating:N', legend=None),\n                      alt.value('lightgray'))\n\nhighlight_ratings = base.add_selection(\n    rating_select\n).encode(\n    color=rating_color_condition\n).properties(title=\"Radio Button Highlighting\")\n\n# Boolean selection for format changes\ninput_checkbox = alt.binding_checkbox()\ncheckbox_selection = alt.selection_single(bind=input_checkbox, name=\"Big Budget Films\")\n\nsize_checkbox_condition = alt.condition(checkbox_selection,\n                                        alt.SizeValue(25),\n                                        alt.Size('Hundred_Million_Production:Q')\n                                       )\n\nbudget_sizing = base.add_selection(\n    checkbox_selection\n).encode(\n    size=size_checkbox_condition\n).properties(title=\"Checkbox Formatting\")\n\n( filter_year | filter_genres) &  (highlight_ratings | budget_sizing  )"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#communicating-when-code-is-a-large-element-of-what-is-being-presented",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#communicating-when-code-is-a-large-element-of-what-is-being-presented",
    "title": "Overview: Communicating code and data",
    "section": "Communicating when code is a large element of what is being presented",
    "text": "Communicating when code is a large element of what is being presented\n\nMicrosoft Word/ppt- type methods aren’t set-up well to include code\nProgramming files (e.g. .py) aren’t set-up well to share\nVideoing code with outputs is an option, but don’t translate to other formats (i.e. we may also need to do a written format of this)\nApps (e.g. streamlit) can be good.\n\nBut the code is hidden\n\nProgramming notebooks (e.g..ipynb) offer a good and easy to share code but with some limitations\n\nAn easier way is to convert the notebooks to html\n\ne.g. maybe someone doesn’t have python installed"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#notebook-benefits",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#notebook-benefits",
    "title": "Overview: Communicating code and data",
    "section": "Notebook Benefits",
    "text": "Notebook Benefits\n\nNotebooks are intuitive\n\nYou have the code then the result of the code\nPlus can add details of how code works\nAnd it’s linear\n\nCan get things up and working quickly\nAid with communicating code\nEncourages Writing\n\nand writing things down aids thinking in the now and understanding what you did and why in the future\n\n\nCan use shell commands e.g. !pip install pandas\nCan use magic commands e.g. %%time to time a cell\n\nWith the ONS moving towards Python/R from Excel and a varied level of skills. The first of these is particularly important to aid communicating code"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#what-i-have-used-to-convert-notebooks",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#what-i-have-used-to-convert-notebooks",
    "title": "Overview: Communicating code and data",
    "section": "What I have used to convert notebooks",
    "text": "What I have used to convert notebooks\n\nfastpages\n\nPreviously I converted notebooks to html via fastpages but this is now deprecated and they are recommending the use of quarto.\n\nquarto\n\nSo far I have found quarto really good and flexible (N.B. R works too)\nEasy to convert a notebook to multiple formats, including html, powerpoint, pdf, word doc\nBUT Quarto is not possible within ONS (as far as I can tell currently)\n\nnbconvert is another option I tried\n\nbut it doesn’t seem to have the functionality of fastpages or quarto.\n\nJupyter Books seems to be the best option within ONS\n\nMaybe not as good as quarto but it works!"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#others",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#others",
    "title": "Overview: Communicating code and data",
    "section": "Others",
    "text": "Others\n\nI know some people use Sphinx,\n\nis recommended by QA\nFrom what I can tell sphinx on it’s own is not as easy to use as notebooks\nBut there is a jupyter extension nbsphinx\nJupyter Books uses Sphinx heavily under the hood\n\nnbdev\n\nI think is connected to quarto\n\nVoila\n\nVoilà turns Jupyter notebooks into standalone web applications.\nLooks good, bit like streamlit\nbut seems to interfere with other libraries and not checked whether works in ONS\nmercury seems similar\n\nAnything else people use and recommend?"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#quarto-outputs",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#quarto-outputs",
    "title": "Overview: Communicating code and data",
    "section": "Quarto Outputs",
    "text": "Quarto Outputs\nWe can then create different files from this .ipynb Jupyter notebook using the following code:\n\nquarto render testPres.ipynb --to pptx\nquarto render testPres.ipynb --to pdf\nquarto render testPres.ipynb --to html\nquarto render testPres.ipynb --to revealjs\n\nor for Jupyter Books - jupyter-book build .\\PesticideDocs\\"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#creating-a-webpage-from-this",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#creating-a-webpage-from-this",
    "title": "Overview: Communicating code and data",
    "section": "Creating a webpage from this",
    "text": "Creating a webpage from this\nTakes about 30 mins including installing chosen converter. (But can be done much quicker)\n\ncreate a Github repo for your website\nchoose the converter (e.g. Jupyter Books)\n\nAnd follow their instructions\n\ngo to settings -> Pages within the repo\n\nfew options to do\n\nOptional: add your own website url to it\n\nLink how to do this here"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-documenting-code",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-documenting-code",
    "title": "Overview: Communicating code and data",
    "section": "Example: Documenting Code",
    "text": "Example: Documenting Code\n\nHere is my website for my research project on pesticides in UK food.\nThis is not the same as documentation for a package but there are parallels\n\nThis does a few things:\n\nDocuments the analysis steps I have taken including the code and outputs\n\nUseful for data transparency, useability of the code if needs modifiying/adapting, and why I did XYZ\n\nProvides a way to present the data\n\nThere is a streamlit app, but sometimes I like to be able to see the code"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-discussing-code",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-discussing-code",
    "title": "Overview: Communicating code and data",
    "section": "Example: Discussing Code",
    "text": "Example: Discussing Code\n\nGP Tables example"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-tool-to-aid-learning",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-tool-to-aid-learning",
    "title": "Overview: Communicating code and data",
    "section": "Example: Tool to aid learning",
    "text": "Example: Tool to aid learning\nA big area I have been using Jupyter Notebooks for is to aid learning\n\nIf you want to understand something it helps to write it down\nHaving the code next to it is a big advantage\nAnd if stored on github you can access it anywhere\n\nTensoflow cheat sheet"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-debugging-code",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#example-debugging-code",
    "title": "Overview: Communicating code and data",
    "section": "Example: Debugging Code",
    "text": "Example: Debugging Code\n\nSince starting at ONS I have been working with understanding an existing project and latterly adding code to it\nThe project consists of multiple python files across several folders\n\nMy Python was good but lots of the functions and their useage weren’t immediately obvious to me\n\nbreak-points in VS Studio is really good to step through the code and work out what happens in the code.\n\nI had not used before with Python (but had lots with MATLAB), and it’s really useful\n\nBut it can be limited what you can do\n\ndifficult to probe code if want to write more than 1 line of code\nthe experience/knowledge exists as you go through it but no documentation to refer to later, e.g. function X does this when I give it Y etc\n\nBy copying and pasting code into Jupyter cells I could see and document how they worked (e.g. changing inputs)\n\nThis (copying and pasting) would get around code changes too (which would be an issue if modules were just imported)\nbecause this was all done in Jupyter notebook I can have a ipynb code file and a html file showing how the code works\nI could even save a pickle file of the variables at a particularly point to understand how the code would work from this point"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#presenting-in-multiple-formats",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#presenting-in-multiple-formats",
    "title": "Overview: Communicating code and data",
    "section": "Presenting in multiple formats",
    "text": "Presenting in multiple formats\n\nJupyter notebooks can be used on their own or as html\nBut can also be used to create presentations, pdf/word documentation or even books\nThis presentation was done with Quarto using the revealjs format\n\nSo it is a presentation format but with a html file\n\nSome of these file types can be difficult within ONS framework to do\n\nI hit a wall when trying to go beyond html and docs with Jupyter books due to dependencies"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#presenting-in-multiple-formats-video",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#presenting-in-multiple-formats-video",
    "title": "Overview: Communicating code and data",
    "section": "Presenting in multiple formats: video",
    "text": "Presenting in multiple formats: video\nVideo"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres.html#questions-comments",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres.html#questions-comments",
    "title": "Overview: Communicating code and data",
    "section": "Questions/ Comments",
    "text": "Questions/ Comments\n\nThoughts on:\n\nusing notebooks\ndocumenting code\nencouraging communication of code across ONS areas and experiences\n\nCan we share html files? Or do we have to work within the current framework?\nAnything else?"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#what-i-have-used-to-convert-notebooks-to-html",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#what-i-have-used-to-convert-notebooks-to-html",
    "title": "Communicating code: Website",
    "section": "What I have used to convert notebooks to html",
    "text": "What I have used to convert notebooks to html\n\nfastpages\n\nPreviously I converted notebooks to html via fastpages but this is now deprecated and they are recommending the use of quarto.\n\nquarto\n\nSo far I have found quarto really good and flexible (N.B. R works too)\nEasy to convert a notebook to multiple formats, including html, powerpoint, pdf, word doc\nBUT Quarto is not possible if installing from non pip sources is an issue (as far as I can tell currently)\n\nnbconvert is another option I tried\n\nbut it doesn’t seem to have the functionality of fastpages or quarto.\n\nJupyter Books seems to be the best option within companies with installation issues\n\nMaybe not as good as quarto but it works!"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#others",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#others",
    "title": "Communicating code: Website",
    "section": "Others",
    "text": "Others\n\nI know some people use Sphinx,\n\nis recommended by QA\nFrom what I can tell sphinx on it’s own is not as easy to use as notebooks\nBut there is a jupyter extension nbsphinx\nJupyter Books uses Sphinx heavily under the hood\n\nnbdev\n\nI think is connected to quarto\n\nVoila\n\nVoilà turns Jupyter notebooks into standalone web applications.\nLooks good, bit like streamlit\nbut seems to interfere with other libraries\nmercury seems similar"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#creating-html-other-formats",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#creating-html-other-formats",
    "title": "Communicating code: Website",
    "section": "Creating html (& other formats)",
    "text": "Creating html (& other formats)\n\nQuarto\nInstallation is via a package i.e. .msi for Windows or .pkg for Mac. Which can cause issues.\nWorks with both ipynb and qmd files, which are both a mixture of markdown and executable code.\nThe only thing that needs to be done with the notebook is add a YAML block at the start of the notebook, like the following (raq not markdown was used):\n---\ntitle: \"Communicating code: Website\"\nsubtitle: \"Using the notebook format for a website\"\nauthor: \"Thomas H. Simm\"\nformat:\n  html:\n    toc: true\ntitle-slide-attributes:\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\njupyter: python3\n---\nWe can create different files from this .ipynb Jupyter notebook using the following code:\n\nquarto render testPres.ipynb --to pptx\nquarto render testPres.ipynb --to pdf\nquarto render testPres.ipynb --to html\nquarto render testPres.ipynb --to revealjs\n\nFurther, formatting for projects (i.e. for website) can be done within the configuration file _quarto.yml\nproject:\n  type: website\n  output-dir: _site\n\nwebsite:\n  title: \"ThomasHSimm\"\n  favicon: /posts/Picture3.png\n  body-header: <img src=\"/posts/header2.png\" height=200>\n\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/ThomasHSimm\n      - icon: mortarboard-fill\n        href: https://scholar.google.com/citations?hl=en&user=HdPDn1sAAAAJ\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#jupyter-books",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#jupyter-books",
    "title": "Communicating code: Website",
    "section": "Jupyter Books",
    "text": "Jupyter Books\nWe can create different files from this .ipynb Jupyter notebook using the following code:\n\njupyter-book build .\\PesticideDocs\\\njupyter-book build <path-to-book>\njupyter-book build <path-to-book> --builder pdfhtml\njupyter-book build <path-to-book> --builder singlehtml\n\nThe only difference in notebook is that it needs to have One header in a markdown cell for the table of contents, e.g. \n# Title of page\n\nConfiguration file\nA seperate files _config.yml is used to define how the html (or other) files will look\n# Book settings\n# Learn more at https://jupyterbook.org/customize/config.html\n\ntitle: Defra Pesticide Testing, Data Analysis\nauthor: Thomas Simm\nlogo: ONS-logo.png\nexclude_patterns: [_build, Thumbs.db, .DS_Store, \"**.ipynb_checkpoints\"]\n\n\n# Force re-execution of notebooks on each build.\n# See https://jupyterbook.org/content/execute.html\nexecute:\n  execute_notebooks: force\n\n# Define the name of the latex output file for PDF builds\nlatex:\n  latex_documents:\n    targetname: book.tex\n\n# Add a bibtex file so that we can create citations\nbibtex_bibfiles:\n  - references.bib\n\n# Information about where the book exists on the web\nrepository:\n  url: https://github.com/ThomasHSimm/Pesticide  # Online location of your book\n  path_to_book: docs  # Optional path to your book, relative to the repository root\n  branch: master  # Which branch of the repository should be used when creating links (optional)\n\n# Add GitHub buttons to your book\n# See https://jupyterbook.org/customize/config.html#add-a-link-to-your-repository\n# HTML-specific settings\nhtml:\n  favicon                   : \"_images/favicon.jpg\"  # A path to a favicon image\n  use_edit_page_button      : false  # Whether to add an \"edit this page\" button to pages. If `true`, repository information in repository: must be filled in\n  use_repository_button     : false  # Whether to add a link to your repository button\n  use_issues_button         : false  # Whether to add an \"open an issue\" button\n  use_multitoc_numbering    : true   # Continuous numbering across parts/chapters\n  extra_navbar              : Powered by <a href=\"https://jupyterbook.org\">Jupyter Book</a>\n                              <br>Home website <a href=\"https://thomashsimm.com/\">thomashsimm.com</a> # Will be displayed underneath the left navbar.\n  extra_footer              : \"\"  # Will be displayed underneath the footer.\n  google_analytics_id       : \"\"  # A GA id that can be used to track book views.\n  home_page_in_navbar       : true  # Whether to include your home page in the left Navigation Bar\n  baseurl                   : \"\"  # The base URL where your book will be hosted. Used for creating image previews and social links. e.g.: https://mypage.com/mybook/\n  comments:\n    hypothesis              : false\n    utterances              : false\n  announcement              : \"\" # A banner announcement at the top of the site.\n\nAnd in addition to the config file a table of contents file is required _toc.yml:\n# Table of contents\n# Learn more at https://jupyterbook.org/customize/toc.html\n\nformat: jb-book\nroot: intro\nchapters:\n- file: Pesticide_Plots\n- file: References\n- file: UK_areas\n- file: using_jupyter_books"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#creating-a-webpage-from-this",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#creating-a-webpage-from-this",
    "title": "Communicating code: Website",
    "section": "Creating a webpage from this",
    "text": "Creating a webpage from this\nTakes about 30 mins including installing the chosen converter. (But can be done much quicker)\n\ncreate a Github repo for your website\nchoose the converter (e.g. Jupyter Books)\n\nAnd follow their instructions\n\ngo to settings -> Pages within the repo\n\nfew options to do\n\nOptional: add your own website url to it\n\nLink how to do this here\nIn Quarto a command from your PC in the repo, publishes the website:\nquarto publish quarto-pub\nOr equivalently with Jupyter Books:\nghp-import -n -p -f _build/html"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#creating-directly-from-the-repo",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_html.html#creating-directly-from-the-repo",
    "title": "Communicating code: Website",
    "section": "Creating directly from the repo",
    "text": "Creating directly from the repo\nIf we instead want to convert notebook files directly from a repo to create a website then this can be done with Netlify.\nThis is useful if using Gitlab (i.e. not Github) or don’t want all the extra html files cluttering the repo.\n\nSteps:\nhttps://jupyterbook.org/en/stable/publish/netlify.html\n\nSign up and connect Github/Gitlab\nAdd a requirements.txt file and also toc.yml to directory\nOn netlify -> Add new site -> import from an existing repo\nInsert something like below\n\nN.B. the command:\npip install -r requirements.txt && jupyter-book build .\nand folder location \n\n\nExample:\n\nGitlab repo\nResulting website https://thomashsimm.netlify.app/intro.html\n\nAnd from the inner folder"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#jupyter-notebooks",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#jupyter-notebooks",
    "title": "Communicating code: Notebooks",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nFrom TalkPython: Awesome Jupyter Libraries and Extensions\n\nJupyter is an amazing environment for exploring data and generating executable reports with Python. But there are many external tools, extensions, and libraries to make it so much better and make you more productive.\n\n\nA notebook consists of two parts\n\nmarkdown part where we can:\n\nwrite text, add images, links, html, LaTeX etc\n\ncode part which runs and displays output of code\n\n\nSome links:\n\nJupyter Book\nA curated list of awesome Jupyter projects\nCode Documentation QA of Code\nFastAI guide for better blogs"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#example-of-a-notebook",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#example-of-a-notebook",
    "title": "Communicating code: Notebooks",
    "section": "Example of a notebook",
    "text": "Example of a notebook\nAn example notebook"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#markdown-in-a-notebook",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#markdown-in-a-notebook",
    "title": "Communicating code: Notebooks",
    "section": "Markdown in a notebook",
    "text": "Markdown in a notebook\nSome useful commands:\n\n# Notebooks Markdown and Code and ## Markdown in a notebook\n![](ghtop_images/pest.png) looks like this\n\n\n\nAnd the same with a mp4 file ![](ghtop_images/revealjs.mp4)\n\nVideo\n\n> If we want text like this\n\n\nIf we want text like this\n\n\nOr if we want code use `a = b + c`\n\nor:\n```\na = b\na = a + c\n```\na = b + c\n\nHTML works too\n\n<img src=\"ghtop_images/pest.png\"></img>"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#code-in-a-notebook",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#code-in-a-notebook",
    "title": "Communicating code: Notebooks",
    "section": "Code in a notebook",
    "text": "Code in a notebook\nExample interactive format using altair:\n\nimport altair as alt\nfrom vega_datasets import data\n\nmovies = alt.UrlData(\n    data.movies.url,\n    format=alt.DataFormat(parse={\"Release_Date\":\"date\"})\n)\nratings = ['G', 'NC-17', 'PG', 'PG-13', 'R']\ngenres = ['Action', 'Adventure', 'Black Comedy', 'Comedy',\n       'Concert/Performance', 'Documentary', 'Drama', 'Horror', 'Musical',\n       'Romantic Comedy', 'Thriller/Suspense', 'Western']\n\nbase = alt.Chart(movies, width=200, height=200).mark_point(filled=True).transform_calculate(\n    Rounded_IMDB_Rating = \"floor(datum.IMDB_Rating)\",\n    Hundred_Million_Production =  \"datum.Production_Budget > 100000000.0 ? 100 : 10\",\n    Release_Year = \"year(datum.Release_Date)\"\n).transform_filter(\n    alt.datum.IMDB_Rating > 0\n).transform_filter(\n    alt.FieldOneOfPredicate(field='MPAA_Rating', oneOf=ratings)\n).encode(\n    x=alt.X('Worldwide_Gross:Q', scale=alt.Scale(domain=(100000,10**9), clamp=True)),\n    y='IMDB_Rating:Q',\n    tooltip=\"Title:N\"\n)\n\n# A slider filter\nyear_slider = alt.binding_range(min=1969, max=2018, step=1)\nslider_selection = alt.selection_single(bind=year_slider, fields=['Release_Year'], name=\"Release Year_\")\n\n\nfilter_year = base.add_selection(\n    slider_selection\n).transform_filter(\n    slider_selection\n).properties(title=\"Slider Filtering\")\n\n# A dropdown filter\ngenre_dropdown = alt.binding_select(options=genres)\ngenre_select = alt.selection_single(fields=['Major_Genre'], bind=genre_dropdown, name=\"Genre\")\n\nfilter_genres = base.add_selection(\n    genre_select\n).transform_filter(\n    genre_select\n).properties(title=\"Dropdown Filtering\")\n\n#color changing marks\nrating_radio = alt.binding_radio(options=ratings)\n\nrating_select = alt.selection_single(fields=['MPAA_Rating'], bind=rating_radio, name=\"Rating\")\nrating_color_condition = alt.condition(rating_select,\n                      alt.Color('MPAA_Rating:N', legend=None),\n                      alt.value('lightgray'))\n\nhighlight_ratings = base.add_selection(\n    rating_select\n).encode(\n    color=rating_color_condition\n).properties(title=\"Radio Button Highlighting\")\n\n# Boolean selection for format changes\ninput_checkbox = alt.binding_checkbox()\ncheckbox_selection = alt.selection_single(bind=input_checkbox, name=\"Big Budget Films\")\n\nsize_checkbox_condition = alt.condition(checkbox_selection,\n                                        alt.SizeValue(25),\n                                        alt.Size('Hundred_Million_Production:Q')\n                                       )\n\nbudget_sizing = base.add_selection(\n    checkbox_selection\n).encode(\n    size=size_checkbox_condition\n).properties(title=\"Checkbox Formatting\")\n\n( filter_year | filter_genres) &  (highlight_ratings | budget_sizing  )"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#simpler-code-output",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#simpler-code-output",
    "title": "Communicating code: Notebooks",
    "section": "Simpler code output",
    "text": "Simpler code output\nx = np.arange(0,np.pi,.01)\ny = np.sin(x)\nplt.plot(x,y)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.arange(0,np.pi,.01)\ny = np.sin(x)\nplt.plot(x,y)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#notebooks-my-view",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#notebooks-my-view",
    "title": "Communicating code: Notebooks",
    "section": "Notebooks: my view",
    "text": "Notebooks: my view\nAlthough notebooks have their validish detractors I don’t like notebooks.- Joel Grus Youtube I think if you approach them in the right way they are a super powerful tool.\nThe negatives seem to be:\n\nencourage bad practice in code (a genuine problem)\nissues around order of what cell is run (easily got around with good practice)\nissues around lack of auto complete (I don’t see the issue, use in visual studio autocomplete is there)\nno grammar/spelling correction\nissues with using git and version control\n\nthere are ways around this though"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#notebook-benefits",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#notebook-benefits",
    "title": "Communicating code: Notebooks",
    "section": "Notebook Benefits",
    "text": "Notebook Benefits\n\nNotebooks are intuitive\n\nYou have the code then the result of the code\nPlus can add details of how code works\nAnd it’s linear\n\nCan get things up and working quickly\nAid with communicating code\nEncourages Writing\n\nand writing things down aids thinking in the now and understanding what you did and why in the future\n\nFastAI guide for better blogs\n\nCan use shell commands e.g. !pip install pandas\nCan use magic commands e.g. %%time to time a cell\nEasy to convert code to a pipeline\n\nWith many companies moving towards Python/R from Excel and a varied level of skills. The first of these is particularly important to aid communicating code"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#communicating-when-code-is-a-large-element-of-what-is-being-presented",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#communicating-when-code-is-a-large-element-of-what-is-being-presented",
    "title": "Communicating code: Notebooks",
    "section": "Communicating when code is a large element of what is being presented",
    "text": "Communicating when code is a large element of what is being presented\n\nMicrosoft Word/ppt- type methods aren’t set-up well to include code\nProgramming files (e.g. .py) aren’t set-up well to share\nVideoing code with outputs is an option, but don’t translate to other formats (i.e. we may also need to do a written format of this)\nApps (e.g. streamlit) can be good.\n\nBut the code is hidden\n\nProgramming notebooks (e.g..ipynb) offer a good and easy to share code but with some limitations\n\nAn easier way is to convert the notebooks to html\n\ne.g. maybe someone doesn’t have python installed"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#example-documenting-code",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#example-documenting-code",
    "title": "Communicating code: Notebooks",
    "section": "Example: Documenting Code",
    "text": "Example: Documenting Code\n\nHere is my website for my research project on pesticides in UK food.\nThis is not the same as documentation for a package but there are parallels\n\nThis does a few things:\n\nDocuments the analysis steps I have taken including the code and outputs\n\nUseful for data transparency, useability of the code if needs modifiying/adapting, and why I did XYZ\n\nProvides a way to present the data\n\nThere is a streamlit app, but sometimes I like to be able to see the code"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#example-tool-to-aid-learning",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#example-tool-to-aid-learning",
    "title": "Communicating code: Notebooks",
    "section": "Example: Tool to aid learning",
    "text": "Example: Tool to aid learning\nA big area I have been using Jupyter Notebooks for is to aid learning\n\nIf you want to understand something it helps to write it down\nHaving the code next to it is a big advantage\nAnd if stored on github you can access it anywhere\n\nTensoflow cheat sheet"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#example-debugging-code",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_notebooks.html#example-debugging-code",
    "title": "Communicating code: Notebooks",
    "section": "Example: Debugging Code",
    "text": "Example: Debugging Code\n\nSince starting at ONS I have been working with understanding an existing project and latterly adding code to it\nThe project consists of multiple python files across several folders\n\nMy Python was good but lots of the functions and their useage weren’t immediately obvious to me\n\nbreak-points in VS Studio is really good to step through the code and work out what happens in the code.\n\nI had not used before with Python (but had lots with MATLAB), and it’s really useful\n\nBut it can be limited what you can do\n\ndifficult to probe code if want to write more than 1 line of code\nthe experience/knowledge exists as you go through it but no documentation to refer to later, e.g. function X does this when I give it Y etc\n\nBy copying and pasting code into Jupyter cells I could see and document how they worked (e.g. changing inputs)\n\nThis (copying and pasting) would get around code changes too (which would be an issue if modules were just imported)\nbecause this was all done in Jupyter notebook I can have a ipynb code file and a html file showing how the code works\nI could even save a pickle file of the variables at a particularly point to understand how the code would work from this point"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#content",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#content",
    "title": "Communicating code: Presentations",
    "section": "Content",
    "text": "Content\n\nQuarto\n\npowerpoint https://quarto.org/docs/presentations/\nhtml\n\nJupyter books\nStreamlit"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#creating-the-template",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#creating-the-template",
    "title": "Communicating code: Presentations",
    "section": "Creating the template",
    "text": "Creating the template\n(Office info correct for Office 365 Feb 2023, Version 2301 Build 16.0.16026.20002)\nIf your workplace has a custom template or you have one you always use, you can incorporate this into quarto.\nHowever, quarto is quite specific on the form this template takes, and requires the following elements - Title Slide - Title and Content - Section Header - Two Content - Comparison - Content with Caption - Blank\nBy selecting Layout from the Home tab in powerpoint the different layouts can be seen\n\nThey can then be modified by going to View tab - Slide Master.\nIf using your own template you will need to match the names of the slides given above. These can be found by hovering over the slides on the left or right clicking on one and selecting “Rename Layout”\n\nAlternatively, create a custom template using quarto and then modify this. The following command creates the template:\nquarto pandoc -o template.pptx --print-default-data-file reference.pptx\nThen go to View tab - Slide Master and modify each slide layout.\nNote if you are trying to match a template, some tips: - go to Design -> Slide Size and match this to your template - when View tab - Slide Master is selected go to first tab (see above it will be left indented) on one you are copying from and select all on this then paste to the new template - these will be background images and other things that want to be passed to all slides - Check other slides for images and font-styles etc to match to the new template"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#load-the-template",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#load-the-template",
    "title": "Communicating code: Presentations",
    "section": "Load the template",
    "text": "Load the template\nTo load the template the first cell in the notebook needs to be modified as follows to reference the template.pptx file.\nformat:\n  pptx:\n    reference-doc: template.pptx\n    slide-level: 2\nIn addition, we can also specify here the rule by which a new slide is defined. If slide-level: 2 is used a new slide is defined by “##’ and a new section header by ‘#’. So if we used ‘###’ this would be a heading within the slide.\nIf slide-level: 1 is used a new slide is defined by “#’ and ‘##’ this would be a heading within the slide (this is normally the default)."
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#check-the-slides",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#check-the-slides",
    "title": "Communicating code: Presentations",
    "section": "Check the slides",
    "text": "Check the slides\nI have found creation of slides to powerpoint more prone to strange results than if .doc/.pdf/.html are used.\nSo check the slides, see if interactive content or code has been included (probably not) and if the slide content goes outside the slide.\n\nIn the example above - There is overlap of text on a slide - Strange ouput of a slide - Code output not displayed"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#adding-style-to-revealjs",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#adding-style-to-revealjs",
    "title": "Communicating code: Presentations",
    "section": "Adding style to revealjs",
    "text": "Adding style to revealjs\nA simple way to add template like details to a revealjs file is to add a style.css sheet.\nIn the example below, the style sheet adds logo.png to the bottom right of each sheet\nThe file style.css looks like this:\n.reveal .slide-logo {\n  display: block;\n  position: fixed;\n  top: unset !important;\n  left: unset !important;\n  bottom: 50px;\n  right: 12px;\n  height: 100px !important;\n  width: 100x !important;\n  max-width: unset !important;\n  max-height: unset !important;\n}\nAnd the revealjs part at the top of the jupyter notebook looks like this\nrevealjs:\n    slide-number: true\n    height: 1080\n    width: 1920\n    logo: logo.png\n    css: style.css\nSo this would then look like the following, with the logo (logo.png) in the bottom right, and size and positioning given by the css file"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#what-the-revealjs-file-looks-like",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#what-the-revealjs-file-looks-like",
    "title": "Communicating code: Presentations",
    "section": "What the revealjs file looks like",
    "text": "What the revealjs file looks like\nVideo"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-overview",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-overview",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: overview",
    "text": "Streamlit Functionality: overview\nStreamlit allows various functionality:\n\ntextbox\nimages/videos\ncharts/tables\nmenus/buttons\netc"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-streamlit_layout",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-streamlit_layout",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: streamlit_layout",
    "text": "Streamlit Functionality: streamlit_layout\nBut unlike some apps (am thinking MATLAB GUIs) you can’t create the look and functionality separately. So if you want something in a certain position it can be tricky. HTML can be used with st.markdown to give more control but it isn’t recommended to use by streamlit.\nInstead, to create the layout as you would like they have the following features:"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-columns-and-sidebar",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-columns-and-sidebar",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: columns and sidebar",
    "text": "Streamlit Functionality: columns and sidebar\nThe most useable are the first two: columns and sidebar\nColumns allows us to split the app vertically. The code is fairly simple:\nEither colL, colM, colR = st.columns(3) for 3 equal columns or to split columns with different sizes:\ncolL, _, colR = st.columns((10, 5, 20))\nwith colL:\n    st.write('On the left')\nwith colR:\n    st.write('On the right twice as big as left')\nst.sidebar just adds a sidebar to the app that can be hidden or shown.\nAnything in the sidebar is just prefixed by st.sidebar so:\nst.sidebar.write('I am in the sidebar')\nst.write('I am in the main app')\nst.sidebar.write('I am back in the sidebar')"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-html",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-html",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: html",
    "text": "Streamlit Functionality: html\nIt is possible to add various additional personalisations using html. BUT it does come with security risks and so is [not recommended]](https://github.com/streamlit/streamlit/issues/152)\n\nBut it does allow much more control over the layout of the app that can be useful for a presentation: - Can add a background image - Can add background color to a textbox - Control over positioning of widgets - lots more\nHTML is implementated using st.markdown with unsafe_allow_html=True inside the former"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-html-examples",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-html-examples",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: html examples",
    "text": "Streamlit Functionality: html examples\nadd background to a text box\ntext = \"Code Examples\"\n        st.markdown(f'<center><p style=font-family:\"Calibri\";background-color:#FFFFFF;color:#000000;font-size:42px;border-radius:10%><b>{text}</b></p></center>', unsafe_allow_html=True)\n\nOr to add a background image\nimport streamlit as st\nimport base64\n\n@st.cache(allow_output_mutation=True)\ndef get_base64_of_bin_file(bin_file):\n    with open(bin_file, 'rb') as f:\n        data = f.read()\n    return base64.b64encode(data).decode()\n\ndef set_png_as_page_bg(png_file):\n    bin_str = get_base64_of_bin_file(png_file) \n    page_bg_img = '''\n    <style>\n    .stApp {\n    background-image: url(\"data:image/png;base64,%s\");\n    background-size: contain;\n    background-repeat: no-repeat;\n    background-attachment: scroll; # doesn't work\n    }\n    </style>\n    ''' % bin_str\n    st.markdown(page_bg_img, unsafe_allow_html=True)\n    return"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-echo",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-echo",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: echo",
    "text": "Streamlit Functionality: echo\n\nSometimes you want your Streamlit app to contain both your usual Streamlit graphic elements and the code that generated those elements. That’s where st.echo() comes in\n\nEasier to display this by an example:\n\nIn the example above the right of the image is given below (st.columns is used, where the input for the function is found from the left column).\n\nst.echo is used with the with statement.\neverything within the with is printed to the screen and executed\n\nwith st.echo():\n    # Everything inside this block will be both printed to the screen\n    # and executed.\n\n    def do_pd_replace(text, text_search, text_sub):\n        col_name = \"Start string\"\n        df = pd.DataFrame(data=[text], columns=[col_name])\n\n        df[\"Final String\"] = df[col_name].replace(\n            text_search, text_sub, regex=True\n        )\n\n        st.dataframe(df)\n        st.write(f\"text_search = '{text_search}' and text_sub = '{text_sub}'\")\n        st.write(f\"Input string = '{text}'\")\n        st.write(f\"Output string = '{df['Final String'].values[0]}'\")\n\n    do_pd_replace(text, text_search, text_sub)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-pages",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-pages",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: pages",
    "text": "Streamlit Functionality: pages\nBy simply creating a folder called pages and putting other streamlit .py files in the folder they can then be accessed in the sidebar.\n\nA main file needs to be outside the pages folder\nThe .py files in pages behave as if they were outside the folder (i.e. when loading files/functions)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#example-streamlit-presentation",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_pres.html#example-streamlit-presentation",
    "title": "Communicating code: Presentations",
    "section": "Example Streamlit Presentation",
    "text": "Example Streamlit Presentation\nVideo"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#excel-files",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#excel-files",
    "title": "Communicating code: Tables",
    "section": "Excel files",
    "text": "Excel files\n\nChatGPT: What are the problems of Excel and xlsx files?\n\n\nLimited scalability: Excel has a limit on the number of rows and columns it can handle effectively.\nInaccurate data: The manual nature of data entry in Excel can lead to errors and inaccuracies.\nFragility: Complex Excel spreadsheets can break easily if any formula or cell reference is altered.\nLack of security: Excel files are vulnerable to unauthorized access and malicious attacks.\nSlow performance: Large and complex Excel files can become slow to open and use, leading to decreased productivity.\nCompatibility issues: XLSX files may not be compatible with older versions of Excel, or with other software applications.\nLimited collaboration: Sharing Excel files and making changes to them can be difficult, especially when multiple people are involved.\n\nFor me it is the Slow performance alongside: (a) we are doing the data manipulation outside Excel anyway and (b) having to have another application open\n\nods with Excel\nAbout 10 s to open 3 ods files with Excel\n\n\n.ods converted to html in firefox browser\nAbout 6 s to open 3 converted ods files in a browser\n\n\n.ods converted to html firefox browser no new tabs\nAlmost instant when open converted ods files in same browser"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#what-aspect-of-tables-i-am-considering",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#what-aspect-of-tables-i-am-considering",
    "title": "Communicating code: Tables",
    "section": "What aspect of tables I am considering",
    "text": "What aspect of tables I am considering"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#convert-xlsx-to-html",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#convert-xlsx-to-html",
    "title": "Communicating code: Tables",
    "section": "Convert xlsx to html?",
    "text": "Convert xlsx to html?\n\nOpening xlsx files in Excel is slow\nConverting to html if we don’t want to edit could be an option\nIf we are moving to Python/R aren’t non-Excel options worth considering??\n\nConverting xlsx files to html\n\nSeems the most obvious course\nBut it doesn’t seem that easy with code\n\nbut easy within Excel"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#what-does-chatgpt-say-to-convert-excel-file",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#what-does-chatgpt-say-to-convert-excel-file",
    "title": "Communicating code: Tables",
    "section": "What does chatgpt say to convert excel file?",
    "text": "What does chatgpt say to convert excel file?\n\nConvert an excel file to html with python"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#what-does-chatgpt-say-without-pandas",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#what-does-chatgpt-say-without-pandas",
    "title": "Communicating code: Tables",
    "section": "What does chatgpt say without pandas?",
    "text": "What does chatgpt say without pandas?\n\nconvert excel file to html in python without pandas include the excel formatting such as column width\n\n\n\nimport pandas as pd\n\nimport os\nfrom pathlib import Path\nimport sys\n\nmodule_path = Path( os.getcwd() )\nmodule_path = module_path.parent.parent.parent.__str__() + '\\\\Pesticide'\n\ncwd = module_path\n\nfolder_path = os.path.join(cwd,'data')\n\nsys.path.insert(0, module_path)\n\ndf2 = pd.read_csv(os.path.join(folder_path,'combined_df.csv') ,index_col=0 )\n# change data type of columns\ndf2['date_of_sampling'] = pd.to_datetime(df2['date_of_sampling'])"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#pandas",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#pandas",
    "title": "Communicating code: Tables",
    "section": "pandas",
    "text": "pandas\n\nSince (in Python) we are mainly working with pandas. Let’s consider how pandas outputs can be modified.\npandas options\n\nSome code functionality\n# precision of all columns\npd.set_option(\"display.precision\", 2)\n# Or map as a string\ndf2['amount_pc_str'] = df2['amount_pc'].map(lambda x: '%.3f' % x)\n# some other options\npd.set_option('max_colwidth', 20)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', 0)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#pandas-basic",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#pandas-basic",
    "title": "Communicating code: Tables",
    "section": "pandas basic",
    "text": "pandas basic\n\ndf2\n\n\n\n\n\n  \n    \n      \n      sample_id\n      date_of_sampling\n      description\n      country_of_origin\n      retail_outlet\n      address\n      brand_name\n      packer_/_manufacturer_/_importer\n      product\n      address_postcode\n      packer_postcode\n      address_area\n      packer_area\n      chem_name\n      amount_detected\n      mrl\n      amount_pc\n    \n  \n  \n    \n      0\n      1958/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Asda\n      Creechbarrow Road, Taunton TA1 2AN\n      Asda\n      Asda Stores Ltd Leeds, UK LS11 5AD\n      Apple\n      TA1 2AN\n      LS11 5AD\n      Somerset\n      West Yorkshire\n      boscalid\n      0.03\n      2.0\n      0.015\n    \n    \n      1\n      1958/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Asda\n      Creechbarrow Road, Taunton TA1 2AN\n      Asda\n      Asda Stores Ltd Leeds, UK LS11 5AD\n      Apple\n      TA1 2AN\n      LS11 5AD\n      Somerset\n      West Yorkshire\n      pyraclostrobin\n      0.01\n      0.5\n      0.020\n    \n    \n      2\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      boscalid\n      0.05\n      2.0\n      0.025\n    \n    \n      3\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      flonicamid (sum)\n      0.02\n      0.2\n      0.100\n    \n    \n      4\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      pyraclostrobin\n      0.03\n      0.5\n      0.060\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      35155\n      2858/2020 Organic\n      2020-10-20\n      Organic Sweet Potatoes\n      Spain\n      Tesco\n      300 Beverley Way, New Malden KT3 4PJ\n      Tesco\n      Tesco Stores Ltd Welwyn Garden City AL7 1GA\n      Sweet_Potatoes_Q4_(BNA)\n      KT3 4PJ\n      AL7 1GA\n      Greater London\n      Hertfordshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35156\n      0562/2020 Organic\n      2020-10-05\n      Organic Duchy Sweet Potatoes\n      Egypt\n      Waitrose\n      Mill Lane, Swindon SN1 7BX\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      SN1 7BX\n      RG12 8YA\n      Wiltshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35157\n      0563/2020\n      2020-10-05\n      Sweet Potatoes\n      USA\n      Waitrose\n      Mill Lane, Swindon SN1 7BX\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      SN1 7BX\n      RG12 8YA\n      Wiltshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35158\n      2601/2020\n      2020-10-14\n      Sweet Potatoes\n      USA\n      Waitrose\n      Ossington Way, Newark NG24 1FF\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      NG24 1FF\n      RG12 8YA\n      Nottinghamshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35159\n      2601/2020\n      2020-10-14\n      Sweet Potatoes\n      USA\n      Waitrose\n      Ossington Way, Newark NG24 1FF\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      NG24 1FF\n      RG12 8YA\n      Nottinghamshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n  \n\n35160 rows × 17 columns"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#pandas-overview",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#pandas-overview",
    "title": "Communicating code: Tables",
    "section": "pandas overview",
    "text": "pandas overview\n\nUsing pandas we can control various outputs\nBut these still need a format to display within\nAnd display functionality is not easy\n\nOr convert to a html file\ndf2.iloc[:500].to_html('df2_500.html')\nBut using a style sheet as shown in stack overflow by Parfait\n\ndf_out = df2.iloc[:500].copy()\n\npd.set_option('colheader_justify', 'center')   # FOR TABLE <th>\n\nhtml_string = '''\n<html>\n  <head><title>HTML Pandas Dataframe with CSS</title></head>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"df_style.css\"/>\n  <body>\n    {table}\n  </body>\n</html>.\n'''\n\n# OUTPUT AN HTML FILE\nwith open('df2_500.html', 'w') as f:\n    f.write(html_string.format(table=df_out.to_html(classes='mystyle')))"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#section",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#section",
    "title": "Communicating code: Tables",
    "section": "",
    "text": "https://www.python-excel.org/"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#ipydatagrid",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#ipydatagrid",
    "title": "Communicating code: Tables",
    "section": "ipydatagrid",
    "text": "ipydatagrid\nhttps://github.com/bloomberg/ipydatagrid\n\n\nfrom ipydatagrid import DataGrid, TextRenderer, VegaExpr\nimport ipydatagrid\ndatagrid = DataGrid(df2, selection_mode=\"cell\", editable=True,\n                   base_row_size=32, base_column_size=150)\n\ndatagrid = DataGrid(df2, base_row_size=30, base_column_size=150)\ndatagrid"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#itables-code",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#itables-code",
    "title": "Communicating code: Tables",
    "section": "itables code",
    "text": "itables code\nfrom itables import init_notebook_mode\n\nimport itables\ninit_notebook_mode(all_interactive=True)\n\nitables.show(df2)\n\nfrom itables import init_notebook_mode\n\nimport itables\ninit_notebook_mode(all_interactive=True)\n\nitables.show(df2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      sample_id\n      date_of_sampling\n      description\n      country_of_origin\n      retail_outlet\n      address\n      brand_name\n      packer_/_manufacturer_/_importer\n      product\n      address_postcode\n      packer_postcode\n      address_area\n      packer_area\n      chem_name\n      amount_detected\n      mrl\n      amount_pc\n    \n  Loading... (need help?)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#dash",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#dash",
    "title": "Communicating code: Tables",
    "section": "Dash",
    "text": "Dash\nhttps://dash.plotly.com/datatable\n\nDownloaded 800,000 times per month, Dash is the original low-code framework for rapidly building data apps in Python, R, Julia, and F# (experimental).\n\nhttps://medium.com/plotly/introducing-jupyterdash-811f1f57c02e\n\nimport plotly.express as px\nfrom jupyter_dash import JupyterDash\nimport dash_core_components as dcc\nimport dash_html_components as html\nfrom dash.dependencies import Input, Output# Load Data\ndf = px.data.tips()# Build App\napp = JupyterDash(__name__)\napp.layout = html.Div([\n    html.H1(\"JupyterDash Demo\"),\n    dcc.Graph(id='graph'),\n    html.Label([\n        \"colorscale\",\n        dcc.Dropdown(\n            id='colorscale-dropdown', clearable=False,\n            value='plasma', options=[\n                {'label': c, 'value': c}\n                for c in px.colors.named_colorscales()\n            ])\n    ]),\n])# Define callback to update graph\n@app.callback(\n    Output('graph', 'figure'),\n    [Input(\"colorscale-dropdown\", \"value\")]\n)\ndef update_figure(colorscale):\n    return px.scatter(\n        df, x=\"total_bill\", y=\"tip\", color=\"size\",\n        color_continuous_scale=colorscale,\n        render_mode=\"webgl\", title=\"Tips\"\n    )# Run app and display result inline in the notebook\napp.run_server(mode='inline')\n\nC:\\Users\\44781\\AppData\\Local\\Temp\\ipykernel_15260\\3294666565.py:3: UserWarning: \nThe dash_core_components package is deprecated. Please replace\n`import dash_core_components as dcc` with `from dash import dcc`\n  import dash_core_components as dcc\nC:\\Users\\44781\\AppData\\Local\\Temp\\ipykernel_15260\\3294666565.py:4: UserWarning: \nThe dash_html_components package is deprecated. Please replace\n`import dash_html_components as html` with `from dash import html`\n  import dash_html_components as html"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#streamlit",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#streamlit",
    "title": "Communicating code: Tables",
    "section": "Streamlit",
    "text": "Streamlit\n\nA faster way to build and share data apps\n\n\nDash can be run within a notebook but is principally an app.\nStreamlit is a similar app.\nBut much easier to code.\n\nimport pandas as pd\nimport streamlit as st\nall_dfs = pd.read_csv(\"./data/combined_df.csv\")\nst.dataframe(all_dfs.head())"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#and-more",
    "href": "posts/PYTHON/Communicating_Code/CommCodePres_tables.html#and-more",
    "title": "Communicating code: Tables",
    "section": "And more",
    "text": "And more\n\nDataTables\n\nDataTables is a plug-in for the jQuery Javascript library. It is a highly flexible tool, built upon the foundations of progressive enhancement, that adds all of these advanced features to any HTML table.\n\n\n\nJupyter widgets\nIf you are looking for Jupyter widgets, have a look at (taken from https://mwouts.github.io/itables/references.html) - QGrid by Quantopian - IPyaggrid by Louis Raison and Olivier Borderies - IPySheet by QuantStack."
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#content",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#content",
    "title": "Presentation: Communicating code and data",
    "section": "Content",
    "text": "Content\n\nNotebooks\n\nWhat are they?\nExamples\nPros and cons\n\nApps\n\nVoila\nStreamlit\n\nWebsites and HTML\n\nConverting notebooks to HTML and websites\n\nPresentations\n\nUsing notebooks for presentations\n\nTabular Data\n\nComments on Excel\nThoughts on code alternatives"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#jupyter-notebooks",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#jupyter-notebooks",
    "title": "Presentation: Communicating code and data",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nFrom TalkPython: Awesome Jupyter Libraries and Extensions\n\nJupyter is an amazing environment for exploring data and generating executable reports with Python. But there are many external tools, extensions, and libraries to make it so much better and make you more productive.\n\n\nA notebook consists of two parts\n\nmarkdown part where we can:\n\nwrite text, add images, links, html, LaTeX etc\n\ncode part which runs and displays output of code\n\n\nSome links:\n\nJupyter Book\nA curated list of awesome Jupyter projects\nCode Documentation QA of Code\nFastAI guide for better blogs"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-of-a-notebook",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-of-a-notebook",
    "title": "Presentation: Communicating code and data",
    "section": "Example of a notebook",
    "text": "Example of a notebook\nAn example notebook"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-1",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-1",
    "title": "Presentation: Communicating code and data",
    "section": "Markdown in a notebook 1",
    "text": "Markdown in a notebook 1\nSome useful commands:\n\n# Notebooks General and ## Markdown in a notebook 1\n![](ghtop_images/pest.png) looks like this"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-2",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-2",
    "title": "Presentation: Communicating code and data",
    "section": "Markdown in a notebook 2",
    "text": "Markdown in a notebook 2\n\nAnd the same with a mp4 file ![](ghtop_images/revealjs.mp4)\nOr a youtube video \"\""
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-3",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-3",
    "title": "Presentation: Communicating code and data",
    "section": "Markdown in a notebook 3",
    "text": "Markdown in a notebook 3\n\n> If we want text like this\n\n\nIf we want text like this\n\n\nOr if we want code use `a = b + c`\n\nor:\n```\na = b\na = a + c\n```\n\na = b\n\na = a + c"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-4",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-4",
    "title": "Presentation: Communicating code and data",
    "section": "Markdown in a notebook 4",
    "text": "Markdown in a notebook 4\n\nHTML works too\n\n<img src=\"ghtop_images/pest.png\"></img>"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#code-in-a-notebook",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#code-in-a-notebook",
    "title": "Presentation: Communicating code and data",
    "section": "Code in a notebook",
    "text": "Code in a notebook\nExample interactive format using altair:"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#simpler-code-output",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#simpler-code-output",
    "title": "Presentation: Communicating code and data",
    "section": "Simpler code output",
    "text": "Simpler code output\nx = np.arange(0,np.pi,.01)\ny = np.sin(x)\nplt.plot(x,y)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#other-code-stuff",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#other-code-stuff",
    "title": "Presentation: Communicating code and data",
    "section": "Other code stuff",
    "text": "Other code stuff\n\nCan use shell commands e.g. !pip install pandas\nCan use magic commands e.g. %%time to time a cell\n\n%%time\ny=0\nfor x in range(0,100):\n    y+=x\nprint(f\"y is {y}\")\n\n\ny is 4950\nCPU times: total: 0 ns\nWall time: 0 ns"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#but-not-everyone-loves-notebooks",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#but-not-everyone-loves-notebooks",
    "title": "Presentation: Communicating code and data",
    "section": "But Not everyone loves notebooks :(",
    "text": "But Not everyone loves notebooks :(\nNotebooks have their validish detractors I don’t like notebooks.- Joel Grus Youtube"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#notebooks-opinion",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#notebooks-opinion",
    "title": "Presentation: Communicating code and data",
    "section": "Notebooks Opinion",
    "text": "Notebooks Opinion\nAlthough notebooks have their validish detractors I don’t like notebooks.- Joel Grus Youtube I think if you approach them in the right way they are a super powerful tool.\nThe negatives seem to be:\n\nencourage bad practice in code (a genuine problem)\nissues around order of what cell is run (easily got around with good practice)\nissues around lack of auto complete (I don’t see the issue, use in visual studio autocomplete is there)\nno grammar/spelling correction\nissues with using git and version control\n\nthere are ways around this though\n\nanything else?"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#notebook-benefits",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#notebook-benefits",
    "title": "Presentation: Communicating code and data",
    "section": "Notebook Benefits",
    "text": "Notebook Benefits\n\nNotebooks are intuitive\n\nYou have the code then the result of the code\nCan add text or images\nAnd it’s linear\n\nCan get things up and working quickly\nAid with communicating code\nEncourages Writing\n\nand writing things down aids thinking in the now and understanding what you did and why in the future\n\nFastAI guide for better blogs\n\nEasy to convert code to a pipeline\nTreat it as a notebook\n\nin the same way an artist would have a sketchbook to help make final piece\n\nWith many companies moving towards Python/R from Excel and a varied level of skills.\n\n“Aid with communicating code” is particularly important"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-documenting-code",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-documenting-code",
    "title": "Presentation: Communicating code and data",
    "section": "Example: Documenting Code",
    "text": "Example: Documenting Code\n\nHere is my website for my research project on pesticides in UK food\nThis is not the same as documentation for a package but there are parallels\n\nThis does a few things:\n\nDocuments the analysis steps I have taken including the code and outputs\n\nUseful for data transparency, useability of the code if needs modifiying/adapting, and why I did XYZ\n\nProvides a way to present the data\n\nThere is a streamlit app, but sometimes I like to be able to see the code"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-tool-to-aid-learning",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-tool-to-aid-learning",
    "title": "Presentation: Communicating code and data",
    "section": "Example: Tool to aid learning",
    "text": "Example: Tool to aid learning\nA big area I have been using Jupyter Notebooks for is to aid learning\n\nIf you want to understand something it helps to write it down\nHaving the code next to it is a big advantage\nAnd if stored on github you can access it anywhere\n\nTensoflow cheat sheet"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-debugging-code",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-debugging-code",
    "title": "Presentation: Communicating code and data",
    "section": "Example: Debugging Code",
    "text": "Example: Debugging Code\n\nSince starting at ONS I have been working with understanding an existing project and latterly adding code to it\nThe project consists of multiple python files across several folders\n\nMy Python was good but lots of the functions and their useage weren’t immediately obvious to me\n\nbreak-points in VS Studio is really good to step through the code and work out what happens in the code.\n\nI had not used before with Python (but had lots with MATLAB), and it’s really useful\n\nBut it can be limited what you can do\n\ndifficult to probe code if want to write more than 1 line of code\nthe experience/knowledge exists as you go through it but no documentation to refer to later, e.g. function X does this when I give it Y etc"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-debugging-code-2",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-debugging-code-2",
    "title": "Presentation: Communicating code and data",
    "section": "Example: Debugging Code 2",
    "text": "Example: Debugging Code 2\n\nBy copying and pasting code into Jupyter cells I could see and document how they worked (e.g. changing inputs)\n\nThis (copying and pasting) would get around code changes too (which would be an issue if modules were just imported)\nbecause this was all done in Jupyter notebook I can have a ipynb code file and a html file showing how the code works\nI could even save a pickle file of the variables at a particularly point to understand how the code would work from this point"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#apps-overview",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#apps-overview",
    "title": "Presentation: Communicating code and data",
    "section": "Apps Overview",
    "text": "Apps Overview\nThere are many packages that can be used to convert python code to an app\nUsing Notebooks directly\n\nVoila\nmercury\n\nApps without notebooks\n\nPySimpleGUI\n\nSimple and useful but not the best for displaying data\n\nDash\n\nLooks really good, but also super complicated\n\nStreamlit\n\nEasy and looks good"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#voila",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#voila",
    "title": "Presentation: Communicating code and data",
    "section": "Voila",
    "text": "Voila\n\nVoila is relatively simple to use\nrun with something like voila .\\Excel_Voila.ipynb\nconverts notebook to an app\ncan use things like ipywidgets for interactivity\nthe reason I’m interested in it’s use is streamlit doesn’t seem to give flexibility to modify table output I’d like"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-overview",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-overview",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Overview",
    "text": "Streamlit Overview\n\nStreamlit is an open-source Python library that makes it easy to create and share beautiful, custom web apps for machine learning and data science. In just a few minutes you can build and deploy powerful data apps. So let’s get started!\n\nPrincipally used to create apps, but some of the functionality works well for code/data presentations"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-overview",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-overview",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: overview",
    "text": "Streamlit Functionality: overview\nStreamlit allows various functionality:\n\ntextbox\nimages/videos\ncharts/tables\nmenus/buttons\netc"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-streamlit_layout",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-streamlit_layout",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: streamlit_layout",
    "text": "Streamlit Functionality: streamlit_layout\nBut unlike some apps (am thinking MATLAB GUIs) you can’t create the look and functionality separately. So if you want something in a certain position it can be tricky. HTML can be used with st.markdown to give more control but it isn’t recommended to use by streamlit.\nInstead, to create the layout as you would like they have the following features:"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-columns-and-sidebar",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-columns-and-sidebar",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: columns and sidebar",
    "text": "Streamlit Functionality: columns and sidebar\nThe most useable are the first two: columns and sidebar\nColumns allows us to split the app vertically. The code is fairly simple:\nEither colL, colM, colR = st.columns(3) for 3 equal columns or to split columns with different sizes:\ncolL, _, colR = st.columns((10, 5, 20))\nwith colL:\n    st.write('On the left')\nwith colR:\n    st.write('On the right twice as big as left')\nst.sidebar just adds a sidebar to the app that can be hidden or shown.\nAnything in the sidebar is just prefixed by st.sidebar so:\nst.sidebar.write('I am in the sidebar')\nst.write('I am in the main app')\nst.sidebar.write('I am back in the sidebar')"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-html",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-html",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: html",
    "text": "Streamlit Functionality: html\nIt is possible to add various additional personalisations using html. - BUT it does come with security risks and so is [not recommended]](https://github.com/streamlit/streamlit/issues/152)\n\nAllows much more control over the layout of the app that can be useful for a presentation: - Can add a background image - Can add background color to a textbox - Control over positioning of widgets - lots more\nHTML is implementated using st.markdown with unsafe_allow_html=True inside the former"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-html-examples",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-html-examples",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: html examples",
    "text": "Streamlit Functionality: html examples\nadd background to a text box\ntext = \"Code Examples\"\n        st.markdown(f'<center><p style=font-family:\"Calibri\";background-color:#FFFFFF;color:#000000;font-size:42px;border-radius:10%><b>{text}</b></p></center>', unsafe_allow_html=True)\n\nOr to add a background image\nimport streamlit as st\nimport base64\n\n@st.cache(allow_output_mutation=True)\ndef get_base64_of_bin_file(bin_file):\n    with open(bin_file, 'rb') as f:\n        data = f.read()\n    return base64.b64encode(data).decode()\n\ndef set_png_as_page_bg(png_file):\n    bin_str = get_base64_of_bin_file(png_file) \n    page_bg_img = '''\n    <style>\n    .stApp {\n    background-image: url(\"data:image/png;base64,%s\");\n    background-size: contain;\n    background-repeat: no-repeat;\n    background-attachment: scroll; # doesn't work\n    }\n    </style>\n    ''' % bin_str\n    st.markdown(page_bg_img, unsafe_allow_html=True)\n    return"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-echo",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-echo",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: echo",
    "text": "Streamlit Functionality: echo\n\nSometimes you want your Streamlit app to contain both your usual Streamlit graphic elements and the code that generated those elements. That’s where st.echo() comes in\n\nEasier to display this by an example:\n\nIn the example above the right of the image is given below (st.columns is used, where the input for the function is found from the left column).\n\nst.echo is used with the with statement.\neverything within the with is printed to the screen and executed\n\nwith st.echo():\n    # Everything inside this block will be both printed to the screen\n    # and executed.\n\n    def do_pd_replace(text, text_search, text_sub):\n        col_name = \"Start string\"\n        df = pd.DataFrame(data=[text], columns=[col_name])\n\n        df[\"Final String\"] = df[col_name].replace(\n            text_search, text_sub, regex=True\n        )\n\n        st.dataframe(df)\n        st.write(f\"text_search = '{text_search}' and text_sub = '{text_sub}'\")\n        st.write(f\"Input string = '{text}'\")\n        st.write(f\"Output string = '{df['Final String'].values[0]}'\")\n\n    do_pd_replace(text, text_search, text_sub)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-pages",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-pages",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: pages",
    "text": "Streamlit Functionality: pages\nBy simply creating a folder called pages and putting other streamlit .py files in the folder they can then be accessed in the sidebar.\n\nA main file needs to be outside the pages folder\nThe .py files in pages behave as if they were outside the folder (i.e. when loading files/functions)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-streamlit-presentation",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#example-streamlit-presentation",
    "title": "Presentation: Communicating code and data",
    "section": "Example Streamlit Presentation",
    "text": "Example Streamlit Presentation\nVideo"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#what-i-have-used-to-convert-notebooks-to-html",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#what-i-have-used-to-convert-notebooks-to-html",
    "title": "Presentation: Communicating code and data",
    "section": "What I have used to convert notebooks to html",
    "text": "What I have used to convert notebooks to html\n\nfastpages\n\nI have used fastpages, but this is now deprecated and they are recommending the use of quarto\n\nquarto\n\nSo far I have found quarto really good and flexible (N.B. R works too)\nEasy to convert a notebook to multiple formats, including html, powerpoint, pdf, word doc\nBUT Quarto is not possible if installing from non pip sources is an issue (as far as I can tell currently)\n\nnbconvert is another option I tried\n\nbut it doesn’t seem to have the functionality of fastpages or quarto\n\nJupyter Books seems to be the best option within companies with installation issues\n\nMaybe not as good as quarto but it works!"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#others",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#others",
    "title": "Presentation: Communicating code and data",
    "section": "Others",
    "text": "Others\n\nI know some people use Sphinx,\n\nis recommended by QA\nFrom what I can tell sphinx on it’s own is not as easy to use as notebooks\nBut there is a jupyter extension nbsphinx\nJupyter Books uses Sphinx heavily under the hood\n\nnbdev\n\nI think is connected to quarto\n\nVoila\n\nVoilà turns Jupyter notebooks into standalone web applications.\nLooks good, bit like streamlit\nbut seems to interfere with other libraries\nmercury seems similar"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-html-other-formats",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-html-other-formats",
    "title": "Presentation: Communicating code and data",
    "section": "Creating html (& other formats)",
    "text": "Creating html (& other formats)\nQuarto\nInstallation is via a package i.e. .msi for Windows or .pkg for Mac. Which can cause issues.\nWorks with both ipynb and qmd files, which are both a mixture of markdown and executable code.\nThe only thing that needs to be done with the notebook is add a YAML block at the start of the notebook, like the following (raq not markdown was used):\n---\ntitle: \"Communicating code: Website\"\nsubtitle: \"Using the notebook format for a website\"\nauthor: \"Thomas H. Simm\"\nformat:\n  html:\n    toc: true\ntitle-slide-attributes:\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\njupyter: python3\n---\nWe can create different files from this .ipynb Jupyter notebook using the following code:\n\nquarto render testPres.ipynb --to pptx\nquarto render testPres.ipynb --to pdf\nquarto render testPres.ipynb --to html\nquarto render testPres.ipynb --to revealjs"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-1",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-1",
    "title": "Presentation: Communicating code and data",
    "section": "Quarto",
    "text": "Quarto\nFurther, formatting for projects (i.e. for website) can be done within the configuration file _quarto.yml\nproject:\n  type: website\n  output-dir: _site\n\nwebsite:\n  title: \"ThomasHSimm\"\n  favicon: /posts/Picture3.png\n  body-header: <img src=\"/posts/header2.png\" height=200>\n\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/ThomasHSimm\n      - icon: mortarboard-fill\n        href: https://scholar.google.com/citations?hl=en&user=HdPDn1sAAAAJ\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#jupyter-books",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#jupyter-books",
    "title": "Presentation: Communicating code and data",
    "section": "Jupyter Books",
    "text": "Jupyter Books\nWe can create different files from this .ipynb Jupyter notebook using the following code:\n\njupyter-book build .\\PesticideDocs\\\njupyter-book build <path-to-book>\njupyter-book build <path-to-book> --builder pdfhtml\njupyter-book build <path-to-book> --builder singlehtml\n\nThe only difference in notebook is that it needs to have One header in a markdown cell for the table of contents, e.g. \n# Title of page"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#configuration-file",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#configuration-file",
    "title": "Presentation: Communicating code and data",
    "section": "Configuration file",
    "text": "Configuration file\nA seperate files _config.yml is used to define how the html (or other) files will look\n# Book settings\n# Learn more at https://jupyterbook.org/customize/config.html\n\ntitle: Defra Pesticide Testing, Data Analysis\nauthor: Thomas Simm\nlogo: ONS-logo.png\nexclude_patterns: [_build, Thumbs.db, .DS_Store, \"**.ipynb_checkpoints\"]\n\n\n# Force re-execution of notebooks on each build.\n# See https://jupyterbook.org/content/execute.html\nexecute:\n  execute_notebooks: force\n\n# Define the name of the latex output file for PDF builds\nlatex:\n  latex_documents:\n    targetname: book.tex\n\n# Add a bibtex file so that we can create citations\nbibtex_bibfiles:\n  - references.bib\n\n# Information about where the book exists on the web\nrepository:\n  url: https://github.com/ThomasHSimm/Pesticide  # Online location of your book\n  path_to_book: docs  # Optional path to your book, relative to the repository root\n  branch: master  # Which branch of the repository should be used when creating links (optional)\n\n# Add GitHub buttons to your book\n# See https://jupyterbook.org/customize/config.html#add-a-link-to-your-repository\n# HTML-specific settings\nhtml:\n  favicon                   : \"_images/favicon.jpg\"  # A path to a favicon image\n  use_edit_page_button      : false  # Whether to add an \"edit this page\" button to pages. If `true`, repository information in repository: must be filled in\n  use_repository_button     : false  # Whether to add a link to your repository button\n  use_issues_button         : false  # Whether to add an \"open an issue\" button\n  use_multitoc_numbering    : true   # Continuous numbering across parts/chapters\n  extra_navbar              : Powered by <a href=\"https://jupyterbook.org\">Jupyter Book</a>\n                              <br>Home website <a href=\"https://thomashsimm.com/\">thomashsimm.com</a> # Will be displayed underneath the left navbar.\n  extra_footer              : \"\"  # Will be displayed underneath the footer.\n  google_analytics_id       : \"\"  # A GA id that can be used to track book views.\n  home_page_in_navbar       : true  # Whether to include your home page in the left Navigation Bar\n  baseurl                   : \"\"  # The base URL where your book will be hosted. Used for creating image previews and social links. e.g.: https://mypage.com/mybook/\n  comments:\n    hypothesis              : false\n    utterances              : false\n  announcement              : \"\" # A banner announcement at the top of the site."
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#table-of-content",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#table-of-content",
    "title": "Presentation: Communicating code and data",
    "section": "Table of content",
    "text": "Table of content\nAnd in addition to the config file a table of contents file is required _toc.yml:\n# Table of contents\n# Learn more at https://jupyterbook.org/customize/toc.html\n\nformat: jb-book\nroot: intro\nchapters:\n- file: Pesticide_Plots\n- file: References\n- file: UK_areas\n- file: using_jupyter_books"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-webpage-from-this",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-webpage-from-this",
    "title": "Presentation: Communicating code and data",
    "section": "Creating a webpage from this",
    "text": "Creating a webpage from this\nTakes about 30 mins including installing the chosen converter. (But can be done much quicker)\n\ncreate a Github repo for your website\nchoose the converter (e.g. Jupyter Books)\n\nAnd follow their instructions\n\ngo to settings -> Pages within the repo\n\nfew options to do\n\nOptional: add your own website url to it\n\nLink how to do this here\nIn Quarto a command from your PC in the repo, publishes the website:\nquarto publish quarto-pub\nOr equivalently with Jupyter Books:\nghp-import -n -p -f _build/html"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-directly-from-the-repo",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-directly-from-the-repo",
    "title": "Presentation: Communicating code and data",
    "section": "Creating directly from the repo",
    "text": "Creating directly from the repo\nIf we instead want to convert notebook files directly from a repo to create a website then this can be done with Netlify.\nThis is useful if using Gitlab (i.e. not Github) or don’t want all the extra html files cluttering the repo.\nSteps:\nhttps://jupyterbook.org/en/stable/publish/netlify.html\n\nSign up and connect Github/Gitlab\nAdd a requirements.txt file and also toc.yml to directory\nOn netlify -> Add new site -> import from an existing repo\nInsert something like below\n\nN.B. the command:\npip install -r requirements.txt && jupyter-book build .\nand folder location"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#on-netlify",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#on-netlify",
    "title": "Presentation: Communicating code and data",
    "section": "On netlify",
    "text": "On netlify\n\nExample:\n\nGitlab repo\nResulting website https://thomashsimm.netlify.app/intro.html"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-presentations",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-presentations",
    "title": "Presentation: Communicating code and data",
    "section": "Quarto Presentations",
    "text": "Quarto Presentations\nQuarto supports a variety of formats for creating presentations, including:\n\nrevealjs — reveal.js (HTML)\npptx — PowerPoint (MS Office)\nbeamer — Beamer (LaTeX/PDF)\n\nI’ll consider the first two"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-powerpoint-overview",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-powerpoint-overview",
    "title": "Presentation: Communicating code and data",
    "section": "Quarto PowerPoint overview",
    "text": "Quarto PowerPoint overview\nThe steps to make a PowerPoint presentation from a notebook:\n\nCreate the inbuilt template.pptx file\nAdjust it to match your own template\nAt the top of the notebook insert format for pptx including the template file\nChoose how you will define a new page\nYou will probably need to manually check the slides and adjust as required\n\nespecially for interactive content and code"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-the-template",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-the-template",
    "title": "Presentation: Communicating code and data",
    "section": "Creating the template",
    "text": "Creating the template\n(Office info correct for Office 365 Feb 2023, Version 2301 Build 16.0.16026.20002)\nIf your workplace has a custom template or you have one you always use, you can incorporate this into quarto.\nHowever, quarto is quite specific on the form this template takes, and requires the following elements\n\nTitle Slide\nTitle and Content\nSection Header\nTwo Content\nComparison\nContent with Caption\nBlank"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template",
    "title": "Presentation: Communicating code and data",
    "section": "Creating a ppt template",
    "text": "Creating a ppt template\nBy selecting Layout from the Home tab in powerpoint the different layouts can be seen\n\nThey can then be modified by going to View tab - Slide Master."
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template-2",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template-2",
    "title": "Presentation: Communicating code and data",
    "section": "Creating a ppt template 2",
    "text": "Creating a ppt template 2\nIf using your own template you will need to match the names of the slides given above. These can be found by hovering over the slides on the left or right clicking on one and selecting “Rename Layout”"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template-3",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template-3",
    "title": "Presentation: Communicating code and data",
    "section": "Creating a ppt template 3",
    "text": "Creating a ppt template 3\nAlternatively, create a custom template using quarto and then modify this. The following command creates the template:\nquarto pandoc -o template.pptx --print-default-data-file reference.pptx\nThen go to View tab - Slide Master and modify each slide layout.\nNote if you are trying to match a template, some tips: - go to Design -> Slide Size and match this to your template - when View tab - Slide Master is selected go to first tab (see above it will be left indented) on one you are copying from and select all on this then paste to the new template - these will be background images and other things that want to be passed to all slides - Check other slides for images and font-styles etc to match to the new template"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#load-the-template",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#load-the-template",
    "title": "Presentation: Communicating code and data",
    "section": "Load the template",
    "text": "Load the template\nTo load the template the first cell in the notebook needs to be modified as follows to reference the template.pptx file.\nformat:\n  pptx:\n    reference-doc: template.pptx\n    slide-level: 2\nIn addition, we can also specify here the rule by which a new slide is defined. If slide-level: 2 is used a new slide is defined by “##’ and a new section header by ‘#’. So if we used ‘###’ this would be a heading within the slide.\nIf slide-level: 1 is used a new slide is defined by “#’ and ‘##’ this would be a heading within the slide (this is normally the default)."
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#check-the-slides",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#check-the-slides",
    "title": "Presentation: Communicating code and data",
    "section": "Check the slides",
    "text": "Check the slides\nI have found creation of slides to powerpoint more prone to strange results than if .doc/.pdf/.html are used.\nSo check the slides, see if interactive content or code has been included (probably not) and if the slide content goes outside the slide.\n\nIn the example above - There is overlap of text on a slide - Strange ouput of a slide - Code output not displayed"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#adding-style-to-revealjs",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#adding-style-to-revealjs",
    "title": "Presentation: Communicating code and data",
    "section": "Adding style to revealjs",
    "text": "Adding style to revealjs\nA simple way to add template like details to a revealjs file is to add a style.css sheet.\nIn the example below, the style sheet adds logo.png to the bottom right of each sheet\nThe file style.css looks like this:\n.reveal .slide-logo {\n  display: block;\n  position: fixed;\n  top: unset !important;\n  left: unset !important;\n  bottom: 50px;\n  right: 12px;\n  height: 100px !important;\n  width: 100x !important;\n  max-width: unset !important;\n  max-height: unset !important;\n}"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#adding-style-to-revealjs-1",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#adding-style-to-revealjs-1",
    "title": "Presentation: Communicating code and data",
    "section": "Adding style to revealjs",
    "text": "Adding style to revealjs\nAnd the revealjs part at the top of the jupyter notebook looks like this\nrevealjs:\n    slide-number: true\n    height: 1080\n    width: 1920\n    logo: logo.png\n    css: style.css\nSo this would then look like the following, with the logo (logo.png) in the bottom right, and size and positioning given by the css file"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#what-the-revealjs-file-looks-like",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#what-the-revealjs-file-looks-like",
    "title": "Presentation: Communicating code and data",
    "section": "What the revealjs file looks like",
    "text": "What the revealjs file looks like\nVideo"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#excel-files",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#excel-files",
    "title": "Presentation: Communicating code and data",
    "section": "Excel files",
    "text": "Excel files\n\nChatGPT: What are the problems of Excel and xlsx files?\n\n\nLimited scalability: Excel has a limit on the number of rows and columns it can handle effectively.\nInaccurate data: The manual nature of data entry in Excel can lead to errors and inaccuracies.\nFragility: Complex Excel spreadsheets can break easily if any formula or cell reference is altered.\nLack of security: Excel files are vulnerable to unauthorized access and malicious attacks.\nSlow performance: Large and complex Excel files can become slow to open and use, leading to decreased productivity.\nCompatibility issues: XLSX files may not be compatible with older versions of Excel, or with other software applications.\nLimited collaboration: Sharing Excel files and making changes to them can be difficult, especially when multiple people are involved.\n\nFor me it is the Slow performance alongside: (a) we are doing the data manipulation outside Excel anyway and (b) having to have another application open"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#what-aspect-of-tables-i-am-considering",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#what-aspect-of-tables-i-am-considering",
    "title": "Presentation: Communicating code and data",
    "section": "What aspect of tables I am considering",
    "text": "What aspect of tables I am considering"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#loading-data",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#loading-data",
    "title": "Presentation: Communicating code and data",
    "section": "Loading data",
    "text": "Loading data\n.ods with Excel\nAbout 10 s to open 3 ods files with Excel\n.ods converted to html in firefox browser\nAbout 6 s to open 3 converted ods files in a browser\n.ods converted to html firefox browser no new tabs\nAlmost instant when open converted ods files in same browser"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#convert-xlsx-to-html",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#convert-xlsx-to-html",
    "title": "Presentation: Communicating code and data",
    "section": "Convert xlsx to html?",
    "text": "Convert xlsx to html?\n\nOpening xlsx files in Excel is slow\nConverting to html if we don’t want to edit could be an option\nIf we are moving to Python/R aren’t non-Excel options worth considering??\n\nConverting xlsx files to html\n\nSeems the most obvious course\nBut it doesn’t seem that easy with code\n\nbut easy within Excel"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#pandas",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#pandas",
    "title": "Presentation: Communicating code and data",
    "section": "pandas",
    "text": "pandas\n\nSince (in Python) we are mainly working with pandas. Let’s consider how pandas outputs can be modified.\npandas options\n\nSome code functionality\n# precision of all columns\npd.set_option(\"display.precision\", 2)\n# Or map as a string\ndf2['amount_pc_str'] = df2['amount_pc'].map(lambda x: '%.3f' % x)\n# some other options\npd.set_option('max_colwidth', 20)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', 0)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#pandas-basic",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#pandas-basic",
    "title": "Presentation: Communicating code and data",
    "section": "pandas basic",
    "text": "pandas basic\n\n\n\n\n\n\n  \n    \n      \n      sample_id\n      date_of_sampling\n      description\n      country_of_origin\n      retail_outlet\n      address\n      brand_name\n      packer_/_manufacturer_/_importer\n      product\n      address_postcode\n      packer_postcode\n      address_area\n      packer_area\n      chem_name\n      amount_detected\n      mrl\n      amount_pc\n    \n  \n  \n    \n      0\n      1958/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Asda\n      Creechbarrow Road, Taunton TA1 2AN\n      Asda\n      Asda Stores Ltd Leeds, UK LS11 5AD\n      Apple\n      TA1 2AN\n      LS11 5AD\n      Somerset\n      West Yorkshire\n      boscalid\n      0.03\n      2.0\n      0.015\n    \n    \n      1\n      1958/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Asda\n      Creechbarrow Road, Taunton TA1 2AN\n      Asda\n      Asda Stores Ltd Leeds, UK LS11 5AD\n      Apple\n      TA1 2AN\n      LS11 5AD\n      Somerset\n      West Yorkshire\n      pyraclostrobin\n      0.01\n      0.5\n      0.020\n    \n    \n      2\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      boscalid\n      0.05\n      2.0\n      0.025\n    \n    \n      3\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      flonicamid (sum)\n      0.02\n      0.2\n      0.100\n    \n    \n      4\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      pyraclostrobin\n      0.03\n      0.5\n      0.060\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      35155\n      2858/2020 Organic\n      2020-10-20\n      Organic Sweet Potatoes\n      Spain\n      Tesco\n      300 Beverley Way, New Malden KT3 4PJ\n      Tesco\n      Tesco Stores Ltd Welwyn Garden City AL7 1GA\n      Sweet_Potatoes_Q4_(BNA)\n      KT3 4PJ\n      AL7 1GA\n      Greater London\n      Hertfordshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35156\n      0562/2020 Organic\n      2020-10-05\n      Organic Duchy Sweet Potatoes\n      Egypt\n      Waitrose\n      Mill Lane, Swindon SN1 7BX\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      SN1 7BX\n      RG12 8YA\n      Wiltshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35157\n      0563/2020\n      2020-10-05\n      Sweet Potatoes\n      USA\n      Waitrose\n      Mill Lane, Swindon SN1 7BX\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      SN1 7BX\n      RG12 8YA\n      Wiltshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35158\n      2601/2020\n      2020-10-14\n      Sweet Potatoes\n      USA\n      Waitrose\n      Ossington Way, Newark NG24 1FF\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      NG24 1FF\n      RG12 8YA\n      Nottinghamshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35159\n      2601/2020\n      2020-10-14\n      Sweet Potatoes\n      USA\n      Waitrose\n      Ossington Way, Newark NG24 1FF\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      NG24 1FF\n      RG12 8YA\n      Nottinghamshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n  \n\n35160 rows × 17 columns"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#pandas-overview",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#pandas-overview",
    "title": "Presentation: Communicating code and data",
    "section": "pandas overview",
    "text": "pandas overview\n\nUsing pandas we can control various outputs\nBut these still need a format to display within\nAnd display functionality is not easy\n\nOr convert to a html file\ndf2.iloc[:500].to_html('df2_500.html')\nBut using a style sheet as shown in stack overflow by Parfait"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#ipydatagrid",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#ipydatagrid",
    "title": "Presentation: Communicating code and data",
    "section": "ipydatagrid",
    "text": "ipydatagrid\nhttps://github.com/bloomberg/ipydatagrid"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code",
    "title": "Presentation: Communicating code and data",
    "section": "itables code",
    "text": "itables code\nfrom itables import init_notebook_mode\n\nimport itables\ninit_notebook_mode(all_interactive=True)\n\nitables.show(df2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      sample_id\n      date_of_sampling\n      description\n      country_of_origin\n      retail_outlet\n      address\n      brand_name\n      packer_/_manufacturer_/_importer\n      product\n      address_postcode\n      packer_postcode\n      address_area\n      packer_area\n      chem_name\n      amount_detected\n      mrl\n      amount_pc\n    \n  Loading... (need help?)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#dash",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#dash",
    "title": "Presentation: Communicating code and data",
    "section": "Dash",
    "text": "Dash\nhttps://dash.plotly.com/datatable\n\nDownloaded 800,000 times per month, Dash is the original low-code framework for rapidly building data apps in Python, R, Julia, and F# (experimental).\n\nhttps://medium.com/plotly/introducing-jupyterdash-811f1f57c02e\n\n\nOSError: Address 'http://127.0.0.1:8050' already in use.\n    Try passing a different port to run_server."
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit",
    "text": "Streamlit\n\nA faster way to build and share data apps\n\n\nDash can be run within a notebook but is principally an app.\nStreamlit is a similar app.\nBut much easier to code.\n\nimport pandas as pd\nimport streamlit as st\nall_dfs = pd.read_csv(\"./data/combined_df.csv\")\nst.dataframe(all_dfs.head())\n# Or\nst.tables(all_dfs)"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#and-more",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#and-more",
    "title": "Presentation: Communicating code and data",
    "section": "And more",
    "text": "And more\nDataTables\n\nDataTables is a plug-in for the jQuery Javascript library. It is a highly flexible tool, built upon the foundations of progressive enhancement, that adds all of these advanced features to any HTML table.\n\nJupyter widgets\nIf you are looking for Jupyter widgets, have a look at (taken from https://mwouts.github.io/itables/references.html) - QGrid by Quantopian - IPyaggrid by Louis Raison and Olivier Borderies - IPySheet by QuantStack."
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#more-details-on-itables",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#more-details-on-itables",
    "title": "Presentation: Communicating code and data",
    "section": "More details on itables",
    "text": "More details on itables\nFrom my brief review I found itables the best package\n\nIt works\nIt gives lots of control of table output to be consistent with good-practice\n\nColumn width\nNumber formatting\nColumn alignment\n\nAlongside\n\nSearch\nColumn ordering\nHow many rows are shown\nScrolling options\netc"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code1",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code1",
    "title": "Presentation: Communicating code and data",
    "section": "itables code1",
    "text": "itables code1\ndef _indi_columnDefs(cols, format,col_width):\n    if 'num_format' in format:\n        if format['num_format'] == \"#,##0\":\n            format_str = \"',', '.', 0, ''\"\n        elif format['num_format'] ==  '0.0':\n            format_str = \"',', '.', 1, ''\"\n        else: \n            format_str = \"',', '.', 3, ''\"\n    else:\n        format_str = \"',', '.', 3, ''\"\n    columnDefs= {\n            \"targets\": cols,\n            \"className\":f\"dt-{format['align']}\",\n            \"render\": JavascriptCode(f\"$.fn.dataTable.render.number({format_str})\"),\n            \"width\": f\"{col_width}px\",\n        }\n    return columnDefs"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code2",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code2",
    "title": "Presentation: Communicating code and data",
    "section": "itables code2",
    "text": "itables code2\nstyle = {\n    \"general\": {\n        \"table_output\" :{\n            \"pct_cols\" : {\n                \"regex_defined\": [\"%\" , \"[Pp]ercentage\"],\n                \"format\": {\"num_format\": \"0.0\", \"align\": \"right\"}\n            },\n            \"total_cols\" : {\n                    \"regex_defined\": [\"[Tt]otal\" ],\n                    \"format\": { \"num_format\": \"0.0\", \"align\": \"center\"}\n            },\n            \"code_cols\" : {\n                \"regex_defined\": [\"[Cc]ode\"],\n                \"format\": { \"align\": \"left\"}\n            },\n            \"_else\" : {\n                \"regex_defined\": [],\n                \"format\": {\"num_format\": \"#,##0\", \"align\": \"right\"}\n            }\n        \n        },\n        \"col_width\": 130.0\n    }\n}"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code3",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code3",
    "title": "Presentation: Communicating code and data",
    "section": "itables code3",
    "text": "itables code3\n\ndef _create_style_col(style: dict, df: pd.DataFrame):\n    style_col = {}\n    colsAll=[]\n    for keys in style['general']['table_output'].keys():\n        if keys !='_else':\n            # print(\">>\",keys)\n            cols=[]\n            for i,column in enumerate(df.columns):\n                # print(column)\n                if [True for reg in style['general']['table_output'][keys]['regex_defined'] if re.search(reg,column)]:\n                    # print(i,column)\n                    cols.append(i)\n            # print(cols)\n            colsAll = colsAll + cols\n            style_col[keys]=cols\n\n    style_col['_else'] = [ i for i,column in enumerate(df.columns) if i not in colsAll]\n\n    return style_col"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code4",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code4",
    "title": "Presentation: Communicating code and data",
    "section": "itables code4",
    "text": "itables code4\ndef create_columnDefs(style: dict, df: pd.DataFrame):\n    \n    style_col = _create_style_col(style, df)\n    columnDefs = []\n    for keys in style['general']['table_output'].keys():\n        columnDefs.append( _indi_columnDefs(style_col[keys],\n                                            style['general']['table_output'][keys]['format'],\n                                            style['general']['col_width']) )\n    return columnDefs"
  },
  {
    "objectID": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code5",
    "href": "posts/PYTHON/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code5",
    "title": "Presentation: Communicating code and data",
    "section": "itables code5",
    "text": "itables code5\n\ncolumnDefs= create_columnDefs(style, data)\nshow(\n    data,\n    # style=\"table-layout:auto;width:80%;float:left\",\n    classes=\"display\",\n    \n    # specify how many rows\n    lengthMenu = [25,100,-1],\n    # or to scroll through data\n    scrollX=True,\n    # scrollY=\"800px\", \n    scrollCollapse=True, \n    # paging=False,\n\n    style=f\"width:{style['general']['col_width']*10}px\",\n    autoWidth=False,\n\n    # add footer\n    # footer=True,\n    \n    columnDefs=columnDefs,\n    tags =f'<caption style=\"caption-side: Bottom\">File: {files[0]} and Tab: {ansa.value}</caption>'\n)"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-is-the-cloud",
    "href": "posts/PYTHON/others_python/AWS.html#what-is-the-cloud",
    "title": "AWS Cheat sheet",
    "section": "What is the Cloud?",
    "text": "What is the Cloud?\nIn the past, companies and organizations hosted and maintained hardware such as compute, storage, and networking equipment in their own data centers. They needed to allocate entire infrastructure departments to take care of them, resulting in a costly operation that made some workloads and experimentation impossible.\nAs internet usage became more widespread, the demand for compute, storage, and networking equipment increased. For some companies and organizations, the cost of maintaining a large physical presence was unsustainable. To solve this problem, cloud computing was created.\nCloud computing is the on-demand delivery of IT resources over the internet with pay-as-you-go pricing. You no longer have to manage and maintain your own hardware in your own data centers. Companies like AWS own and maintain these data centers and provide virtualized data center technologies and services to users over the internet.\nTo help differentiate between running workloads on-premises versus in the cloud, consider the scenario where your developers need to deploy a new feature on your application. Before they deploy, the team wants to test the feature in a separate quality assurance (QA) environment that has the exact same configurations as production.\nIf you run your application on-premises, creating this additional environment requires you to buy and install hardware, connect the necessary cabling, provision power, install operating systems, and more. All of these tasks can be time-consuming and take days to perform. Meanwhile, the new product feature’s time-to-market is increasing and your developers are waiting for this environment.\nIf you ran your application in the cloud, you can replicate the entire environment as often as needed in a matter of minutes or even seconds. Instead of physically installing hardware and connecting cabling, you can logically manage your physical infrastructure over the internet.\nUsing cloud computing not only saves you time from the set-up perspective, but it also removes the undifferentiated heavy lifting. If you look at any application, you’ll see that some of the aspects of it are very important to your business, like the code. However, there are other aspects that are no different than any other application you might make: for instance the compute the code runs on. By removing repetitive common tasks that don’t differentiate your business, like installing virtual machines, or storing backups, you can focus on what is strategically unique to your business and let AWS handle the tasks that are time consuming and don’t separate you from your competitors.\nSo where does AWS fit into all of this? Well AWS simply just provides cloud computing services. Those IT resources mentioned in the cloud computing definition are AWS services in this case. We’ll need to use these AWS services to architect a scalable, highly available, and cost effective infrastructure to host our corporate directory application. This way we can get our corporate directory app out into the world quickly, without having to manage any heavy-duty physical hardware. There are the six main advantages to running your workloads on AWS."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#the-six-benefits-of-cloud-computing",
    "href": "posts/PYTHON/others_python/AWS.html#the-six-benefits-of-cloud-computing",
    "title": "AWS Cheat sheet",
    "section": "The Six Benefits of Cloud Computing",
    "text": "The Six Benefits of Cloud Computing\n\nPay as you go. Instead of investing in data centers and hardware before you know how you are going to use them, you pay only when you use computing resources, and pay only for how much you use.\nBenefit from massive economies of scale. By using cloud computing, you can achieve a lower cost than you can get on your own. Because usage from hundreds of thousands of customers is aggregated in the cloud, AWS can achieve higher economies of scale, which translates into lower pay as-you-go prices.\nStop guessing capacity. Eliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often end up either sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little capacity as you need, and scale up and down as required with only a few minutes notice.\nIncrease speed and agility. IT resources are only a click away, which means that you reduce the time to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization since the cost and time it takes to experiment and develop is significantly lower.\nStop spending money running and maintaining data centers. Focus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your customers, rather than on the heavy lifting of racking, stacking, and powering physical infrastructure. This is often referred to as undifferentiated heavy lifting.\nGo global in minutes. Easily deploy your application in multiple Regions around the world with just a few clicks. This means you can provide lower latency and a better experience for your customers at a minimal cost.\n\n\nhttps://aws.amazon.com/what-is-cloud-computing/\nhttp://docs.aws.amazon.com/whitepapers/latest/aws-overview/types-of-cloud-computing.html\nhttps://aws.amazon.com/what-is-aws/\n\n\nAWS Global Infrastructure\n\nInfrastructure, like data centers and networking connectivity, still exists as the foundation of every cloud application. In AWS, this physical infrastructure makes up the AWS Global Infrastructure, in the form of Availability Zones and Regions.\nRegions are geographic locations worldwide where AWS hosts its data centers. AWS Regions are named after the location where they reside. For example, in the United States, there is a Region in Northern Virginia called the Northern Virginia Region and a Region in Oregon called the Oregon Region. There are Regions in Asia Pacific, Canada, Europe, the Middle East, and South America, and AWS continues to expand to meet the needs of its customers.\nEach AWS Region is associated with a geographical name and a Region code.\nfor example, - us-east-1: This is the first Region created in the east of the US. The geographical name for this Region is N. Virginia. - ap-northeast-1: The first Region created in the northeast of Asia Pacific. The geographical name for this Region is Tokyo.\n\nChoose the Right AWS Region\nConsider four main aspects when deciding which AWS Region to host your applications and workloads: latency, price, service availability, and compliance.\n\nLatency. If your application is sensitive to latency, choose a Region that is close to your user base. This helps prevent long wait times for your customers. Synchronous applications such as gaming, telephony, WebSockets, and IoT are significantly affected by higher latency, but even asynchronous workloads, such as ecommerce applications, can suffer from an impact on user connectivity.\nPrice. Due to the local economy and the physical nature of operating data centers, prices may vary from one Region to another. The pricing in a Region can be impacted by internet connectivity, prices of imported pieces of equipment, customs, real estate, and more. Instead of charging a flat rate worldwide, AWS charges based on the financial factors specific to the location.\n\nService availability. Some services may not be available in some Regions. The AWS documentation provides a table containing the Regions and the available services within each one.\nData compliance. Enterprise companies often need to comply with regulations that require customer data to be stored in a specific geographic territory. If applicable, you should choose a Region that meets your compliance requirements."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#availability-zones",
    "href": "posts/PYTHON/others_python/AWS.html#availability-zones",
    "title": "AWS Cheat sheet",
    "section": "Availability Zones",
    "text": "Availability Zones\nInside every Region is a cluster of Availability Zones (AZ). An AZ consists of one or more data centers with redundant power, networking, and connectivity. These data centers operate in discrete facilities with undisclosed locations. They are connected using redundant high-speed and low-latency links.\n\nWhat is low latency link? Low latency describes a computer network that is optimized to process a very high volume of data messages with minimal delay (latency).\n\n\nWhat does redundant mean in routing? Failover or Redundant routing is a network arrangement with several links and paths between the person who places a call and the call recipient. Should at any time a path or link in the network, the other links will automatically route the incoming call to a predetermined number, device or location.\n\nAZs also have a code name. Since they’re located inside Regions, they can be addressed by appending a letter to the end of the Region code name. For example:\n\nus-east-1a: an AZ in us-east-1 (Northern Virginia Region)\nsa-east-1b: an AZ in sa-east-1 (São Paulo Region in South America)\n\nIf you see that a resource exists in us-east-1c, you know this resource is located in AZ c of the us-east-1 Region.\n\nScope AWS Services\nDepending on the AWS Service you use, your resources are either deployed at the AZ, Region, or Global level. Each service is different, so you need to understand how the scope of a service may affect your application architecture.\nWhen you operate a Region-scoped service, you only need to select the Region you want to use. If you are not asked to specify an individual AZ to deploy the service in, this is an indicator that the service operates on a Region-scope level. For region-scoped services, AWS automatically performs actions to increase data durability and availability.\nOn the other hand, some services ask you to specify an AZ. With these services, you are often responsible for increasing the data durability and high availability of these resources.\n\n\nMaintain Resiliency\n\nWhat is resiliency? The capability to recover when stressed by load (more requests for service), attacks (either accidental through a bug, or deliberate through intention), and failure of any component in the workload’s components.\n\nTo keep your application available, you need to maintain high availability and resiliency. A well-known best practice for cloud architecture is to use Region-scoped, managed services. These services come with availability and resiliency built in.\nWhen that is not possible, make sure the workload is replicated across multiple AZs. At a minimum, you should use two AZs. If one entire AZ fails, your application will have infrastructure up and running in at least a second AZ to take over the traffic.\n\nInteracting with AWS\n\n\nAPI call: Application programming interfaces (APIs) are a way for one program to interact with another. API calls are the medium by which they interact. An API call, or API request, is a message sent to a server asking an API to provide a service or information.\n\nEvery action you make in AWS is an API call that is authenticated and authorized. In AWS, you can make API calls to services and resources through the AWS Management Console, the AWS Command Line Interface (CLI), or the AWS Software Development Kits (SDKs).\n\n\nThe AWS Management Console\nOne way to manage cloud resources is through the web-based console, where you log in and click on the desired service. This can be the easiest way to create and manage resources when you first begin working with the cloud. Below is a screenshot that shows the landing page when you first log into the AWS Management Console.\n\nThe services are placed in categories, such as compute, database, storage and security, identity and compliance.\nOn the upper right corner is the Region selector. If you click it and change the Region, you will make requests to the services in the chosen Region. The URL changes, too. Changing the Region directs the browser to make requests to a whole different AWS Region, represented by a different subdomain.\n\n\nThe AWS Command Line Interface (CLI)\nConsider the scenario where you run tens of servers on AWS for your application’s backend. You want to run a report to collect data from all of these servers. You need to do this programmatically every day because the server details may change. Instead of manually logging into the AWS Management Console and copying/pasting information, you can schedule an AWS Command Line Interface (CLI) script with an API call to pull this data for you.\nThe AWS CLI is a unified tool to manage AWS services. With just one tool to download and configure, you control multiple AWS services from the command line and automate them with scripts. The AWS CLI is open-source, and there are installers available for Windows, Linux, and Mac OS.\nHere is an example of running an API call against a service using the AWS CLI: aws ec2 describe-instances\nYou get this response:\n{     \"Reservations\": [         {             \"Groups\": [],             \"Instances\": [                 {                     \"AmiLaunchIndex\": 0,\nand so on.\n\n\nAWS Software Development Kits (SDKs)\nAPI calls to AWS can also be performed by executing code with programming languages. You can do this by using AWS Software Development Kits (SDKs). SDKs are open-source and maintained by AWS for the most popular programming languages, such as C++, Go, Java, JavaScript, .NET, Node.js, PHP, Python, and Ruby.\nDevelopers commonly use AWS SDKs to integrate their application source code with AWS services. Let’s say the backend of the application runs in Python and every time it receives a cat photo, it uploads that photo to a storage service. This action can be achieved from within the source code by using the AWS SDK for Python.\nHere is an example of code you can implement to work with AWS resources using the Python AWS SDK.\nimport boto3 ec2 = boto3.client('ec2') response = ec2.describe_instances() print(response)\n\nBack to contents\n\n\n\nSecurity and the AWS Shared Responsibility Model\n\n\nWhen you begin working with the AWS Cloud, managing security and compliance is a shared responsibility between AWS and you. To depict this shared responsibility, AWS created the shared responsibility model. This distinction of responsibility is commonly referred to as security of the cloud, versus security in the cloud.\n\n\n\nWhat Is AWS Responsible For?\nAWS is responsible for security of the cloud. This means AWS is required to protect and secure the infrastructure that runs all the services offered in the AWS Cloud. AWS is responsible for:\n\nProtecting and securing AWS Regions, Availability Zones, and data centers, down to the physical security of the buildings\nManaging the hardware, software, and networking components that run AWS services, such as the physical server, host operating systems, virtualization layers, and AWS networking components\n\nThe level of responsibility AWS has depends on the service. AWS classifies services into three different categories. The following table provides information about each, as well as the AWS responsibility.\n\n\n\n\n\n\n\n\nCategory\nExamples of AWS Services in the Category\nAWS Responsibility\n\n\n\n\nInfrastructure services\nCompute services, such as Amazon Elastic Compute Cloud (Amazon EC2)\nAWS manages the underlying infrastructure and foundation services.\n\n\nContainer services\nServices that require less management from the customer, such as Amazon Relational Database Service (Amazon RDS)\nAWS manages the underlying infrastructure and foundation services, operating system, and application platform.\n\n\nAbstracted services\nServices that require very little management from the customer, such as Amazon Simple Storage Service (Amazon S3)\nAWS operates the infrastructure layer, operating system, and platforms, as well as server-side encryption and data protection.\n\n\n\nNote Container services refer to AWS abstracting application containers behind the scenes, not Docker container services. This enables AWS to move the responsibility of managing that platform away from customers.\n\n\nWhat Is the Customer Responsible For?\nYou’re responsible for security in the cloud. When using any AWS service, you’re responsible for properly configuring the service and your applications, as well as ensuring your data is secure.\nThe level of responsibility you have depends on the AWS service. Some services require you to perform all the necessary security configuration and management tasks, while other more abstracted services require you to only manage the data and control access to your resources. Using the three categories of AWS services, you can determine your level of responsibility for each AWS service you use.\n\n\n\n\n\n\n\n\nCategory\nAWS Responsibility\nCustomer Responsibility\n\n\n\n\nInfrastructure services\nAWS manages the infrastructure and foundation services.\nYou control the operating system and application platform, as well as encrypting, protecting, and managing customer data.\n\n\nContainer services\nAWS manages the infrastructure and foundation services, operating system, and application platform.\nYou are responsible for customer data, encrypting that data, and protecting it through network firewalls and backups.\n\n\nAbstracted services\nAWS operates the infrastructure layer, operating system, and platforms, as well as server-side encryption and data protection.\nYou are responsible for managing customer data and protecting it through client-side encryption.\n\n\n\nDue to the varying level of effort, it’s important to consider which AWS service you use and review the level of responsibility required to secure the service. It’s also important to review how the shared security model aligns with the security standards in your IT environment, as well as any applicable laws and regulations.\nIt’s important to note that you maintain complete control of your data and are responsible for managing the security related to your content. Here are some examples of your responsibilities in context.\n\nChoosing a Region for AWS resources in accordance with data sovereignty regulations\nImplementing data protection mechanisms, such as encryption and managing backups\nUsing access control to limit who has access to your data and AWS resources\n\n\nProtect the AWS Root User"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#whats-the-big-deal-about-auth",
    "href": "posts/PYTHON/others_python/AWS.html#whats-the-big-deal-about-auth",
    "title": "AWS Cheat sheet",
    "section": "What’s the Big Deal About Auth?",
    "text": "What’s the Big Deal About Auth?\nWhen you’re configuring access to any account, two terms come up frequently: - authentication - and authorization.\nThough these terms may seem basic, you need to understand them to properly configure access management on AWS. It’s important to keep this in mind as you progress through the course. Let’s define both terms.\n\nUnderstand Authentication\nWhen you create your AWS account, you use a combination of an email address and a password to verify your identity. If the user types in the correct email and password, the system assumes the user is allowed to enter and grants them access. This is the process of authentication.\nAuthentication ensures that the user is who they say they are. Usernames and passwords are the most common types of authentication, but you may also work with other forms, such as token-based authentication or biometric data like a fingerprint. Authentication simply answers the question, “Are you who you say you are?”\n\n\nUnderstand Authorization\nOnce you’re inside your AWS account, you might be curious about what actions you can take. This is where authorization comes in. Authorization is the process of giving users permission to access AWS resources and services. Authorization determines whether the user can perform an action—whether it be to read, edit, delete, or create resources.\nAuthorization answers the question, “What actions can you perform?”\n\n\nWhat Is the AWS Root User?\nWhen you first create an AWS account, you begin with a single sign-in identity that has complete access to all AWS services and resources in the account. This identity is called the AWS root user and is accessed by signing in with the email address and password that you used to create the account.\n\n\nUnderstand the AWS Root User Credentials\nThe AWS root user has two sets of credentials associated with it. One set of credentials is the email address and password used to create the account. This allows you to access the AWS Management Console. The second set of credentials is called access keys, which allow you to make programmatic requests from the AWS Command Line Interface (AWS CLI) or AWS API.\nAccess keys consist of two parts:\n\nAn access key ID, for example, A2lAl5EXAMPLE\nA secret access key, for example, wJalrFE/KbEKxE\n\nSimilar to a username and password combination, you need both the access key ID and secret access key to authenticate your requests via the AWS CLI or AWS API. Access keys should be managed with the same security as an email address and password.\n\n\nFollow Best Practices When Working with the AWS Root User\nKeep in mind that the root user has complete access to all AWS services and resources in your account, as well as your billing and personal information. Due to this, securely lock away the credentials associated with the root user and do not use the root user for everyday tasks.\nTo ensure the safety of the root user:\n\nChoose a strong password for the root user.\nNever share your root user password or access keys with anyone.\nDisable or delete the access keys associated with the root user.\nDo not use the root user for administrative tasks or everyday tasks.\n\nWhen is it OK to use the AWS root user?\nThere are some tasks where it makes sense to use the AWS root user. Check out the links at the end of this section to read about them.\n\n\nDelete Your Keys to Stay Safe\nIf you don’t already have an access key for your AWS account root user, don’t create one unless you absolutely need to. If you do have an access key for your AWS account root user and want to delete the keys:\n\nGo to the My Security Credentials page in the AWS Management Console and sign in with the root user’s email address and password.\nOpen the Access keys section.\nUnder Actions, click Delete.\nClick Yes.\n\n\n\nThe Case for Multi-Factor Authentication\nWhen you create an AWS account and first log in to that account, you use single-factor authentication. Single-factor authentication is the simplest and most common form of authentication. It only requires one authentication method. In this case, you use a username and password to authenticate as the AWS root user. Other forms of single-factor authentication include a security pin or a security token.\nHowever, sometimes a user’s password is easy to guess. For example, your coworker Bob’s password, IloveCats222, might be easy for someone who knows Bob personally to guess, because it’s a combination of information that is easy to remember and describes certain things about Bob (1. Bob loves cats, and 2. Bob’s birthday is February 22).\nIf a bad actor guessed or cracked Bob’s password through social engineering, bots, or scripts, Bob might lose control of his account. Unfortunately, this is a common scenario that users of any website often face.\nThis is why using MFA has become so important in preventing unwanted account access. MFA requires two or more authentication methods to verify an identity, pulling from three different categories of information.\n\nSomething you know, such as a username and password, or pin number\nSomething you have, such as a one-time passcode from a hardware device or mobile app\nSomething you are, such as fingerprint or face scanning technology\n\nUsing a combination of this information enables systems to provide a layered approach to account access. Even though the first method of authentication, Bob’s password, was cracked by a malicious user, it’s very unlikely that a second method of authentication, such as a fingerprint, would also be cracked.\nThis extra layer of security is needed when protecting your most sacred accounts, which is why it’s important to enable MFA on your AWS root user.\n\n\nUse MFA on AWS\nIf you enable MFA on your root user, you are required to present a piece of identifying information from both the something you know category and the something you have category. The first piece of identifying information the user enters is an email and password combination. The second piece of information is a temporary numeric code provided by an MFA device.\nEnabling MFA adds an additional layer of security because it requires users to use a supported MFA mechanism in addition to their regular sign-in credentials. It’s best practice to enable MFA on the root user.\n\nReview Supported MFA Devices\nAWS supports a variety of MFA mechanisms, such as virtual MFA devices, hardware devices, and Universal 2nd Factor (U2F) security keys. For instructions on how to set up each method, check out the Resources section.\n\nIntroduction to AWS Identity and Access Management\n\n\n\n\nWhat Is IAM?\nIAM is a web service that enables you to manage access to your AWS account and resources. It also provides a centralized view of who and what are allowed inside your AWS account (authentication), and who and what have permissions to use and work with your AWS resources (authorization).\nWith IAM, you can share access to an AWS account and resources without having to share your set of access keys or password. You can also provide granular access to those working in your account, so that people and services only have permissions to the resources they need. For example, to provide a user of your AWS account with read-only access to a particular AWS service, you can granularly select which actions and which resources in that service they can access.\n\nGet to Know the IAM Features\nTo help control access and manage identities within your AWS account, IAM offers many features to ensure security.\n\nIAM is global and not specific to any one Region. This means you can see and use your IAM configurations from any Region in the AWS Management Console.\nIAM is integrated with many AWS services by default.\nYou can establish password policies in IAM to specify complexity requirements and mandatory rotation periods for users.\nIAM supports MFA (multi factor auth).\nIAM supports identity federation, which allows users who already have passwords elsewhere—for example, in your corporate network or with an internet identity provider—to get temporary access to your AWS account.\nAny AWS customer can use IAM; the service is offered at no additional charge.\n\n\n\n\nWhat Is an IAM User?\nAn IAM user represents a person or service that interacts with AWS. You define the user within your AWS account. And any activity done by that user is billed to your account. Once you create a user, that user can sign in to gain access to the AWS resources inside your account.\nYou can also add more users to your account as needed. For example, for your cat photo application, you could create individual users in your AWS account that correspond to the people who are working on your application. Each person should have their own login credentials. Providing users with their own login credentials prevents sharing of credentials.\n\n\nIAM User Credentials\nAn IAM user consists of a name and a set of credentials. When creating a user, you can choose to provide the user:\n\nAccess to the AWS Management Console\nProgrammatic access to the AWS Command Line Interface (AWS CLI) and AWS Application Programming Interface (AWS API)\n\nTo access the AWS Management Console, provide the users with a user name and password. For programmatic access, AWS generates a set of access keys that can be used with the AWS CLI and AWS API. IAM user credentials are considered permanent, in that they stay with the user until there’s a forced rotation by admins.\nWhen you create an IAM user, you have the option to grant permissions directly at the user level.\nThis can seem like a good idea if you have only one or a few users. However, as the number of users helping you build your solutions on AWS increases, it becomes more complicated to keep up with permissions. For example, if you have 3,000 users in your AWS account, administering access becomes challenging, and it’s impossible to get a top-level view of who can perform what actions on which resources.\nIf only there were a way to group IAM users and attach permissions at the group level instead. Guess what: There is!\n\n\nWhat Is an IAM Group?\nAn IAM group is a collection of users. All users in the group inherit the permissions assigned to the group. This makes it easy to give permissions to multiple users at once. It’s a more convenient and scalable way of managing permissions for users in your AWS account. This is why using IAM groups is a best practice.\nIf you have an application that you’re trying to build and have multiple users in one account working on the application, you might decide to organize these users by job function. You might want IAM groups organized by developers, security, and admins. You would then place all of your IAM users in the respective group for their job function.\nThis provides a better view to see who has what permissions within your organization and an easier way to scale as new people join, leave, and change roles in your organization.\nConsider the following examples.\n\nA new developer joins your AWS account to help with your application. You simply create a new user and add them to the developer group, without having to think about which permissions they need.\nA developer changes jobs and becomes a security engineer. Instead of editing the user’s permissions directly, you can instead remove them from the old group and add them to the new group that already has the correct level of access.\n\nKeep in mind the following features of groups.\n\nGroups can have many users.\nUsers can belong to many groups.\nGroups cannot belong to groups.\n\nThe root user can perform all actions on all resources inside an AWS account by default. This is in contrast to creating new IAM users, new groups, or new roles. New IAM identities can perform no actions inside your AWS account by default until you explicitly grant them permission.\nThe way you grant permissions in IAM is by using IAM policies.\n\n\nWhat Is an IAM Policy?\nTo manage access and provide permissions to AWS services and resources, you create IAM policies and attach them to IAM users, groups, and roles. Whenever a user or role makes a request, AWS evaluates the policies associated with them.\nFor example, if you have a developer inside the developers group who makes a request to an AWS service, AWS evaluates any policies attached to the developers group and any policies attached to the developer user to determine if the request should be allowed or denied.\n\nIAM Policy Examples\nMost policies are stored in AWS as JSON documents with several policy elements. Take a look at the following example of what providing admin access through an IAM identity-based policy looks like.\n{ \"Version\": \"2012-10-17\",     \"Statement\": [{         \"Effect\": \"Allow\",         \"Action\": \"*\",         \"Resource\": \"*\"      }] }\nIn this policy, there are four major JSON elements: - Version, - Effect, - Action, - Resource.\nThe Version element defines the version of the policy language. It specifies the language syntax rules that are needed by AWS to process a policy. To use all the available policy features, include “Version”: “2012-10-17” before the “Statement” element in all your policies.\nThe Effect element specifies whether the statement will allow or deny access. In this policy, the Effect is “Allow”, which means you’re providing access to a particular resource.\nThe Action element describes the type of action that should be allowed or denied. In the above policy, the action is “*“. This is called a wildcard, and it is used to symbolize every action inside your AWS account.\nThe Resource element specifies the object or objects that the policy statement covers. In the policy example above, the resource is also the wildcard “*“. This represents all resources inside your AWS console.\nPutting all this information together, you have a policy that allows you to perform all actions on all resources inside your AWS account. This is what we refer to as an administrator policy.\nLet’s look at another example of a more granular IAM policy.\n{ \"Version\": \"2012-10-17\",     \"Statement\": [{         \"Effect\": \"Allow\",         \"Action\": [             \"iam: ChangePassword\",             \"iam: GetUser\"             ]         \"Resource\": \"arn:aws:iam::123456789012:user/${aws:username}\"     }] }\nAfter looking at the JSON, you can see that this policy allows the IAM user to change their own IAM password (iam:ChangePassword) and get information about their own user (iam:GetUser).\nIt only permits them to access their own credentials because the resource restricts access with the variable substitution ${aws:username}.\n\n\nUnderstand Policy Structure\nWhen creating a policy, it is required to have each of the following elements inside a policy statement.\n\n\n\n\n\n\n\n\n\nElement\nDescription\nRequired\nExample\n\n\n\n\nEffect\nSpecifies whether the statement results in an allow or an explicit deny\n✔\n“Effect”: “Deny”\n\n\nAction\nDescribes the specific actions that will be allowed or denied\n✔\n“Action”: “iam:CreateUser”\n\n\nResource\nSpecifies the object or objects that the statement covers\n✔\n“Resource”: “arn:aws:iam::account-ID-without-hyphens:user/Bob”\n\n\n\n\nSummary Role Based Access in AWS\n\nThroughout these last few lessons, there have been sprinklings of IAM best practices. It’s helpful to have a brief summary of some of the most important IAM best practices you need to be familiar with before building out solutions on AWS.\n\nLock Down the AWS Root User\n\n\nThe root user is an all-powerful and all-knowing identity within your AWS account. If a malicious user were to gain control of root-user credentials, they would be able to access every resource within your account, including personal and billing information. To lock down the root user:\n\n\nDon’t share the credentials associated with the root user.\nConsider deleting the root user access keys.\nEnable MFA on the root account.\n\n\nFollow the Principle of Least Privilege\n\n\nLeast privilege is a standard security principle that advises you to grant only the necessary permissions to do a particular job and nothing more. To implement least privilege for access control, start with the minimum set of permissions in an IAM policy and then grant additional permissions as necessary for a user, group, or role.\n\n\nUse IAM Appropriately\n\n\nIAM is used to secure access to your AWS account and resources. It simply provides a way to create and manage users, groups, and roles to access resources within a single AWS account. IAM is not used for website authentication and authorization, such as providing users of a website with sign-in and sign-up functionality. IAM also does not support security controls for protecting operating systems and networks.\n\n\nUse IAM Roles When Possible\n\n\nMaintaining roles is easier than maintaining users. When you assume a role, IAM dynamically provides temporary credentials that expire after a defined period of time, between 15 minutes and 36 hours. Users, on the other hand, have long-term credentials in the form of user name and password combinations or a set of access keys.\n\nUser access keys only expire when you or the admin of your account rotates these keys. User login credentials expire if you have applied a password policy to your account that forces users to rotate their passwords.\n\nConsider Using an Identity Provider\n\n\nIf you decide to make your cat photo application into a business and begin to have more than a handful of people working on it, consider managing employee identity information through an identity provider (IdP). Using an IdP, whether it be an AWS service such as AWS Single Sign-On (SSO) or a third-party identity provider, provides you a single source of truth for all identities in your organization.\n\nYou no longer have to create separate IAM users in AWS. You can instead use IAM roles to provide permissions to identities that are federated from your IdP.\nFor example, you have an employee, Martha, that has access to multiple AWS accounts. Instead of creating and managing multiple IAM users named Martha in each of those AWS accounts, you can manage Martha in your company’s IdP. If Martha moves within the company or leaves the company, Martha can be updated in the IdP, rather than in every AWS account you have.\n\nConsider AWS SSO\n\n\nIf you have an organization that spans many employees and multiple AWS accounts, you may want your employees to sign in with a single credential. AWS SSO is an IdP that lets your users sign in to a user portal with a single set of credentials. It then provides them access to all their assigned accounts and applications in one central location.\n\nAWS SSO is similar to IAM, in that it offers a directory where you can create users, organize them in groups, and set permissions across those groups, and grant access to AWS resources. However, AWS SSO has some advantages over IAM. For example, if you’re using a third-party IdP, you can sync your users and groups to AWS SSO.\nThis removes the burden of having to re-create users that already exist elsewhere, and it enables you to manage those users from your IdP. More importantly, AWS SSO separates the duties between your IdP and AWS, ensuring that your cloud access management is not inside or dependent on your IdP.\n\nBack to contents\n\n\n\nCompute as a Service on AWS"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#understanding-servers",
    "href": "posts/PYTHON/others_python/AWS.html#understanding-servers",
    "title": "AWS Cheat sheet",
    "section": "Understanding Servers",
    "text": "Understanding Servers\nThe first building block you need to host an application is a server. Servers often times can handle Hypertext Transfer Protocol (HTTP) requests and send responses to clients following the client-server model, though any API based communication also falls under this model. A client being a person or computer that sends a request, and a server handling the requests is a computer, or collection of computers, connected to the internet serving websites to internet users.\nThese servers power your application by providing CPU, memory, and networking capacity to process users’ requests and transform them into responses. For context, common HTTP servers include:\n\nWindows options, such as Internet Information Services (IIS).\nLinux options, such as Apache HTTP Web Server, Nginx, and Apache Tomcat.\n\nTo run an HTTP server on AWS, you need to find a service that provides compute power in the AWS Management Console. You can log into the console and view the complete list of AWS compute services."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#choose-the-right-compute-option",
    "href": "posts/PYTHON/others_python/AWS.html#choose-the-right-compute-option",
    "title": "AWS Cheat sheet",
    "section": "Choose the Right Compute Option",
    "text": "Choose the Right Compute Option\nIf you’re responsible for setting up servers on AWS to run your infrastructure, you have many compute options. You need to know which service to use for which use case. At a fundamental level, there are three types of compute options: - virtual machines, e.g. EC2 - container services, - serverless.\nIf you’re coming to AWS with prior infrastructure knowledge, a virtual machine can often be the easiest compute option in AWS to understand. This is because a virtual machine emulates a physical server and allows you to install an HTTP server to run your applications. To run these virtual machines, you install a hypervisor on a host machine. This hypervisor provisions the resources to create and run your virtual machines.\n\nHow does AWS hypervisor work? A hypervisor is a piece of system software that provides virtual machines (VMs), on which users can run their OS and applications. The hypervisor provides isolation between VMs, which run independent of each other, and allows different VMs to run their own OS\n\nIn AWS, these virtual machines are called Amazon Elastic Compute Cloud or Amazon EC2. Behind the scenes, AWS operates and manages the host machines and the hypervisor layer. AWS also installs the virtual machine operating system, called the guest operating system.\nSome AWS compute services use Amazon EC2 or use virtualization concepts under the hood, therefore it is best to understand this service first before moving on to container services and serverless compute.\n\nIntroduction to Amazon Elastic Compute Cloud\n\n\nWhat Is Amazon EC2?\nAmazon EC2 is a web service that provides secure, resizable compute capacity in the cloud. It allows you to provision virtual servers called EC2 instances. Although AWS uses the phrase “web service” to describe it, it doesn’t mean that you are limited to running just web servers on your EC2 instances.\nYou can create and manage these instances through the AWS Management Console, the AWS Command Line Interface (CLI), AWS Software Development Kits (SDKs), or through automation tools and infrastructure orchestration services.\nIn order to create an EC2 instance, you need to define:\n\nHardware specifications, like CPU, memory, network, and storage.\nLogical configurations, like networking location, firewall rules, authentication, and the operating system of your choice.\n\nWhen launching an EC2 instance, the first setting you configure is which operating system you want by selecting an Amazon Machine Image (AMI).\n\n\nWhat Is an Amazon Machine Image (AMI)?\nIn the traditional infrastructure world, the process of spinning up a server consists of installing an operating system from installation disks, installation drives, or installation wizards over the network. In the AWS Cloud, this operating system installation is no longer your responsibility, and is instead built into the AMI that you choose.\nNot only does an AMI let you configure which operating system you want, you can also select storage mappings, the architecture type (such as 32-bit, 64-bit, or 64-bit ARM), and additional software installed.\n\n\nWhat Is the Relationship Between AMIs and EC2 Instances?\nEC2 instances are live instantiations of what is defined in an AMI, much like a cake is a live instantiation of a cake recipe. If you are familiar with software development, you can also see this kind of relationship between a Class and an Object.\nA Class is something you model and define, while an object is something you interact with. In this case, the AMI is how you model and define your instance, while the EC2 instance is the entity you interact with, where you can install your web server, and serve your content to users.\nWhen you launch a new instance, AWS allocates a virtual machine that runs on a hypervisor. Then the AMI you selected is copied to the root device volume, which contains the image used to boot the volume. In the end, you get a server you can connect to and install packages and any additional software. In this case, you install a web server along with the properly configured source code of your employee directory app.\n\nOne advantage of using AMIs is that they are reusable.\nYou might choose a Linux-based AMI and configure the HTTP server, application packages, and any additional software you may need to run your application.\nIf you wanted to create a second EC2 instance with the same configurations, how can you easily do that? One option is to go through the entire instance creation and configuration process and try to match your settings to the first instance. However, this is time consuming and leaves room for human error.\nThe second, better option, is to create an AMI from your running instance and use this AMI to start a new instance. This way, your new instance will have all the same configurations as your current instance, because the configurations set in the AMIs are the same.\n\n\nWhere Can You Find AMIs?\nYou can select an AMI from the following categories.\n\nQuick Start AMIs that are premade by AWS and allow you to get started quickly.\nAWS Marketplace AMIs that provide popular open source and commercial software from third-party vendors.\nMy AMIs that are created from your EC2 instances.\nCommunity AMIs that are provided by the AWS user community.\nBuild your own custom image with EC2 Image Builder.\n\nEach AMI in the AWS Management Console has an AMI ID, which is prefixed by “ami-”, followed by a random hash of numbers and letters. These IDs are unique to each AWS region."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#amazon-ec2-instance-lifecycle",
    "href": "posts/PYTHON/others_python/AWS.html#amazon-ec2-instance-lifecycle",
    "title": "AWS Cheat sheet",
    "section": "Amazon EC2 Instance Lifecycle",
    "text": "Amazon EC2 Instance Lifecycle\nNow that you know how to select an operating system for your EC2 instance, it’s time to choose other configurations to create your EC2 instance, such as the instance type, network, and storage.\nFor an application like the employee directory application, you need instances with enough capacity to run web servers and process incoming customer requests. Your instance sizing will depend on both the demands of your application and the anticipated size of your user base.\nForecasting server capacity for an on-premises application requires difficult decisions involving significant up-front capital spending, while changes to the allocation of your cloud-based services can be made with a simple API call.\nBecause of AWS’s pay-as-you-go model, you can match your infrastructure capacity to your application’s demand, instead of the other way around.\n\nWhat Makes Up an EC2 Instance?\nEC2 instances are a combination of virtual processors (vCPUs), memory, network, and in some cases, instance storage and graphics processing units (GPUs). When you create an EC2 instance, you need to choose how much you need of each of these components.\nAWS offers a variety of instances that differ based on performance. Some instances provide you with more capacity and others provide less. To get an overview of the capacity details for a particular instance, you should look at the instance type.\nInstance types consist of a prefix identifying the type of workloads they’re optimized for, followed by a size. For example, the instance type c5.large can be broken down into the following elements.\n\nc5 determines the instance family and generation number. Here, the instance belongs to the fifth generation of instances in an instance family that’s optimized for generic computation.\nlarge, which determines the amount of instance capacity.\n\n\n\nWhat Are Instance Families?\n\n\n\n\n\n\n\n\nInstance Family\nDescription\nUse Cases\n\n\n\n\nGeneral purpose\nProvides a balance of compute, memory, and networking resources, and can be used for a variety of workloads.\nScale-out workloads such as web servers, containerized microservices, caching fleets, distributed data stores, and development environments.\n\n\nCompute optimized\nIdeal for compute-bound applications that benefit from high-performance processors.\nHigh-performance web servers, scientific modeling, batch processing, distributed analytics, high-performance computing (HPC), machine/deep learning, ad serving, highly scalable multiplayer gaming.\n\n\nMemory optimized\nDesigned to deliver fast performance for workloads that process large data sets in memory.\nMemory-intensive applications such as high-performance databases, distributed web-scale in-memory caches, mid-size in-memory databases, real-time big-data analytics, and other enterprise applications.\n\n\nAccelerated computing\nUse hardware accelerators or co-processors to perform functions such as floating-point number calculations, graphics processing, or data pattern matching more efficiently than is possible with conventional CPUs.\n3D visualizations, graphics-intensive remote workstations, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.\n\n\nStorage optimized\nDesigned for workloads that require high, sequential read and write access to large data sets on local storage. They are optimized to deliver tens of thousands of low-latency random I/O operations per second (IOPS) to applications that replicate their data across different instances.\nNoSQL databases, such as Cassandra, MongoDB, and Redis, in-memory databases, scale-out transactional databases, data warehousing, Elasticsearch, and analytics.\n\n\n\n\nWhere Does Your EC2 Instance Live?\nBy default, your EC2 instances are placed in a network called the default Amazon Virtual Private Cloud (VPC). This network was created so that you can easily get started with Amazon EC2 without having to learn how to create and configure a VPC.\nAny resource you put inside the default VPC will be public and accessible by the internet, so you shouldn’t place any customer data or private information inside of it.\nOnce you get more comfortable with networking on AWS, you should change this default setting to choose your own custom VPCs and restrict access with additional routing and connectivity mechanisms.\n\n\nArchitect for High Availability\nInside this network, your instance resides in an Availability Zone of your choice. AWS services that are scoped at the Availability Zone level must be architected with high availability in mind.\nWhile EC2 instances are typically reliable, two is better than one, and three is better than two. Specifying the instance size gives you an advantage when designing your architecture because you can use more smaller instances instead of a few larger ones.\nIf your frontend only has a single instance and that instance fails, your application goes down. On the other hand, if your workload is distributed across 10 instances and one fails, you lose only 10 percent of your fleet and your application availability is hardly affected.\nWhen architecting any application for high availability, consider using at least two EC2 instances in two separate Availability Zones.\n\n\nExplore the EC2 Instance Lifecycle\nAn EC2 instance transitions between different states from the moment you create it all the way through to its termination.\n\n\nWhen you launch an instance, it enters the pending state (1). When the instance is pending, billing has not started. At this stage, the instance is preparing to enter the running state. Pending is where AWS performs all actions needed to set up an instance, such as copying the AMI content to the root device and allocating the necessary networking components.\nWhen your instance is running (2), it’s ready to use. This is also the stage where billing begins. As soon as an instance is running, you are then able to take other actions on the instance, such as reboot, terminate, stop, and stop-hibernate.\nWhen you reboot an instance (3), it’s different than performing a stop action and then a start action. Rebooting an instance is equivalent to rebooting an operating system. The instance remains on the same host computer and maintains its public and private IP address, and any data on its instance store.\nIt typically takes a few minutes for the reboot to complete. When you stop and start an instance (4), your instance may be placed on a new underlying physical server. Therefore, you lose any data on the instance store that were on the previous host computer. When you stop an instance, the instance gets a new public IP address but maintains the same private IP address.\nWhen you terminate an instance (5), the instance store are erased, and you lose both the public IP address and private IP address of the machine. Termination of an instance means you can no longer access the machine.\n\n\n\nWhat Is the Difference Between Stop and Stop-Hibernate?\nWhen you stop your instance, it enters the stopping state, and then the stopped state. AWS does not charge usage or data transfer fees for your instance after you stop it, but storage for any Amazon EBS volumes is still charged. While your instance is in the stopped state, you can modify some attributes, like the instance type. When you stop your instance, the data stored in memory (RAM) is lost.\nWhen you stop-hibernate your instance, AWS signals the operating system to perform hibernation (suspend-to-disk), which saves the contents from the instance memory (RAM) to the Amazon EBS root volume.\nConsider a scenario where you build a standard three tier application, where you have web servers, application servers and database servers. Turns out, the application you built becomes extremely popular. To relieve some stress on the database that supports your application, you want to implement a custom backend layer that caches database information in memory (RAM). You decide to run this custom backend caching solution on Amazon EC2.\nIn this scenario, the stop-hibernate feature would be instrumental in persisting storage. It would prevent you from having to manually create scripts to save this RAM data before shutting down the server.\n\n\n\nWhat Makes Up the Pricing?\nTo understand EC2 pricing, let’s decouple the instance price from other services attached to it, such as storage and networking costs. In this unit we refer to the instance cost as the cost associated with the instance in terms of specifications and not the total blended cost of running an instance.\nOnce an instance is launched in your AWS account, the billing usually accrues on a per-second basis. For simplicity of calculation, prices are stated per-hour. For example, if you have an instance running for 5 minutes and 38 seconds during a given month, you only pay for 338 seconds of utilization at the end of the month.\nOne exception to this pricing convention may be third-party AMIs purchased from the AWS Marketplace, which may have a minimum billing of 1 hour. For more details, check out the resources section of this unit.\n\nWhat Are the EC2 Pricing Options?\nOne of the ways to reduce costs with Amazon EC2 is to choose the right pricing option for the way your applications run. There are three main purchasing options for EC2 instances: - on-demand, - reserved, and - spot instances.\n\n\nPay As You Go with On-Demand Instances\nWith On-Demand instances, you pay for compute capacity with no long-term commitments. Billing begins whenever the instance is running, and billing stops when the instance is in a stopped or terminated state. The price per second for a running On-Demand instance is fixed.\nFor applications that require servers to be running all the time, you are less likely to benefit from the On-Demand pricing model, simply because there is no situation where you will need to turn servers off. For example, you might want the web server hosting the frontend of your corporate directory application to be running 24/7 so that users can access the website at any time. Even if there are no users connected to your website, you don’t want to shut down the servers supporting the site in case of potential user activity.\nIn the case when servers cannot be stopped, consider using a Reserved Instance to save on costs.\n\n\nReserve Capacity with Reserved Instances (RIs)\nRIs provide you with a significant discount compared to On-Demand instance pricing. RIs provide a discounted hourly rate and an optional capacity reservation for EC2 instances. You can choose between three payment options: - All Upfront, - Partial Upfront, or - No Upfront.\nYou can select for each of these options either a - 1-year or - 3-year term\nDepending on which option you choose, you are discounted differently.\n\nAll Upfront offers a higher discount than Partial Upfront instances.\nPartial Upfront instances offer a higher discount than No Upfront.\nNo Upfront offers a higher discount than On-Demand.\n\nOn-Demand and No Upfront are similar since both do not require any upfront payment. However, there is a major difference. When you choose an On-Demand instance, you stop paying for the instance when you stop or terminate the instance. When you stop an RI, you still pay for it because you committed to a 1-year or 3-year term.\nReserved Instances are associated with an instance type and an Availability Zone depending on how you reserve it. The discount applied by a Reserved Instance purchase is not directly associated with a specific instance ID, but with an instance type.\n\n\nSave on Costs with Spot Instances\nAnother way of paying for EC2 instances is by using Spot Instances. Amazon EC2 Spot Instances allow you to take advantage of unused EC2 capacity in the AWS Cloud. They are available at up to a 90% discount compared to On-Demand prices.\nWith Spot Instances, you set a limit on how much you would like to pay for the instance hour. This is compared against the current Spot price that AWS determines. If the amount you pay is more than the current Spot price and there is capacity, then you will receive an instance. While they are very promising from the billing perspective, there are some architectural considerations you will need to consider in order to use them effectively.\nOne consideration is that your spot instance may be interrupted. For example, if AWS determines that capacity is no longer available for a particular spot instance or if the Spot price exceeds how much you are willing to pay, AWS will give you a 2-minute warning before it interrupts your instance. That means any application or workload that runs on a Spot instance must be able to be interrupted.\nBecause of this unique consideration, inherently fault-tolerant workloads are typically good candidates to use with Spot instances.\nThese include - big data, - containerized workloads, - continuous integration/continuous delivery (CI/CD), - web servers, - high-performance computing (HPC), - image and media rendering, - or other test and development workloads."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#steps-to-create-an-ec2-instance",
    "href": "posts/PYTHON/others_python/AWS.html#steps-to-create-an-ec2-instance",
    "title": "AWS Cheat sheet",
    "section": "Steps to create an EC2 instance",
    "text": "Steps to create an EC2 instance\n\nClick on Launch instance\nChoose Amazon Machine Image, click select\nChoose instance type (e.g. t2 micro) and click on config details\nEnter values in Network and Subnet field\nClick checkbox to protect against accidental terminaton\nChoose Share-Run a shared hardware instance tenancy.\nSelect storage type\nReview and Launch\nConfigure security group.\nLaunch\nSelect/create key pair\nLaunch Instances\nView Instance.\n\n\nContainer Services on AWS\n\nAWS offers a broad spectrum of compute offerings that give you the flexibility to choose the right tool for the right job. The three main categories of compute are - virtual machines, - containers, and - serverless.\nThere is no one-size-fits-all service because it depends on your needs.\nThe key is to understand what each option has to offer in order to build a more appropriate cloud architecture for your use case."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-is-a-container",
    "href": "posts/PYTHON/others_python/AWS.html#what-is-a-container",
    "title": "AWS Cheat sheet",
    "section": "What Is a Container?",
    "text": "What Is a Container?\n\nWhat is the container in AWS? Containers provide a standard way to package your application’s code, configurations, and dependencies into a single object. Containers share an operating system installed on the server and run as resource-isolated processes, ensuring quick, reliable, and consistent deployments, regardless of environment\n\nContainers can host a variety of different workloads, including - web applications, - lift and shift migrations, - distributed applications, and - streamlining of development, test, and production environments.\nWith the evolution of the open source software community, containers evolved. Today, containers are used as a solution to problems of traditional compute, including the issue of getting software to run reliably when it moves from one compute environment to another.\nA container is a standardized unit that packages up your code and all of its dependencies. This package is designed to run reliably on any platform, because the container creates its own independent environment. This makes it easy to carry workloads from one place to another, such as from development to production or from on-premises to the cloud."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-is-docker",
    "href": "posts/PYTHON/others_python/AWS.html#what-is-docker",
    "title": "AWS Cheat sheet",
    "section": "What Is Docker?",
    "text": "What Is Docker?\nWhen you hear the word container, you may associate it with Docker. Docker is a popular container runtime that simplifies the management of the entire operating system stack needed for container isolation, including networking and storage. Docker makes it easy to create, package, deploy, and run containers.\n\nWhat Is the Difference Between Containers and VMs?\nContainers share the same operating system and kernel as the host they exist on, whereas virtual machines contain their operating system. Since each virtual machine has to maintain a copy of an operating system, there’s a degree of wasted space.\nA container is more lightweight. They spin up quicker, almost instantly. This difference in startup time becomes instrumental when designing applications that need to scale quickly during input/output (I/O) bursts.\nWhile containers can provide speed, virtual machines offer you the full strength of an operating system and offer more resources, like package installation, a dedicated kernel, and more.\n\n\n\nOrchestrate Containers\nIn AWS, containers run on EC2 instances. For example, you may have a large instance and run a few containers on that instance.\nWhile running one instance is easy to manage, it lacks high availability and scalability. Most companies and organizations run many containers on many EC2 instances across several Availability Zones.\nIf you’re trying to manage your compute at a large scale, you need to know:\n\nHow to place your containers on your instances.\nWhat happens if your container fails.\nWhat happens if your instance fails.\nHow to monitor deployments of your containers.\n\nThis coordination is handled by a container orchestration service. AWS offers two container orchestration services: Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS).\n\n\nManage Containers with Amazon Elastic Container Service (Amazon ECS)\n\nAmazon ECS is an end-to-end container orchestration service that allows you to quickly spin up new containers and manage them across a cluster of EC2 instances.\nTo run and manage your containers, you need to install the Amazon ECS Container Agent on your EC2 instances. This agent is open source and responsible for communicating back to the Amazon ECS service about cluster management details. You can run this agent on both Linux and Windows AMIs. An instance with the container agent installed is often called a container instance.\n\nOnce the Amazon ECS container instances are up and running, you can perform actions that include, but are not limited to, - launching and stopping containers, - getting cluster state, - scaling in and out, - scheduling the placement of containers across your cluster, - assigning permissions, and - meeting availability requirements.\nTo prepare your application to run on Amazon ECS, you create a task definition. The task definition is a text file, in JSON format, that describes one or more containers. A task definition is similar to a blueprint that describes the resources you need to run that container, such as CPU, memory, ports, images, storage, and networking information.\nHere is a simple task definition that you can use for your corporate director application. In this example, the runs on the Nginx web server.\n{     \"family\": \"webserver\",     \"containerDefinitions\": [ {         \"name\": \"web\",         \"image\": \"nginx\",         \"memory\": \"100\",         \"cpu\": \"99\"     } ],     \"requiresCompatibilities\": [ \"FARGATE\" ],     \"networkMode\": \"awsvpc\",     \"memory\": \"512\",     \"cpu\": \"256\" }\n\n\nUse Kubernetes with Amazon Elastic Kubernetes Service (Amazon EKS)\nKubernetes is a portable, extensible, open source platform for managing containerized workloads and services. By bringing software development and operations together by design, Kubernetes created a rapidly growing ecosystem that is very popular and well established in the market.\nIf you already use Kubernetes, you can use Amazon EKS to orchestrate these workloads in the AWS Cloud.\nAmazon EKS is conceptually similar to Amazon ECS, but there are some differences.\n\nAn EC2 instance with the ECS Agent installed and configured is called a container instance.\n\nIn Amazon EKS, it is called a worker node.\n\nAn ECS Container is called a task.\n\nIn the Amazon EKS ecosystem, it is called a pod.\n\nWhile Amazon ECS runs on AWS native technology,\n\nAmazon EKS runs on top of Kubernetes.\n\n\nIf you have containers running on Kubernetes and want an advanced orchestration solution that can provide simplicity, high availability, and fine-grained control over your infrastructure, Amazon EKS is the tool for you.\n\nServerless and AWS Lambda\n\n\n\nRemove the Undifferentiated Heavy Lifting\nIf you run your code on Amazon EC2, AWS is responsible for the physical hardware and you are responsible for the logical controls, such as guest operating system, security and patching, networking, security, and scaling.\nIf you run your code in containers on Amazon ECS and Amazon EKS, AWS is responsible for more of the container management, such as deploying containers across EC2 instances and managing the container cluster. However, when running ECS and EKS on EC2, you are still responsible for maintaining the underlying EC2 instances.\nIf you want to deploy your workloads and applications without having to manage any EC2 instances, you can do that on AWS with serverless compute.\n\n\nGo Serverless\n\nWhat is serverless in AWS? A serverless architecture is a way to build and run applications and services without having to manage infrastructure. Your application still runs on servers, but all the server management is done by AWS\n\nEvery definition of serverless mentions four aspects.\n\nNo servers to provision or manage.\nScales with usage.\nYou never pay for idle resources.\nAvailability and fault tolerance are built-in.\n\nWith serverless, spend time on the things that differentiate your application, rather than spending time on ensuring availability, scaling, and managing servers.\nAWS has several serverless compute options, including AWS Fargate and AWS Lambda.\n\n\nExplore Serverless Containers with AWS Fargate\nAmazon ECS and Amazon EKS enable you to run your containers in two modes.\n\nAmazon EC2 mode\nAWS Fargate mode\n\nAWS Fargate is a purpose-built serverless compute engine for containers. Fargate scales and manages the infrastructure, allowing developers to work on what they do best: application development.\nIt achieves this by allocating the right amount of compute, eliminating the need to choose and handle EC2 Instances and cluster capacity and scaling. Fargate supports both Amazon ECS and Amazon EKS architecture and provides workload isolation and improved security by design.\nAWS Fargate abstracts the EC2 instance so you’re not required to manage it. However, with AWS Fargate, you can use all the same ECS primitives, APIs, and AWS integrations. It natively integrates with AWS Identity and Access Management (IAM) and Amazon Virtual Private Cloud (VPC). Having native integration with Amazon VPC allows you to launch Fargate containers inside your network and control connectivity to your applications.\n\n\nRun Your Code on AWS Lambda\nIf you want to deploy your workloads and applications without having to manage any EC2 instances or containers, you can use AWS Lambda.\nAWS Lambda lets you run code without provisioning or managing servers or containers. You can run code for virtually any type of application or backend service, including data processing, real-time stream processing, machine learning, WebSockets, IoT backends, mobile backends, and web apps, like your corporate directory app!\nAWS Lambda requires zero administration from the user. You upload your source code and Lambda takes care of everything required to run and scale your code with high availability. There are no servers to manage, bringing you continuous scaling with subsecond metering and consistent performance.\n\n\nHow Lambda Works\nThere are three primary components of a Lambda function: - the trigger, - code, and - configuration.\nThe code is source code, that describes what the Lambda function should run. This code can be authored in three ways.\n\nYou create the code from scratch.\nYou use a blueprint that AWS provides.\nYou use same code from the AWS Serverless Application Repository, a resource that contains sample applications, such as “hello world” code, Amazon Alexa Skill sample code, image resizing code, video encoding, and more.\n\nWhen you create your Lambda function, you specify the runtime you want your code to run in. There are built-in runtimes such as Python, Node.js, Ruby, Go, Java, .NET Core, or you can implement your Lambda functions to run on a custom runtime.\nThe configuration of a Lambda function consists of information that describes how the function should run. In the configuration, you specify network placement, environment variables, memory, invocation type, permission sets, and other configurations. To dive deeper into these configurations, check out the resources section of this unit.\nTriggers describe when the Lambda function should run. A trigger integrates your Lambda function with other AWS services, enabling you to run your Lambda function in response to certain API calls that occur in your AWS account. This makes you quicker to respond to events in your console without having to perform manual actions.\nAll you need is the what, how, and when of a Lambda function to have functional compute capacity that runs only when you need it to.\nAmazon’s CTO, Werner Vogels, says, “No server is easier to manage than no server.” This quote summarizes the convenience you can have when running serverless solutions, like AWS Fargate and AWS Lambda. In the next unit, you apply all the information you’ve learned about Amazon EC2, Amazon ECS and Amazon EKS, and AWS Fargate and learn the use cases for each service.\n\n\nAWS Lambda function handler\nThe AWS Lambda function handler is the method in your function code that processes events. When your function is invoked, Lambda runs the handler method. When the handler exits or returns a response, it becomes available to handle another event.\nYou can use the following general syntax when creating a function handler in Python:\ndef handler_name(event, context):      ...     return some_value\n\nNaming\nThe Lambda function handler name specified at the time you create a Lambda function is derived from the following: - the name of the file in which the Lambda handler function is located - the name of the Python handler function\nA function handler can be any name; however, the default on the Lambda console is lambda_function.lambda_handler. This name reflects the function name as lambda_handler, and the file where the handler code is stored in lambda_function.py.\nIf you choose a different name for your function handler on the Lambda console, you must update the name on the Runtime settings pane.\n\n\nBilling Granularity\nAWS Lambda lets you run code without provisioning or managing servers, and you pay only for what you use. You are charged for the number of times your code is triggered (requests) and for the time your code executes, rounded up to the nearest 1ms (duration).\nAWS rounds up duration to the nearest millisecond with no minimum execution time.\nWith this pricing, it can be very cost effective to run functions whose execution time is very low, such as functions with durations under 100ms or low latency APIs.\nRead more here: https://aws.amazon.com/blogs/aws/new-for-aws-lambda-1ms-billing-granularity-adds-cost-savings/\n\n\nSource Code\nYou can find a tutorial on creating the AWS Lambda function as well as the code used in the AWS Lambda demo here: https://aws.amazon.com/blogs/compute/resize-images-on-the-fly-with-amazon-s3-aws-lambda-and-amazon-api-gateway/\n\nBack to contents\n\n\n\nNetworking on AWS"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-is-networking",
    "href": "posts/PYTHON/others_python/AWS.html#what-is-networking",
    "title": "AWS Cheat sheet",
    "section": "What Is Networking?",
    "text": "What Is Networking?\nNetworking is how you connect computers around the world and allow them to communicate with one another. In this trail, you’ve already seen a few examples of networking. One is the AWS global infrastructure. AWS has created a network of resources using data centers, Availability Zones, and Regions.\n\nKnow the Networking Basics\nThink about sending a letter. When sending a letter, there are three pieces of information you need.\n\nThe payload or letter inside the envelope.\nThe address of the sender in the From section.\nThe address of the recipient in the To section.\n\nLet’s go further. Each address must contain information such as:\n\nName of sender and recipient\nStreet\nCity\nState or province\nZip, area, or postal code\nCountry\n\nYou need all parts of an address to ensure that your letter gets to its destination. Without the correct address, postal workers are not able to properly deliver the message. In the digital world, computers handle the delivery of messages in a similar way. This is called routing."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-are-ip-addresses",
    "href": "posts/PYTHON/others_python/AWS.html#what-are-ip-addresses",
    "title": "AWS Cheat sheet",
    "section": "What Are IP Addresses?",
    "text": "What Are IP Addresses?\nIn order to properly route your messages to a location, you need an address. Just like each home has a mail address, each computer has an IP address. However, instead of using the combination of street, city, state, zip code, and country, the IP address uses a combination of bits, 0s and 1s.\nHere is an example of a 32-bit address in binary format:\n11000000 10101000 00000001 00011110\nIt’s called 32-bit because you have 32 digits. Feel free to count!\n\nWhat Is IPv4 Notation?\nTypically, you don’t see an IP address in this binary format. Instead, it’s converted into decimal format and noted as an Ipv4 address.\nIn the diagram below, the 32 bits are grouped into groups of 8 bits, also called octets. Each of these groups is converted into decimal format separated by a period.\n11000000 10101000 00000001 00011110\n192.168.1.30\nIn the end, this is what is called an Ipv4 address. This is important to know when trying to communicate to a single computer. But remember, you’re working with a network. This is where CIDR Notation comes in.\n\n\nUse CIDR Notation\n192.168.1.30 is a single IP address. If you wanted to express IP addresses between the range of 192.168.1.0 and 192.168.1.255, how can you do that?\nOne way is by using Classless Inter-Domain Routing (CIDR) notation. CIDR notation is a compressed way of specifying a range of IP addresses. Specifying a range determines how many IP addresses are available to you.\nCIDR notation looks like this:\n192.168.1.0/24\n\n192 is fixed\n168 is fixed\n1 is fixed\n0 is flexible\n\nIt begins with a starting IP address and is separated by a forward slash (the “/” character) followed by a number. The number at the end specifies how many of the bits of the IP address are fixed. In this example, the first 24 bits of the IP address are fixed. The rest are flexible.\n32 total bits subtracted by 24 fixed bits leaves 8 flexible bits. Each of these flexible bits can be either 0 or 1, because they are binary. That means you have two choices for each of the 8 bits, providing 256 IP addresses in that IP range.\nThe higher the number after the /, the smaller the number of IP addresses in your network. For example, a range of 192.168.1.0/24 is smaller than 192.168.1.0/16.\nWhen working with networks in the AWS Cloud, you choose your network size by using CIDR notation. In AWS, the smallest IP range you can have is /28, which provides you 16 IP addresses. The largest IP range you can have is a /16, which provides you with 65,536 IP addresses.\nStanford: Introduction to Computer Networking\nExternal Site: Ionos: CIDR: What is classless inter-domain routing?"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#introduction-to-amazon-vpc",
    "href": "posts/PYTHON/others_python/AWS.html#introduction-to-amazon-vpc",
    "title": "AWS Cheat sheet",
    "section": "Introduction to Amazon VPC",
    "text": "Introduction to Amazon VPC\nA VPC is an isolated network you create in the AWS cloud, similar to a traditional network in a data center. When you create a VPC, you need to choose three main things.\n\nThe name of your VPC.\nA Region for your VPC to live in. Each VPC spans multiple Availability Zones within the Region you choose.\nA IP range for your VPC in CIDR notation. This determines the size of your network. Each VPC can have up to four /16 IP ranges.\n\nUsing this information, AWS will provision a network and IP addresses for that network.\n\n\nCreate a Subnet\nAfter you create your VPC, you need to create subnets inside of this network.\nThink of subnets as smaller networks inside your base network—or virtual area networks (VLANs) in a traditional, on-premises network. In an on-premises network, the typical use case for subnets is to isolate or optimize network traffic. In AWS, subnets are used for high availability and providing different connectivity options for your resources.\nWhen you create a subnet, you need to choose three settings.\n\nThe VPC you want your subnet to live in, in this case VPC (10.0.0.0/16).\nThe Availability Zone you want your subnet to live in, in this case AZ1.\nA CIDR block for your subnet, which must be a subset of the VPC CIDR block, in this case 10.0.0.0/24.\n\nWhen you launch an EC2 instance, you launch it inside a subnet, which will be located inside the Availability Zone you choose.\n\n\n\nHigh Availability with A VPC\nWhen you create your subnets, keep high availability in mind. In order to maintain redundancy and fault tolerance, create at least two subnets configured in two different Availability Zones.\nAs you learned earlier in the trail, it’s important to consider that “everything fails all the time.” In this case, if one of these AZs fail, you still have your resources in another AZ available as backup.\n\n\n\nReserved IPs\nFor AWS to configure your VPC appropriately, AWS reserves five IP addresses in each subnet. These IP addresses are used for routing, Domain Name System (DNS), and network management.\nFor example, consider a VPC with the IP range 10.0.0.0/22. The VPC includes 1,024 total IP addresses. This is divided into four equal-sized subnets, each with a /24 IP range with 256 IP addresses. Out of each of those IP ranges, there are only 251 IP addresses that can be used because AWS reserves five.\n\nSince AWS reserves these five IP addresses, it can impact how you design your network. A common starting place for those who are new to the cloud is to create a VPC with a IP range of /16 and create subnets with a IP range of /24. This provides a large amount of IP addresses to work with at both the VPC and subnet level.\n\n\nGateways\n\nInternet Gateway\nTo enable internet connectivity for your VPC, you need to create an internet gateway. Think of this gateway as similar to a modem. Just as a modem connects your computer to the internet, the internet gateway connects your VPC to the internet. Unlike your modem at home, which sometimes goes down or offline, an internet gateway is highly available and scalable. After you create an internet gateway, you then need to attach it to your VPC.\n\n\nVirtual Private Gateway\nA virtual private gateway allows you to connect your AWS VPC to another private network. Once you create and attach a VGW to a VPC, the gateway acts as anchor on the AWS side of the connection. On the other side of the connection, you’ll need to connect a customer gateway to the other private network. A customer gateway device is a physical device or software application on your side of the connection. Once you have both gateways, you can then establish an encrypted VPN connection between the two sides.\n\nAmazon VPC Routing and Security"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#the-main-route-table",
    "href": "posts/PYTHON/others_python/AWS.html#the-main-route-table",
    "title": "AWS Cheat sheet",
    "section": "The Main Route Table",
    "text": "The Main Route Table\nWhen you create a VPC, AWS creates a route table called the main route table. A route table contains a set of rules, called routes, that are used to determine where network traffic is directed. AWS assumes that when you create a new VPC with subnets, you want traffic to flow between them. Therefore, the default configuration of the main route table is to allow traffic between all subnets in the local network. Below is an example of a main route table:\n\n\n\nDestination\nTarget\nStatus\nPropagated\n\n\n\n\n10.2.0.0/16\nlocal\nactive\nno\n\n\n\nThere are two main parts to this route table.\n\nThe destination, which is a range of IP addresses where you want your traffic to go. In the example of sending a letter, you need a destination to route the letter to the appropriate place. The same is true for routing traffic. In this case, the destination is the IP range of our VPC network.\nThe target, which is the connection through which to send the traffic. In this case, the traffic is routed through the local VPC network.\n\n\nCustom Route Tables\nWhile the main route table controls the routing for your VPC, you may want to be more granular about how you route your traffic for specific subnets. For example, your application may consist of a frontend and a database. You can create separate subnets for these resources and provide different routes for each of them.\nIf you associate a custom route table with a subnet, the subnet will use it instead of the main route table. By default, each custom route table you create will have the local route already inside it, allowing communication to flow between all resources and subnets inside the VPC.\n\n\n\nSecure Your Subnets with Network ACLs\nThink of a network ACL as a firewall at the subnet level. A network ACL enables you to control what kind of traffic is allowed to enter or leave your subnet. You can configure this by setting up rules that define what you want to filter. Here’s an example.\n\nInbound\n\n\n\nRule #\nType\nProtocolPort Range\nSource\nAllow/Deny\n\n\n\n\n100\nAll IPv4 traffic\nAll\n0.0.0.0/0\nALLOW\n\n\n*\nAll IPv4 traffic\nAll\n0.0.0.0/0\nDENY\n\n\n\n\n\nOutbound\n\n\n\nRule #\nType\nProtocolPort Range\nSource\nAllow/Deny\n\n\n\n\n100\nAll IPv4 traffic\nAll\n0.0.0.0/0\nALLOW\n\n\n*\nAll IPv4 traffic\nAll\n0.0.0.0/0\nDENY\n\n\n\nThe default network ACL, shown in the table above, allows all traffic in and out of your subnet. To allow data to flow freely to your subnet, this is a good starting place.\nHowever, you may want to restrict data at the subnet level. For example, if you have a web application, you might restrict your network to allow HTTPS traffic and remote desktop protocol (RDP) traffic to your web servers.\n\n\nInbound\n\n\n\n\n\n\n\n\n\n\n\nRule #\nSource IP\nProtocol\nPort\nAllow/Deny\nComments\n\n\n\n\n100\nAll IPv4 traffic\nTCP\n443\nALLOW\nAllows inbound HTTPS traffic from anywhere\n\n\n130\n192.0.2.0/24\nTCP\n3389\nALLOW\nAllows inbound RDP traffic to the web servers from your home network’s public IP address range (over the internet gateway)\n\n\n*\nAll IPv4 traffic\nAll\nAll\nDENY\nDenies all inbound traffic not already handled by a preceding rule (not modifiable)\n\n\n\n\n\nOutbound\n\n\n\n\n\n\n\n\n\n\n\nRule #\nDestination IP\nProtocol\nPort\nAllow/Deny\nComments\n\n\n\n\n120\n0.0.0.0/0\nTCP\n1025-65535\nALLOW\nAllows outbound responses to clients on the internet (serving people visiting the web servers in the subnet)\n\n\n*\n0.0.0.0/0\nAll\nAll\nDENY\nDenies all outbound traffic not already handled by a preceding rule (not modifiable)\n\n\n\nNotice that in the network ACL example above, you allow inbound 443 and outbound range 1025-65535. That’s because HTTP uses port 443 to initiate a connection and will respond to an ephemeral port. Network ACL’s are considered stateless, so you need to include both the inbound and outbound ports used for the protocol. If you don’t include the outbound range, your server would respond but the traffic would never leave the subnet.\nSince network ACLs are configured by default to allow incoming and outgoing traffic, you don’t need to change their initial settings unless you need additional security layers.\n\n\n\nSecure Your EC2 Instances with Security Groups\nThe next layer of security is for your EC2 Instances. Here, you can create a firewall called a security group. The default configuration of a security group blocks all inbound traffic and allows all outbound traffic.\n\nYou might be wondering: “Wouldn’t this block all EC2 instances from receiving the response of any customer requests?” Well, security groups are stateful, meaning they will remember if a connection is originally initiated by the EC2 instance or from the outside and temporarily allow traffic to respond without having to modify the inbound rules.\nIf you want your EC2 instance to accept traffic from the internet, you’ll need to open up inbound ports. If you have a web server, you may need to accept HTTP and HTTPS requests to allow that type of traffic in through your security group. You can create an inbound rule that will allow port 80 (HTTP) and port 443 (HTTPS) as shown below.\n\n\n\nType\nProtocol\nPort Range\nSource\n\n\n\n\nHTTP (80)\nTCP (6)\n80\n0.0.0.0/0\n\n\nHTTP (80)\nTCP (6)\n80\n::/0\n\n\nHTTP (443)\nTCP (6)\n443\n0.0.0.0/0\n\n\nHTTP (443)\nTCP (6)\n443\n::/0\n\n\n\nYou learned in a previous unit that subnets can be used to segregate traffic between computers in your network. Security groups can be used to do the same thing. A common design pattern is organizing your resources into different groups and creating security groups for each to control network communication between them.\n\nThis example allows you to define three tiers and isolate each tier with the security group rules you define. In this case, you only allow internet traffic to the web tier over HTTPS, Web Tier to Application Tier over HTTP, and Application tier to Database tier over MySQL. This is different from traditional on-premises environments, in which you isolate groups of resources via VLAN configuration. In AWS, security groups allow you to achieve the same isolation without tying it to your network.\n\nBack to contents\n\n\n\nStorage Types on AWS\n\n\nAWS storage services are grouped into three different categories: - block storage, e.g. EBS - file storage, e.g. EFS - object storage, e.g. S3"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#file-storage",
    "href": "posts/PYTHON/others_python/AWS.html#file-storage",
    "title": "AWS Cheat sheet",
    "section": "File Storage",
    "text": "File Storage\nYou may be familiar with file storage if you’ve interacted with file storage systems like Windows File Explorer or Finder on MacOS. You place your files in a tree-like hierarchy that consists of folders and subfolders. For example, if you have hundreds of cat photos on your laptop, you may want to create a folder called Cat photos, and place those images inside that folder to organize them. Since you know these images will be used in an application, you may want to place the cat photos folder inside another folder called Application files.\nEach file has metadata such as file name, file size, and the date the file was created. The file also has a path, for example, computer/Application_files/Cat_photos/cats-03.png. When you need to retrieve a file, your system can use the path to find it in the file hierarchy.\nFile storage is ideal when you require centralized access to files that need to be easily shared and managed by multiple host computers. Typically, this storage is mounted onto multiple hosts and requires file locking and integration with existing file system communication protocols.\nCommon use cases for file storage include:\n\nLarge content repositories\nDevelopment environments\nUser home directories"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#block-storage",
    "href": "posts/PYTHON/others_python/AWS.html#block-storage",
    "title": "AWS Cheat sheet",
    "section": "Block Storage",
    "text": "Block Storage\nWhile file storage treats files as a singular unit, block storage splits files into fixed-size chunks of data called blocks that have their own addresses. Since each block is addressable, blocks can be retrieved efficiently.\nWhen data is requested, these addresses are used by the storage system to organize the blocks in the correct order to form a complete file to present back to the requestor. Outside of the address, there is no additional metadata associated with each block. So, when you want to change a character in a file, you just change the block, or the piece of the file, that contains the character. This ease of access is why block storage solutions are fast and use less bandwidth.\n\nSince block storage is optimized for low-latency operations, it is a typical storage choice for high-performance enterprise workloads, such as databases or enterprise resource planning (ERP) systems, that require low-latency storage."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#object-storage",
    "href": "posts/PYTHON/others_python/AWS.html#object-storage",
    "title": "AWS Cheat sheet",
    "section": "Object Storage",
    "text": "Object Storage\nObjects, much like files, are also treated as a single unit of data when stored. However, unlike file storage, these objects are stored in a flat structure instead of a hierarchy. Each object is a file with a unique identifier. This identifier, along with any additional metadata, is bundled with the data and stored.\nChanging just one character in an object is more difficult than with block storage. When you want to change one character in a file, the entire file must be updated.\n\nWith object storage, you can store almost any type of data, and there is no limit to the number of objects stored, making it easy to scale. Object storage is generally useful when storing large data sets, unstructured files like media assets, and static assets, such as photos.\n\nRelate Back to Traditional Storage Systems\nIf you’ve worked with storage on-premises, you may already be familiar with block, file, and object storage. Consider the following technologies and how they relate to systems you may have seen before.\n\nBlock storage in the cloud is analogous to direct-attached storage (DAS) or a storage area network (SAN).\nFile storage systems are often supported with a network attached storage (NAS) server.\n\nAdding more storage in a traditional data center environment is a more rigid process, as you need to purchase, install, and configure these storage solutions. With cloud computing, the process is more flexible. You can create, delete, and modify storage solutions all within a matter of minutes.\n\nAmazon EC2 Instance Storage and Amazon Elastic Block Store"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#amazon-ec2-instance-store",
    "href": "posts/PYTHON/others_python/AWS.html#amazon-ec2-instance-store",
    "title": "AWS Cheat sheet",
    "section": "Amazon EC2 Instance Store",
    "text": "Amazon EC2 Instance Store\nAmazon EC2 Instance Store provides temporary block-level storage for your instance. This storage is located on disks that are physically attached to the host computer. This ties the lifecycle of your data to the lifecycle of your EC2 instance. If you delete your instance, the instance store is deleted as well. Due to this, instance store is considered ephemeral storage (volatile temporary storage attached to your instances which is only present during the running lifetime of the instance).\nInstance store is ideal if you are hosting applications that replicate data to other EC2 instances, such as Hadoop clusters. For these cluster-based workloads, having the speed of locally attached volumes and the resiliency of replicated data helps you achieve data distribution at high performance. It’s also ideal for temporary storage of information that changes frequently, such as buffers, caches, scratch data, and other temporary content."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#amazon-elastic-block-storage-amazon-ebs",
    "href": "posts/PYTHON/others_python/AWS.html#amazon-elastic-block-storage-amazon-ebs",
    "title": "AWS Cheat sheet",
    "section": "Amazon Elastic Block Storage (Amazon EBS)",
    "text": "Amazon Elastic Block Storage (Amazon EBS)\nAs the name implies, Amazon EBS is a block-level storage device that you can attach to an Amazon EC2 instance. These storage devices are called Amazon EBS volumes. EBS volumes are essentially drives of a user-configured size attached to an EC2 instance, similar to how you might attach an external drive to your laptop.\nEBS volumes act similarly to external drives in more than one way.\n\nMost Amazon EBS volumes can only be connected with one computer at a time. Most EBS volumes have a one-to-one relationship with EC2 instances, so they cannot be shared by or attached to multiple instances at one time. Note: Recently, AWS announced the Amazon EBS multi-attach feature that enables volumes to be attached to multiple EC2 instances at one time. This feature is not available for all instance types and all instances must be in the same Availability Zone.\nDetach and re-attach. You can detach an EBS volume from one EC2 instance and attach it to another EC2 instance in the same Availability Zone, to access the data on it.\nThe external drive is separate from the computer. That means, if an accident happens and the computer goes down, you still have your data on your external drive. The same is true for EBS volumes.\nYou’re limited to the size of the external drive, since it has a fixed limit to how scalable it can be. For example, you may have a 2 TB external drive and that means you can only have 2 TB of content on there. This relates to EBS as well, since volumes also have a max limitation of how much content you can store on the volume.\n\n\nSteps to create EBS\n\nOpen Amazon Ec2 console\nChoose Volumes from navigation pane\nCreate Volume\nChoose Volume type\nEnter volume size in Gb\nEnter min/max input/output operations per second (IOPS)\nEnter Throughput (MiB/s)\nChoose Availability Zone (has to be same as instance)\nSnapshot ID (keep as default)\nCreate volume\n\n\n\nScale Amazon EBS Volumes\nYou can scale Amazon EBS volumes in two ways.\n\nIncrease the volume size, as long as it doesn’t increase above the maximum size limit. For EBS volumes, the maximum amount of storage you can have is 16 TB. That means if you provision a 5 TB EBS volume, you can choose to increase the size of your volume until you get to 16 TB.\nAttach multiple volumes to a single Amazon EC2 instance. EC2 has a one-to-many relationship with EBS volumes. You can add these additional volumes during or after EC2 instance creation to provide more storage capacity for your hosts.\n\n\n\nAmazon EBS Use Cases\nAmazon EBS is useful when you need to retrieve data quickly and have data persist long-term. Volumes are commonly used in the following scenarios.\n\nOperating systems: Boot/root volumes to store an operating system. The root device for an instance launched from an Amazon Machine Image (AMI) is typically an Amazon EBS volume. These are commonly referred to as EBS-backed AMIs.\nDatabases: A storage layer for databases running on Amazon EC2 that rely on transactional reads and writes.\nEnterprise applications: Amazon EBS provides reliable block storage to run business-critical applications.\nThroughput-intensive applications: Applications that perform long, continuous reads and writes.\n\n\n\nAmazon EBS Volume Types\nThere are two main categories of Amazon EBS volumes: solid-state drives (SSDs) and hard-disk drives (HDDs). SSDs provide strong performance for random input/output (I/O), while HDDs provide strong performance for sequential I/O. AWS offers two types of each.\nThe following chart can help you decide which EBS volume is the right option for your workload.\n\nEBS Provisioned IOPS SSD\n\nDescription\n\nHighest performance SSD designed for latency-sensitive transactional workloads\n\nUse Cases\n\nI/O-intensive NoSQL and relational databases\n\nVolume Size\n\n4 GB-16 TB\n\nMax IOPS/Volume\n\n64,000\n\nMax Throughput/Volume\n\n1,000 MB/s\n\n\n\n\nEBS General Purpose SSD\n\nDescription\n\nGeneral purpose SSD that balances price and performance for a wide variety of transactional workloads\n\nUse Cases\n\nBoot volumes, low-latency interactive apps, development, and test\n\nVolume Size\n\n1 GB-16 TB\n\nMax IOPS/Volume\n\n16,000\n\nMax Throughput/Volume\n\n250 MB/s\n\n\n\n\nThroughput Optimized HDD\n\nDescription\n\nLow-cost HDD designed for frequently accessed, throughput intensive workloads\n\nUse Cases\n\nBig data, data warehouses, log processing\n\nVolume Size\n\n500 GB-16 TB\n\nMax IOPS/Volume\n\n500\n\nMax Throughput/Volume\n\n500 MB/s\n\n\n\n\nCold HDD\n\nDescription\n\nLowest cost HDD designed for less frequently accessed workloads\n\nUse Cases\n\nColder data requiring fewer scans per day\n\nVolume Size\n\n500 GB-16 TB\n\nMax IOPS/Volume\n\n250\n\nMax Throughput/Volume\n\n250 MB/s\n\n\n\n\n\nBenefits of Using Amazon EBS\nHere are the following benefits of using Amazon EBS (in case you need a quick cheat sheet).\n\nHigh availability: When you create an EBS volume, it is automatically replicated within its Availability Zone to prevent data loss from single points of failure.\nData persistence: The storage persists even when your instance doesn’t.\nData encryption: All EBS volumes support encryption.\nFlexibility: EBS volumes support on-the-fly changes. You can modify volume type, volume size, and input/output operations per second (IOPS) capacity without stopping your instance.\nBackups: Amazon EBS provides you the ability to create backups of any EBS volume.\n\n\n\nEBS Snapshots\nErrors happen. One of those errors is not backing up data, and then, inevitably losing that data. To prevent this from happening to you, you should back up your data—even in AWS.\nSince your EBS volumes consist of the data from your Amazon EC2 instance, you’ll want to take backups of these volumes, called snapshots.\nEBS snapshots are incremental backups that only save the blocks on the volume that have changed after your most recent snapshot. For example, if you have 10 GB of data on a volume, and only 2 GB of data have been modified since your last snapshot, only the 2 GB that have been changed are written to Amazon Simple Storage Service (Amazon S3).\nWhen you take a snapshot of any of your EBS volumes, these backups are stored redundantly in multiple Availability Zones using Amazon S3. This aspect of storing the backup in Amazon S3 will be handled by AWS, so you won’t need to interact with Amazon S3 to work with your EBS snapshots. You simply manage them in the EBS console (which is part of the EC2 console).\nEBS snapshots can be used to create multiple new volumes, whether they’re in the same Availability Zone or a different one. When you create a new volume from a snapshot, it’s an exact copy of the original volume at the time the snapshot was taken.\n\nObject Storage with Amazon S3"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-is-amazon-s3",
    "href": "posts/PYTHON/others_python/AWS.html#what-is-amazon-s3",
    "title": "AWS Cheat sheet",
    "section": "What Is Amazon S3?",
    "text": "What Is Amazon S3?\nUnlike Amazon EBS, Amazon S3 is a standalone storage solution that isn’t tied to compute. It enables you to retrieve your data from anywhere on the web. If you’ve ever used an online storage service to back up the data from your local machine, then you most likely have used a service similar to Amazon S3. The big difference between those online storage services and Amazon S3 is the storage type.\nAmazon S3 is an object storage service. Object storage stores data in a flat structure, using unique identifiers to look up objects when requested. An object is simply a file combined with metadata and that you can store as many of these objects as you’d like. All of these characteristics of object storage are also characteristics of Amazon S3.\n\nUnderstand Amazon S3 Concepts\nIn Amazon S3, you have to store your objects in containers called buckets. You can’t upload any object, not even a single photo, to S3 without creating a bucket first. When you create a bucket, you choose, at the very minimum, two things: the bucket name and the AWS Region you want the bucket to reside in.\nThe first part is choosing the Region you want the bucket to reside in. Typically, this will be a Region that you’ve used for other resources, such as your compute. When you choose a Region for your bucket, all objects you put inside that bucket are redundantly stored across multiple devices, across multiple Availability Zones. This level of redundancy is designed to provide Amazon S3 customers with 99.999999999% durability and 99.99% availability for objects over a given year.\nThe second part is choosing a bucket name which must be unique across all AWS accounts. AWS stops you from choosing a bucket name that has already been chosen by someone else in another AWS account. Once you choose a name, that name is yours and cannot be claimed by anyone else unless you delete that bucket, which then releases the name for others to use.\n\nAWS uses this name as part of the object identifier. In S3, each object is identified using a URL, which looks like this:\nAfter the http://, you see the bucket name. In this example, the bucket is named doc. Then, the identifier uses the service name, s3 and specifies the service provider amazonaws. After that, you have an implied folder inside the bucket called 2006-03-01 and the object inside the folder that is named AmazonS3.html. The object name is often referred to as the key name.\nNote, you can have folders inside of buckets to help you organize objects. However, remember that there’s no actual file hierarchy that supports this on the back end. It is instead a flat structure where all files and folders live at the same level. Using buckets and folders implies a hierarchy, which makes it easy to understand for the human eye.\n\n\nS3 Use Cases\nAmazon S3 is one of the most widely used storage services, with far more use cases than could fit on one screen. The following list summarizes some of the most common ways you can use Amazon S3.\n\nBackup and storage: S3 is a natural place to back up files because it is highly redundant. As mentioned in the last unit, AWS stores your EBS snapshots in S3 to take advantage of its high availability.\nMedia hosting: Because you can store unlimited objects, and each individual object can be up to 5 TBs, S3 is an ideal location to host video, photo, or music uploads.\nSoftware delivery: You can use S3 to host your software applications that customers can download.\nData lakes: S3 is an optimal foundation for a data lake because of its virtually unlimited scalability. You can increase storage from gigabytes to petabytes of content, paying only for what you use.\nStatic websites: You can configure your bucket to host a static website of HTML, CSS, and client-side scripts.\nStatic content: Because of the limitless scaling, the support for large files, and the fact that you access any object over the web at any time, S3 is the perfect place to store static content.\n\n\n\nChoose the Right Connectivity Option for Your Resources\nEverything in Amazon S3 is private by default. This means that all S3 resources, such as buckets, folders, and objects can only be viewed by the user or AWS account that created that resource. Amazon S3 resources are all private and protected to begin with.\nIf you decide that you want everyone on the internet to see your photos, you can choose to make your buckets, folders, and objects public. Keep in mind that a public resource means that everyone on the internet can see it. Most of the time, you don’t want your permissions to be all or nothing. Typically, you want to be more granular about the way you provide access to your resources.\n\nTo be more specific about who can do what with your S3 resources, Amazon S3 provides two main access management features: IAM policies and S3 bucket policies.\n\n\nUnderstand IAM Policies\nPreviously, you learned about creating and using IAM policies, and now you get to apply this to Amazon S3. When IAM policies are attached to IAM users, groups, and roles, the policies define which actions they can perform. IAM policies are not tied to any one AWS service and can be used to define access to nearly any AWS action.\nYou should use IAM policies for private buckets when:\n\nYou have many buckets with different permission requirements. Instead of defining many different S3 bucket policies, you can use IAM policies instead.\nYou want all policies to be in a centralized location. Using IAM policies allows you to manage all policy information in one location.\n\n\n\nUnderstand S3 Bucket Policies\nS3 bucket policies are similar to IAM policies, in that they are both defined using the same policy language in a JSON format. The difference is IAM policies are attached to users, groups, and roles, whereas S3 bucket policies are only attached to buckets. S3 bucket policies specify what actions are allowed or denied on the bucket.\nFor example, if you have a bucket called employeebucket, you can attach an S3 bucket policy to it that allows another AWS account to put objects in that bucket.\nOr if you wanted to allow anonymous viewers to read the objects in employeebucket, then you can apply a policy to that bucket that allows anyone to read objects in the bucket using \"Effect\":Allow on the \"Action:[\"s3:GetObject\"]\".\nHere’s an example of what that S3 bucket policy might look like. {     \"Version\":\"2012-10-17\",         \"Statement\":[{             \"Sid\":\"PublicRead\",             \"Effect\":\"Allow\",             \"Principal\": \"*\",             \"Action\":[\"s3:GetObject\"],             \"Resource\":[\"arn:aws:s3:::employeebucket/*\"]         }] }\nS3 Bucket policies can only be placed on buckets, and cannot be used for folders or objects. However, the policy that is placed on the bucket applies to every object in that bucket.\nYou should use S3 bucket policies when:\n\nYou need a simple way to do cross-account access to S3, without using IAM roles.\nYour IAM policies bump up against the defined size limit. S3 bucket policies have a larger size limit."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#encrypt-s3",
    "href": "posts/PYTHON/others_python/AWS.html#encrypt-s3",
    "title": "AWS Cheat sheet",
    "section": "Encrypt S3",
    "text": "Encrypt S3\nAmazon S3 reinforces encryption in transit (as it travels to and from Amazon S3) and at rest. To protect data at rest, you can use:\n\nServer-side encryption: This allows Amazon S3 to encrypt your object before saving it on disks in its data centers and then decrypt it when you download the objects.\nClient-side encryption: Encrypt your data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and all related tools.\n\nTo encrypt in transit, you can use client-side encryption or Secure Sockets Layer (SSL).\n\nUse Versioning to Preserve Objects\nAs you know, Amazon S3 identifies objects in part by using the object name. For example, when you upload an employee photo to S3, you may name the object employee.jpg and store it in a folder called employees. If you don’t use Amazon S3 versioning, anytime you upload an object called employee.jpg to the employees folder, it overwrites the original file. This can be an issue for several reasons.\n\nemployee.jpg is a common name for an employee photo object. You or someone else who has access to that bucket might not have intended to overwrite it, and now that you have, you no longer have access to the original file.\nYou may want to preserve different versions of employee.jpg. Without versioning, if you wanted to create a new version of employee.jpg, you would need to upload the object and choose a different name for it. Having several objects all with slight differences in naming variations may cause confusion and clutter in your bucket.\n\nSo, what do you do? You use S3 versioning!\nVersioning enables you to keep multiple versions of a single object in the same bucket. This allows you to preserve old versions of an object without having to use different naming constructs, in case you need to recover from accidental deletions, accidental overwrites, or even application failures. Let’s see how this works.\n\nIf you enable versioning for a bucket, Amazon S3 automatically generates a unique version ID for the object being stored. In one bucket, for example, you can have two objects with the same key, but different version IDs, such as employeephoto.gif (version 111111) and employeephoto.gif (version 121212).\nVersioning-enabled buckets let you recover objects from accidental deletion or overwrite.\n\nDeleting an object does not remove the object permanently. Instead, Amazon S3 puts a marker on the object that shows you tried to delete it. If you want to restore the object, you can remove this marker and it reinstates the object.\nIf you overwrite an object, it results in a new object version in the bucket. You still have access to previous versions of the object.\n\n\n\nUnderstand Versioning States\nBuckets can be in one of three states.\n\nUnversioned (the default): No new or existing objects in the bucket have a version.\nVersioning-enabled: This enables versioning for all objects in the bucket.\nVersioning-suspended: This suspends versioning for new objects. All new objects in the bucket will not have a version. However, all existing objects keep their object versions.\n\nThe versioning state applies to all of the objects in that bucket. Keep in mind that storage costs are incurred for all objects in your bucket and all versions of those objects. To reduce your S3 bill, you may want to delete previous versions of your objects that are no longer in use."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-are-amazon-s3-storage-classes",
    "href": "posts/PYTHON/others_python/AWS.html#what-are-amazon-s3-storage-classes",
    "title": "AWS Cheat sheet",
    "section": "What Are Amazon S3 Storage Classes?",
    "text": "What Are Amazon S3 Storage Classes?\nWhen you upload an object to Amazon S3 and you don’t specify the storage class, you’re uploading it to the default storage class—often referred to as standard storage. When you learned about Amazon S3 in previous units, you were learning about the standard storage class without even knowing it!\nS3 storage classes let you change your storage tier as your data characteristics change. For example, if you are now accessing your old photos infrequently, you may want to change the storage class those photos are stored in to save on costs.\nThere are six S3 storage classes.\n\nAmazon S3 Standard: This is considered general purpose storage for cloud applications, dynamic websites, content distribution, mobile and gaming applications, and big data analytics.\nAmazon S3 Intelligent-Tiering: This tier is useful if your data has unknown or changing access patterns. S3 Intelligent-Tiering stores objects in two tiers, a frequent access tier and an infrequent access tier. Amazon S3 monitors access patterns of your data, and automatically moves your data to the most cost-effective storage tier based on frequency of access.\nAmazon S3 Standard-Infrequent Access (S3 Standard-IA): S3 Standard-IA is for data that is accessed less frequently, but requires rapid access when needed. S3 Standard-IA offers the high durability, high throughput, and low latency of S3 Standard, with a low per-GB storage price and per-GB retrieval fee. This storage tier is ideal if you want to store long-term backups, disaster recovery files, and so on.\nAmazon S3 One Zone-Infrequent Access (S3 One Zone-IA): Unlike other S3 storage classes which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ and costs 20% less than S3 Standard-IA. S3 One Zone-IA is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA. It’s a good choice for storing secondary backup copies of on-premises data or easily re-creatable data.\nAmazon S3 Glacier: S3 Glacier is a secure, durable, and low-cost storage class for data archiving. You can reliably store any amount of data at costs that are competitive with or cheaper than on-premises solutions. To keep costs low yet suitable for varying needs, S3 Glacier provides three retrieval options that range from a few minutes to hours.\nAmazon S3 Glacier Deep Archive: S3 Glacier Deep Archive is Amazon S3’s lowest-cost storage class and supports long-term retention and digital preservation for data that may be accessed once or twice in a year. It is designed for customers—particularly those in highly regulated industries, such as the Financial Services, Healthcare, and Public Sectors—that retain data sets for 7 to 10 years or longer to meet regulatory compliance requirements.\n\n\nAutomate Tier Transitions with Object Lifecycle Management\nIf you keep manually changing your objects, such as your employee photos, from storage tier to storage tier, you may want to look into automating this process using a lifecycle policy. When you define a lifecycle policy configuration for an object or group of objects, you can choose to automate two actions: transition and expiration actions.\n\nTransition actions are used to define when you should transition your objects to another storage class.\nExpiration actions define when objects expire and should be permanently deleted.\n\nFor example, you might choose to transition objects to S3 Standard-IA storage class 30 days after you created them, or archive objects to the S3 Glacier storage class one year after creating them.\n\nThe following use cases are good candidates for lifecycle management.\n\nPeriodic logs: If you upload periodic logs to a bucket, your application might need them for a week or a month. After that, you might want to delete them.\nData that changes in access frequency: Some documents are frequently accessed for a limited period of time. After that, they are infrequently accessed. At some point, you might not need real-time access to them, but your organization or regulations might require you to archive them for a specific period. After that, you can delete them.\n\n\nChoose the Right Storage Service\n\nHere’s a recap of all the storage services mentioned so far. By the end of this reading, you should be able to better answer the question “Which storage service should I use?” for some of the more common scenarios."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#amazon-ec2-instance-store-1",
    "href": "posts/PYTHON/others_python/AWS.html#amazon-ec2-instance-store-1",
    "title": "AWS Cheat sheet",
    "section": "Amazon EC2 Instance Store",
    "text": "Amazon EC2 Instance Store\nInstance store is ephemeral block storage. This is preconfigured storage that exists on the same physical server that hosts the EC2 instance and cannot be detached from Amazon EC2. You can think of it as a built-in drive for your EC2 instance.\nInstance store is generally well-suited for temporary storage of information that is constantly changing, such as buffers, caches, and scratch data. It is not meant for data that is persistent or long-lasting.\nIf you need persistent long-term block storage that can be detached from Amazon EC2 and provide you more management flexibility, such as increasing volume size or creating snapshots, then you should use Amazon EBS."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#amazon-ebs",
    "href": "posts/PYTHON/others_python/AWS.html#amazon-ebs",
    "title": "AWS Cheat sheet",
    "section": "Amazon EBS",
    "text": "Amazon EBS\nAmazon EBS is meant for data that changes frequently and needs to persist through instance stops, terminations, or hardware failures. Amazon EBS has two different types of volumes: SSD-backed volumes and HDD-backed volumes.\nSSD-backed volumes have the following characteristics.\n\nPerformance depends on IOPS (input/output operations per second).\nIdeal for transactional workloads such as databases and boot volumes.\n\nHDD-backed volumes have the following characteristics:\n\nPerformance depends on MB/s.\nIdeal for throughput-intensive workloads, such as big data, data warehouses, log processing, and sequential data I/O.\n\nHere are a few important features of Amazon EBS that you need to know when comparing it to other services.\n\nIt is block storage.\nYou pay for what you provision (you have to provision storage in advance).\nEBS volumes are replicated across multiple servers in a single Availability Zone.\nMost EBS volumes can only be attached to a single EC2 instance at a time."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#amazon-s3",
    "href": "posts/PYTHON/others_python/AWS.html#amazon-s3",
    "title": "AWS Cheat sheet",
    "section": "Amazon S3",
    "text": "Amazon S3\nIf your data doesn’t change that often, Amazon S3 might be a more cost-effective and scalable storage solution. S3 is ideal for storing static web content and media, backups and archiving, data for analytics, and can even be used to host entire static websites with custom domain names.\nHere are a few important features of Amazon S3 to know about when comparing it to other services.\n\nIt is object storage.\nYou pay for what you use (you don’t have to provision storage in advance).\nAmazon S3 replicates your objects across multiple Availability Zones in a Region.\nAmazon S3 is not storage attached to compute."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#amazon-elastic-file-system-amazon-efs-and-amazon-fsx",
    "href": "posts/PYTHON/others_python/AWS.html#amazon-elastic-file-system-amazon-efs-and-amazon-fsx",
    "title": "AWS Cheat sheet",
    "section": "Amazon Elastic File System (Amazon EFS) and Amazon FSx",
    "text": "Amazon Elastic File System (Amazon EFS) and Amazon FSx\nIn this module, you’ve already learned about Amazon S3 and Amazon EBS. You learned that S3 uses a flat namespace and isn’t meant to serve as a standalone file system. You also learned most EBS volumes can only be attached to one EC2 instance at a time. So, if you need file storage on AWS, which service should you use?\nFor file storage that can mount on to multiple EC2 instances, you can use Amazon Elastic File System (Amazon EFS) or Amazon FSx. Use the following table for more information about each of these services.\n\n\n\n\n\n\n\n\nService\nCharacteristic\nMore Information\n\n\n\n\nAmazon Elastic File System (EFS)\nFully managed NFS file system.\nEFS FAQs\n\n\nAmazon FSx for Windows File Server\nFully managed file server built on Windows Server that supports the SMB protocol.\nFSx for Windows File Server FAQs\n\n\nAmazon FSx for Lustre\nFully managed Lustre file system that integrates with S3.\nFSx for Lustre FAQs\n\n\n\nHere are a few important features of Amazon EFS and FSx to know about when comparing them to other services.\n\nIt is file storage.\nYou pay for what you use (you don’t have to provision storage in advance).\nAmazon EFS and Amazon FSx can be mounted onto multiple EC2 instances.\n\n\n\nExplore Databases on AWS"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#understanding-the-history-behind-enterprise-databases",
    "href": "posts/PYTHON/others_python/AWS.html#understanding-the-history-behind-enterprise-databases",
    "title": "AWS Cheat sheet",
    "section": "Understanding the History Behind Enterprise Databases",
    "text": "Understanding the History Behind Enterprise Databases\nChoosing a database used to be a straightforward decision. There were only a few options to choose from. In the past, you likely considered a few vendors and then inevitably chose one for all of your applications.\nBusinesses often selected the database technology they were going to use, even before they fully understood their use case. Since the 1970s, the database most commonly selected by businesses was a relational database.\n\nWhat Is a Relational Database?\nA relational database organizes data into tables. Data in one table can be linked to data in other tables to create relationships—hence, the relational part of the name.\nA table stores data in rows and columns. A row, often called a record, contains all information about a specific entry. Columns describe attributes of that entry. Here’s an example of three tables in a relational database.\n\nThis shows a table for books, a table for sales, and a table for authors. In the books table, each row includes the book ISBN, the title, the author, and the format. Each of these attributes is stored in its own column. The books table has something in common with the other two tables: the author attribute. That common column creates a relationship between the tables.\nThe tables, rows, columns, and relationships between them is referred to as a logical schema. With relational databases, a schema is fixed. Once the database is operational, it becomes difficult to change the schema. This requires most of the data modeling to be done upfront before the database is active.\n\n\nWhat Is a Relational Database Management System?\nA relational database management system (RDBMS) lets you create, update, and administer a relational database. Here are some common examples of relational database management systems:\n\nMySQL\nPostgresQL\nOracle\nSQL server\nAmazon Aurora\n\nYou communicate with most RDBMS by using Structured Query Language (SQL) queries. Here’s an example: SELECT * FROM table_name.\nThis query selects all of the data from a particular table. However, the real power of SQL queries is in creating more complex queries that let you pull data from several tables to piece together patterns and answers to business problems. For example, querying the sales table and the book table together to see sales in relation to an author’s books. This is made possible by a join, which we talk about next.\n\n\nThe Benefits of Using a Relational Database\nThere are many benefits to using a relational database. A few of them are listed here.\n\nJoins: You can join tables, enabling you to better understand relationships between your data.\nReduced redundancy: You can store data in one table and reference it from other tables instead of saving the same data in different places.\nFamiliarity: Relational databases have been a popular choice since the 1970s. Due to this popularity, technical professionals often have familiarity and experience with this type of database.\nAccuracy: Relational databases ensure that your data is persisted with high integrity and adheres to the ACID (atomicity, consistency, isolation, durability) principle.\n\n\n\nUse Cases for Relational Databases\nMuch of the world runs on relational databases. In fact, they’re at the core of many mission-critical applications, some of which you may use in your day to day life. Here are some common use cases for relational databases.\nApplications that have a solid schema that doesn’t change often, such as:\n\nLift and shift applications that lifts an app from on-premises and shifts it to the cloud, with little or no modifications.\n\nApplications that need persistent storage that follows the ACID principle, such as:\n\nEnterprise Resource Planning (ERP) applications\nCustomer Relationship Management (CRM) applications\nCommerce and financial applications\n\n\n\nChoose Between Unmanaged and Managed Databases\nIf you want to run a relational database on AWS, you first need to select how you want to run it: the unmanaged way or the managed way.\nThe paradigm of managed versus unmanaged services is similar to the Shared Responsibility Model. The Shared Responsibility Model distinguishes between AWS’s and the customer’s security responsibility over a service. Similarly, managed versus unmanaged can be understood as a tradeoff between convenience and control.\n\n\nOn-Premises Database\nLet’s say you operate a relational database on-premises (in your own data center). In this scenario, you are responsible for all aspects of operation, including the security and electricity of the data center, the management of the host machine, the management of the database on that host, as well as optimizing queries and managing customer data. You are responsible for absolutely everything, which means you have control over absolutely everything.\n\n\nUnmanaged Database\n\nNow, let’s say you want to shift some of this work to AWS by running your relational database on Amazon EC2. If you host a database on Amazon EC2, AWS takes care of implementing and maintaining the physical infrastructure and hardware and installing the operating system of the EC2 instance. However, you’re still responsible for managing the EC2 instance, managing the database on that host, optimizing queries, and managing customer data.\nThis is what is often referred to as the unmanaged database option on AWS. AWS is responsible for and has control over the hardware and underlying infrastructure, and you are responsible and have control over management of the host and database.\n\n\nManaged Database\n\nIf you want to shift even more of the work to AWS, you can use a managed database service. These services provide the setup of both the EC2 instance and the database, and they provide systems for high availability, scalability, patching, and backups. However, you’re still responsible for database tuning, query optimization, and of course, ensuring that your customer data is secure. This provides you ultimate convenience, but you have the least amount of control compared to the two previous options."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-is-amazon-rds",
    "href": "posts/PYTHON/others_python/AWS.html#what-is-amazon-rds",
    "title": "AWS Cheat sheet",
    "section": "What Is Amazon RDS?",
    "text": "What Is Amazon RDS?\nAmazon RDS enables you to create and manage relational databases in the cloud without the operational burden of traditional database management. For example, if you sell healthcare equipment and your goal is to be the number-one seller in the Pacific Northwest, building out a database doesn’t directly help you achieve that goal though having a database is necessary to achieve the goal.\nAmazon RDS helps you offload some of this unrelated work of creating and managing a database. You can focus on the tasks that differentiate your application, instead of infrastructure-related tasks such as provisioning, patching, scaling, and restoring.\nAmazon RDS supports most of the popular relational database management systems, ranging from commercial options, open source options, and even an AWS-specific option. Here are the supported Amazon RDS engines.\n\nCommercial: Oracle, SQL Server\nOpen Source: MySQL, PostgreSQL, MariaDB\nCloud Native: Amazon Aurora\n\nNote: The cloud native option, Amazon Aurora, is a MySQL and PostgreSQL-compatible database built for the cloud. It is more durable, more available, and provides faster performance than the Amazon RDS version of MySQL and PostgreSQL.\n\nUnderstand DB Instances\nJust like the databases that you would build and manage yourself, Amazon RDS is built off of compute and storage. The compute portion is called the DB (database) instance, which runs the database engine. Depending on the engine of the DB instance you choose, the engine will have different supported features and configurations. A DB instance can contain multiple databases with the same engine, and each database can contain multiple tables.\nUnderneath the DB instance is an EC2 instance. However, this instance is managed through the Amazon RDS console instead of the Amazon EC2 console. When you create your DB instance, you choose the instance type and size. Amazon RDS supports three instance families.\n\nStandard, which include general-purpose instances\nMemory Optimized, which are optimized for memory-intensive applications\nBurstable Performance, which provides a baseline performance level, with the ability to burst to full CPU usage.\n\nThe DB instance you choose affects how much processing power and memory it has. Not all of the options are available to you, depending on the engine that you choose.\nMuch like a regular EC2 instance, the DB instance uses Amazon Elastic Block Store (EBS) volumes as its storage layer. You can choose between three types of EBS volume storage.\n\nGeneral purpose (SSD)\nProvisioned IOPS (SSD)\nMagnetic storage (not recommended)\n\n\n\nWork with Amazon RDS in an Amazon Virtual Private Cloud\nWhen you create a DB instance, you select the Amazon Virtual Private Cloud (VPC) that your databases will live in. Then, you select the subnets that you want the DB instances to be placed in. This is referred to as a DB subnet group. To create a DB subnet group, you specify:\n\nThe Availability Zones (AZs) that include the subnets you want to add\nThe subnets in that AZ where your DB instance are placed\n\nThe subnets you add should be private so they don’t have a route to the internet gateway. This ensures your DB instance, and the cat data inside of it, can only be reached by the app backend.\nAccess to the DB instance can be further restricted by using network access control lists (ACLs) and security groups. With these firewalls, you can control, at a granular level, what type of traffic you want to allow into your database. Using these controls provide layers of security for your infrastructure. It reinforces that only the backend instances have access to the database.\n\n\nUse AWS Identity and Access Management (IAM) Policies to Secure Amazon RDS\nNetwork ACLs and security groups allow you to dictate the flow of traffic. If you want to restrict what actions and resources your employees can access, you can use IAM policies."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#back-up-your-data",
    "href": "posts/PYTHON/others_python/AWS.html#back-up-your-data",
    "title": "AWS Cheat sheet",
    "section": "Back Up Your Data",
    "text": "Back Up Your Data\nYou don’t want to lose any of that precious cat information. To take regular backups of your RDS instance, you can use:\n\nAutomatic backups\nManual snapshots\n\n\nAutomatic Backups\nAutomated backups are turned on by default. This backs up your entire DB instance (not just individual databases on the instance), and your transaction logs. When you create your DB instance, you set a backup window that is the period of time that automatic backups occur. Typically, you want to set these windows during a time when your database experiences little activity because it can cause increased latency and downtime.\nYou can retain your automated backups between 0 and 35 days. You might ask yourself, “Why set automated backups for 0 days?” The 0 days setting actually disables automatic backups from happening. Keep in mind that if you set it to 0, it will also delete all existing automated backups. This is not ideal, as the benefit of having automated backups is having the ability to do point-in-time recovery.\nIf you restore data from an automated backup, you have the ability to do point-in-time recovery. Point-in-time recovery creates a new DB instance using data restored from a specific point in time. This restoration method provides more granularity by restoring the full backup and rolling back transactions up to the specified time range.\n\n\nManual Snapshots\nIf you want to keep your automated backups longer than 35 days, use manual snapshots. Manual snapshots are similar to taking EBS snapshots, except you manage them in the RDS console. These are backups that you can initiate at any time, that exist until you delete them.\nFor example, to meet a compliance requirement that mandates you to keep database backups for a year, you would need to use manual snapshots to ensure those backups are retained for that period of time.\nIf you restore data from a manual snapshot, it creates a new DB instance using the data from the snapshot.\n\n\nWhich Backup Option Should I Use?\nThe answer, almost always, is both. Automated backups are beneficial for the point-in-time recovery. Manual snapshots allow you to retain backups for longer than 35 days.\n\n\nGet Redundancy with Amazon RDS Multi-AZ\nWhen you enable Amazon RDS Multi-AZ, Amazon RDS creates a redundant copy of your database in another AZ. You end up with two copies of your database: a primary copy in a subnet in one AZ and a standby copy in a subnet in a second AZ.\nThe primary copy of your database provides access to your data so that applications can query and display that information.\nThe data in the primary copy is synchronously replicated to the standby copy. The standby copy is not considered an active database, and does not get queried by applications.\nTo improve availability, Amazon RDS Multi-AZ ensures that you have two copies of your database running and that one of them is in the primary role. If there’s an availability issue, such as the primary database losing connectivity, Amazon RDS triggers an automatic failover.\nWhen you create a DB instance, a domain name system (DNS) name is provided. AWS uses that DNS name to failover to the standby database. In an automatic failover, the standby database is promoted to the primary role and queries are redirected to the new primary database.\nTo ensure that you don’t lose Multi-AZ configuration, a new standby database is created by either:\n\nDemoting the previous primary to standby if it’s still up and running\nOr standing up a new standby DB instance\n\nThe reason you can select multiple subnets for an Amazon RDS database is because of the Multi-AZ configuration. You’ll want to ensure that you have used subnets in different AZs for your primary and standby copies."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-is-amazon-dynamodb",
    "href": "posts/PYTHON/others_python/AWS.html#what-is-amazon-dynamodb",
    "title": "AWS Cheat sheet",
    "section": "What Is Amazon DynamoDB?",
    "text": "What Is Amazon DynamoDB?\nAmazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. DynamoDB lets you offload the administrative burdens of operating and scaling a distributed database so that you don’t have to worry about hardware provisioning, setup and configuration, replication, software patching, or cluster scaling.\nWith DynamoDB, you can create database tables that can store and retrieve any amount of data and serve any level of request traffic. You can scale up or scale down your tables’ throughput capacity without downtime or performance degradation. You can use the AWS Management Console to monitor resource utilization and performance metrics.\nDynamoDB automatically spreads the data and traffic for your tables over a sufficient number of servers to handle your throughput and storage requirements, while maintaining consistent and fast performance. All of your data is stored on solid-state disks (SSDs) and is automatically replicated across multiple Availability Zones in an AWS Region, providing built-in high availability and data durability."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#core-components-of-amazon-dynamodb",
    "href": "posts/PYTHON/others_python/AWS.html#core-components-of-amazon-dynamodb",
    "title": "AWS Cheat sheet",
    "section": "Core Components of Amazon DynamoDB",
    "text": "Core Components of Amazon DynamoDB\nIn DynamoDB, tables, items, and attributes are the core components that you work with. A table is a collection of items, and each item is a collection of attributes. DynamoDB uses primary keys to uniquely identify each item in a table and secondary indexes to provide more querying flexibility.\nThe following are the basic DynamoDB components:\nTables – Similar to other database systems, DynamoDB stores data in tables. A table is a collection of data. For example, see the example table called People that you could use to store personal contact information about friends, family, or anyone else of interest. You could also have a Cars table to store information about vehicles that people drive.\nItems – Each table contains zero or more items. An item is a group of attributes that is uniquely identifiable among all of the other items. In a People table, each item represents a person. For a Cars table, each item represents one vehicle. Items in DynamoDB are similar in many ways to rows, records, or tuples in other database systems. In DynamoDB, there is no limit to the number of items you can store in a table.\nAttributes – Each item is composed of one or more attributes. An attribute is a fundamental data element, something that does not need to be broken down any further. For example, an item in a People table contains attributes called PersonID, LastName, FirstName, and so on. For a Department table, an item might have attributes such as DepartmentID, Name, Manager, and so on. Attributes in DynamoDB are similar in many ways to fields or columns in other database systems.\n\nSecurity with Amazon DynamoDB\nDynamoDB also offers encryption at rest, which eliminates the operational burden and complexity involved in protecting sensitive data. For more information, see DynamoDB Encryption at Rest."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#aws-database-services",
    "href": "posts/PYTHON/others_python/AWS.html#aws-database-services",
    "title": "AWS Cheat sheet",
    "section": "AWS Database Services",
    "text": "AWS Database Services\nAWS has a variety of different database options for different use cases. Use the table below to get a quick look at the AWS database portfolio.\n\n\n\n\n\n\n\n\nDatabase Type\nUse Cases\nAWS Service\n\n\n\n\nRelational\nTraditional applications, ERP, CRM, e-commerce\nAmazon RDS, Amazon Aurora, Amazon Redshift\n\n\nKey-value\nHigh-traffic web apps, e-commerce systems, gaming applications\nAmazon DynamoDB\n\n\nIn-memory\nCaching, session management, gaming leaderboards, geospatial applications\nAmazon ElastiCache for Memcached, Amazon ElastiCache for Redis\n\n\nDocument\nContent management, catalogs, user profiles\nAmazon DocumentDB (with MongoDB compatibility)\n\n\nWide column\nHigh-scale industrial apps for equipment maintenance, fleet management, and route optimization\nAmazon Keyspaces (for Apache Cassandra)\n\n\nGraph\nFraud detection, social networking, recommendation engines\nAmazon Neptune\n\n\nTime series\nIoT applications, DevOps, industrial telemetry\nAmazon Timestream\n\n\nLedger\nSystems of record, supply chain, registrations, banking transactions\nAmazon QLDB"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#breaking-up-applications-and-databases",
    "href": "posts/PYTHON/others_python/AWS.html#breaking-up-applications-and-databases",
    "title": "AWS Cheat sheet",
    "section": "Breaking Up Applications and Databases",
    "text": "Breaking Up Applications and Databases\nAs the industry changes, applications and databases change too. Today, with larger applications, you no longer see just one database supporting it. Instead, these applications are being broken into smaller services, each with their own purpose-built database supporting it.\nThis shift removes the idea of a one-size-fits-all database and replaces it with a complementary database strategy. You can give each database the appropriate functionality, performance, and scale that the workload requires.\n\n\nMonitoring on AWS\n\n\nWhen operating a website like the Employee Directory Application on AWS you may have questions like:\n\nHow many people are visiting my site day to day?\nHow can I track the number of visitors over time?\nHow will I know if the website is having performance or availability issues?\nWhat happens if my Amazon Elastic Compute Cloud (EC2) instance runs out of capacity?\nWill I be alerted if my website goes down?\n\nYou need a way to collect and analyze data about the operational health and usage of your resources. The act of collecting, analyzing, and using data to make decisions or answer questions about your IT resources and systems is called monitoring.\nMonitoring enables you to have a near real-time pulse on your system and answer the questions listed above. You can use the data you collect to watch for operational issues caused by events like over-utilization of resources, application flaws, resource misconfiguration, or security-related events.\nThink of the data collected through monitoring as outputs of the system, or metrics."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#use-metrics-to-solve-problems",
    "href": "posts/PYTHON/others_python/AWS.html#use-metrics-to-solve-problems",
    "title": "AWS Cheat sheet",
    "section": "Use Metrics to Solve Problems",
    "text": "Use Metrics to Solve Problems\nThe resources that host your solutions on AWS all create various forms of data that you might be interested in collecting. You can think of each individual data point that is created by a resource as a metric. Metrics that are collected and analyzed over time become statistics, like the example of average CPU utilization over time.\nConsider this: One way to evaluate the health of an Amazon EC2 instance is through CPU utilization. Generally speaking, if an EC2 instance has a high CPU utilization, it can mean a flood of requests. Or it can reflect a process that has encountered an error and is consuming too much of the CPU. When analyzing CPU utilization, take a process that exceeds a specific threshold for an unusual length of time. Use that abnormal event as a cue to either manually or automatically resolve the issue through actions like scaling the instance.\nThis is one example of a metric. Other examples of metrics EC2 instances have are - network utilization, - disk performance, - memory utilization, and - the logs created by the applications running on top of EC2."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#know-the-different-types-of-metrics",
    "href": "posts/PYTHON/others_python/AWS.html#know-the-different-types-of-metrics",
    "title": "AWS Cheat sheet",
    "section": "Know the Different Types of Metrics",
    "text": "Know the Different Types of Metrics\nDifferent resources in AWS create different types of metrics. An Amazon Simple Storage Service (S3) bucket would not have CPU utilization like an EC2 instance does. Instead, S3 creates metrics related to - the objects stored in a bucket like the overall size - the number of objects in a bucket - requests made to the bucket such as reading or writing objects.\nAmazon Relational Database Service (RDS) creates metrics such as - database connections, - CPU utilization of an instance, - or disk space consumption.\nThis is not a complete list for any of the services mentioned, but you can see how different resources create different metrics.\nYou could be interested in a wide variety of metrics depending on the types of resources you are using, the goals you have, or the types of questions you want answered."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#understand-the-benefits-of-monitoring",
    "href": "posts/PYTHON/others_python/AWS.html#understand-the-benefits-of-monitoring",
    "title": "AWS Cheat sheet",
    "section": "Understand the Benefits of Monitoring",
    "text": "Understand the Benefits of Monitoring\nMonitoring gives you visibility into your resources, but the question now is, “Why is that important?” The following are some of the benefits of monitoring.\nRespond to operational issues proactively before your end users are aware of them. It’s a bad practice to wait for end users to let you know your application is experiencing an outage. Through monitoring, you can keep tabs on metrics like error response rate or request latency, over time, that help signal that an outage is going to occur. This enables you to automatically or manually perform actions to prevent the outage from happening—fixing the problem before your end users are aware of it.\nImprove the performance and reliability of your resources. Monitoring the different resources that comprise your application provides you with a full picture of how your solution behaves as a system. Monitoring, if done well, can illuminate bottlenecks and inefficient architectures. This enables you to drive performance and reliability improvement processes.\nRecognize security threats and events. When you monitor resources, events, and systems over time, you create what is called a baseline. A baseline defines what activity is normal. Using a baseline, you can spot anomalies like unusual traffic spikes or unusual IP addresses accessing your resources. When an anomaly occurs, an alert can be sent out or an action can be taken to investigate the event.\nMake data-driven decisions for your business. Monitoring is not only to keep an eye on IT operational health. It also helps drive business decisions. For example, let’s say you launched a new feature for your cat photo app, and want to know whether it’s being used. You can collect application-level metrics and view the number of users who use the new feature. With your findings, you decide whether to invest more time into improving the new feature.\nCreate more cost-effective solutions. Through monitoring, you can view resources that are being underutilized and rightsize your resources to your usage. This helps you optimize cost and make sure you aren’t spending more money than necessary."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#enable-visibility",
    "href": "posts/PYTHON/others_python/AWS.html#enable-visibility",
    "title": "AWS Cheat sheet",
    "section": "Enable Visibility",
    "text": "Enable Visibility\nAWS resources create data you can monitor through metrics, logs, network traffic, events, and more. This data is coming from components that are distributed in nature, which can lead to difficulty in collecting the data you need if you don’t have a centralized place to review it all. AWS has already done that for you with a service called Amazon CloudWatch.\nAmazon CloudWatch is a monitoring and observability service that collects data like those mentioned in this module. CloudWatch provides actionable insights into your applications, and enables you to respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health. This unified view is important.\nYou can use CloudWatch to:\n\nDetect anomalous behavior in your environments.\nSet alarms to alert you when something’s not right.\nVisualize logs and metrics with the AWS Management Console.\nTake automated actions like scaling.\nTroubleshoot issues.\nDiscover insights to keep your applications healthy."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#how-cloudwatch-works",
    "href": "posts/PYTHON/others_python/AWS.html#how-cloudwatch-works",
    "title": "AWS Cheat sheet",
    "section": "How CloudWatch Works",
    "text": "How CloudWatch Works\nThe great thing about CloudWatch is that all you need to get started is an AWS account. It is a managed service, which enables you to focus on monitoring, without managing any underlying infrastructure.\nThe employee directory app is built with various AWS services working together as building blocks. It would be difficult to monitor all of these different services independently, so CloudWatch acts as one centralized place where metrics are gathered and analyzed. You already learned how EC2 instances post CPU utilization as a metric to CloudWatch. Different AWS resources post different metrics that you can monitor. You can view a list of services that send metrics to CloudWatch in the resources section of this unit.\nMany AWS services send metrics automatically for free to CloudWatch at a rate of one data point per metric per 5-minute interval, without you needing to do anything to turn on that data collection. This by itself gives you visibility into your systems without you needing to spend any extra money to do so. This is known as basic monitoring. For many applications, basic monitoring does the job.\nFor applications running on EC2 instances, you can get more granularity by posting metrics every minute instead of every 5 minutes using a feature like detailed monitoring. Detailed monitoring has an extra fee associated."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#break-down-metrics",
    "href": "posts/PYTHON/others_python/AWS.html#break-down-metrics",
    "title": "AWS Cheat sheet",
    "section": "Break Down Metrics",
    "text": "Break Down Metrics\nEach metric in CloudWatch has a timestamp and is organized into containers called namespaces. Metrics in different namespaces are isolated from each other—you can think of them as belonging to different categories.\nAWS services that send data to CloudWatch attach dimensions to each metric. A dimension is a name/value pair that is part of the metric’s identity. You can use dimensions to filter the results that CloudWatch returns. For example, you can get statistics for a specific EC2 instance by specifying the InstanceId dimension when you search."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#set-up-custom-metrics",
    "href": "posts/PYTHON/others_python/AWS.html#set-up-custom-metrics",
    "title": "AWS Cheat sheet",
    "section": "Set Up Custom Metrics",
    "text": "Set Up Custom Metrics\nLet’s say for your application you wanted to record the number of page views your website gets. How would you record this metric to CloudWatch? It’s an application-level metric, meaning that it’s not something the EC2 instance would post to CloudWatch by default. This is where custom metrics come in. Custom metrics allows you to publish your own metrics to CloudWatch.\nIf you want to gain more granular visibility, you can use high-resolution custom metrics, which enable you to collect custom metrics down to a 1-second resolution. This means you can send one data point per second per custom metric.\nOther examples of custom metrics are:\n\nWeb page load times\nRequest error rates\nNumber of processes or threads on your instance\nAmount of work performed by your application\n\nNote: You can get started with custom metrics by programmatically sending the metric to CloudWatch using the PutMetricData API."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#understand-the-cloudwatch-dashboards",
    "href": "posts/PYTHON/others_python/AWS.html#understand-the-cloudwatch-dashboards",
    "title": "AWS Cheat sheet",
    "section": "Understand the CloudWatch Dashboards",
    "text": "Understand the CloudWatch Dashboards\nOnce you’ve provisioned your AWS resources and they are sending metrics to CloudWatch, you can then visualize and review that data using the CloudWatch console with dashboards. Dashboards are customizable home pages that you use for data visualization for one or more metrics through the use of widgets, such as a graph or text.\nYou can build many custom dashboards, each one focusing on a distinct view of your environment. You can even pull data from different Regions into a single dashboard in order to create a global view of your architecture.\nCloudWatch aggregates statistics according to the period of time that you specify when creating your graph or requesting your metrics. You can also choose whether your metric widgets display live data. Live data is data published within the last minute that has not been fully aggregated.\nYou are not bound to using CloudWatch exclusively for all your visualization needs. You can use external or custom tools to ingest and analyze CloudWatch metrics using the GetMetricData API.\nAs far as security goes, you can control who has access to view or manage your CloudWatch dashboards through AWS Identity and Access Management (IAM) policies that get associated with IAM users, IAM groups, or IAM roles.\n\nGet to Know CloudWatch Logs\nCloudWatch can also be the centralized place for logs to be stored and analyzed, using CloudWatch Logs. CloudWatch Logs can monitor, store, and access your log files from applications running on Amazon EC2 instances, AWS Lambda functions, and other sources.\nCloudWatch Logs allows you to query and filter your log data. For example, let’s say you’re looking into an application logic error for your application, and you know that when this error occurs it will log the stack trace. Since you know it logs the error, you query your logs in CloudWatch Logs to find the stack trace. You also set up metric filters on logs, which turn log data into numerical CloudWatch metrics that you graph and use on your dashboards.\nSome services are set up to send log data to CloudWatch Logs with minimal effort, like AWS Lambda. With AWS Lambda, all you need to do is give the Lambda function the correct IAM permissions to post logs to CloudWatch Logs. Other services require more configuration. For example, if you want to send your application logs from an EC2 instance into CloudWatch Logs, you need to first install and configure the CloudWatch Logs agent on the EC2 instance.\nThe CloudWatch Logs agent enables Amazon EC2 instances to automatically send log data to CloudWatch Logs. The agent includes the following components.\n\nA plug-in to the AWS Command Line Interface (CLI) that pushes log data to CloudWatch Logs.\nA script that initiates the process to push data to CloudWatch Logs.\nA cron job that ensures the daemon is always running.\n\nAfter the agent is installed and configured, you can then view your application logs in CloudWatch Logs.\n\n\nLearn the CloudWatch Logs Terminology\nLog data sent to CloudWatch Logs can come from different sources, so it’s important you understand how they’re organized and the terminology used to describe your logs.\nLog event: A log event is a record of activity recorded by the application or resource being monitored, and it has a timestamp and an event message.\nLog stream: Log events are then grouped into log streams, which are sequences of log events that all belong to the same resource being monitored. For example, logs for an EC2 instance are grouped together into a log stream that you can then filter or query for insights.\nLog groups: Log streams are then organized into log groups. A log group is composed of log streams that all share the same retention and permissions settings. For example, if you have multiple EC2 instances hosting your application and you are sending application log data to CloudWatch Logs, you can group the log streams from each instance into one log group. This helps keep your logs organized."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#configure-a-cloudwatch-alarm",
    "href": "posts/PYTHON/others_python/AWS.html#configure-a-cloudwatch-alarm",
    "title": "AWS Cheat sheet",
    "section": "Configure a CloudWatch Alarm",
    "text": "Configure a CloudWatch Alarm\nYou can create CloudWatch alarms to automatically initiate actions based on sustained state changes of your metrics. You configure when alarms are triggered and the action that is performed.\nYou first need to decide what metric you want to set up an alarm for, then you define the threshold at which you want the alarm to trigger. Next, you define the specified time period of which the metric should cross the threshold for the alarm to be triggered.\nFor example, if you wanted to set up an alarm for an EC2 instance to trigger when the CPU utilization goes over a threshold of 80%, you also need to specify the time period the CPU utilization is over the threshold. You don’t want to trigger an alarm based on short temporary spikes in the CPU. You only want to trigger an alarm if the CPU is elevated for a sustained amount of time, for example if it is over 80% for 5 minutes or longer, when there is a potential resource issue.\nKeeping all that in mind, to set up an alarm you need to choose the metric, the threshold, and the time period.\nAn alarm has three possible states.\n\nOK: The metric is within the defined threshold. Everything appears to be operating like normal.\nALARM: The metric is outside of the defined threshold. This could be an operational issue.\nINSUFFICIENT_DATA: The alarm has just started, the metric is not available, or not enough data is available for the metric to determine the alarm state.\n\nAn alarm can be triggered when it transitions from one state to another. Once an alarm is triggered, it can initiate an action. Actions can be an Amazon EC2 action, an Auto Scaling action, or a notification sent to Amazon Simple Notification Service (SNS).\n\nUse CloudWatch Alarms to Prevent and Troubleshoot Issues\nCloudWatch Logs uses metric filters to turn the log data into metrics that you can graph or set an alarm on. For the employee directory application, let’s say you set up a metric filter for 500-error response codes.\nThen, you define an alarm for that metric that will go into the ALARM state if 500-error responses go over a certain amount for a sustained time period. Let’s say if it’s more than five 500-error responses per hour, the alarm should enter the ALARM state. Next, you define an action that you want to take place when the alarm is triggered.\nIn this case, it makes sense to send an email or text alert to you so you can start troubleshooting the website, hopefully fixing it before it becomes a bigger issue. Once the alarm is set up, you feel comfortable knowing that if the error happens again, you’ll be notified promptly.\nYou can set up different alarms for different reasons to help you prevent or troubleshoot operational issues. In the scenario just described, the alarm triggered an SNS notification that went to a person who looked into the issue manually. Another option is to have alarms trigger actions that automatically remediate technical issues.\nFor example, you can set up an alarm to trigger an EC2 instance to reboot, or scale services up or down. You can even set up an alarm to trigger an SNS notification, which then triggers an AWS Lambda function. The Lambda function then calls any AWS API to manage your resources, and troubleshoot operational issues. By using AWS services together like this, you respond to events more quickly."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#what-is-availability",
    "href": "posts/PYTHON/others_python/AWS.html#what-is-availability",
    "title": "AWS Cheat sheet",
    "section": "What Is Availability?",
    "text": "What Is Availability?\nThe availability of a system is typically expressed as a percentage of uptime in a given year or as a number of nines. Below, you can see a list of the percentages of availability based on the downtime per year, as well as its notation in nines.\n\n\n\nAvailability (%)\nDowntime (per year)\n\n\n\n\n90% (“one nine”)\n36.53 days\n\n\n99% (“two nines”)\n3.65 days\n\n\n99.9% (“three nines”)\n8.77 hours\n\n\n99.95% (“three and a half nines”)\n4.38 hours\n\n\n99.99% (“four nines”)\n52.60 minutes\n\n\n99.995% (“four and a half nines”)\n26.30 minutes\n\n\n99.999% (“five nines”)\n5.26 minutes\n\n\n\nTo increase availability, you need redundancy. This typically means more infrastructure: - more data centers, - more servers, - more databases, and - more replication of data.\nYou can imagine that adding more of this infrastructure means a higher cost. Customers want the application to always be available, but you need to draw a line where adding redundancy is no longer viable in terms of revenue."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#improve-application-availability",
    "href": "posts/PYTHON/others_python/AWS.html#improve-application-availability",
    "title": "AWS Cheat sheet",
    "section": "Improve Application Availability",
    "text": "Improve Application Availability\nIn the current application, there is only one EC2 instance used to host the application, the photos are served from Amazon Simple Storage Service (S3) and the structured data is stored in Amazon DynamoDB. That single EC2 instance is a single point of failure for the application.\nEven if the database and S3 are highly available, customers have no way to connect if the single instance becomes unavailable. One way to solve this single point of failure issue is by adding one more server."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#use-a-second-availability-zone",
    "href": "posts/PYTHON/others_python/AWS.html#use-a-second-availability-zone",
    "title": "AWS Cheat sheet",
    "section": "Use a Second Availability Zone",
    "text": "Use a Second Availability Zone\nThe physical location of that server is important. On top of having software issues at the operating system or application level, there can be a hardware issue. It could be in the physical server, the rack, the data center or even the Availability Zone hosting the virtual machine. An easy way to fix the physical location issue is by deploying a second EC2 instance in a different Availability Zone.\nThat would also solve issues with the operating system and the application. However, having more than one instance brings new challenges."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#manage-replication-redirection-and-high-availability",
    "href": "posts/PYTHON/others_python/AWS.html#manage-replication-redirection-and-high-availability",
    "title": "AWS Cheat sheet",
    "section": "Manage Replication, Redirection, and High Availability",
    "text": "Manage Replication, Redirection, and High Availability\n\nCreate a Process for Replication\nThe first challenge is that you need to create a process to replicate the configuration files, software patches, and application itself across instances. The best method is to automate where you can.\n\n\nAddress Customer Redirection\nThe second challenge is how to let the clients, the computers sending requests to your server, know about the different servers. There are different tools that can be used here. The most common is using a Domain Name System (DNS) where the client uses one record which points to the IP address of all available servers. However, the time it takes to update that list of IP addresses and for the clients to become aware of such change, sometimes called propagation, is typically the reason why this method isn’t always used.\nAnother option is to use a load balancer which takes care of health checks and distributing the load across each server. Being between the client and the server, the load balancer avoids propagation time issues. We discuss load balancers later.\n\n\nUnderstand the Types of High Availability\nThe last challenge to address when having more than one server is the type of availability you need—either be an active-passive or an active-active system.\n\nActive-Passive: With an active-passive system, only one of the two instances is available at a time. One advantage of this method is that for stateful applications where data about the client’s session is stored on the server, there won’t be any issues as the customers are always sent to the same server where their session is stored.\nActive-Active: A disadvantage of active-passive and where an active-active system shines is scalability. By having both servers available, the second server can take some load for the application, thus allowing the entire system to take more load. However, if the application is stateful, there would be an issue if the customer’s session isn’t available on both servers. Stateless applications work better for active-active systems."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#whats-a-load-balancer",
    "href": "posts/PYTHON/others_python/AWS.html#whats-a-load-balancer",
    "title": "AWS Cheat sheet",
    "section": "What’s a Load Balancer?",
    "text": "What’s a Load Balancer?\nLoad balancing refers to the process of distributing tasks across a set of resources. In the case of the corporate directory application, the resources are EC2 instances that host the application, and the tasks are the different requests being sent. It’s time to distribute the requests across all the servers hosting the application using a load balancer.\nTo do this, you first need to enable the load balancer to take all of the traffic and redirect it to the backend servers based on an algorithm. The most popular algorithm is round-robin, which sends the traffic to each server one after the other.\nA typical request for the application would start from the browser of the client. It’s sent to a load balancer. Then, it’s sent to one of the EC2 instances that hosts the application. The return traffic would go back through the load balancer and back to the client browser. Thus, the load balancer is directly in the path of the traffic.\nAlthough it is possible to install your own software load balancing solution on EC2 instances, AWS provides a service for that called Elastic Load Balancing (ELB)."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#features-of-elb",
    "href": "posts/PYTHON/others_python/AWS.html#features-of-elb",
    "title": "AWS Cheat sheet",
    "section": "Features of ELB",
    "text": "Features of ELB\nThe ELB service provides a major advantage over using your own solution to do load balancing, in that you don’t need to manage or operate it. It can distribute incoming application traffic across EC2 instances as well as containers, IP addresses, and AWS Lambda functions.\n\nThe fact that ELB can load balance to IP addresses means that it can work in a hybrid mode as well, where it also load balances to on-premises servers.\nELB is highly available. The only option you have to ensure is that the load balancer is deployed across multiple Availability Zones.\nIn terms of scalability, ELB automatically scales to meet the demand of the incoming traffic. It handles the incoming traffic and sends it to your backend application."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#health-checks",
    "href": "posts/PYTHON/others_python/AWS.html#health-checks",
    "title": "AWS Cheat sheet",
    "section": "Health Checks",
    "text": "Health Checks\nTaking the time to define an appropriate health check is critical. Only verifying that the port of an application is open doesn’t mean that the application is working. It also doesn’t mean that simply making a call to the home page of an application is the right way either.\nFor example, the employee directory application depends on a database, and S3. The health check should validate all of those elements. One way to do that would be to create a monitoring webpage like “/monitor” that will make a call to the database to ensure it can connect and get data, and make a call to S3. Then, you point the health check on the load balancer to the “/monitor” page.\n\nAfter determining the availability of a new EC2 instance, the load balancer starts sending traffic to it. If ELB determines that an EC2 instance is no longer working, it stops sending traffic to it and lets EC2 Auto Scaling know. EC2 Auto Scaling’s responsibility is to remove it from the group and replace it with a new EC2 instance. Traffic only sends to the new instance if it passes the health check.\nIn the case of a scale down action that EC2 Auto Scaling needs to take due to a scaling policy, it lets ELB know that EC2 instances will be terminated. ELB can prevent EC2 Auto Scaling from terminating the EC2 instance until all connections to that instance end, while preventing any new connections. That feature is called connection draining."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#elb-components",
    "href": "posts/PYTHON/others_python/AWS.html#elb-components",
    "title": "AWS Cheat sheet",
    "section": "ELB Components",
    "text": "ELB Components\nThe ELB service is made up of three main components.\n\n\nListeners: The client connects to the listener. This is often referred to as client-side. To define a listener, a port must be provided as well as the protocol, depending on the load balancer type. There can be many listeners for a single load balancer.\nTarget groups: The backend servers, or server-side, is defined in one or more target groups. This is where you define the type of backend you want to direct traffic to, such as EC2 Instances, AWS Lambda functions, or IP addresses. Also, a health check needs to be defined for each target group.\nRules: To associate a target group to a listener, a rule must be used. Rules are made up of a condition that can be the source IP address of the client and a condition to decide which target group to send the traffic to.\n\n\nApplication Load Balancer (ALB)\nHere are some primary features of Application Load Balancer (ALB).\nALB routes traffic based on request data. It makes routing decisions based on the HTTP protocol like the URL path (/upload) and host, HTTP headers and method, as well as the source IP address of the client. This enables granular routing to the target groups.\nSend responses directly to the client. ALB has the ability to reply directly to the client with a fixed response like a custom HTML page. It also has the ability to send a redirect to the client which is useful when you need to redirect to a specific website or to redirect the request from HTTP to HTTPS, removing that work from your backend servers.\nALB supports TLS offloading. Speaking of HTTPS and saving work from backend servers, ALB understands HTTPS traffic. To be able to pass HTTPS traffic through ALB, an SSL certificate is provided by either importing a certificate via Identity and Access Management (IAM) or AWS Certificate Manager (ACM) services, or by creating one for free using ACM. This ensures the traffic between the client and ALB is encrypted.\nAuthenticate users. On the topic of security, ALB has the ability to authenticate the users before they are allowed to pass through the load balancer. ALB uses the OpenID Connect protocol and integrates with other AWS services to support more protocols like SAML, LDAP, Microsoft AD, and more.\nSecure traffic. To prevent traffic from reaching the load balancer, you configure a security group to specify the supported IP address ranges.\nALB uses the round-robin routing algorithm. ALB ensures each server receives the same number of requests in general. This type of routing works for most applications.\nALB uses the least outstanding request routing algorithm. If the requests to the backend vary in complexity where one request may need a lot more CPU time than another, then the least outstanding request algorithm is more appropriate. It’s also the right routing algorithm to use if the targets vary in processing capabilities. An outstanding request is when a request is sent to the backend server and a response hasn’t been received yet.\nFor example, if the EC2 instances in a target group aren’t the same size, one server’s CPU utilization will be higher than the other if the same number of requests are sent to each server using the round-robin routing algorithm. That same server will have more outstanding requests as well. Using the least outstanding request routing algorithm would ensure an equal usage across targets.\nALB has sticky sessions. In the case where requests need to be sent to the same backend server because the application is stateful, then use the sticky session feature. This feature uses an HTTP cookie to remember across connections which server to send the traffic to.\nFinally, ALB is specifically for HTTP and HTTPS traffic. If your application uses a different protocol, then consider the Network Load Balancer (NLB)."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#network-load-balancer",
    "href": "posts/PYTHON/others_python/AWS.html#network-load-balancer",
    "title": "AWS Cheat sheet",
    "section": "Network Load Balancer",
    "text": "Network Load Balancer\nHere are some primary features of Network Load Balancer (NLB).\nNetwork Load Balancer supports TCP, UDP, and TLS protocols. HTTPS uses TCP and TLS as protocol. However, NLB operates at the connection layer, so it doesn’t understand what a HTTPS request is. That means all features discussed above that are required to understand the HTTP and HTTPS protocol, like routing rules based on that protocol, authentication, and least outstanding request routing algorithm, are not available with NLB.\nNLB uses a flow hash routing algorithm. The algorithm is based on: The protocol\n\nThe source IP address and source port\nThe destination IP address and destination port\nThe TCP sequence number\n\nIf all of these parameters are the same, then the packets are sent to the exact same target. If any of them are different in the next packets, then the request may be sent to a different target.\nNLB has sticky sessions. Different from ALB, these sessions are based on the source IP address of the client instead of a cookie.\nNLB supports TLS offloading. NLB understands the TLS protocol. It can also offload TLS from the backend servers similar to how ALB works.\nNLB handles millions of requests per second. While ALB can also support this number of requests, it needs to scale to reach that number. This takes time. NLB can instantly handle this amount of requests.\nNLB supports static and elastic IP addresses. There are some situations where the application client needs to send requests directly to the load balancer IP address instead of using DNS. For example, this is useful if your application can’t use DNS or if the connecting clients require firewall rules based on IP addresses. In this case, NLB is the right type of load balancer to use.\nNLB preserves source IP address. NLB preserves the source IP address of the client when sending the traffic to the backend. With ALB, if you look at the source IP address of the requests, you will find the IP address of the load balancer. While with NLB, you would see the real IP address of the client, which is required by the backend application in some cases.\n\nSelect Between ELB Types\nSelecting between the ELB service types is done by determining which feature is required for your application. Below you can find a list of the major features that you learned in this unit and the previous.\n\n\n\n\n\n\n\n\nFeature\nApplication Load Balancer\nNetwork Load Balancer\n\n\n\n\nProtocols\nHTTP, HTTPS\n\n\n\nConnection draining (deregistration delay)\n✔\n\n\n\nIP addresses as targets\n✔\n✔\n\n\nStatic IP and Elastic IP address\n\n✔\n\n\nPreserve Source IP address\n\n✔\n\n\nRouting based on Source IP address, path, host, HTTP headers, HTTP method, and query string\n✔\n\n\n\nRedirects\n✔\n\n\n\nFixed response\n✔\n\n\n\nUser authentication\n✔"
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#vertical-scaling",
    "href": "posts/PYTHON/others_python/AWS.html#vertical-scaling",
    "title": "AWS Cheat sheet",
    "section": "Vertical Scaling",
    "text": "Vertical Scaling\nIf there are too many requests sent to a single active-passive system, the active server will become unavailable and hopefully failover to the passive server. But this doesn’t solve anything.\nWith active-passive, you need vertical scaling. This means increasing the size of the server. With EC2 instances, you select either a larger type or a different instance type. This can only be done while the instance is in a stopped state.\nIn this scenario, the following steps occur:\n\nStop the passive instance. This doesn’t impact the application since it’s not taking any traffic.\nChange the instance size or type, then start the instance again.\nShift the traffic to the passive instance, turning it active.\nThe last step is to stop, change the size, and start the previous active instance as both instances should match.\n\nWhen the amount of requests reduces, the same operation needs to be done. Even though there aren’t that many steps involved, it’s actually a lot of manual work to do. Another disadvantage is that a server can only scale vertically up to a certain limit.\nOnce that limit is reached, the only option is to create another active-passive system and split the requests and functionalities across them. This could require massive application rewriting.\nThis is where the active-active system can help. When there are too many requests, this system can be scaled horizontally by adding more servers."
  },
  {
    "objectID": "posts/PYTHON/others_python/AWS.html#horizontal-scaling",
    "href": "posts/PYTHON/others_python/AWS.html#horizontal-scaling",
    "title": "AWS Cheat sheet",
    "section": "Horizontal Scaling",
    "text": "Horizontal Scaling\nAs mentioned above, for the application to work in an active-active system, it’s already created as stateless, not storing any client session on the server. This means that having two servers or having four wouldn’t require any application changes. It would only be a matter of creating more instances when required and shutting them down when the traffic decreases.\nThe Amazon EC2 Auto Scaling service can take care of that task by automatically creating and removing EC2 instances based on metrics from Amazon CloudWatch.\nYou can see that there are many more advantages to using an active-active system in comparison with an active-passive. Modifying your application to become stateless enables scalability.\n\nIntegrate ELB with EC2 Auto Scaling\nThe ELB service integrates seamlessly with EC2 Auto Scaling. As soon as a new EC2 instance is added to or removed from the EC2 Auto Scaling group, ELB is notified. However, before it can send traffic to a new EC2 instance, it needs to validate that the application running on that EC2 instance is available.\nThis validation is done via the health checks feature of ELB. Monitoring is an important part of load balancers, as it should route traffic to only healthy EC2 instances. That’s why ELB supports two types of health checks.\n\nEstablishing a connection to a backend EC2 instance using TCP, and marking the instance as available if that connection is successful.\nMaking an HTTP or HTTPS request to a webpage that you specify, and validating that an HTTP response code is returned.\n\n\n\nDifferentiate Between Traditional Scaling and Auto Scaling\nWith a traditional approach to scaling, you buy and provision enough servers to handle traffic at its peak. However, this means that at night time, there is more capacity than traffic. This also means you’re wasting money. Turning off those servers at night or at times where the traffic is lower only saves on electricity.\nThe cloud works differently, with a pay-as-you-go model. It’s important to turn off the unused services, especially EC2 instances that you pay for On-Demand. One could manually add and remove servers at a predicted time. But with unusual spikes in traffic, this solution leads to a waste of resources with over-provisioning or with a loss of customers due to under-provisioning.\nThe need here is for a tool that automatically adds and removes EC2 instances according to conditions you define—that’s exactly what the EC2 Auto Scaling service does.\n\n\nUse Amazon EC2 Auto Scaling\nThe EC2 Auto Scaling service works to add or remove capacity to keep a steady and predictable performance at the lowest possible cost. By adjusting the capacity to exactly what your application uses, you only pay for what your application needs. And even with applications that have steady usage, EC2 Auto Scaling can help with fleet management. If there is an issue with an EC2 instance, EC2 Auto Scaling can automatically replace that instance. This means that EC2 Auto Scaling helps both to scale your infrastructure and ensure high availability.\n\n\nConfigure EC2 Auto Scaling Components\nThere are three main components to EC2 Auto Scaling.\n\nLaunch template or configuration: What resource should be automatically scaled?\nEC2 Auto Scaling Group: Where should the resources be deployed?\nScaling policies: When should the resources be added or removed?\n\n\n\nLearn About Launch Templates\nThere are multiple parameters required to create EC2 instances: Amazon Machine Image (AMI) ID, instance type, security group, additional Amazon Elastic Block Store (EBS) volumes, and more. All this information is also required by EC2 Auto Scaling to create the EC2 instance on your behalf when there is a need to scale. This information is stored in a launch template.\nYou can use a launch template to manually launch an EC2 instance. You can also use it with EC2 Auto Scaling. It also supports versioning, which allows for quickly rolling back if there was an issue or to specify a default version of your launch template. This way, while iterating on a new version, other users can continue launching EC2 instances using the default version until you make the necessary changes.\n\nYou can create a launch template one of three ways.\n\nThe fastest way to create a template is to use an existing EC2 instance. All the settings are already defined.\nAnother option is to create one from an already existing template or a previous version of a launch template.\nThe last option is to create a template from scratch. The following options will need to be defined: AMI ID, instance type, key pair, security group, storage, and resource tags.\n\nNote: Another way to define what Amazon EC2 Auto Scaling needs to scale is by using a launch configuration. It’s similar to the launch template, but it doesn’t allow for versioning using a previously created launch configuration as a template. Nor does it allow for creating one from an already existing EC2 instance. For these reasons and to ensure that you’re getting the latest features from Amazon EC2, use a launch template instead of launch configuration.\n\n\nGet to Know EC2 Auto Scaling Groups\nThe next component that EC2 Auto Scaling needs is an EC2 Auto Scaling Group (ASG). An ASG enables you to define where EC2 Auto Scaling deploys your resources. This is where you specify the Amazon Virtual Private Cloud (VPC) and subnets the EC2 instance should be launched in.\nEC2 Auto Scaling takes care of creating the EC2 instances across the subnets, so it’s important to select at least two subnets that are across different Availability Zones.\nASGs also allow you to specify the type of purchase for the EC2 instances. You can use On-Demand only, Spot only, or a combination of the two, which allows you to take advantage of Spot instances with minimal administrative overhead. To specify how many instances EC2 Auto Scaling should launch, there are three capacity settings to configure for the group size.\n\nMinimum: The minimum number of instances running in your ASG even if the threshold for lowering the amount of instances is reached.\nMaximum: The maximum number of instances running in your ASG even if the threshold for adding new instances is reached.\nDesired capacity: The amount of instances that should be in your ASG. This number can only be within or equal to the minimum or maximum. EC2 Auto Scaling automatically adds or removes instances to match the desired capacity number.\n\n\nWhen EC2 Auto Scaling removes EC2 instances because the traffic is minimal, it keeps removing EC2 instances until it reaches a minimum capacity. Depending on your application, using a minimum of two is a good idea to ensure high availability, but you know how many EC2 instances at a bare minimum your application requires at all times. When reaching that limit, even if EC2 Auto Scaling is instructed to remove an instance, it does not, to ensure the minimum is kept.\nOn the other hand, when the traffic keeps growing, EC2 Auto Scaling keeps adding EC2 instances. This means the cost for your application will also keep growing. That’s why it’s important to set a maximum amount to make sure it doesn’t go above your budget.\nThe desired capacity is the amount of EC2 instances that EC2 Auto Scaling creates at the time the group is created. If that number decreases, then EC2 Auto Scaling removes the oldest instance by default. If that number increases, then EC2 Auto Scaling creates new instances using the launch template.\n\n\nEnsure Availability with EC2 Auto Scaling\n\nUsing different numbers for minimum, maximum, and desired capacity is used for dynamically adjusting the capacity. However, if you prefer to use EC2 Auto Scaling for fleet management, you can configure the three settings to the same number, for example four. EC2 Auto Scaling will ensure that if an EC2 instance becomes unhealthy, it replaces it to always ensure that four EC2 instances are available. This ensures high availability for your applications.\n\n\nEnable Automation with Scaling Policies\nBy default, an ASG will be kept to its initial desired capacity. Although it’s possible to manually change the desired capacity, you can also use scaling policies.\nIn the AWS Monitoring module, you learned about Amazon CloudWatch metrics and alarms. You use metrics to keep information about different attributes of your EC2 instance like the CPU percentage. You use alarms to specify an action when a threshold is reached. Metrics and alarms are what scaling policies use to know when to act. For example, you set up an alarm that says when the CPU utilization is above 70% across the entire fleet of EC2 instances, trigger a scaling policy to add an EC2 instance.\nThere are three types of scaling policies: simple, step, and target tracking scaling.\n\n\nSimple Scaling Policy\nA simple scaling policy allows you to do exactly what’s described above. You use a CloudWatch alarm and specify what to do when it is triggered. This can be a number of EC2 instances to add or remove, or a specific number to set the desired capacity to. You can specify a percentage of the group instead of using an amount of EC2 instances, which makes the group grow or shrink more quickly.\nOnce this scaling policy is triggered, it waits a cooldown period before taking any other action. This is important as it takes time for the EC2 instances to start and the CloudWatch alarm may still be triggered while the EC2 instance is booting. For example, you could decide to add an EC2 instance if the CPU utilization across all instances is above 65%. You don’t want to add more instances until that new EC2 instance is accepting traffic.\nHowever, what if the CPU utilization was now above 85% across the ASG? Only adding one instance may not be the right move here. Instead, you may want to add another step in your scaling policy. Unfortunately, a simple scaling policy can’t help with that.\n\n\nStep Scaling Policy\nThis is where a step scaling policy helps. Step scaling policies respond to additional alarms even while a scaling activity or health check replacement is in progress. Similar to the example above, you decide to add two more instances in case the CPU utilization is at 85%, and four more instances when it’s at 95%.\nDeciding when to add and remove instances based on CloudWatch alarms may seem like a difficult task. This is why the third type of scaling policy exists: target tracking. Target Tracking Scaling Policy\nIf your application scales based on average CPU utilization, average network utilization (in or out), or based on request count, then this scaling policy type is the one to use. All you need to provide is the target value to track and it automatically creates the required CloudWatch alarms."
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#introduction-to-git-and-github",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#introduction-to-git-and-github",
    "title": "Git and Github",
    "section": "Introduction to Git and GitHub",
    "text": "Introduction to Git and GitHub\nFrom the Coursera course within Google IT Automation with Python Professional Certificate https://www.coursera.org/learn/introduction-git-github/home/welcome"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#check-out-the-following-links-for-more-information",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#check-out-the-following-links-for-more-information",
    "title": "Git and Github",
    "section": "Check out the following links for more information:",
    "text": "Check out the following links for more information:\nhttps://git-scm.com/doc\nhttps://en.wikipedia.org/wiki/Version_control\nThe Linux kernel documentation itself Linux stuff, as well as impassioned opinions from other developers. stopwritingramblingcommitmessages 5-useful-tips-for-a-better-commit-message\nYou can check out “Setting your email in Git” setting-your-email-in-git and “Keeping your email address private” on the GitHub help site for how to do this. setting-your-commit-email-address\nRun in github bash\nGit is a distributed version control system.\nDistributed means that each developer has a copy of the whole repository on their local machine."
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#diff-find-the-difference-between-two-files",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#diff-find-the-difference-between-two-files",
    "title": "Git and Github",
    "section": "diff find the difference between two files",
    "text": "diff find the difference between two files\ndiff\nhttps://man7.org/linux/man-pages/man1/diff.1.html\ndiff is used to find differences between two files. On its own, it’s a bit hard to use; instead, use it with diff -u to find lines which differ in two files: diff -u\ndiff -u is used to compare two files, line by line, and have the differing lines compared side-by-side in the same output. See below:\n\n>>diff test.py test2.py\n\n\noutput\n\n3c3\n< c=a**b\n---\n> c=a**b+a\n4a5\n> d=c**c\n\n3c3\nline in file 1 - c=change - line in file 2 a=added\n\n>>diff -u test.py test2.py\n\n#output\n\n--- test.py     2021-10-17 11:14:24.880950400 +0100\n+++ test2.py    2021-10-17 11:14:21.155278200 +0100\n@@ -1,4 +1,5 @@\n a=3\n b=2\n-c=a**b\n+c=a**b+a\n print(c)\n+d=c**c\n\nadding -u gives extra context to changes"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#applying-changes",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#applying-changes",
    "title": "Git and Github",
    "section": "applying changes",
    "text": "applying changes\n\nCreate a file with the changes in\n\n>>diff -u test.py test2.py >change.diff\n\n\n\npatch\nhttp://man7.org/linux/man-pages/man1/patch.1.html\n\n>>patch test-Copy1.py < change.diff\n\nthis applies changes in change.diff to test-Copy1.diff"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#vcs-version-control-system",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#vcs-version-control-system",
    "title": "Git and Github",
    "section": "VCS version control system",
    "text": "VCS version control system\nBy keeping track of the changes that we make to our files, a VCS lets us know when a file changed, who changed it, and also lets us easily roll back those changes."
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#git-config",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#git-config",
    "title": "Git and Github",
    "section": "git config",
    "text": "git config\n\n>>git config --global user.email \"me@example.com\" \n>>git config --global user.name \"My name\" \n\nset email and name\n–global means for all repositories\n\n# Find details of configuration\n>>git config -l"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#create-a-new-repository",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#create-a-new-repository",
    "title": "Git and Github",
    "section": "create a new repository",
    "text": "create a new repository\n\n>>mkdir testa\n>>cd testa\n>>git init \n\ndetals of the created directory\n\n>>ls -l .git\n\n#output->>\n-rw-r--r-- 1 44781 197609  23 Oct 17 12:06 HEAD\n-rw-r--r-- 1 44781 197609 130 Oct 17 12:06 config\n-rw-r--r-- 1 44781 197609  73 Oct 17 12:06 description\ndrwxr-xr-x 1 44781 197609   0 Oct 17 12:06 hooks/\ndrwxr-xr-x 1 44781 197609   0 Oct 17 12:06 info/\ndrwxr-xr-x 1 44781 197609   0 Oct 17 12:06 objects/\ndrwxr-xr-x 1 44781 197609   0 Oct 17 12:06 refs/\n\nThe git directory acts as a database for all the changes tracked in Git and the working tree acts as a sandbox where we can edit the current versions of the files."
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#add-a-file-to-the-directory-and-get-it-tracked",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#add-a-file-to-the-directory-and-get-it-tracked",
    "title": "Git and Github",
    "section": "add a file to the directory and get it tracked",
    "text": "add a file to the directory and get it tracked\n\n>>cp ../test.py . \n#note the dot at end to say copy to this directory\n>>git add test.py\n\nThe file is now in the staging area or index\ncontains all info about what files and changes are in the next commit\n\n>>git add -p\n\nthis would all tracked and shows differences and asks if want to make the add"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#get-the-status",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#get-the-status",
    "title": "Git and Github",
    "section": "get the status",
    "text": "get the status\n\n>>git status\n\nOn branch master\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached <file>...\" to unstage)\n        new file:   test.py\n\ntest.py ready to be committed"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#make-a-commit",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#make-a-commit",
    "title": "Git and Github",
    "section": "Make a commit",
    "text": "Make a commit\n\n>>git commit\n\n# Please enter the commit message for your changes. Lines starting\n# with '#' will be ignored, and an empty message aborts the commit.\n#\n# On branch master\n#\n# Initial commit\n#\n# Changes to be committed:\n#       new file:   test.py\n#\n~\n~\n~\n~\n~\n~\n~\n~\n~\n~\n~\n\nthis opens up an editor with text as shown\nEnter details of the commit\nTo exit and save: Type the description at the very top, press esc to exit insert mode, then type :x! (now the cursor is at the bottom) and hit enter to save and exit\nAlternatively add -m command with details of commit\ngit commit -m ‘Changed print to include some text’\n\nTracked files\n\nModified\n\nmade changes but not committed yet\n\nStaged\n\nin staging area\ngit add\n\nCommitted\n\nin git directory\ngit commit\n\n\n\n\nCommit messages\nBrief description\nMore indepth details\nMore indepth\n(remember to add new lines)"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#git-log",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#git-log",
    "title": "Git and Github",
    "section": "Git log",
    "text": "Git log\n\n>>git log\ncommit 05958854b7ad68f8b1a178f260dccd844aec0e16 (HEAD -> master)\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 13:04:10 2021 +0100\n\n    added python start line\n\ncommit 917a027f6282ce1c2c01e00a48bb72995e3984a6\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 12:56:41 2021 +0100\n\n    Changed print to include some text\n\ncommit 7e32e328db17594fd0a507b4a23f489b68c09543\nAuthor: thomashsimm <thomas  @gmail.com>\nDate:   Sun Oct 17 12:38:02 2021 +0100\n\n    Add new file test.py"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#skipping-the-staging-area",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#skipping-the-staging-area",
    "title": "Git and Github",
    "section": "Skipping the Staging Area",
    "text": "Skipping the Staging Area\n\n>>git commit -a\n\nor\n>>git commit -a -m \"Added a new output\"\n\na shortcut to stage any changes to tracked files and commit them in one step"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#getting-more-information-about-our-changes",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#getting-more-information-about-our-changes",
    "title": "Git and Github",
    "section": "Getting more information about our changes",
    "text": "Getting more information about our changes\n\n>>git log -p\n\nEquivalent to diff -u (describe above)\nto get more info on a particular commit\n\n>>git show 7e32e328db17594fd0a507b4a23f489b68c09543\n\nSome stats of repo\n\n>>git log --stat\n\nchanges in file, relative to repo/staging area\n\n>>git diff"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#deleting-and-renaming-files",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#deleting-and-renaming-files",
    "title": "Git and Github",
    "section": "Deleting and Renaming Files",
    "text": "Deleting and Renaming Files\n\n>>git rm test.py\n\nremoves the file test.py\n\n>>git commit -m \"Deleted test.py\"\n\ncommit the change/deletion of the file\n\n>>git mv test2.py test.py \n\nrename a file\nN.B. git mv can also be used for moving files\n\n>>echo .DS_STORE > .gitignore\n#create .gitignore file to ignore .DS_STORE files (OS sys)\n>>ls -la\n#view hidden files\n>>git add .gitignore\n#add file\n>>git commit -m \"added a gitignore file\"\n#commit changes"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#gitignore-files",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#gitignore-files",
    "title": "Git and Github",
    "section": ".gitignore files",
    "text": ".gitignore files\n.gitignore files are used to tell the git tool to intentionally ignore some files in a given Git repository. For example, this can be useful for configuration files or metadata files that a user may not want to check into the master branch. Check out more at: https://git-scm.com/docs/gitignore.\nA few common examples of file patterns to exclude can be found here https://gist.github.com/octocat/9257657."
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#undoing-changes",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#undoing-changes",
    "title": "Git and Github",
    "section": "Undoing changes",
    "text": "Undoing changes\n\nUndoing unstaged changes\n\n>>git restore test.py\n\n“git restore …” to discard changes in working directory\nThis comes up as an option to do when go git status\nSame as git checkout\nThis takes the file from the directory and changes the one in the working tree to match this\n\n\nUndoing staged changes\nSay we’ve added all files in a directory\ngit add *\nWhen we run git status we reaslise it includes a file we don’t want to add\nTo remove the add we do:\n\n>>git restore --staged newfile.txt\n\nor\n>>git reset HEAD newfile.txt"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#amending-commits",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#amending-commits",
    "title": "Git and Github",
    "section": "Amending commits",
    "text": "Amending commits\n\n>git commit --amend\n\nThis allows us to ammend the last commit\nSo for example we could add some more files to it and then modify the comments on the commit\nThen overwrites the previous commit\n\nOnly use for: local changes\n\n\nAmend Commits are not for commits that have been made public"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#rollbacks",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#rollbacks",
    "title": "Git and Github",
    "section": "Rollbacks",
    "text": "Rollbacks\nRevert to an earlier commit\nWith git revert, a new commit is created with inverse changes. This cancels previous changes instead of making it as though the original commit never happened.\n\n>>git revert HEAD\n\nAdd description of why doing rollback\nRecall press esc to exit insert mode, then type :x! (now the cursor is at the bottom) and hit enter to save and exit"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#identifying-a-commit",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#identifying-a-commit",
    "title": "Git and Github",
    "section": "Identifying a commit",
    "text": "Identifying a commit\nSHA1 hash numbers that Git uses to identify commits - They provide the consistency that is critical for distributed systems such as Git.\n\nThey are created using the commit message, date, author, and the snapshot taken of the working tree.\nThey are composed of 40 characters.\n\n\n>>git show\n\n# pick one of the commits\n\n>>git show 34051fe65ab25ae011b0473fd1707e6e84f89b71\n\n# And if we wanted to revert to this\n\n>>git revert 34051fe65ab25ae011b0473fd1707e6e84f89b71\n\n# this would also work if id is unique in repo\n>> git revert 34051f"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#git-revert-cheat-sheet",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#git-revert-cheat-sheet",
    "title": "Git and Github",
    "section": "Git Revert Cheat Sheet",
    "text": "Git Revert Cheat Sheet\n\ngit checkout is effectively used to switch branches. https://git-scm.com/docs/git-checkout\ngit reset basically resets the repo, throwing away some changes. It’s somewhat difficult to understand, so reading the examples in the documentation may be a bit more useful. https://git-scm.com/docs/git-reset#_examples\nThere are some other useful articles online, which discuss more aggressive approaches to resetting the repo. https://jwiegley.github.io/git-from-the-bottom-up/3-Reset/4-doing-a-hard-reset.html\ngit commit –amend is used to make changes to commits after-the-fact, which can be useful for making notes about a given commit. https://git-scm.com/docs/git-commit#Documentation/git-commit.txt—amend\ngit revert makes a new commit which effectively rolls back a previous commit. It’s a bit like an undo command. https://git-scm.com/docs/git-revert\nThere are a few ways you can rollback commits in Git. https://git-scm.com/book/en/v2/Git-Basics-Undoing-Things\nThere are some interesting considerations about how git object data is stored, such as the usage of sha-1.\n\nFeel free to read more here:\n\nhttps://en.wikipedia.org/wiki/SHA-1\nhttps://github.blog/2017-03-20-sha-1-collision-detection-on-github-com"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#git-branch",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#git-branch",
    "title": "Git and Github",
    "section": "Git Branch",
    "text": "Git Branch\n\na pointer to a particular commit\nit represents an independent line of development in a project\nthe default branch that git creates for you when initialised is called master (sometimes main)\nTo do something new or experimenting try adding a new branch\nNew branches enable changes to be worked on without disrupting the most current working state\n\n\nList all branches in a repo\n\n>>git branch\n* master\n\njust the one at the moment the master\n\n\nAdd a new branch\n\n>>git branch tryThis\n>>git branch\n* master\n  tryThis\n\nthe * indicates the branch we are in\n\n\nSwitch to different branch\nwe use git checkout to check out the latest snapshot for both files and for branches.\n\n>>git checkout tryThis\nSwitched to branch 'tryThis'\n>>git branch\n  master\n* tryThis\n\n\n\nAdd and switch branches\n\n>>git checkout -b orThis\nSwitched to a new branch 'orThis'\n>>git branch\n  master\n* orThis\n  tryThis\n\n\n# look at last two commits\n>> git log -2\ncommit 9204f0f890143d81c8fc3fa5db839be5f65e63e9 (HEAD -> orThis)\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 18:25:06 2021 +0100\n\n    add an empty file\n\ncommit 34051fe65ab25ae011b0473fd1707e6e84f89b71 (tryThis, master)\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 15:36:19 2021 +0100\n\n    Revert \"Revert \"added a gitignore file\"\"\n\n    This reverts commit dc28347e0177c298e9b527ab8140973fb3a567ba.\n\nWe see the last two commits in this branch. Notice how next to the latest commit ID, git shows that this is where head is pointing to and that the branch is called orThis.\nNext to the previous commit,git shows that both the master and the trThis branches are pointing to that snapshot of the project.\nIn this way, we can see that the orThis branch is ahead of the master branch.\n\n>>nano gogo2.py\n#creates file gogo2.py\n>>git add *\n>>git commit -m \"gogo2.py file added to orThis\"\n>>ls -l\ntotal 2\n-rw-r--r-- 1 44781 197609  9 Oct 17 18:56 gogo2.py\n-rw-r--r-- 1 44781 197609 38 Oct 17 14:51 test.py\n\n#go back to master\n>>git checkout master\ntotal 3\n-rw-r--r-- 1 44781 197609  7 Oct 17 18:59 go.py\n-rw-r--r-- 1 44781 197609 16 Oct 17 18:59 gogo.py\n-rw-r--r-- 1 44781 197609 38 Oct 17 14:51 test.py\n\n#gogo2.py is not here!\n\n\n\nDelete branch\n\n>>git branch -d tryThis\nerror: The branch 'tryThis' is not fully merged.\nIf you are sure you want to delete it, run 'git branch -D tryThis'.\n\n>>git branch -D tryThis\nDeleted branch tryThis (was 59ec266).\n\n>>git branch\n* master\n  orThis"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#merging-branches",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#merging-branches",
    "title": "Git and Github",
    "section": "Merging branches",
    "text": "Merging branches\nMerging is the term that Git uses for combining branch data and history together.\n\n#make sure in master\n>>git branch\n* master\n  orThis\n#then merge orThis\n>>git merge orThis\nUpdating da04c1c..4eb59cb\nFast-forward\n go2.py | 4 ++++\n 1 file changed, 4 insertions(+)\n create mode 100644 go2.py\n\n\n>>git log\ncommit 4eb59cb2dca6a09fb59477fcdf4595551ff9f85f (HEAD -> master, branch2)\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 19:17:28 2021 +0100\n\nBoth branches are pointed at the same commit -> (HEAD -> master, branch2)\n\nMerge conflict\nFrom time to time, we might find that both the branches we’re trying to merge have edits to the same part of the same file.\nThis will result in something called a merge conflict.\nNormally, Git can automatically merge files for us. But when we have a merge conflict, it will need a little help to figure out what to do.\n\n#amend same file in master and a new branch- branch2\n>>git merge branch2\nAuto-merging go.py\nCONFLICT (content): Merge conflict in go.py\nAutomatic merge failed; fix conflicts and then commit the result.\n\n#error message produced\n\n\n>>git status\nOn branch master\nYou have unmerged paths.\n  (fix conflicts and run \"git commit\")\n  (use \"git merge --abort\" to abort the merge)\n\nUnmerged paths:\n  (use \"git add <file>...\" to mark resolution)\n        both modified:   go.py\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n        .gogo.py.swp\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nTo try to resolve this we open up the file in editor\n\n>>nano go.py\n\n####in editor>>\n\nb=3\n<<<<<<< HEAD\n#hello\n\n=======\n#comment here too\n>>>>>>> branch2\n\n\n####which we change to this to keep both mods>>\n\nb=3\n#hello\n#comment here too\n\n\nThen add the file and check the status\n\n>>git add go.py\n>>git status\nOn branch master\nAll conflicts fixed but you are still merging.\n  (use \"git commit\" to conclude merge)\n\nChanges to be committed:\n        modified:   go.py\n>>git commit \n[master b7e6929] Merge branch 'branch2' Kept both features\n\nConflicts now gone\nAnd committed\n–graph –oneline ==>> helps us visualise the merge\n\n>>git log --graph --oneline\n\n\n\nAbort merge\n\n>>git merge --abort"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#git-branches-and-merging-cheat-sheet",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#git-branches-and-merging-cheat-sheet",
    "title": "Git and Github",
    "section": "Git Branches and Merging Cheat Sheet",
    "text": "Git Branches and Merging Cheat Sheet\ngit branch Used to manage branches git-branch\ngit branch [branchname]  Creates the branch Git-Branching-Basic-Branching-and-Merging\ngit branch -d [branchname] Deletes the branch git-branch.txt–D\ngit branch -D [branchname]  Forcibly deletes the branch\ngit checkout [branchname]  Switches to a branch. git-checkout\ngit checkout -b [branchname] Creates a new branch and switches to it. git-checkout.txt–bltnewbranchgt\ngit merge [branchname]  Merge joins branches together. git-merge\ngit merge –abort If there are merge conflicts (meaning files are incompatible), –abort can be used to abort the merge action.\ngit log –graph –onelineThis shows a summarized view of the commit history for a repo. Git-Basics-Viewing-the-Commit-History"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#working-with-remotes",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#working-with-remotes",
    "title": "Git and Github",
    "section": "Working with remotes",
    "text": "Working with remotes\nGitHub is a web-based Git repository hosting service.\nOn top of the version control functionality of Git, GitHub includes extra features like bug tracking, wikis, and task management.\nGitHub lets us share and access repositories on the web and copy or clone them to our local computer, so we can work on them.\nGitHub is a popular choice with a robust feature set, but it’s not the only one. Other services that provide similar functionality are BitBucket, and GitLab.\n\n\n\nhtpps://github.com\n\n\nGitHub provides free access to a Git server for public and private repositories.\nIt limits the number of contributors for the free private repositories, and offers an unlimited private repository service for a monthly fee. We’ll be using a free repository for our examples, which is fine for educational use, small personal projects, or open source development.\n\nClone a directory\nThis is to create a local copy of a repository from the github website\n\nGo to the repo\nClick code and copy the clone URL HTTPS\n\n\nother options are availabe too\n\n\n\nIn Git bash run\n\ngit clone https://github.com/ThomasHSimm/SwanseaProperty.git\nFill in any passwords if required\n\n# Make changes to files\n\n#Then add and commit the changes\n>>git commit -a -m \"Modified the readme\"\n[main c9307f7] modified read me\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#git-push",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#git-push",
    "title": "Git and Github",
    "section": "Git Push",
    "text": "Git Push\nSend the changes to the remote repository\n\n>>git push\nEnumerating objects: 5, done.\nCounting objects: 100% (5/5), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (3/3), done.\nWriting objects: 100% (3/3), 309 bytes | 309.00 KiB/s, done.\nTotal 3 (delta 2), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/ThomasHSimm/SwanseaProperty.git\n   08aa0a2..c9307f7  main -> main"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#basic-interaction-with-github-cheat-sheet",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#basic-interaction-with-github-cheat-sheet",
    "title": "Git and Github",
    "section": "Basic Interaction with GitHub Cheat-Sheet",
    "text": "Basic Interaction with GitHub Cheat-Sheet\nThere are various remote repository hosting sites:\n- GitHub\n\n- BitBucket\n\n- Gitlab.\nFollow the workflow at https://github.com/join to set up a free account, username, and password. After that, these steps create-a-repo will help you create a brand new repository on GitHub.\nSome useful commands for getting started:\n\ngit clone URL\nGit clone is used to clone a remote repository into a local workspace https://git-scm.com/docs/git-clone\n\n\ngit push\nGit push is used to push commits from your local repo to a remote repo https://git-scm.com/docs/git-push\n\n\ngit pull\nGit pull is used to fetch the newest updates from a remote repository https://git-scm.com/docs/git-pull\n\n\nThese can be useful for keeping your local workspace up to date.\n\ncaching-your-github-password-in-git\ngenerating-an-ssh-key"
  },
  {
    "objectID": "posts/PYTHON/others_python/Git_and_Github.html#fetching-new-changes",
    "href": "posts/PYTHON/others_python/Git_and_Github.html#fetching-new-changes",
    "title": "Git and Github",
    "section": "Fetching new changes",
    "text": "Fetching new changes\n\n>>git fetch\n\nThis copies changes done in remote repo to local repo\nBut unlike git pull doesn’t instantly merge changes\n\ngit pull = fetch and merge\ngit fetch = just fetches\n\nCan merge like this\n\n>>git merge orgin/master\n\nOr just do both with pull\nAs long as there are no conflicts, Git will move the current branch tip up to the target branch tip and combine histories of both commits. Using a fast-forward merge\n\n>>git pull\n\nTo create a local branch for a remote branch we don’t have yet run git checkout BRANCH_NAME\ngit remote update will fetch the contents of all remote branches and allow us to merge the contents ourselves."
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#name-of-operating-system",
    "href": "posts/PYTHON/others_python/OS.html#name-of-operating-system",
    "title": "The operating system",
    "section": "name of operating system",
    "text": "name of operating system\n\nprint('os.name',',',os.name,'\\n')\n\nos.name , nt"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#get-current-dir",
    "href": "posts/PYTHON/others_python/OS.html#get-current-dir",
    "title": "The operating system",
    "section": "get current dir",
    "text": "get current dir\n\nprint('os.getcwd()',',',os.getcwd(),'\\n')\n\nos.getcwd() , C:\\Users\\44781\\pyproj\\_misc"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#list-files-in-dir",
    "href": "posts/PYTHON/others_python/OS.html#list-files-in-dir",
    "title": "The operating system",
    "section": "list files in dir",
    "text": "list files in dir\n\nprint('os.listdir()',',',os.listdir(),'\\n')\n\nos.listdir() , ['.ipynb_checkpoints', 'adapic.jpg', 'awarhol.jpg', 'awarhol.webp', 'dog.jpg', 'draw.png', 'ebsd2.tif', 'ebsdmap.png', 'ebsdmap.tif', 'fastAI_C1_notes.ipynb', 'image_1000.jpg', 'image_5000(1).jpg', 'IndeedExtract-Copy1.ipynb', 'IndeedExtract-Copy2.ipynb', 'No_61_Mark_Rothko-thumbnail_webp-9999x9999.webp', 'os.ipynb', 'output', 'PF_500C R.png', 'PythonBook.ipynb', 're.ipynb', 'styleTransfer.ipynb', 'test2', 'Untitled.ipynb', 'vangogh.jpg', 'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', 'water.webp']"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#make-a-directory",
    "href": "posts/PYTHON/others_python/OS.html#make-a-directory",
    "title": "The operating system",
    "section": "make a directory",
    "text": "make a directory\n\nthis_dir=os.getcwd()\ndirectory='test'\n#this adds either / or \\ depending on os\npath = os.path.join(this_dir, directory)\n\ntry:\n    os.mkdir(path)\nexcept:\n    pass\n\n#or \ntry:\n    os.mkdir('test2')\nexcept:\n    pass"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#list-files-in-dir-1",
    "href": "posts/PYTHON/others_python/OS.html#list-files-in-dir-1",
    "title": "The operating system",
    "section": "list files in dir",
    "text": "list files in dir\n\nprint('os.listdir()',',',os.listdir(),'\\n')\n\nos.listdir() , ['.ipynb_checkpoints', 'adapic.jpg', 'awarhol.jpg', 'awarhol.webp', 'dog.jpg', 'draw.png', 'ebsd2.tif', 'ebsdmap.png', 'ebsdmap.tif', 'fastAI_C1_notes.ipynb', 'image_1000.jpg', 'image_5000(1).jpg', 'IndeedExtract-Copy1.ipynb', 'IndeedExtract-Copy2.ipynb', 'No_61_Mark_Rothko-thumbnail_webp-9999x9999.webp', 'os.ipynb', 'output', 'PF_500C R.png', 'PythonBook.ipynb', 're.ipynb', 'styleTransfer.ipynb', 'test', 'test2', 'Untitled.ipynb', 'vangogh.jpg', 'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', 'water.webp']"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#check-filedir-exists",
    "href": "posts/PYTHON/others_python/OS.html#check-filedir-exists",
    "title": "The operating system",
    "section": "Check file/dir exists",
    "text": "Check file/dir exists\n\nprint(os.path.exists(\"test2\"),os.path.exists(\"test\"))\n\nTrue True"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#change-directory",
    "href": "posts/PYTHON/others_python/OS.html#change-directory",
    "title": "The operating system",
    "section": "change directory",
    "text": "change directory\n\nos.chdir(directory)\nprint('os.getcwd()',',',os.getcwd(),'\\n')\n\nos.getcwd() , C:\\Users\\44781\\pyproj\\_misc\\test"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#create-and-rename-a-file",
    "href": "posts/PYTHON/others_python/OS.html#create-and-rename-a-file",
    "title": "The operating system",
    "section": "Create and Rename a file",
    "text": "Create and Rename a file\n\n# create a file 'a' is append\nopen('Old.txt','a').close()\n\n# check file exists \nprint('old=',os.path.exists(\"Old.txt\"),'. new=',os.path.exists(\"New.txt\"))\n\n# rename a file\nfd = \"Old.txt\"\nos.rename(fd,'New.txt')\n\n# check file exists \nprint('old=',os.path.exists(\"Old.txt\"),'. new=',os.path.exists(\"New.txt\"))\n\nold= True . new= False\nold= False . new= True"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#copy-a-file-",
    "href": "posts/PYTHON/others_python/OS.html#copy-a-file-",
    "title": "The operating system",
    "section": "Copy a file-",
    "text": "Copy a file-\n\ncan be done in os but easier in shutil\nhttps://stackabuse.com/how-to-copy-a-file-in-python/\n\nimport shutil\nshutil.copyfile('New.txt', 'Old.txt')\n\n# check file exists \nprint('old=',os.path.exists(\"Old.txt\"),'. new=',os.path.exists(\"New.txt\"))\n\nold= True . new= True"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#remove-a-file",
    "href": "posts/PYTHON/others_python/OS.html#remove-a-file",
    "title": "The operating system",
    "section": "Remove a file",
    "text": "Remove a file\n\n# remove a file\nos.remove(\"New.txt\")\n# os.remove(\"Old.txt\")\n\n# check file exists \nprint('old=',os.path.exists(\"Old.txt\"),'. new=',os.path.exists(\"New.txt\"))\n\nold= True . new= False"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#go-back-up-in-directory",
    "href": "posts/PYTHON/others_python/OS.html#go-back-up-in-directory",
    "title": "The operating system",
    "section": "Go back up in directory",
    "text": "Go back up in directory\n\n\nos.path.dirname(os.path.dirname(   ))\n\n'C:\\\\Users\\\\44781\\\\pyproj'\n\n\n\n#remove directory\nos.rmdir(path)\n#list files in dir\nprint('os.listdir()',',',os.listdir(),'\\n')\n\nos.listdir() , ['.ipynb_checkpoints', 'adapic.jpg', 'awarhol.jpg', 'awarhol.webp', 'dog.jpg', 'draw.png', 'ebsd2.tif', 'ebsdmap.png', 'ebsdmap.tif', 'fastAI_C1_notes.ipynb', 'image_1000.jpg', 'image_5000(1).jpg', 'IndeedExtract-Copy1.ipynb', 'IndeedExtract-Copy2.ipynb', 'No_61_Mark_Rothko-thumbnail_webp-9999x9999.webp', 'os.ipynb', 'output', 'PF_500C R.png', 'PythonBook.ipynb', 're.ipynb', 'styleTransfer.ipynb', 'test2', 'Untitled.ipynb', 'vangogh.jpg', 'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', 'water.webp']"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#create-new-files",
    "href": "posts/PYTHON/others_python/OS.html#create-new-files",
    "title": "The operating system",
    "section": "Create new files",
    "text": "Create new files\n\n#create new file and edit\nnano file.txt\n#create file\ntouch file.txt\n\n\n!cd\n\nC:\\Users\\44781\\pyproj\\_misc\\test"
  },
  {
    "objectID": "posts/PYTHON/others_python/OS.html#shell-commands",
    "href": "posts/PYTHON/others_python/OS.html#shell-commands",
    "title": "The operating system",
    "section": "Shell Commands",
    "text": "Shell Commands\n\necho\n\necho HELLO print HELLO to screen\necho $string1 print variable string1\n\n\n\nmaths operations\n\necho $(( 10 + 5 )) add two numbers\n\n\n\ncat\n\ncat [file] command allows us to create single or multiple files, view the contents of a file, concatenate files, and redirect output in terminal or other files.\n\n\n\ngrep\nGrep command, which stands for “global regular expression print”, processes text line-by-line and prints any lines that match a specified pattern.\n\ngrep [pattern] [file-directory/location]\ne.g. grep \"jane\" list.txt find the occurances of “jane” in list.txt\n\nHere, [file-directory] is the path to the directory/folder where you want to perform a search operation. The grep command is also used to search text and match a string or pattern within a file.\n\n\ncut\n\ncut [options] [file] The cut command extracts a given number of characters or columns from a file. A delimiter is a character or set of characters that separate text strings.\nFor delimiter separated fields, the - d option is used. The -f option specifies the field, a set of fields, or a range of fields to be extracted. cut -d [delimiter] -f [field number]\n\n\n\ncat\n\ncat > [file]\nEach stream uses redirection commands. A single greater than sign (>) or a double greater than sign (>>) can be used to redirect standard output. If the target file doesn’t exist, a new file with the same name will be created.\ncat >> [file]\nCommands with a double greater than sign (>>) do not overwrite the existing file content, but it will append to it.\n> can be used to create a file\ne.g. > test.txt\ncreates the file test.txt\necho \"I am appending text to this test file\" >> test.txt\nto append to the same file\n\n\n\ntest\ntests an assertion can be replaced with []\n\n\nnano\nEdit a file / create a file and edit it\nfor a shell script - #!/bin/bash\nAnd for a python script - #!/usr/bin/env python3\n\n\nchmod\n\nchmod +x findJane.sh\n\n\n\nfor statement\n\nfor i in 1 2 3; do echo $i; done\nthe key elements to note are ; do and done\n\nExamples\ncat list.txt\n001 jane /data/jane_profile_07272018.doc\n002 kwood /data/kwood_profile_04022017.doc\n003 pchow /data/pchow_profile_05152019.doc\n004 janez /data/janez_profile_11042019.doc\n005 jane /data/jane_pic_07282018.jpg\n006 kwood /data/kwood_pic_04032017.jpg\n007 pchow /data/pchow_pic_05162019.jpg\n008 jane /data/jane_contact_07292018.csv\n009 kwood /data/kwood_contact_04042017.csv\n010 pchow /data/pchow_contact_05172019.csv\ncat list.txt | cut -d ' ' -f 2\njane\nkwood\npchow\njanez\njane\nkwood\npchow\njane\nkwood\npchow\n\nhere | is a pipe to connect commands\neach line is cut by delimiter space ’ ’ then the 2nd term is outputted. IF we put 1 instead we get 001, 002 etc\nor f 1,3 would get 1st and 3rd parts after split by space\n\nif test -e ~/data/jane_profile_07272018.doc; then echo \"File exists\"; else echo \"File doesn't exist\"; fi\n\nthe use of e tests if a file exists\n\n\n# For statement print numbers 1 to 99 in steps of 1\nfor i in {1..99..1}\ndo \n  echo $i\ndone\n\n\n# For and If statements with math operation\nfor i in {1..99..1}\ndo \n  if [ $(( i % 2 )) == 1 ]\n  then\n    echo $i\n  fi\ndone\n\n\n#!/bin/bash\n> oldFiles.txt\n\nfiles=\"$(grep \" jane \" ../data/list.txt | cut -d \" \" -f 3)\"\n\nfor file in $files;\n  do\n   if test -e \"..\"$file;\n   then echo $file >> oldFiles.txt;\n   else echo \"no\" $file;\n   fi\n\ndone\n\nBash Scripting Resources\nCheck out the following links for more information:\n\nhttps://ryanstutorials.net/bash-scripting-tutorial/\nhttps://linuxconfig.org/bash-scripting-tutorial-for-beginners\nhttps://www.shellscript.sh"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#some-maths",
    "href": "posts/PYTHON/others_python/Python_book.html#some-maths",
    "title": "ThomasHSimm",
    "section": "Some maths",
    "text": "Some maths\n\nimport math\nprint(math.pi)\nprint(math.sqrt(34))\n\n3.141592653589793\n5.830951894845301\n\n\n\nimport random\nprint(random.random())\n\nprint(random.choice([1,2,3,4]))\nprint(random.choice([1,2,3,4]))\n\n0.7617615023592539\n4\n2"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#indexing",
    "href": "posts/PYTHON/others_python/Python_book.html#indexing",
    "title": "ThomasHSimm",
    "section": "Indexing",
    "text": "Indexing\n\nS='Spam'\n\nprint(S[1:3])\nprint(S[:-1])\nprint(S[1:])\nprint(S[:])\nprint(S*3)\n\npa\nSpa\npam\nSpam\nSpamSpamSpam"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#immutability",
    "href": "posts/PYTHON/others_python/Python_book.html#immutability",
    "title": "ThomasHSimm",
    "section": "Immutability",
    "text": "Immutability\n\n\n# strings are not immutable\nS[0]='p' ##error\n\nTypeError: 'str' object does not support item assignment\n\n\n\n# but we can create a new string\nS = 'z' +S[1:]\nprint(S)\n#or use replaces\n\nzpam"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#string-specific-methods",
    "href": "posts/PYTHON/others_python/Python_book.html#string-specific-methods",
    "title": "ThomasHSimm",
    "section": "String specific methods",
    "text": "String specific methods\nhttps://docs.python.org/3/library/stdtypes.html#string-methods\n\nSplit\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then there is no limit on the number of splits (all possible splits are made).\n\nstra='xsxhu csjoaij jsaijaio j dijoi'\nstra1=stra.split()\nprint(stra1)\nstra1=stra.split('j',maxsplit=2)\nprint(stra1)\n\n['xsxhu', 'csjoaij', 'jsaijaio', 'j', 'dijoi']\n['xsxhu cs', 'oai', ' jsaijaio j dijoi']\n\n\n\nline='aaa,bbb,cccc,dd d\\n'\n\n#split based on something\nprint(line.split(','))\n#creates a list\nprint(type(line.split(',')))\n\n# strip out whitespace on rhs\nprint(line.rstrip())\n\n\n\nStrip\nReturn a copy of the string with the leading and trailing characters removed.\n\n'   spacious   '.strip()\n\n'spacious'\n\n\n\n\nCheck nature of string\nstr.isalnum()\nThis method checks if all the characters of a string are alphanumeric (a-z, A-Z and 0-9).\n\nstra='abcD1'\nprint(stra,stra.isalnum())\nstra='abcD1#'\nprint(stra,stra.isalnum())\n\nabcD1 True\nabcD1# False\n\n\nstr.isalpha()\nThis method checks if all the characters of a string are alphabetical (a-z and A-Z).\n\nstra='abcD1'\nprint(stra,stra.isalpha())\nstra='abcD'\nprint(stra,stra.isalpha())\n\nabcD1 False\nabcD True\n\n\nstr.isdigit()\nThis method checks if all the characters of a string are digits (0-9)\nstra=‘abcD1’ print(stra,stra.isdigit()) stra=‘190’ print(stra,stra.isdigit())\nstr.islower()\nThis method checks if all the characters of a string are lowercase characters (a-z).\n\nstra='abcD1'\nprint(stra,stra.islower())\nstra='190'\nprint(stra,stra.islower())\n\nabcD1 False\n190 False\n\n\nstr.lower or str.upper change whether upper or lower case\n\nstra='abcD1'\nprint(stra,stra.lower(),stra.upper())\n\nabcD1 abcd1 ABCD1\n\n\ncaptialize the first character\n\nprint(stra.capitalize())\n\nAbcd1\n\n\n\n\nFind\nFind the position of a substring within a string\nstring.find(stringIN) scan left to right\nstring.rfind(stringIN) scan right to left\n\nstra='ABCDCDC'\nstraa='BCD'\nstra.find('CD'),stra.rfind('CD')\n\n(2, 4)\n\n\n\n\nReplace\nstring.replace(sub_string,string) replace parts of a string\n\nS='oke doke karaoke'\n\n#replace parts of a string\nprint(S)\nprint(S.replace('karaoke','noke'))\n\n\noke doke karaoke\noke doke noke"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#formatting",
    "href": "posts/PYTHON/others_python/Python_book.html#formatting",
    "title": "ThomasHSimm",
    "section": "Formatting",
    "text": "Formatting\n\n\nprint('%s, eggs, and %s' % ('spam', 'SPAM!'))\n\nprint('{0}, eggs, and {1}'.format('spam', 'SPAM!'))"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#help",
    "href": "posts/PYTHON/others_python/Python_book.html#help",
    "title": "ThomasHSimm",
    "section": "Help",
    "text": "Help\nPut into help( ) to get help on it\n\nhelp(S.format)"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#lists",
    "href": "posts/PYTHON/others_python/Python_book.html#lists",
    "title": "ThomasHSimm",
    "section": "Lists",
    "text": "Lists\nhttps://docs.python.org/3/tutorial/datastructures.html?highlight=tuple\nThe Python list object is the most general sequence provided by the language. Lists are positionally ordered collections of arbitrarily typed objects, and they have no fixed size. They are also mutable—unlike strings, lists can be modified in-place by assignment to offsets as well as a variety of list method calls\n\nNew List\nCreate a list with list(XX)\n\na='1 2 3 4 5 6 7'\nlista = list(a)\nprint(lista)\n\n['1', ' ', '2', ' ', '3', ' ', '4', ' ', '5', ' ', '6', ' ', '7']\n\n\n\n\nCopy\nlist.copy\n\nlista =a.split(' ')\nlista=lista[0:3]\nprint('Original a=\\n',lista)\nlistb=lista\nlistc=lista.copy()\nlistd=lista[:]\n\nlistb[1]='po'\n\nprint('list b, where b=a and b[1] modified, b=\\n',listb,\n    '\\nJust using equals b=a after mods, a=\\n',lista,\n      '\\n Using a copy c=a.copy(), c=\\n',listc,\n      '\\n Using d=a[:] to create a copy, d=\\n',listd)\n\nOriginal a=\n ['1', '2', '3']\nlist b, where b=a and b[1] modified, b=\n ['1', 'po', '3'] \nJust using equals b=a after mods, a=\n ['1', 'po', '3'] \n Using a copy c=a.copy(), c=\n ['1', '2', '3'] \n Using d=a[:] to create a copy, d=\n ['1', '2', '3']\n\n\n\n\nAppend\nlist.append(x), add x to end of a list\n\nprint(lista)\nlista.append('ok')\nprint(lista)\n\n['1', 'po', '3']\n['1', 'po', '3', 'ok']\n\n\n\n\nInsert\nlista.insert(i,x) insert x at position i\n\nlista.insert(2,'two')\nprint(lista)\n\n['1', 'po', 'two', '3', 'ok']\n\n\n\n\nRemove\nlista.remove(x) Remove the first item from the list whose value is equal to x.\n\nlista.remove('two')\nprint(lista)\n\n['1', 'po', '3', 'ok']\n\n\n\n\nPop\nlista.pop([i]) Remove the item at the given position in the list, and return it\nlist.popleft at left\n\nprint(lista.pop(1))\n\npo\n\n\n\n\nRemove\nlist.clear() Remove all items from the list. Equivalent to del a[:].\n\nprint(lista.clear())\nprint(lista)\n\nNone\n[]\n\n\n\n\nIndex\nlist.index(x,i) Return position of x within list starting at position i\n\nlistc.append('1')\nprint(listc)\nprint(listc.index('1'),2)\n\n['1', '2', '3', '1']\n0 2\n\n\n\n\nCount\nlista.count(x) Return the number of times x appears in the list.\n\nprint(listc.count('1'))\n\n2\n\n\n\n\nSort\nlista.sort(*, key=None, reverse=False) Sort the items of the list in place (the arguments can be used for sort customization, see sorted() (https://docs.python.org/3/library/functions.html#sorted) for their explanation).\n\nlistc.sort()\nprint(listc)\n\n['1', '1', '2', '3']\n\n\n\n\nReverse\nlista.reverse() Reverse the elements of the list in place.\n\n\nDel\ndel lista[0] remove an item from a list given its index instead of its value\n\nprint(listc)\ndel listc[2]\nprint(listc)\n\n['1', '1', '2', '3']\n['1', '1', '3']\n\n\n\n\n#list of different types\nL =[123, 'spam',1.23]\nprint(L)\n\n#access\nprint(L[2])\n\n#append\nL.append('NI')\nprint(L)\n\n#get rid of one pop!\nL.pop(0)\nprint(L)\n\nM=['aa','jeji','boio','popo','gsss','zulu','ccc']\n#sort\nM.sort()\nprint(M)\nM.reverse()\nprint(M)\n\n[123, 'spam', 1.23]\n1.23\n[123, 'spam', 1.23, 'NI']\n['spam', 1.23, 'NI']\n['aa', 'boio', 'ccc', 'gsss', 'jeji', 'popo', 'zulu']\n['zulu', 'popo', 'jeji', 'gsss', 'ccc', 'boio', 'aa']"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#comprehensions",
    "href": "posts/PYTHON/others_python/Python_book.html#comprehensions",
    "title": "ThomasHSimm",
    "section": "Comprehensions",
    "text": "Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition.\n\nsquares=[]\nfor x in range(10):\n    squares.append(x**2)\nprint(squares)\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\n\n# the comprehension version\n\nprint([x**2 for x in range(10)])\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\nA list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for or if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if clauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n\n[(x,y) for x in [1,2,3] for y in [3, 1, 4] if x!=y]\n\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\n\n\n\nvec = [[1,2,3], [4,5,6], [7,8,9]]\n[num for elem in vec for num in elem]\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\nmatrix=[[1,2,3,4],\n       [5,6,7,8],\n       [9,19,11,12]]\n[[col[i] for col in matrix] for i in range(4)]\n\n[[1, 5, 9], [2, 6, 19], [3, 7, 11], [4, 8, 12]]\n\n\n\nList to string\nConvert a list to a string with \"\".join(lista)\n\nstra = \"\".join(listd)\nprint(stra,'-',stra[1:])\n\n123 - 23"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#dictionaries",
    "href": "posts/PYTHON/others_python/Python_book.html#dictionaries",
    "title": "ThomasHSimm",
    "section": "Dictionaries",
    "text": "Dictionaries\nPython dictionaries are something completely different (Monty Python reference intended)—they are not sequences at all, but are instead known as mappings. Mappings are also collections of other objects, but they store objects by key instead of by relative position. In fact, mappings don’t maintain any reliable left-to-right order; they simply map keys to associated values. Dictionaries, the only mapping type in Python’s core objects set, are also mutable: they may be changed in-place and can grow and shrink on demand, like lists.\n\n#create dict\n\nD = {'food':'Spam','quality':4, 'color':'pink'}\nprint(D)\n\n#or create by key assignment \nD={}\nD['food']='Spam'\nD['quality']=4\nD['color']='pink'\nprint(D)\n\n#index it\nprint(D['food'])\n\n\n# Nesting\n#what if the info is more complex? Nest\n\nrec = {'name':{'first':'Bob','last':'Smith'},\n        'job':['dev','mgr'],\n        'age':40.5}\n\n#index them\nprint(rec['name'])\n\nprint(rec['name']['last'])\n\nprint(rec['job'][0])\n\n#or add more NB job is a list\nrec['job'].append('janitor')\n\nprint(rec)\n\n#keys are 1st bit\nprint(rec.keys())"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#tuples",
    "href": "posts/PYTHON/others_python/Python_book.html#tuples",
    "title": "ThomasHSimm",
    "section": "Tuples",
    "text": "Tuples\nroughly like a list that cannot be changed—tuples are sequences, like lists, but they are immutable, like strings. Syntactically, they are coded in parentheses instead of square brackets, and they support arbitrary types, arbitrary nesting, and the usual sequence operations:\n\nT=(1,2,3,4)\nprint(len(T))\n\n#concatenation\nprint(T+(5,6))\n\n#indexing\nprint(T[0])\n\n## or\nT = ('spam', 3.0, [11, 22, 33])\nprint(T)"
  },
  {
    "objectID": "posts/PYTHON/others_python/Python_book.html#print",
    "href": "posts/PYTHON/others_python/Python_book.html#print",
    "title": "ThomasHSimm",
    "section": "Print",
    "text": "Print\n\n# to so many decimal places\n\nx=30.5557889\n\nprint('{:.5f}'.format(x))\n\n30.55579\n\n\n\n# add additional characters to string\n\nwidth = 20\nprint('HackerRank'.ljust(width,'-'))#or rjust\n\nHackerRank----------\n\n\n\nwidth = 20\nprint('HackerRank'.center(width,'-'))\n\n-----HackerRank-----\n\n\nhttps://docs.python.org/3/library/stdtypes.html#string-methods\nConversion……………………… Meaning\nd………………………………. Signed integer decimal.\ni………………………………. Signed integer decimal.\no………………………………. Signed octal value.\nu………………………………. Obsolete type – it is identical to ‘d’.\nx………………………………. Signed hexadecimal (lowercase).\nX………………………………. Signed hexadecimal (uppercase).\ne ………………………………. Floating point exponential format (lowercase).\nE………………………………. Floating point exponential format (uppercase).\nf………………………………. Floating point decimal format.\nF………………………………. Floating point decimal format.\ng………………………………. Floating point format. Uses lowercase exponential format if exponent is less than -4 or not less than precision, decimal format otherwise.\nG ………………………………. Floating point format. Uses uppercase exponential format if exponent is less than -4 or not less than precision, decimal format otherwise.\nc………………………………. Single character (accepts integer or single character string).\nr………………………………. String (converts any Python object using repr()).\ns………………………………. String (converts any Python object using str()).\na………………………………. String (converts any Python object using ascii()).\n%………………………………. No argument is converted, results in a ‘%’ character in the result."
  },
  {
    "objectID": "posts/PYTHON/others_python/Regular_expressions.html#regular-expressions-cheat-sheets",
    "href": "posts/PYTHON/others_python/Regular_expressions.html#regular-expressions-cheat-sheets",
    "title": "Regular expressions RE",
    "section": "Regular Expressions Cheat-Sheets",
    "text": "Regular Expressions Cheat-Sheets\nCheck out the following links for more information:\nhttps://docs.python.org/3/howto/regex.html\nhttps://docs.python.org/3/library/re.html\nhttps://docs.python.org/3/howto/regex.html#greedy-versus-non-greedy\nShout out to regex101.com, which will explain each stage of a regex."
  },
  {
    "objectID": "posts/PYTHON/others_python/Regular_expressions.html#summary",
    "href": "posts/PYTHON/others_python/Regular_expressions.html#summary",
    "title": "Regular expressions RE",
    "section": "Summary",
    "text": "Summary\n^ Beginning character\n$ End character\nPutting  before finds the special char\n\\w matches letters number and underscores\n\\d matches digits\n\\s for whitespace characters, space tab or newline\n\\b for word boundaries\n[a-z] is all lowercase letters\n[A-Z] is upercase letters\n[0-9] is numbers\n. is a joker button\n* means can have any length\n? zero or one occurence of the character before it\n^ NOT to all in the character class\n| Or statement\n[] within square brackets are or statements\n{n,m} numeric repetition qualifiers with brackets between n and m. Remove n or m can do less or more"
  },
  {
    "objectID": "posts/PYTHON/others_python/Regular_expressions.html#different-commands",
    "href": "posts/PYTHON/others_python/Regular_expressions.html#different-commands",
    "title": "Regular expressions RE",
    "section": "Different commands",
    "text": "Different commands\nre.search finds first instance\nre.findall finds all instances\nre.split split based on the expression\nre.sub substitute a part of the string\n\nprint('Using>> re.search(r\"ba\",\"babar\") gives:\\n',\\\n      re.search(r\"ba\",\"babar\"))\nprint('Using>> re.findall(r\"ba\",\"babar\") gives:\\n',\\\n      re.findall(r\"ba\",\"babar\"))\n\nUsing>> re.search(r\"ba\",\"babar\") gives:\n <re.Match object; span=(0, 2), match='ba'>\nUsing>> re.findall(r\"ba\",\"babar\") gives:\n ['ba', 'ba']\n\n\n\nprint(re.split(r\"[.?!]\",\"the dog! is here. whhere? oh I see.\"))\n\n['the dog', ' is here', ' whhere', ' oh I see', '']\n\n\n\nprint(re.sub(r\"dog\",\"cat\",\"the dog! is here. whhere? oh I see.\"))\n\nthe cat! is here. whhere? oh I see."
  },
  {
    "objectID": "posts/PYTHON/others_python/Regular_expressions.html#search-within-a-string",
    "href": "posts/PYTHON/others_python/Regular_expressions.html#search-within-a-string",
    "title": "Regular expressions RE",
    "section": "Search within a string",
    "text": "Search within a string\n\nprint('        Find a string within a string')\n\nresult = re.search(r\"aza\",\"bazaar\")\nprint(result)\nresult = re.search(r\"aza\",\"plaza\")\nprint(result)\n\nprint('\\n        At start of the string')\nresult=re.search(r\"^z\",\"zebra\")\nprint(result)\nresult = re.search(r\"^z\",\"plaza\")\nprint(result)\n\nprint('\\n        The joker .')\nresult = re.search(r\"x.n\",\"xenon\")\nprint(result)\nresult = re.search(r\"x..o\",\"xenon\")\nprint(result)\n\n        Find a string within a string\n<re.Match object; span=(1, 4), match='aza'>\n<re.Match object; span=(2, 5), match='aza'>\n\n        At start of the string\n<re.Match object; span=(0, 1), match='z'>\nNone\n\n        The joker .\n<re.Match object; span=(0, 3), match='xen'>\n<re.Match object; span=(0, 4), match='xeno'>\n\n\n\nCharacter classes\nThese are inside square brackets and are OR statements\n[a-z] is all lowercase letters [A-Z] is upercase letters [0-9] is numbers\n\nprint(re.search(r\"[Ppc]ython\",\"cython\"))\nprint(re.search(r\"[a-z]ython\",\"dython\"))\nprint(re.search(r\"[a-z]way\",\"My way\"))\nprint(re.search(r\"[a-z]way\",\"Myway\"))\n\n#find cloud with letter or number after it\nprint(re.search(r\"cloud[a-zA-Z0-9]\",\"cloud9\"))\nprint(re.search(r\"[a-zA-Z0-9]\",\"dy9thon\"))\n\n<re.Match object; span=(0, 6), match='cython'>\n<re.Match object; span=(0, 6), match='dython'>\nNone\n<re.Match object; span=(1, 5), match='yway'>\n<re.Match object; span=(0, 6), match='cloud9'>\n<re.Match object; span=(0, 1), match='d'>\n\n\n\n\napply a NOT to all in the character class\nThis uses the pipe class ^\n\n#this finds a space\nprint(re.search(r\"[^a-zA-Z0-9]\",\"dy9 thon\"))\n#this finds an underscore\nprint(re.search(r\"[^a-zA-Z0-9]\",\"dy9_thon\"))\n\n#this includes a not for spaces\nprint(re.search(r\"[^a-zA-Z0-9 ]\",\"dy9 thon-\"))\n\n<re.Match object; span=(3, 4), match=' '>\n<re.Match object; span=(3, 4), match='_'>\n<re.Match object; span=(8, 9), match='-'>\n\n\n\n\nfind a string OR another one\n\n\nprint(re.search(r\"cat|dog\",\"I ilke cats\"))\n\n<re.Match object; span=(7, 10), match='cat'>\n\n\n\n\nGreedy *\nExtension of .\n.* means can have any length\n\n#this finds something starting with p and ending with n\nprint(re.search(r\"p.*n\",\"python programming\"))\n\n#this finds something starting with py ending n but only a-z chars\nprint(re.search(r\"py[a-z]*n\",\"python programming\"))\n\n<re.Match object; span=(0, 17), match='python programmin'>\n<re.Match object; span=(0, 6), match='python'>\n\n\n\n\nmatch one or more occurence +\nSo o+l looks for ol\n\n#this works\nprint(re.search(r\"o+l\",\"olly\"))\n\n#this fails because there is an i inbetween\nprint(re.search(r\"o+l\",\"oilly\"))\n\n#this finds from 1st o to l\nprint(re.search(r\"o+l\",\"oolly\"))\n\n# here we can just remove the +\nprint(re.search(r\"ol\",\"oolly\"))\n\n<re.Match object; span=(0, 2), match='ol'>\nNone\n<re.Match object; span=(0, 3), match='ool'>\n<re.Match object; span=(1, 3), match='ol'>\n\n\n\n\nzero or one occurence of the character before it ?\n\n#\nprint(re.search(r\"p?each\",\"To each their own\"))\n\n#\nprint(re.search(r\"p?each\",\"To peach their own\"))\n\n#\nprint(re.search(r\"p?each\",\"Top each their own\"))\n\n<re.Match object; span=(3, 7), match='each'>\n<re.Match object; span=(3, 8), match='peach'>\n<re.Match object; span=(4, 8), match='each'>\n\n\n\n\nspecial characters \\\nPutting \\ before finds the special char\n\n# . here is anything so works here\nprint(re.search(r\".com\",\"internet.com\"))\n# but not here\nprint(re.search(r\".com\",\"welcome\"))\n# Add backslash we get it here \nprint(re.search(r\"\\.com\",\"internet.com\"))\n# and a negative here\nprint(re.search(r\"\\.com\",\"welcome\"))\n# find a (\nprint(re.search(r\"\\(\",\"welcome (no dont)\"))\n\n<re.Match object; span=(8, 12), match='.com'>\n<re.Match object; span=(2, 6), match='lcom'>\n<re.Match object; span=(8, 12), match='.com'>\nNone\n<re.Match object; span=(8, 9), match='('>\n\n\n\n\nMore special chars\n\\w matches letters number and underscores\n\\d matches digits\n\\s for whitespace characters, space tab or newline\n^ Beginning character\n$ End character\n\nprint('       so get here internet (stops at dot)')\nprint(re.search(r\"\\w*\",\"internet.com\"))\n\nprint(\"\\n     and here the whole string\")\nprint(re.search(r\"\\w*\",\"internet99_com\"))\n\n\nprint(\"\\n     find country start and end in 'a'\")\n\nprint(\"this works>>\\n\",re.search(r\"A.*a\",\"Australia\"))\nprint(\"this doesn't end in a>>\\n\",re.search(r\"A.*a\",\"Azerbaijan\"))\n\nprint(\"\\n     add the begin and end chars- works correct for both\")\nprint(re.search(r\"^A.*a$\",\"Australia\"))\nprint(re.search(r\"^A.*a$\",\"Azerbaijan\"))\n\n       so get here internet (stops at dot)\n<re.Match object; span=(0, 8), match='internet'>\n\n     and here the whole string\n<re.Match object; span=(0, 14), match='internet99_com'>\n\n     find country start and end in 'a'\nthis works>>\n <re.Match object; span=(0, 9), match='Australia'>\nthis doesn't end in a>>\n <re.Match object; span=(0, 9), match='Azerbaija'>\n\n     add the begin and end chars- works correct for both\n<re.Match object; span=(0, 9), match='Australia'>\nNone\n\n\n\n\nWord boundaries \\b\nFor word boundaries the \\b needs to be placed on both sides of the word to find\n\nprint(\"           Find the word hello\")\nprint(re.search(r\"\\bhello\\b\",\"hello darkness my old friend\"))\nprint(\"\\n           Find the substring hell\")\nprint(\"works without \\b>>\\n\",re.search(r\"hell\",\"hello darkness my old friend\"))\nprint(\"but not a full word so doesn't work with \\b>>\\n\",re.search(r\"\\bhell\\b\",\"hello darkness my old friend\"))\n\n           Find the word hello\n<re.Match object; span=(0, 5), match='hello'>\n\n           Find the substring hell\nworks without \b>>\n <re.Match object; span=(0, 4), match='hell'>\nbut not a full word so doesn't work with \b>>\n None\n\n\n\n\nCombine a few\nThis is for valid variable names\n\n# ^[a-zA-Z_] startswith letters or underscore\n# [a-zA-Z0-9_] then letters, numbers or undercore\n# *$ end with above\npattern=r\"^[a-zA-Z_][a-zA-Z0-9_]*$\"\n\nprint(re.search(pattern,\"LLnananj_9\"))\n\nprint(re.search(pattern,\"LLnananj_9\"))\nprint(re.search(pattern,\"9LLnananj_9\"))\n\n<re.Match object; span=(0, 10), match='LLnananj_9'>\n<re.Match object; span=(0, 10), match='LLnananj_9'>\nNone\n\n\n\n\nnumeric repetition qualifiers {m,n}\n[a-z]{n} for a repetition of lower case chars n time\n[a-z]{n,m} repetition between n and m\n[a-z]{n,} repetition of n or more\n[a-z]{,n} repetitions of n or less\n\nprint(re.search(r\"[a-zA-Z]{5}\",\"a ghost\"))\n\n# a number but we only get the first\nprint(re.search(r\"[a-zA-Z]{5}\",\"a scary super ghost\"))\n\n<re.Match object; span=(2, 7), match='ghost'>\n<re.Match object; span=(2, 7), match='scary'>\n\n\n\nprint(re.findall(r\"[a-zA-Z]{5}\",\"a scary super ghost\"))\n\n# but if we give a longer word?\nprint(re.findall(r\"[a-zA-Z]{5}\",\"a scary superior ghost\"))\n\n# we get part of the superior word\n\n# to get just the words we want of 5 long can use \\b\nprint(re.findall(r\"\\b[a-zA-Z]{5}\\b\",\"a scary superior ghost\"))\n\n['scary', 'super', 'ghost']\n['scary', 'super', 'ghost']\n['scary', 'ghost']\n\n\n\n#between 2 and 4 exactly  full word\nprint(re.search(r\"\\b[a-zA-Z]{2,4}\\b\",\"a ab abc abcd abcde abcdef\"))\n\nprint(re.findall(r\"\\b[a-zA-Z]{2,4}\\b\",\"a ab abc abcd abcde abcdef\"))\n\n#NB \\b needed otherwise see below\nprint(re.findall(r\"[a-zA-Z]{2,4}\",\"a ab abc abcd abcde abcdef\"))\n\n# 2 and above full word\nprint(re.findall(r\"\\b[a-zA-Z]{2,}\\b\",\"a ab abc abcd abcde abcdef\"))\n\n# {,3} up to this many reps\nprint(re.findall(r\"\\b[a-zA-Z]{,3}\\b\",\"a ab abc abcd abcde abcdef\"))\n\n<re.Match object; span=(2, 4), match='ab'>\n['ab', 'abc', 'abcd']\n['ab', 'abc', 'abcd', 'abcd', 'abcd', 'ef']\n['ab', 'abc', 'abcd', 'abcde', 'abcdef']\n['a', '', 'ab', '', 'abc', '', '', '', '', '', '', '']"
  },
  {
    "objectID": "posts/PYTHON/others_python/Regular_expressions.html#capturing-groups",
    "href": "posts/PYTHON/others_python/Regular_expressions.html#capturing-groups",
    "title": "Regular expressions RE",
    "section": "Capturing groups",
    "text": "Capturing groups\n\n# start with letters number and underscores  \n# then comma and space\n# ends with letters number and underscores\n\ndef dogroups(regExpr,string):\n\n    result = re.search(regExpr,string)\n    \n    print(\"String is >> {},\\n regExpr is >> {},\\n result is >> {}\\n\".format(string, regExpr,result))\n\n    print(\"groups\",result.groups())\n    try:\n        print(\"result[0]\",result[0])\n    except:\n        print(\"no result 0\")\n    try:\n        print(\"result[1]\",result[1])\n    except:\n        print(\"no result 1\")\n    try:\n        print(\"result[2]\",result[2])\n    except:\n        print(\"no result 2\")\n             \n\n\nMatch normally, just get one result\n\ndogroups(r\"^\\w*, \\w*$\",\"Lovelace, Ada\") \n\nString is >> Lovelace, Ada,\n regExpr is >> ^\\w*, \\w*$,\n result is >> <re.Match object; span=(0, 13), match='Lovelace, Ada'>\n\ngroups ()\nresult[0] Lovelace, Ada\nno result 1\nno result 2\n\n\n\n\nUse brackets () to match multiple results\n\ndogroups(r\"(^\\w*), (\\w*$)\",\"Lovelace, Ada\") \n\nString is >> Lovelace, Ada,\n regExpr is >> (^\\w*), (\\w*$),\n result is >> <re.Match object; span=(0, 13), match='Lovelace, Ada'>\n\ngroups ('Lovelace', 'Ada')\nresult[0] Lovelace, Ada\nresult[1] Lovelace\nresult[2] Ada\n\n\n\nlog = \"July 31 07:51:48 mycomputer bad_process[12345]: ERROR Performing package upgrade\"\n# has [ followed by digits at least 1 followed by ]\nregex= r\"\\[(\\d+)\\]\"\nresult= re.search(regex,log)\nprint(\"result[0]= {}, result[1]={}\".format(result[0],result[1]))\nprint(\"result.group= {}, result.groups= {}\".format(result.group(),result.groups()))\n\n\nresult[0]= [12345], result[1]=12345\nresult.group= [12345], result.groups= ('12345',)\n\n\n\ndef extract_pid(log_line):\n    regex= r\"\\[(\\d+)\\]\"\n    result=re.search(regex,log_line)\n    if result is None:\n        return \"None\"\n    return result[1]\n\nprint(extract_pid(log))\nprint(extract_pid(\"[cat]  sass\"))\n\n12345\nNone\n\n\n\n\nre.sub\nthe general format is:\nre.sub(regular_expression_looking_for, what_to_replace_with,the_input_string)\n\n# (char num _) at least one + folowed by @ with char dot or dash at least one +\n\nprint(re.sub(r\"[\\w.%+-]+@[\\w.-]+\",\"[REDACTED]\",\"Received an email for go_nuts95@my.examle.com\"))\n\nReceived an email for [REDACTED]\n\n\n\nCombining with groups\nIf the regular expression has split the answer into groups (using ()) then can specify those parts using \\1 for first term \\2 for second term etc in the what to replace with part\nre.sub(regexp,r\"\\1 and \\2\",string)\nthe output is just the 1st and 2nd parts with “and” in the middle\n\ntexta = \"Lovelace, Ada\"\npatt = r\"^([\\w]*), ([\\w]*$)\"\nres=re.search(patt, texta)\nprint(res[0],res[1],res[2])\n\n     #this says sub with: result2 space result 1\nre.sub(patt, r\"\\2 \\1\",texta)\n\nLovelace, Ada Lovelace Ada\n\n\n'Ada Lovelace'"
  },
  {
    "objectID": "posts/PYTHON/others_python/Regular_expressions.html#some-examples",
    "href": "posts/PYTHON/others_python/Regular_expressions.html#some-examples",
    "title": "Regular expressions RE",
    "section": "Some Examples",
    "text": "Some Examples\n\nimport re\ndef repeating_letter_a(text):\n    #here we go A or a - followed by a-z or space- followed by a or A  \n    result = re.search(r\"(a|A)[a-z ]*(a|A)\", text)\n\n    return result != None\n\nprint(repeating_letter_a(\"banana\")) # True\nprint(repeating_letter_a(\"pineapple\")) # False\nprint(repeating_letter_a(\"Animal Kingdom\")) # True\nprint(repeating_letter_a(\"A is for apple\")) # True\n\n\n# Fill in the code to check if the text\n# passed has at least 2 groups of alphanumeric characters \n# (including letters, numbers, and underscores)\n# separated by one or more whitespace characters.\nimport re\ndef check_character_groups(text):\n  result = re.search(r\"\\w\\s\\w\", text)\n  return result != None\n\nprint(check_character_groups(\"One\")) # False\nprint(check_character_groups(\"123  Ready Set GO\")) # True\nprint(check_character_groups(\"username user_01\")) # True\nprint(check_character_groups(\"shopping_list: milk, bread, eggs.\")) # False\n\n\nimport re\ndef check_web_address(text):\n\n# starts with letters,numbers,underscores\n# followed by a dot then ends with letters,numbers,underscores\n    pattern = r\"\\w\\.\\w*$\"\n    result = re.search(pattern, text)\n    return result != None\n\nprint(check_web_address(\"gmail.com\")) # True\nprint(check_web_address(\"www@google\")) # False\nprint(check_web_address(\"www.Coursera.org\")) # True\nprint(check_web_address(\"web-address.com/homepage\")) # False\nprint(check_web_address(\"My_Favorite-Blog.US\")) # True\n\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n\nimport re\ndef rearrange_name(name):\n    result = re.search(r\"^([\\w \\.-]*), ([\\w \\.-]*)$\", name)\n    if result == None:\n        \n        return name\n        \n    return \"{} {}\".format(result[2], result[1])\n\nname=rearrange_name(\"Kennedy, John F.\")\nprint(name)\n\nname=rearrange_name(\"Kennedy, John Franklin\")\nprint(name)\n\nJohn F. Kennedy\nJohn Franklin Kennedy\n\n\n\n#words of at least 7 chars\nimport re\ndef long_words(text):\n    #this says full words (\\b) with chars [A-Za-z] repeated 7 times or more {7,}\n    pattern = r\"\\b[A-Za-z]{7,}\\b\"\n    result = re.findall(pattern, text)\n    return result\n\nprint(long_words(\"I like to drink coffee in the morning.\")) # ['morning']\nprint(long_words(\"I also have a taste for hot chocolate in the afternoon.\")) # ['chocolate', 'afternoon']\nprint(long_words(\"I never drink tea late at night.\")) # []\n\n\n\n['morning']\n['chocolate', 'afternoon']\n[]\n\n\n\n# Add to the regular expression used in the extract_pid function, \n# to return the uppercase message in parenthesis, after the process id.\n\nimport re\ndef extract_pid(log_line):\n    regex = r\"\\[([0-9]*)\\]\"  #\n    result = re.search(regex, log_line)\n    if result is None:\n        return None\n    print(result)\n    return result[1]#\"{} ({})\".format(result[1],result[2])\n\nprint(extract_pid(\"July 31 07:51:48 mycomputer bad_process[12345]: ERROR Performing package upgrade\")) # 12345 (ERROR)\nprint(extract_pid(\"99 elephants in a [cage]\")) # None\nprint(extract_pid(\"A string that also has numbers [34567] but no uppercase message\")) # None\nprint(extract_pid(\"July 31 08:08:08 mycomputer new_process[67890]: RUNNING Performing backup\")) # 67890 (RUNNING)\n\n<re.Match object; span=(39, 46), match='[12345]'>\n12345\nNone\n<re.Match object; span=(31, 38), match='[34567]'>\n34567\n<re.Match object; span=(39, 46), match='[67890]'>\n67890\n\n\n\n# We want to split a piece of text by either the word \"a\" or \"the\", \n# as implemented in the following code. \n# What is the resulting split list?\n\nre.split(r\"the|a\", \"One sentence. Another one? And the last one!\")\n\n['One sentence. Ano', 'r one? And ', ' l', 'st one!']\n\n\n\nimport re\ndef transform_record(record):\n    pat = r\"(\\b[A-Za-z ]{2,}\\b),([0-9-]{2,}),(\\b[A-Za-z ]{2,}\\b)\"\n    new_record = re.sub(pat,r\"\\1,\\3 (+1-\\2)\",record)\n    \n    return new_record\n\n# Change the order to Name, Job, (Phone No.)\n\nprint(transform_record(\"Sabrina Green,802-867-5309,System Administrator\")) \n\nprint(transform_record(\"Eli Jones,684-3481127,IT specialist\")) \n\nprint(transform_record(\"Melody Daniels,846-687-7436,Programmer\")) \n\nprint(transform_record(\"Charlie Rivera,698-746-3357,Web Developer\")) \n\nSabrina Green,System Administrator (+1-802-867-5309)\nEli Jones,IT specialist (+1-684-3481127)\nMelody Daniels,Programmer (+1-846-687-7436)\nCharlie Rivera,Web Developer (+1-698-746-3357)\n\n\n\nimport re\ndef multi_vowel_words(text):\n  pattern = r\"[A-Za-z]*[aeiou]{3,}[a-z]*\"\n  result = re.findall(pattern, text)\n  return result\n\nprint(multi_vowel_words(\"Life is beautiful\")) \n# ['beautiful']\n\nprint(multi_vowel_words(\"Obviously, the queen is courageous and gracious.\")) \n# ['Obviously', 'queen', 'courageous', 'gracious']\n\nprint(multi_vowel_words(\"The rambunctious children had to sit quietly and await their delicious dinner.\")) \n# ['rambunctious', 'quietly', 'delicious']\n\nprint(multi_vowel_words(\"The order of a data queue is First In First Out (FIFO)\")) \n# ['queue']\n\nprint(multi_vowel_words(\"Hello world!\")) \n# []\n\n['beautiful']\n['Obviously', 'queen', 'courageous', 'gracious']\n['rambunctious', 'quietly', 'delicious']\n['queue']\n[]\n\n\n\nimport re\ndef transform_comments(line_of_code):\n    patt=r\"#{1,}\"\n    result = re.sub(patt,\"//\",line_of_code)\n    return result\n\nprint(transform_comments(\"### Start of program\")) \n# Should be \"// Start of program\"\nprint(transform_comments(\"  number = 0   ## Initialize the variable\")) \n# Should be \"  number = 0   // Initialize the variable\"\nprint(transform_comments(\"  number += 1   # Increment the variable\")) \n# Should be \"  number += 1   // Increment the variable\"\nprint(transform_comments(\"  return(number)\")) \n# Should be \"  return(number)\"\n\n// Start of program\n  number = 0   // Initialize the variable\n  number += 1   // Increment the variable\n  return(number)\n\n\n\nstring = \"My number is 21-345-9999.\"\n\npatt = r\"([0-9]{2}-)\"\nresa=re.findall(patt,phone)\n# result = re.sub(patt,r\"({0}),{1},{2}\".format(resa[0],resa[1],resa[2]),phone)\n\n\n# result\n\n\nimport re\ndef convert_phone_number(phone):\n  patt = r\"\\s([0-9]{1,})[-\\s]([0-9]{1,})[-]([0-9]{1,})\"\n    \n  result = re.sub(patt,r\" (\\1) \\2-\\3\",phone)\n  return result\n\nprint(convert_phone_number(\"My number is 212-345-9999.\")) # My number is (212) 345-9999.\nprint(convert_phone_number(\"Please call 888-555-1234\")) # Please call (888) 555-1234\nprint(convert_phone_number(\"123-123-12345\")) # 123-123-12345\nprint(convert_phone_number(\"Phone number of Buckingham Palace is +44 303 123 7300\")) # Phone number of Buckingham Palace is +44 303 123 7300\n\nMy number is (212) 345-9999.\nPlease call (888) 555-1234\n123-123-12345\nPhone number of Buckingham Palace is +44 303 123 7300"
  },
  {
    "objectID": "posts/PYTHON/others_python/speech_recog.html#resources-sources",
    "href": "posts/PYTHON/others_python/speech_recog.html#resources-sources",
    "title": "Speech recognition",
    "section": "Resources / Sources",
    "text": "Resources / Sources\n\nusing-speech-recognition-to-convert-speech-to-text-python\ncreate-a-voice-recorder-using-python\ni-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14\nexamples/audio_transcribe.py"
  },
  {
    "objectID": "posts/PYTHON/others_python/speech_recog.html#installs",
    "href": "posts/PYTHON/others_python/speech_recog.html#installs",
    "title": "Speech recognition",
    "section": "Installs",
    "text": "Installs\n\n\n!pip install speechrecognition pydub\n!pip3 install sounddevice\n!pip3 install wavio\n!pip install scipy"
  },
  {
    "objectID": "posts/PYTHON/others_python/speech_recog.html#create-a-recording",
    "href": "posts/PYTHON/others_python/speech_recog.html#create-a-recording",
    "title": "Speech recognition",
    "section": "Create a recording",
    "text": "Create a recording\n\n# import required libraries\nimport sounddevice as sd\nfrom scipy.io.wavfile import write\nimport wavio as wv\n  \n# Sampling frequency\nfreq = 44100\n  \n# Recording duration\nduration = 20\n  \n# Start recorder with the given values \n# of duration and sample frequency\nrecording = sd.rec(int(duration * freq), \n                   samplerate=freq, channels=2)\n  \n# Record audio for the given number of seconds\nsd.wait()\n  \n# This will convert the NumPy array to an audio\n# file with the given sampling frequency\n# write(\"recording0.wav\", freq, recording)\n  \n# Convert the NumPy array to audio file\nfileo=\"recording1.wav\"\nwv.write(fileo, recording, freq, sampwidth=2)\n\nTo make it an arbitrary duration\nhttps://python-sounddevice.readthedocs.io/en/0.3.12/examples.html#recording-with-arbitrary-duration"
  },
  {
    "objectID": "posts/PYTHON/others_python/speech_recog.html#convert-audio-to-text",
    "href": "posts/PYTHON/others_python/speech_recog.html#convert-audio-to-text",
    "title": "Speech recognition",
    "section": "Convert Audio to text",
    "text": "Convert Audio to text\n\nimport speech_recognition as sr\n\nAUDIO_FILE = fileo\nr = sr.Recognizer()\nwith sr.AudioFile(AUDIO_FILE) as source:\n    audio = r.record(source)  # read the entire audio file\n\n\ntry:\n    # we're just using the default API key\n    print(\"->> \" + r.recognize_google(audio))\nexcept sr.UnknownValueError:\n    print(\"Google Speech Recognition could not understand audio\")\nexcept sr.RequestError as e:\n    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n\n->> I heard you have a compilation of every good song ever done by anybody every great song by The Beach Boys All the underground hits all the modern lovers tracks I heard you have a vinyl record on German imports I heard that you have a white label every cm\n\n\nWhen reading out Losing My Edge by LCD Soundsystem\nI heard you have a compilation of every good song ever done by anybody. Every great song by the Beach Boys. All the underground hits. All the Modern Lovers tracks. I heard you have a vinyl of every Niagra record on German import. I heard that you have a white label of every semina"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#select-from",
    "href": "posts/PYTHON/others_python/SQL.html#select-from",
    "title": "Basics SQL",
    "section": "Select, From",
    "text": "Select, From\nThe general syntax of SELECT statments is:\nselect FirstName, LastName from Employees ;\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nNancy\nEdwards\n\n\nJane\nPeacock\n\n\nMargaret\nPark\n\n\nSteve\nJohnson\n\n\nMichael\nMitchell\n\n\nRobert\nKing\n\n\nLaura\nCallahan\n\n\n\nTo retrieve all columns from the Employees table we could use “*” instead of specifying individual column names:\nselect * from Employees ;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployeeId\nLastName\nFirstName\nTitle\nReportsTo\nBirthDate\nHireDate\nAddress\nCity\nState\nCountry\nPostalCode\nPhone\nFax\nEmail\n\n\n\n\n1\nAdams\nAndrew\nGeneral Manager\nNone\n1962-02-18 00:00:00\n2002-08-14 00:00:00\n11120 Jasper Ave NW\nEdmonton\nAB\nCanada\nT5K 2N1\n+1 (780) 428-9482\n+1 (780) 428-3457\nandrew@chinookcorp.com\n\n\n2\nEdwards\nNancy\nSales Manager\n1\n1958-12-08 00:00:00\n2002-05-01 00:00:00\n825 8 Ave SW\nCalgary\nAB\nCanada\nT2P 2T3\n+1 (403) 262-3443\n+1 (403) 262-3322\nnancy@chinookcorp.com\n\n\n3\nPeacock\nJane\nSales Support Agent\n2\n1973-08-29 00:00:00\n2002-04-01 00:00:00\n1111 6 Ave SW\nCalgary\nAB\nCanada\nT2P 5M5\n+1 (403) 262-3443\n+1 (403) 262-6712\njane@chinookcorp.com\n\n\n4\nPark\nMargaret\nSales Support Agent\n2\n1947-09-19 00:00:00\n2003-05-03 00:00:00\n683 10 Street SW\nCalgary\nAB\nCanada\nT2P 5G3\n+1 (403) 263-4423\n+1 (403) 263-4289\nmargaret@chinookcorp.com\n\n\n5\nJohnson\nSteve\nSales Support Agent\n2\n1965-03-03 00:00:00\n2003-10-17 00:00:00\n7727B 41 Ave\nCalgary\nAB\nCanada\nT3B 1Y7\n1 (780) 836-9987\n1 (780) 836-9543\nsteve@chinookcorp.com\n\n\n6\nMitchell\nMichael\nIT Manager\n1\n1973-07-01 00:00:00\n2003-10-17 00:00:00\n5827 Bowness Road NW\nCalgary\nAB\nCanada\nT3B 0C5\n+1 (403) 246-9887\n+1 (403) 246-9899\nmichael@chinookcorp.com\n\n\n7\nKing\nRobert\nIT Staff\n6\n1970-05-29 00:00:00\n2004-01-02 00:00:00\n590 Columbia Boulevard West\nLethbridge\nAB\nCanada\nT1K 5N8\n+1 (403) 456-9986\n+1 (403) 456-8485\nrobert@chinookcorp.com\n\n\n8\nCallahan\nLaura\nIT Staff\n6\n1968-01-09 00:00:00\n2004-03-04 00:00:00\n923 7 ST NW\nLethbridge\nAB\nCanada\nT1H 1Y8\n+1 (403) 467-3351\n+1 (403) 467-8772\nlaura@chinookcorp.com"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#where",
    "href": "posts/PYTHON/others_python/SQL.html#where",
    "title": "Basics SQL",
    "section": "Where",
    "text": "Where\nThe WHERE clause can be added to your query to filter results or get specific rows of data. To retrieve data for all rows in the Employees table where the ID is less than 5:\nselect * from Employees where EmployeeID < 5 ;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployeeId\nLastName\nFirstName\nTitle\nReportsTo\nBirthDate\nHireDate\nAddress\nCity\nState\nCountry\nPostalCode\nPhone\nFax\nEmail\n\n\n\n\n1\nAdams\nAndrew\nGeneral Manager\nNone\n1962-02-18 00:00:00\n2002-08-14 00:00:00\n11120 Jasper Ave NW\nEdmonton\nAB\nCanada\nT5K 2N1\n+1 (780) 428-9482\n+1 (780) 428-3457\nandrew@chinookcorp.com\n\n\n2\nEdwards\nNancy\nSales Manager\n1\n1958-12-08 00:00:00\n2002-05-01 00:00:00\n825 8 Ave SW\nCalgary\nAB\nCanada\nT2P 2T3\n+1 (403) 262-3443\n+1 (403) 262-3322\nnancy@chinookcorp.com\n\n\n3\nPeacock\nJane\nSales Support Agent\n2\n1973-08-29 00:00:00\n2002-04-01 00:00:00\n1111 6 Ave SW\nCalgary\nAB\nCanada\nT2P 5M5\n+1 (403) 262-3443\n+1 (403) 262-6712\njane@chinookcorp.com\n\n\n4\nPark\nMargaret\nSales Support Agent\n2\n1947-09-19 00:00:00\n2003-05-03 00:00:00\n683 10 Street SW\nCalgary\nAB\nCanada\nT2P 5G3\n+1 (403) 263-4423\n+1 (403) 263-4289\nmargaret@chinookcorp.com\n\n\n\nIn case of character based columns the values of the predicates in the where clause need to be enclosed in single quotes. To retrieve the data for the Employees names with First Name “Jane” we would issue:\nselect LastName, FirstName from Employees where FirstName = 'Jane';\n\n\n\nLastName\nFirstName\n\n\n\n\nPeacock\nJane"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#in-or-not",
    "href": "posts/PYTHON/others_python/SQL.html#in-or-not",
    "title": "Basics SQL",
    "section": "In, Or, Not",
    "text": "In, Or, Not\nIn is used when we want to specify a range of conditions.\nFor example, find values of employees with last name Adams or Park\nselect FirstName, LastName from Employees\nwhere LastName In ('Adams','Park');\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nCan do a similar thing with the OR operator. When using OR it is often helpful to use with brackets ()\nselect FirstName, LastName from Employees\nwhere (LastName = 'Adams' OR LastName ='Park');\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nWhy the order matters and use of ()\nselect FirstName, LastName from Employees\nwhere LastName = 'Adams' OR LastName ='Park'\nand reportsto=2;\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nselect FirstName, LastName from Employees\nwhere (LastName = 'Adams' OR LastName ='Park')\nand reportsto=2;\n\n\n\nFirstName\nLastName\n\n\n\n\nMargaret\nPark\n\n\n\nThis is because SQL processes AND before OR\nIn benefits over or - Long list of options - In is faster - Don’t have to consider order with IN - Can contain another select\nThe not command is represented as <>\nfor example select the titles not beginning with c\nselect title from albums\nwhere substr(title,1,1) <> 'C'\n\n\n\nTitle\n\n\n\n\nFor Those About To Rock We Salute You\n\n\nBalls to the Wall\n\n\nRestless and Wild\n\n\nLet There Be Rock\n\n\nBig Ones\n\n\nJagged Little Pill\n\n\nFacelift\n\n\nWarner 25 Anos\n\n\nPlays Metallica By Four Cellos\n\n\nAudioslave\n\n\n\nIf it is used with IN then we use NOT\nfor example cities names not starting with a vowel\nselect distinct city from station\nwhere substr(city,1,1) not in ('a','e','i','o','u')\n\n\n\nCity\n\n\n\n\nKissee Mills\n\n\nLoma Mar\n\n\nSandy Hook\n\n\nTipton\n\n\nTurner\n\n\nSlidell\n\n\nNegreet"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#distinct",
    "href": "posts/PYTHON/others_python/SQL.html#distinct",
    "title": "Basics SQL",
    "section": "Distinct",
    "text": "Distinct\nFind unique values\nselect distinct artistid from albums\n\n\n\nAlbumId\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#wildcards",
    "href": "posts/PYTHON/others_python/SQL.html#wildcards",
    "title": "Basics SQL",
    "section": "Wildcards",
    "text": "Wildcards\nTo find parts within a string can use the % wildcard\n_ works in a similar way but matches a single character (not supported by DB2)\n\n\n\n\n\n\n\nWildcard\nAction\n\n\n\n\n‘%ly’\nFind all strings ending ‘ly’\n\n\n‘To%’\nFind all strings starting ‘To’\n\n\n‘t%@gmail.com’\nFind all gmail address strings starting ‘t’\n\n\n’_ill’\nFind all strings ending ill with one other chaharacter  e.g. Kill, Bill\n\n\n\nImplementation, to implement use where and like.\nFind Names ending in t\nselect FirstName, LastName from Employees\nwhere FirstName like '%t';\n\n\n\nFirstName\nLastName\n\n\n\n\nMargaret\nPark\n\n\nRobert\nKing\n\n\n\nDownsides of wildcards:\n\nTakes longer to run (particularly at end of pattern\nBetter to use another operator e.g. =,>,<"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#order-data",
    "href": "posts/PYTHON/others_python/SQL.html#order-data",
    "title": "Basics SQL",
    "section": "Order Data",
    "text": "Order Data\norder by - take name of 1 or more columns - Can use a column not retrieved - The last clause in a statement - Can use a number to represent column number - Add dsc or asc after column name to order acending or descending\nOrder employee names by last name ascending then last name descending\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nLaura\nCallahan\n\n\nNancy\nEdwards\n\n\nSteve\nJohnson\n\n\nRobert\nKing\n\n\nMichael\nMitchell\n\n\nMargaret\nPark\n\n\nJane\nPeacock"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#aggregate-functions",
    "href": "posts/PYTHON/others_python/SQL.html#aggregate-functions",
    "title": "Basics SQL",
    "section": "Aggregate Functions",
    "text": "Aggregate Functions\n\naverage average of a column (avg)\ncount counts number of values\nmin finds the minimum value\nmax finds the maximum value\nsum sums the column values\n\nselect count(trackid) from tracks\nwhere albumid = 10\n\n\n\ncount(trackid)\n\n\n\n\n14"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#group-by-and-having",
    "href": "posts/PYTHON/others_python/SQL.html#group-by-and-having",
    "title": "Basics SQL",
    "section": "Group by and Having",
    "text": "Group by and Having\nDo the same command as above but with group by, instead of where need to use having after the group by statement\nwhere filters before data is grouped and having after data is grouped\nselect count(trackid) from tracks\ngroup by albumid\nhaving albumid = 10\n\n\n\ncount(trackid)\n\n\n\n\n14\n\n\n\nor could get the number of tracks in all albums\nselect count(trackid) from tracks\ngroup by albumid\n\n\n\ncount(trackid)\n\n\n\n\n10\n\n\n1\n\n\n3\n\n\n8\n\n\n15\n\n\n13\n\n\n12\n\n\n14\n\n\n8\n\n\n14"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#windowing",
    "href": "posts/PYTHON/others_python/SQL.html#windowing",
    "title": "Basics SQL",
    "section": "Windowing",
    "text": "Windowing\n\nA window function performs a calculation across a set of table rows that are somehow related to the current row.\nComparable to the type of calculation that can be done with an aggregate function.\nUnlike regular aggregate functions, windowing does not cause rows to become grouped into a single output row — the rows retain their separate identities.\nBehind the scenes, the window function is able to access more than just the current row of the query result.\nhttps://www.postgresql.org/docs/9.1/tutorial-window.html\n\nFor example, compare each song track’s length to the average salength for each composer\nselect composer, name,\nmilliseconds/(1000*60)                                    AS track_length,\navg(milliseconds/(1000*60)) over (partition by composer)  AS avg_track_length\nfrom ah_uyekita.chinook_track\n\n\n\ncomposer\nname\ntrack_length\navg_track_length\n\n\n\n\nAaron Copland\nFanfare for the Common Man\n3.3011\n3.3011\n\n\nAaron Goldberg\nOAM’s Blues\n4.4489\n4.4489\n\n\nA.Bouchard/J.Bouchard/S.Pearlman\nAstronomy\n6.6255\n6.6255\n\n\nAC/DC\nLet There Be Rock\n6.1109\n5.1110\n\n\nAC/DC\nOverdose\n6.1553 5.1110\n\n\n\nAC/DC\nProblem Child\n5.4173\n5.1110\n\n\nAC/DC\nBad Boy Boogie\n4.4621\n5.1110\n\n\nAC/DC\nGo Down\n5.5197\n5.1110\n\n\n\n\nWindow functions\n\nCUME_DIST Calculate the cumulative distribution of a value in a set of values\nDENSE_RANK Assign a rank value to each row within a partition of a result, with no gaps in rank values.\nFIRST_VALUE Get the value of the first row in an ordered partition of a result set.\nLAG Provide access to a row at a given physical offset that comes before the current row.\nLAST_VALUE Get the value of the last row in an ordered partition of a result set.\nLEAD Provide access to a row at a given physical offset that follows the current row.\nNTILE Distribute rows of an ordered partition into a number of groups or buckets\nPERCENT_RANK Calculate the percent rank of a value in a set of values.\nRANK Assign a rank value to each row within a partition of a result set\nROW_NUMBER Assign a unique sequential integer to rows within a partition of a result set, the first row starts from 1.\n\nhttps://www.sqlservertutorial.net/sql-server-window-functions/"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#subqueries",
    "href": "posts/PYTHON/others_python/SQL.html#subqueries",
    "title": "Basics SQL",
    "section": "Subqueries",
    "text": "Subqueries\nThese are queries within other queries Which merge data from multiple sources together\nget customerid and city when their invoice total is more than 20\nselect CustomerID, City\nfrom customers\nwhere customerid in (select customerid\nfrom invoices\nwhere total>20)\n\n\n\nCustomerId\nCity\n\n\n\n\n6\nPrague\n\n\n26\nFort Worth\n\n\n45\nBudapest\n\n\n46\nDublin\n\n\n\nHow many albums does the band LEd Zeppelin have?\nselect count(*)\nfrom albums\nwhere artistid IN\n(select artistid\nfrom artists\nwhere Name ='Led Zeppelin')\n\n\n\ncount(*)\n\n\n\n\n14\n\n\n\nOr what are the name of the tracks for the artist Audioslave?\nselect Name\nfrom tracks\nwhere albumid IN\n(select albumid\nfrom albums\nwhere artistid IN\n(select artistid\nfrom artists\nwhere Name ='Audioslave'))\n\n\n\nName\n\n\n\n\nCochise\n\n\nShow Me How to Live\n\n\nGasoline\n\n\nWhat You Are\n\n\nLike a Stone\n\n\nSet It Off\n\n\nShadow on the Sun\n\n\nI am the Highway\n\n\nExploder\n\n\nHypnotize"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#joins",
    "href": "posts/PYTHON/others_python/SQL.html#joins",
    "title": "Basics SQL",
    "section": "Joins",
    "text": "Joins\n\nefficient storage\neasier manipulation\ngreater scalability\nlogically models a process\ntables are related through common values or keys\ndata retrival from multiple tables in one query\nonly persist for the duration of the query\n\n\nCartesian cross joins\n\neach row from first table joins with all rows from the other table\noutput size of joins in A multiplied rows in B\ncomputationally taxing\nrarely used\n\n\nselect a.title, ar.name from albums as a\ncross join artists as ar\norder by a.title\n\n\n\nTitle\nName\n\n\n\n\n…And Justice For All\nAC/DC\n\n\n…And Justice For All\nAccept\n\n\n\ntotal rows = 95425\ntotal rows of albums = 347\ntotal rows of artists = 275\n\n\nInner join\n\nselect records that have matching values in both tables\nUse on to select what joining on\njoining more table affects database performance\nCan join multiple tables- no limit\n\n\nFor example get the artist name and title of each album. N.B. albums has columns AlbumID, Title and ArtistID only\nselect artists.Name, albums.Title\nfrom artists\nINNER JOIN albums\non artists.artistid = albums.artistID\n\n\n\nName\nTitle\n\n\n\n\nAC/DC\nFor Those About To Rock We Salute You\n\n\nAC/DC\nLet There Be Rock\n\n\nAccept\nBalls to the Wall\n\n\nAccept\nRestless and Wild\n\n\nAerosmith\nBig Ones\n\n\nAlanis Morissette\nJagged Little Pill\n\n\nAlice In Chains\nFacelift\n\n\nAntônio Carlos Jobim\nWarner 25 Anos\n\n\nAntônio Carlos Jobim\nChill: Brazil (Disc 2)\n\n\nApocalyptica\nPlays Metallica By Four Cellos\n\n\n\nOr as a multiple join\nSELECT o.orderId, c.CompanyName, e.LastName\nFROM ((orders o INNER JOIN customers c ON o.customerID = c.CustomerID)\n`INNER JOIN employees e ON o.EmployeeID = e.EmployeeID);\n\n\nSelf joins\n\nTakes the table and treats it like two separate tables\nJoin the original table to itself\n\nFor example, match cities from the same state\nselect A.city,A.state,B.city, B.state\nfrom station A, station B\nwhere A.city=B.city\nand A.state=B.state\norder by A.state;\n\n\n\ncity A\nstate A\ncity B\nstate B\n\n\n\n\nSeward\nAK\nSeward\nAK\n\n\nChignik Lagoon\nAK\nChignik Lagoon\nAK\n\n\nFive Points\nAL\nFive Points\nAL\n\n\nGroveoak\nAL\nGroveoak\nAL\n\n\nNotasulga\nAL\nNotasulga\nAL\n\n\nJackson\nAL\nJackson\nAL\n\n\n….\n….\n….\n…."
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#advanced-joins",
    "href": "posts/PYTHON/others_python/SQL.html#advanced-joins",
    "title": "Basics SQL",
    "section": "Advanced Joins",
    "text": "Advanced Joins\n\nLeft Joins\nReturns all records from the left table and the matched records from the righ table\nThe result is NULL from the right hand side if there is no match\nRight joins are the same but from the RHS. Can be converted to left join by reversing the order\n\nFor example, find all the customers who have an invoice\nselect c.FirstNAme, c.LastName, i.InvoiceId\nfrom customers c\nLEFT JOIN invoices i on c.customerid = i.customerid\norder by c.customerid\n\n\n\nFirstName\nLastName\nInvoiceId\n\n\n\n\nLuís\nGonçalves\n98\n\n\nLuís\nGonçalves\n121\n\n\nLuís\nGonçalves\n143\n\n\nLuís\nGonçalves\n195\n\n\nLuís\nGonçalves\n316\n\n\nLuís\nGonçalves\n327\n\n\nLuís\nGonçalves\n382\n\n\nLeonie\nKöhler\n1\n\n\nLeonie\nKöhler\n12\n\n\nLeonie\nKöhler\n67\n\n\nLeonie\nKöhler\n196\n\n\nLeonie\nKöhler\n219\n\n\nLeonie\nKöhler\n241\n\n\nLeonie\nKöhler\n293\n\n\nFrançois\nTremblay\n99\n\n\n\n\n\nFull outer join\nReturns all records where there is a match in either table\n“Give me everything”\nselect c.FirstNAme, c.LastName, i.InvoiceId\nfrom customers c\nFULL OUTER JOIN invoices i on c.customerid = i.customerid\norder by c.customerid"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#unions",
    "href": "posts/PYTHON/others_python/SQL.html#unions",
    "title": "Basics SQL",
    "section": "Unions",
    "text": "Unions\nCombine two or more select statements - Each select must have the same number of columns - Columns must have similar data types - Columns in the same order - Less commonly used\ne.g. combine two string statements, the first a list of occupations and the second a summary of the above\n(select concat(name,'(',substr(occupation,1,1),')') from occupations)\nunion\n(select concat('There are a total number of ',count(*),' ',occupation,'s.')\nfrom occupations\ngroup by occupation\norder by count(occupation));"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#substr",
    "href": "posts/PYTHON/others_python/SQL.html#substr",
    "title": "Basics SQL",
    "section": "Substr",
    "text": "Substr\nReturns part of a string\nsubstr(string name, string position, number of characters to return)\nIf string position is negative counts from the end\ne.g., find city names that start and end with a vowel\nselect city from station\nwhere substr(city,1,1) in ('a','e','i','o','u')\nand substr(city,-1,1) in ('a','e','i','o','u')"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#others",
    "href": "posts/PYTHON/others_python/SQL.html#others",
    "title": "Basics SQL",
    "section": "Others",
    "text": "Others\nLimit 1 limit the results to 1\nconcat combine multiple parts\nselect concat(name, '(', substr(occupation,1,1), ')')\nfrom occupations\nround(X,5)\nrounds X to 5 decimal places\nor round(x) to nearest integer"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#mode",
    "href": "posts/PYTHON/others_python/SQL.html#mode",
    "title": "Basics SQL",
    "section": "Mode",
    "text": "Mode\nMode seems like a good free way to perform SQL. I’ve yet to work out if the course provided me a link to access datasets or if these are freely available for everyone opeing a new account. The website is not easy to navigate and I only found access to my workspaces from a link I saved and not from links on the website.\nhttps://app.mode.com/thomassimm/reports/e9412b22b846/runs/c4e7c78695f3\n\nSpark SQL\n\nhttps://files.training.databricks.com/courses/ucdavis/Lessons.dbc\nSpark SQL and DataFrames and Datasets Guides -SQL Guide from Databricks\nLearning Spark, 2nd Edition (eBook compliments of Databricks).\nIntroduction - The Internals of Spark SQL (free gitbook)"
  },
  {
    "objectID": "posts/PYTHON/others_python/SQL.html#appendix",
    "href": "posts/PYTHON/others_python/SQL.html#appendix",
    "title": "Basics SQL",
    "section": "Appendix",
    "text": "Appendix\nhttps://dev.mysql.com/doc/refman/8.0/en/union.html\nhttps://www.w3schools.com/sql/default.asp\nhttps://blog.sqlauthority.com/category/sql-puzzle/\nhttps://sqlzoo.net/wiki/SQL_Tutorial\nhttps://mode.com/sql-tutorial/introduction-to-sql\nhttps://www.postgresql.org/docs/9.1/tutorial.html\nhttps://www.coursera.org/specializations/learn-sql-basics-data-science#courses"
  },
  {
    "objectID": "posts/PYTHON/others_python/Tweepy.html#resources",
    "href": "posts/PYTHON/others_python/Tweepy.html#resources",
    "title": "Tweepy",
    "section": "Resources",
    "text": "Resources\n\nA. Getting started with twitter API - Twitter Developer Platform\nhttps://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api\n\n\nB. Tweepy Documentation\nhttps://docs.tweepy.org/en/stable/index.html\n\n\nC. A comprehensive guide for using the Twitter API v2 with Tweepy in Python - Suhem Parack\nhttps://dev.to/twitterdev/a-comprehensive-guide-for-using-the-twitter-api-v2-using-tweepy-in-python-15d9\n\n\nD. Making queries to Twitter API on tweepy - Roberto Aguilar\nhttps://medium.com/@robguilarr/making-queries-to-twitter-api-on-tweepy-66afeb7184a4\n\n\nE. Accessing the Twitter API with Python - Mihajlo Pavloski\nhttps://stackabuse.com/accessing-the-twitter-api-with-python/\n\n\nF. How to Apply for a Twitter Developer Account - jean-christophe-chouinard\nhttps://www.jcchouinard.com/apply-for-a-twitter-developer-account/\n\n\nG. How to get Twitter API Credentials (API Keys) - jean-christophe-chouinard\nhttps://www.jcchouinard.com/twitter-api-credentials/\n\n\nH. Twitter API with Python (Complete Guide) - jean-christophe-chouinard\nhttps://www.jcchouinard.com/twitter-api/"
  },
  {
    "objectID": "posts/PYTHON/others_python/Tweepy.html#setting-up-twitter-api",
    "href": "posts/PYTHON/others_python/Tweepy.html#setting-up-twitter-api",
    "title": "Tweepy",
    "section": "Setting up twitter API",
    "text": "Setting up twitter API\n\n1. Apply for a developer account\nBefore using the Twitter API, you first need a Twitter account, and to have obtained some credentials. The process of getting credentials could change with time, but currently it is as follows:\n\nVisit the Application Management page at https://apps.twitter.com/, and sign in with your Twitter account\nClick on the \"Create New App\" button, fill in the details and agree the Terms of Service\nNavigate to \"Keys and Access Tokens\" section and take a note of your Consumer Key and Secret\nIn the same section click on \"Create my access token\" button\nTake note of your Access Token and Access Token Secret\nAnd that's all. The consumer key/secret is used to authenticate the app that is using the Twitter API, while the access token/secret authenticates the user. All of these parameters should be treated as passwords, and should not be included in your code in plain text. One suitable way is to store them in a JSON file \"twitter_credentials.json\" and load these values from your code when needed.\nSource E. Accessing the Twitter API with Python - Mihajlo Pavloski\nTwitter API access levels and versions\n\nWhile the Twitter API v2 is the primary Twitter API, the platform currently supports previous versions (v1.1, Gnip 2.0) as well. We recommend that all users start with v2 as this is where all future innovation will happen. \n\nThe Twitter API v2 includes a few access levels to help you scale your usage on the platform. In general, new accounts can quickly sign up for free, Essential access. Should you want additional access, you may choose to apply for free Elevated access and beyond. \nSource A. Getting started with twitter API - Twitter Developer Platform\n\nI applied for elevated access. This involved filling in several questions about what I would user twitter API for and a follow up email.\nFor more info on how to apply for a twitter development account see F. How to Apply for a Twitter Developer Account - jean-christophe-chouinard\n\n\n2. Create a project/app\nTo use the twitter API you need to create a twitter App. From this you can then get the security IDs, bearer_token, API_key etc.\nFor more details on this see G. How to get Twitter API Credentials (API Keys) - jean-christophe-chouinard\n\n\n3. Set up an environment\nTwitter API bestows us several endpoints at the moment we request our App access. From which 3 of them are for searching methods, those that bring samples of the tweets we want according to specific criteria.\napi.search_30_day()\n\nPremium Search for tweets from the last 30 days.\nMonthly limitation of 4500 tweets per minute, without exceeding 25K tweets per month — Sandbox\n\napi.search_full_archive()\n\nPremium Search for tweets from March of 2006.\nMonthly limitation of 3000 tweets per minute, without exceeding 5K tweets per month — Sandbox\n\napi.search_tweets()\n\nRegular Search for tweets from the last 6–9 days as maximum.\nMonthly limitation of 3000 tweets per minute — Sandbox, this is the one that we gonna use in this case.\nFrom D. Making queries to Twitter API on tweepy - Roberto Aguilar\nThese environments are found at https://developer.twitter.com/en/account/environments.\nAnd the name of the environment is included in the particular search (as shown below label=XXX.\n\n\n4. Install tweepy\npip install tweepy"
  },
  {
    "objectID": "posts/PYTHON/others_python/Tweepy.html#tweepy-code",
    "href": "posts/PYTHON/others_python/Tweepy.html#tweepy-code",
    "title": "Tweepy",
    "section": "Tweepy code",
    "text": "Tweepy code\n\nimport os\nos.environ[\"BEARER_TOKEN\"]=\" insert here \"\nos.environ[\"API_key\"]='insert here'\nos.environ[\"API_secret\"]=' insert here'\nos.environ[\"access_token\"] = \" insert here \"\nos.environ[\"access_token_secret\"]=\" insert here \"\n\n\nImport and check it is authenticated\n\nimport tweepy\n\n# API keys that yous saved earlier\napi_key = os.environ.get(\"API_KEY\")\napi_secrets = os.environ.get(\"API_secret\")\naccess_token = os.environ.get(\"access_token\")\naccess_secret = os.environ.get(\"access_token_secret\")\n \n# Authenticate to Twitter\nauth = tweepy.OAuthHandler(api_key,api_secrets)\nauth.set_access_token(access_token,access_secret)\n \napi = tweepy.API(auth)\n \ntry:\n    api.verify_credentials()\n    print('Successful Authentication')\nexcept:\n    print('Failed authentication')\n\n\n\nSearch tweets\nTwo main ones:\nFor last 30 days:\nouta = api.search_30_day(label, query, *, tag, fromDate, toDate, maxResults,next)\nAnd for any times:\nouta = api.search_full_archive(label, query, *, tag, fromDate, toDate,                                maxResults, next)\n\nQuery\nfrom the python script:\nThe equivalent of one premium rule/filter, with up to 1,024 characters (256 with Sandbox dev environments).\n\nThis parameter should include ALL portions of the rule/filter,including all operators, and portions of the rule should not be separated into other parameters of the query.\nFollowing adapted from D. Making queries to Twitter API on tweepy - Roberto Aguilar\n\nSearch for a term\n\nquery = 'holiday' - Containing two words\nquery = 'holiday jet2' - Containing exact words\nquery='\"jet2 braces\" \"holiday\"' - Contain one word OR another\nquery='jet2 OR \"tuiuk\"' - Hashtags and mentions\nquery = '@jet2tweets #holiday' - Exclude words\nquery='@jet2tweets -travel' - Who the tweet is sent from and to\nquery='holiday from:jet2tweets'\nquery='holiday to:jet2tweets'\n\n\nDates\nDates are in the format YYYYMMDDHHmm\nSo 0:00 21st March 2021 = ‘202103210000’\n#hide #### Tag\nfrom script:\nTags can be used to segregate rules and their matching data into\ndifferent logical groups. If a rule tag is provided, the rule tag\nis included in the 'matching_rules' attribute.\n\nIt is recommended to assign rule-specific UUIDs to rule tags and\nmaintain desired mappings on the client side.\nFollowing adapted from D. Making queries to Twitter API on tweepy - Roberto Aguilar\n\nRetweets\n\ntag='-filter:retweets' without retweets\ntag='filter:retweets' and just RTs\n\nHas links\n\ntag='-filter:links'\n\nHas media\n\ntag='-filter:media'\n\nTrusted\n\ntag='-filter:trusted'\nMore filters can be seen in the Docs\n\n\n\nThe results file\nouta=api.search_full_archive(label=label,          query=query,toDate=end_time,fromDate=start_time)\nThe information from outa is accessed for each element using _json, i.e. \nouta[0]._json gives the first search result\n\nxx=outa[0]._json\nfor ii,x in enumerate(xx):\n    print(ii,x)\n\n\nIf the tweet is longer than 140 char the text property doesn’t display all the text of the tweet.\nThis will normally then be in the extended_tweet property but also sometimes in the retweeted_status property.\nSo to get around this put in exceptions.\n\ntextAll=[]\n\nfor numa in range(0,10):\n    xx=outa1[numa]._json\n    \n    try:\n        textAll.append(numa,'1', xx['created_at'],\n              xx['retweeted_status']['extended_tweet']['full_text'] )\n    except:\n        try:\n            textAll.append(numa,'2',xx['created_at'],\n                  xx['extended_tweet']['full_text'])\n        except:\n            textAll.append(numa,'3',xx['created_at'],xx['text'])"
  },
  {
    "objectID": "posts/PYTHON/others_python/Web_scraping.html#overview",
    "href": "posts/PYTHON/others_python/Web_scraping.html#overview",
    "title": "Web scraping",
    "section": "Overview",
    "text": "Overview\n Photo by Ilya Pavlov on Unsplash\n“Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites.” from https://en.wikipedia.org/wiki/Web_scraping\n\nThere are legal issues around web scraping, so be careful “The legality of web scraping varies across the world. In general, web scraping may be against the terms of use of some websites, but the enforceability of these terms is unclear.”\n\nThe first step is to go to a website and add /robots.txt onto the end of the web address to see what they allow. Most will disallow most areas.\nI am only doing this for research and learning purposes and the information is all available freely."
  },
  {
    "objectID": "posts/PYTHON/others_python/Web_scraping.html#indeed-beautifulsoup-and-pandas",
    "href": "posts/PYTHON/others_python/Web_scraping.html#indeed-beautifulsoup-and-pandas",
    "title": "Web scraping",
    "section": "Indeed, BeautifulSoup and Pandas",
    "text": "Indeed, BeautifulSoup and Pandas\n\nPhoto by Clem Onojeghuo on Unsplash\nIndeed has a wealth of job information across the UK and beyond for virtually every job. So whether you are looking for work or examining economic activity, it is a good resource. But how do you get the data from the website into a form you can work with?\n            By web scraping Indeed \n\nExamine the website\nThe first step in web scraping is to examine the website. Here I’ll use Google Chrome, but the same capabilities are in most browsers. Let’s open indeed and do a search for jobs in an area. The output is below\n\nWhen searching for “electrician mate” in the location Swansea we get the url https://uk.indeed.com/jobs?q=electrician+mate&l=Swansea%2C+Swansea.\nHence, in Python we can specify the url as follows, this allows us to change for job type and location later if we want:\n\nlocation=\"Swansea%2C+Swansea\"\njobtype=\"electrician+mate\"\n\nURL=\"https://uk.indeed.com/jobs?q=\"+jobtype+\"&l=\"+location\nURL\n\n'https://uk.indeed.com/jobs?q=electrician+mate&l=Swansea%2C+Swansea'\n\n\nNext open developer tools on Chrome (Ctrl+Shift+I or More Tools-> developer tools)\n\nThen click on the icon circled in the image below to examine the website. Placing the cursor over the website reveals the html structure. When this is done on one of the job blocks we can see that it is identified as:\n\n<div class=\"job_seen_beacon\">\nOR\n<a id=\"..........>\n\nExamining other blocks shows this is repeated for them all. So we can get the job blocks!\nWe’ll return to this later…\n\n\nBeautifulSoup\nBeautiful soup is a Python library for pulling data out of HTML and XML files. Something similar can be done with pandas, but for this situation I’ll use the soup.\n\n#import the libraries\nimport requests\nimport bs4\nfrom bs4 import BeautifulSoup\n\nTo use: the libraries are loaded, then get get the page, then pass to Beautiful soup.\nSoup can be viewed. But it is still a mess so we’ll now use what we learned about the job tabs and extract these.\n\n#collapse-output\n#Using beautiful soup-get page\npage = requests.get(URL)\n#get soup\nsoup = BeautifulSoup(page.text, \"html.parser\")\nsoup\n\n<!DOCTYPE html>\n<html><head><meta content=\"website\" property=\"og:type\"/><meta content=\"Matmatch\" name=\"apple-mobile-web-app-title\"/><meta content=\"Matmatch\" name=\"application-name\"/><link href=\"/static/images/favicon/favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/><link href=\"/static/images/favicon/favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/><link href=\"/static/images/favicon/apple-touch-icon.png\" rel=\"apple-touch-icon\" sizes=\"180x180\"/><link href=\"/static/images/favicon/manifest.json\" rel=\"manifest\"/><link color=\"#526294}\" href=\"/static/images/favicon/safari-pinned-tab.svg\" rel=\"mask-icon\"/><link href=\"/static/images/favicon/favicon.ico?v2=pgrv6keokB\" rel=\"shortcut icon\"/><script src=\"https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js\"></script><script>WebFont.load({custom: {families: [\"Open Sans\"],urls: [\"/static/fonts/fonts.css\"]}});</script><script type=\"application/ld+json\">{\n              \"@context\": \"http://schema.org\",\n              \"@type\": \"Corporation\",\n              \"name\": \"Matmatch\",\n              \"url\": \"https://matmatch.com\",\n              \"logo\": \"https://matmatch.com/blog/wp-content/uploads/2019/01/matmatch_logo_stacked_large.png\",\n              \"contactPoint\": {\n              \"@type\": \"ContactPoint\",\n              \"telephone\": \"+49089262075200\",\n              \"contactType\": \"customer service\",\n              \"availableLanguage\": [\"English\",\"Spanish\",\"German\"]\n            },\n              \"sameAs\": [\n              \"https://www.facebook.com/MatmatchGmbH/\",\n              \"https://twitter.com/matmatchgmbh\",\n              \"https://www.youtube.com/channel/UCUaSuhkac7eIGDt_oslErqg\",\n              \"https://www.linkedin.com/company/matmatch/\"\n              ]\n            }</script><meta charset=\"utf-8\"/><meta content=\"initial-scale=1.0, width=device-width\" name=\"viewport\"/><meta content=\"/static/images/og-homepage.png\" property=\"og:image\"/><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\n          new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\n          j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n          'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n        })(window,document,'script','dataLayer','GTM-PV6RPFJ');</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n            ga('create', 'UA-85033665-5', { 'cookieName': '_ga', 'cookieExpires': 0, storeGac: false });\n            ga('require', 'GTM-KQK3NFF');\n            ga('set', 'anonymizeIp', true);\n          </script><title>Advanced Search - Matmatch</title><meta content=\"6\" name=\"next-head-count\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-5cd94c89d3acac5f.js\"></script><script defer=\"\" src=\"/_next/static/chunks/webpack-7f7ce7d3b611b805.js\"></script><script defer=\"\" src=\"/_next/static/chunks/framework-00d20ba7ea4a049e.js\"></script><script defer=\"\" src=\"/_next/static/chunks/main-e7e93353c7fa0f3d.js\"></script><script defer=\"\" src=\"/_next/static/chunks/pages/_app-d283c11d990f5118.js\"></script><script defer=\"\" src=\"/_next/static/chunks/4287-f7e14c54c16c4711.js\"></script><script defer=\"\" src=\"/_next/static/chunks/8423-5df76c682adf5f31.js\"></script><script defer=\"\" src=\"/_next/static/chunks/5345-398cd87d7cf78279.js\"></script><script defer=\"\" src=\"/_next/static/chunks/3789-912517a4e13b4a43.js\"></script><script defer=\"\" src=\"/_next/static/chunks/pages/advanced-search-2c198b26c959d4ab.js\"></script><script defer=\"\" src=\"/_next/static/d4287122/_buildManifest.js\"></script><script defer=\"\" src=\"/_next/static/d4287122/_ssgManifest.js\"></script><script defer=\"\" src=\"/_next/static/d4287122/_middlewareManifest.js\"></script><style data-styled=\"\" data-styled-version=\"5.3.3\">html{line-height:1.15;-webkit-text-size-adjust:100%;}/*!sc*/\nbody{margin:0;}/*!sc*/\nmain{display:block;}/*!sc*/\nh1{font-size:2em;margin:0.67em 0;}/*!sc*/\nhr{box-sizing:content-box;height:0;overflow:visible;}/*!sc*/\npre{font-family:monospace,monospace;font-size:1em;}/*!sc*/\na{background-color:transparent;}/*!sc*/\nabbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted;}/*!sc*/\nb,strong{font-weight:bolder;}/*!sc*/\ncode,kbd,samp{font-family:monospace,monospace;font-size:1em;}/*!sc*/\nsmall{font-size:80%;}/*!sc*/\nsub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline;}/*!sc*/\nsub{bottom:-0.25em;}/*!sc*/\nsup{top:-0.5em;}/*!sc*/\nimg{border-style:none;}/*!sc*/\nbutton,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0;}/*!sc*/\nbutton,input{overflow:visible;}/*!sc*/\nbutton,select{text-transform:none;}/*!sc*/\nbutton,[type=\"button\"],[type=\"reset\"],[type=\"submit\"]{-webkit-appearance:button;}/*!sc*/\nbutton::-moz-focus-inner,[type=\"button\"]::-moz-focus-inner,[type=\"reset\"]::-moz-focus-inner,[type=\"submit\"]::-moz-focus-inner{border-style:none;padding:0;}/*!sc*/\nbutton:-moz-focusring,[type=\"button\"]:-moz-focusring,[type=\"reset\"]:-moz-focusring,[type=\"submit\"]:-moz-focusring{outline:1px dotted ButtonText;}/*!sc*/\nfieldset{padding:0.35em 0.75em 0.625em;}/*!sc*/\nlegend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal;}/*!sc*/\nprogress{vertical-align:baseline;}/*!sc*/\ntextarea{overflow:auto;}/*!sc*/\n[type=\"checkbox\"],[type=\"radio\"]{box-sizing:border-box;padding:0;}/*!sc*/\n[type=\"number\"]::-webkit-inner-spin-button,[type=\"number\"]::-webkit-outer-spin-button{height:auto;}/*!sc*/\n[type=\"search\"]{-webkit-appearance:textfield;outline-offset:-2px;}/*!sc*/\n[type=\"search\"]::-webkit-search-decoration{-webkit-appearance:none;}/*!sc*/\n::-webkit-file-upload-button{-webkit-appearance:button;font:inherit;}/*!sc*/\ndetails{display:block;}/*!sc*/\nsummary{display:list-item;}/*!sc*/\ntemplate{display:none;}/*!sc*/\n[hidden]{display:none;}/*!sc*/\ndata-styled.g1[id=\"sc-global-ecVvVt1\"]{content:\"sc-global-ecVvVt1,\"}/*!sc*/\n.uluvW{margin:0;overflow:hidden;list-type:none;padding:0;}/*!sc*/\ndata-styled.g7[id=\"list__List-sc-7ainlj-0\"]{content:\"uluvW,\"}/*!sc*/\n.RbSSA{color :#fff;text-align:left;}/*!sc*/\n.bzfZbQ{color :#fff;}/*!sc*/\n.bzfZbQ:not(:last-child){margin-bottom:6px;}/*!sc*/\n.cJazBI{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color :#fff;}/*!sc*/\n.cJazBI:not(:last-child){margin-bottom:6px;}/*!sc*/\n.gJZFKn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color :#fff;}/*!sc*/\ndata-styled.g8[id=\"list__ListItem-sc-7ainlj-1\"]{content:\"RbSSA,bzfZbQ,cJazBI,gJZFKn,\"}/*!sc*/\n.ghQHoL{max-width:100%;margin:0;font-size :28px;font-weight :600;color:#3a4056;}/*!sc*/\n.fEFHaQ{max-width:100%;margin:0;font-size :15px;color:#3a4056;margin-bottom:36px;}/*!sc*/\n.fcGhiO{max-width:100%;margin:0;font-size :15px;color :#3880E5;display :inline-block;cursor :pointer;-webkit-text-decoration:underline;text-decoration:underline;margin-left:24px;}/*!sc*/\n.hJBnMN{max-width:100%;margin:0;font-size :16px;color :#ffffff;cursor :pointer;-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n.hJBnMN:hover{color:#e0e0e0;}/*!sc*/\n.kFbVgZ{max-width:100%;margin:0;font-size :15px;font-weight :600;color :white;margin:3.5999999999999996px;}/*!sc*/\n.wmqFD{max-width:100%;margin:0;font-size :16px;font-weight :600;color :#526193;margin-bottom:12px;}/*!sc*/\n.cJojhb{max-width:100%;margin:0;font-size :12px;color:#3a4056;text-align :center;margin-top:6px;}/*!sc*/\n.dzDHxo{max-width:100%;margin:0;font-size :15px;color:#3a4056;}/*!sc*/\n.dSdjdP{max-width:100%;margin:0;font-size :15px;color :#526193;}/*!sc*/\n.ehJUxb{max-width:100%;margin:0;font-size :16px;color :#4f4f4f;white-space:nowrap;margin-right:12px;}/*!sc*/\n.jLqxex{max-width:100%;margin:0;font-size :15px;font-weight :600;color :#526193;text-transform:uppercase;}/*!sc*/\n.cgTHVD{max-width:100%;margin:0;font-size :13px;color :#333333;}/*!sc*/\n.hjLFxX{max-width:100%;margin:0;font-size :13px;color:#3a4056;display :inline-block;margin-left:6px;}/*!sc*/\n.ldWNpx{max-width:100%;margin:0;font-size :13px;font-weight :600;color :#3880E5;cursor :pointer;}/*!sc*/\n.LLywI{max-width:100%;margin:0;font-size :13px;color :#333333;margin-bottom:6px;}/*!sc*/\n.hjtwVq{max-width:100%;margin:0;font-size :16px;color :#333333;}/*!sc*/\n.hLVIHw{max-width:100%;margin:0;font-size :15px;font-weight :600;color :#526193;margin-bottom:12px;}/*!sc*/\n.KmEHA{max-width:100%;margin:0;font-size :13px;color :#333333;margin-left:6px;}/*!sc*/\n.fWynpt{max-width:100%;margin:0;font-size :13px;color :#333333;display :inline-block;}/*!sc*/\n.eUTBqM{max-width:100%;margin:0;font-size :16px;color :#ff8200;}/*!sc*/\n.hMWWGw{max-width:100%;margin:0;font-size :16px;color :#828282;}/*!sc*/\n.iidREl{max-width:100%;margin:0;font-size :13px;color :#828282;}/*!sc*/\n.lolWkU{max-width:100%;margin:0;font-size :13px;color:#3a4056;display :inline-block;margin-right:6px;}/*!sc*/\n.tenyk{max-width:100%;margin:0;font-size :20px;font-weight :600;color :#526193;}/*!sc*/\n.GTisG{max-width:100%;margin:0;font-size :16px;color :#333333;display :inline-block;margin-left:12px;}/*!sc*/\ndata-styled.g10[id=\"text__Text-sc-f4nboj-0\"]{content:\"ghQHoL,fEFHaQ,fcGhiO,hJBnMN,kFbVgZ,wmqFD,cJojhb,dzDHxo,dSdjdP,ehJUxb,jLqxex,cgTHVD,hjLFxX,ldWNpx,LLywI,hjtwVq,hLVIHw,KmEHA,fWynpt,eUTBqM,hMWWGw,iidREl,lolWkU,tenyk,GTisG,\"}/*!sc*/\n.ipttFt{cursor:pointer;color:#03c7a7;display:block;margin:0 auto;}/*!sc*/\n.ipttFt:hover{color:#02a187;-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.eYFpTR{cursor:pointer;color:#03c7a7;}/*!sc*/\n.eYFpTR:hover{-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.eePTOF{cursor:pointer;color:#03c7a7;display:block;}/*!sc*/\n.eePTOF:hover{color:#02a187;-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.fpFFKD{cursor:pointer;color:#03c7a7;}/*!sc*/\n.fpFFKD:hover{color:#02a187;-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.QbWNQ{cursor:pointer;color:#3880E5;display:block;font-weight:600;}/*!sc*/\n.QbWNQ:hover{-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.dhcylR{cursor:pointer;color:#333333;font-size:13px;font-weight:600;}/*!sc*/\n.dhcylR:hover{-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.kdVFv{cursor:pointer;color:#333333;}/*!sc*/\n.kdVFv:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\ndata-styled.g18[id=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0\"]{content:\"ipttFt,eYFpTR,eePTOF,fpFFKD,QbWNQ,dhcylR,kdVFv,\"}/*!sc*/\n.jkkDbK{background-position:center;background-repeat:no-repeat;background-color:transparent;background-image:url('/static/images/inlined/logo_inverted.svg');width:167px;height:37px;}/*!sc*/\n.dOZIXC{background-position:center;background-repeat:no-repeat;background-color:transparent;background-image:url('/static/images/inlined/logo_inverted.svg');width:95px;height:22px;}/*!sc*/\ndata-styled.g20[id=\"styled-link-styles__ImageLinkStyles-sc-l1ctuc-2\"]{content:\"jkkDbK,dOZIXC,\"}/*!sc*/\n.lhTnpm{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;padding:14.399999999999999px 18px;font-size:16px;font-weight:600;}/*!sc*/\n.MSVaf{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;}/*!sc*/\n.kPiOHq{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;width:100%;padding:18px 24px;font-size:20px;font-weight:600;}/*!sc*/\n.NWGvI{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;width:100%;}/*!sc*/\n.eGHzTm{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;opacity:0.7;pointer-events:none;background-repeat:no-repeat;background-size:12px;background-image:url(\"/static/images/icons/2.0/white/arrow-back.svg\");padding:14.399999999999999px 18px;background-position:center;margin-right:24px;}/*!sc*/\n.ljvJNw{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;background-repeat:no-repeat;background-size:12px;background-image:url(\"/static/images/icons/2.0/white/arrow-forward.svg\");padding:14.399999999999999px 18px;background-position:center;margin-left:24px;}/*!sc*/\ndata-styled.g29[id=\"button__BaseButton-sc-ekfcy0-0\"]{content:\"lhTnpm,MSVaf,kPiOHq,NWGvI,eGHzTm,ljvJNw,\"}/*!sc*/\n.nqeas{color:#ffffff;background-color:#3880E5;border:1px solid #4c8de8;}/*!sc*/\ndata-styled.g30[id=\"button__ButtonPrimary-sc-ekfcy0-1\"]{content:\"nqeas,\"}/*!sc*/\n.kTlrHY{color:#ffffff;border:1px solid #bdbdbd;background-color:#828282;}/*!sc*/\ndata-styled.g31[id=\"button__ButtonDefault-sc-ekfcy0-2\"]{content:\"kTlrHY,\"}/*!sc*/\n.juQzaQ{color:#ffffff;border:1px solid #ffd8af;background-color:#ff8200;}/*!sc*/\n.juQzaQ:hover{background-color:#cc6900;}/*!sc*/\ndata-styled.g33[id=\"button__ButtonSpecial-sc-ekfcy0-4\"]{content:\"juQzaQ,\"}/*!sc*/\n.gKwwSj{color:#ffffff;border:1px solid #7cd16d;background-color:#67ac5b;}/*!sc*/\n.gKwwSj:hover{background-color:#48A43F;}/*!sc*/\ndata-styled.g34[id=\"button__ButtonSuccess-sc-ekfcy0-5\"]{content:\"gKwwSj,\"}/*!sc*/\n.jUHcrU{display:inline-block;cursor:pointer;}/*!sc*/\n.hrfsee{margin-bottom:24px;}/*!sc*/\n.hrfsee:after{content:\" \";display:block;height:0;clear:both;}/*!sc*/\n.cdlmON:after{content:\" \";display:block;height:0;clear:both;}/*!sc*/\n.zDQjJ{margin-bottom:24px;}/*!sc*/\n.kneKJ{text-align:center;}/*!sc*/\n.kTmWRN{margin-left:24px;}/*!sc*/\n.kqTmue{width :438px;}/*!sc*/\n.UxvCa{margin-top:6px;margin-bottom:6px;}/*!sc*/\n.bcLXBB{margin-bottom:6px;}/*!sc*/\n.bRaHnE{margin-bottom:12px;}/*!sc*/\n.dTGKOg{margin-left:12px;}/*!sc*/\n.kXMRZj{max-width :1170px;margin :0 auto;}/*!sc*/\n.eHEnyb{max-width :1200px;margin :0 auto;}/*!sc*/\ndata-styled.g38[id=\"wrappers__Wrapper-sc-14fw43j-0\"]{content:\"cJNByu,jUHcrU,hrfsee,cdlmON,zDQjJ,kneKJ,kTmWRN,kqTmue,UxvCa,bcLXBB,bRaHnE,dTGKOg,kXMRZj,eHEnyb,\"}/*!sc*/\n.hFcCJB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/\n.gFqwTB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content :space-between;-ms-flex-pack:justify;justify-content :space-between;}/*!sc*/\n.dMXLyl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n.cwHZQB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content :space-between;-ms-flex-pack:justify;justify-content :space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n.cdLigN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content :space-between;-ms-flex-pack:justify;justify-content :space-between;}/*!sc*/\ndata-styled.g41[id=\"wrappers__WrapperFlex-sc-14fw43j-3\"]{content:\"hFcCJB,gFqwTB,dMXLyl,cwHZQB,cdLigN,\"}/*!sc*/\n.hzZiwD{max-width:1400px;margin:0 auto;padding:36px;}/*!sc*/\n@media (max-width:991.98px){.hzZiwD{width:100%;}}/*!sc*/\n@media (max-width:767.98px){.hzZiwD{width:100%;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:0px;}}/*!sc*/\n@media (max-width:575.98px){.hzZiwD{padding:0px;min-height:0px;}}/*!sc*/\ndata-styled.g42[id=\"wrappers__WrapperStaticContent-sc-14fw43j-4\"]{content:\"hzZiwD,\"}/*!sc*/\n.flfCwz{overflow:hidden;max-width:1400px;margin:0 auto;padding:36px;}/*!sc*/\n@media (max-width:991.98px){.flfCwz{width:100%;}}/*!sc*/\n@media (max-width:767.98px){.flfCwz{width:100%;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:0px;}}/*!sc*/\n@media (max-width:575.98px){.flfCwz{padding:0px;min-height:0px;}}/*!sc*/\ndata-styled.g43[id=\"wrappers__WrapperStaticContentNoFlex-sc-14fw43j-5\"]{content:\"flfCwz,\"}/*!sc*/\n.prlvG{width:calc((100% - 42px) * 0.7);margin-right:0px;margin-left:42px;float:left;}/*!sc*/\n@media (max-width:991.98px){.prlvG{margin-top:24px;margin-left:0;margin-right:0;width:100%;}}/*!sc*/\ndata-styled.g47[id=\"wrappers__WrapperMainContent-sc-14fw43j-9\"]{content:\"prlvG,\"}/*!sc*/\n.fUzxei{width:calc((100% - 42px) * 0.4);float:left;-webkit-transition:width 0.5s;transition:width 0.5s;}/*!sc*/\n@media (max-width:991.98px){.fUzxei{width:100%;}}/*!sc*/\ndata-styled.g48[id=\"wrappers__WrapperSidebar-sc-14fw43j-10\"]{content:\"fUzxei,\"}/*!sc*/\n.ftzCdl{max-height:0px;overflow:hidden;-webkit-transition:max-height .2s;transition:max-height .2s;}/*!sc*/\ndata-styled.g50[id=\"wrappers__CollapseContentWrapper-sc-14fw43j-12\"]{content:\"ftzCdl,\"}/*!sc*/\n.ejKxFX{color:#ffffff;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background:#ff8200;width:36px;height:18px;border-radius:12px;-webkit-text-decoration:none;text-decoration:none;font-size:12px;margin-left:3px;}/*!sc*/\ndata-styled.g52[id=\"badge__LinkBadge-sc-1kc0y45-0\"]{content:\"ejKxFX,\"}/*!sc*/\n.iIAlRS{width:25%;}/*!sc*/\n@media (max-width:767.98px){.iIAlRS{float:left;width:50%;margin-top:24px;}}/*!sc*/\ndata-styled.g53[id=\"footer-list__FooterListWrapper-sc-17tjnty-0\"]{content:\"iIAlRS,\"}/*!sc*/\n.gFyZtw{margin-bottom:12px;}/*!sc*/\ndata-styled.g54[id=\"footer-list__FooterListHeading-sc-17tjnty-1\"]{content:\"gFyZtw,\"}/*!sc*/\n@media (max-width:767.98px){.jHUSlK{display:block;}}/*!sc*/\ndata-styled.g69[id=\"footer-copyright__FooterCopyrightWrapper-sc-p1jkef-0\"]{content:\"jHUSlK,\"}/*!sc*/\n.EMFJO{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:24px;width:24px;background-image:url(\"/static/images/icons/white/search.svg\");}/*!sc*/\n.gpNPvA{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:24px;width:24px;background-image:url(\"/static/images/icons/2.0/white/ios-world-outline.svg\");}/*!sc*/\n.bZBKhy{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:30px;width:30px;background-image:url(\"/static/images/icons/2.0/default/arrow-up.svg\");}/*!sc*/\n.cXnjPW{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:24px;width:30px;background-image:url(\"/static/images/icons/2.0/white/ios-search-strong.svg\");}/*!sc*/\n.eyhBpa{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:22px;width:22px;background-image:url(\"/static/images/icons/2.0/white/android-menu.svg\");}/*!sc*/\n.kbRKml{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:14px;width:14px;background-image:url(\"/static/images/icons/2.0/primary/ios-arrow-down.svg\");margin-left:6px;}/*!sc*/\n.iNazJp{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:12px;width:12px;background-image:url(\"/static/images/icons/2.0/primary/ios-arrow-down.svg\");margin-left:6px;}/*!sc*/\n.eiXgPa{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:10px;width:10px;background-image:url(\"/static/images/icons/2.0/white/plus.svg\");margin-left:6px;}/*!sc*/\n.kXkjMs{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:12px;width:12px;background-image:url(\"/static/images/icons/2.0/default/close.svg\");margin-right:12px;}/*!sc*/\n.kTando{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:unset;height:20px;width:20px;margin-right:12px;background-image:url(\"/static/images/icons/2.0/multicolor/default.svg\");}/*!sc*/\n.duJtpp{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:30px;width:30px;background-image:url(\"/static/images/icons/2.0/footer/social-linkedin.svg\");}/*!sc*/\n.UGQFe{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:30px;width:30px;background-image:url(\"/static/images/icons/2.0/footer/social-twitter.svg\");}/*!sc*/\n.bfOfuL{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:30px;width:30px;background-image:url(\"/static/images/icons/2.0/footer/social-facebook.svg\");}/*!sc*/\n.cnxXUV{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:default;height:16px;width:16px;background-image:url(\"/static/images/icons/2.0/footer/ios-telephone.svg\");}/*!sc*/\n.jLgsnQ{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:default;height:16px;width:16px;background-image:url(\"/static/images/icons/2.0/footer/ios-location.svg\");}/*!sc*/\ndata-styled.g70[id=\"icon__Icon-sc-1230ehg-0\"]{content:\"EMFJO,gpNPvA,bZBKhy,cXnjPW,eyhBpa,kbRKml,iNazJp,eiXgPa,kXkjMs,kTando,duJtpp,UGQFe,bfOfuL,cnxXUV,jLgsnQ,\"}/*!sc*/\n.caVxgD{width:20px;height:20px;fill:#3880E5;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;cursor:pointer;}/*!sc*/\n.jWARuS{width:20px;height:20px;fill:#526193;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;}/*!sc*/\n.fXOOJz{width:32px;height:32px;fill:#3880e5;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;}/*!sc*/\n.haqEoE{width:14px;height:14px;fill:#333333;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;cursor:pointer;}/*!sc*/\n.hrGMmp{width:12px;height:12px;fill:#4496ec;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;cursor:pointer;}/*!sc*/\n.enTUov{width:28px;height:22px;fill:#4496ec;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;cursor:pointer;margin-left:9px;}/*!sc*/\ndata-styled.g71[id=\"icon__Svg-sc-1230ehg-1\"]{content:\"caVxgD,jWARuS,fXOOJz,haqEoE,hrGMmp,enTUov,\"}/*!sc*/\n@media (max-width:991.98px){.hwyVjw{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;margin-top:48px;}}/*!sc*/\n@media (max-width:767.98px){.hwyVjw{width:100%;display:inline-block;margin-top:24px;}}/*!sc*/\ndata-styled.g76[id=\"footer-social-links__SocialLinksList-sc-1hjdthk-0\"]{content:\"hwyVjw,\"}/*!sc*/\n.jkNDpJ{display:inline-block;}/*!sc*/\n.jkNDpJ:not(:first-child){margin-left:42px;}/*!sc*/\n@media{.jkNDpJ:not(:first-child){margin-left:30px;}}/*!sc*/\ndata-styled.g77[id=\"footer-social-links__SocialLinksListItem-sc-1hjdthk-1\"]{content:\"jkNDpJ,\"}/*!sc*/\n.lcDCgL{width:25%;}/*!sc*/\n@media (max-width:767.98px){.lcDCgL{width:100%;}}/*!sc*/\ndata-styled.g78[id=\"footer-matmatch-logo-and-gdpr__NameAndDescriptionWrapper-sc-1mbx1ll-0\"]{content:\"lcDCgL,\"}/*!sc*/\n.dLmbUA{border:none;height:1px;margin-top:24px;margin-bottom:24px;margin-top:12px;margin-bottom:12px;}/*!sc*/\n.cVgbLf{border:none;height:1px;margin-top:24px;margin-bottom:24px;margin-top:12px;margin-left:36px;margin-right:36px;margin-bottom:12px;}/*!sc*/\ndata-styled.g79[id=\"separation-line__SeparationLine-sc-1gtqai2-0\"]{content:\"dLmbUA,cVgbLf,\"}/*!sc*/\n.kwnPiJ{color:#bdbdbd;background-color:#bdbdbd;}/*!sc*/\ndata-styled.g80[id=\"separation-line__SeparationLineDefault-sc-1gtqai2-1\"]{content:\"kwnPiJ,\"}/*!sc*/\n.fGzocz{width:100%;padding:0 12px;margin:0;}/*!sc*/\n@media (min-width:768px){.fGzocz{padding-left:24px;padding-right:24px;}}/*!sc*/\n@media (min-width:1170px){.fGzocz{max-width:1170px;margin-left:auto;margin-right:auto;}}/*!sc*/\ndata-styled.g84[id=\"static-page-wrappers__StaticPageContentWrapper-sc-fz58vx-1\"]{content:\"fGzocz,\"}/*!sc*/\n.kUuTvA{padding:96px 0;background-color:#fcfcfd;}/*!sc*/\n@media (max-width:767.98px){.kUuTvA{padding:36px 0;}}/*!sc*/\ndata-styled.g89[id=\"footer-container__FooterContainer-sc-16jfcf3-0\"]{content:\"kUuTvA,\"}/*!sc*/\nhtml{-webkit-tap-highlight-color:transparent;}/*!sc*/\nbody{background-color:#fcfcfd;color:#3a4056;font-family:'Open Sans',sans-serif;font-size:15px;line-height:1.6;}/*!sc*/\n*,:after,:before{box-sizing:border-box;margin:0;}/*!sc*/\nimg{max-height:100%;max-width:100%;}/*!sc*/\na{color:#3880e5;-webkit-text-decoration:none;text-decoration:none;border:none;background:none;padding:0;}/*!sc*/\nbody.body-noscroll{overflow:hidden;}/*!sc*/\nbutton{cursor:pointer;-webkit-appearance:button;outline:none;}/*!sc*/\ndiv.DraftEditor-root{padding:12px;border:1px solid #3a4056;color:#3a4056;}/*!sc*/\ndiv.about-google-map{height:100%;}/*!sc*/\n.description ul{list-style-type:none;padding-left:24px;}/*!sc*/\n@media (max-width:767.98px){.description ul{padding-left:12px;}}/*!sc*/\n.description ol{padding-left:40px;}/*!sc*/\n@media (max-width:767.98px){.description ol{padding-left:28px;}}/*!sc*/\n.description ul li{position:relative;padding-left:16px;}/*!sc*/\n.description ul li:before{width:8px;height:8px;border-radius:4px;background-color:#03c7a7;content:'';margin-top:9px;position:absolute;left:0;}/*!sc*/\n.write-message div.DraftEditor-root,.render-message div.DraftEditor-root{border:none;height:80%;overflow-y:auto;}/*!sc*/\n.write-message div.DraftEditor-editorContainer,.render-message div.DraftEditor-editorContainer{height:100%;}/*!sc*/\n.write-message div.public-DraftEditor-content,.render-message div.public-DraftEditor-content{height:100%;}/*!sc*/\n.write-message-retargeting div.DraftEditor-root{border:none;height:100%;overflow-y:auto;}/*!sc*/\n.write-message-retargeting div.DraftEditor-editorContainer{height:100%;}/*!sc*/\n.write-message-retargeting div.public-DraftEditor-content{height:100%;}/*!sc*/\n.grecaptcha-badge{visibility:hidden;}/*!sc*/\n.hiddenBlockQuote{display:none;}/*!sc*/\n.particle-table{width:100%;text-align:left;margin:24px 0;}/*!sc*/\ndata-styled.g90[id=\"sc-global-hpWtfi1\"]{content:\"sc-global-hpWtfi1,\"}/*!sc*/\n.OhGlj{cursor:pointer;border-radius:2px;vertical-align:top;display:inline-block;background-color:#ffffff;width:18px;height:18px;min-width:18px;border:1px solid #828282;margin-right:6px;}/*!sc*/\n.bBVMlc{cursor:pointer;border-radius:2px;vertical-align:top;display:inline-block;background-color:#ffffff;width:18px;height:18px;min-width:18px;border:1px solid #828282;margin-left:6px;}/*!sc*/\n.kurrkX{cursor:pointer;border-radius:2px;vertical-align:top;display:inline-block;background-color:#ffffff;width:18px;height:18px;min-width:18px;border:1px solid #828282;}/*!sc*/\ndata-styled.g156[id=\"check-box__CheckBoxDesign-sc-1ptpc08-0\"]{content:\"OhGlj,bBVMlc,kurrkX,\"}/*!sc*/\n.dsaEue{cursor:pointer;border-radius:2px;vertical-align:top;display:inline-block;background-color:#ffffff;width:18px;height:18px;min-width:18px;border:1px solid #828282;background-size:contain;background-repeat:no-repeat;background-color:#3880E5;background-image:url(\"/static/images/icons/2.0/white/minus.svg\");margin-left:6px;}/*!sc*/\ndata-styled.g157[id=\"check-box__MinusCheckboxDesign-sc-1ptpc08-1\"]{content:\"dsaEue,\"}/*!sc*/\n.eajQMm{color:#ffffff;font-size:13px;margin-left:12px;border-radius:12px;padding:0 6px;background-color:#333333;}/*!sc*/\ndata-styled.g168[id=\"advanced-search-count-number__CountNumber-sc-8hlubs-0\"]{content:\"eajQMm,\"}/*!sc*/\n.bhkHlB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;cursor:pointer;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:6px 0px;padding-left:0px;}/*!sc*/\ndata-styled.g169[id=\"tree-item__TreeItem-sc-1ndoqn1-0\"]{content:\"bhkHlB,\"}/*!sc*/\n.djLvdn{list-style-type:none;padding-inline-start:0px;}/*!sc*/\ndata-styled.g170[id=\"tree-renderer__TreeWrapper-sc-wdfwzn-0\"]{content:\"djLvdn,\"}/*!sc*/\n.gslBUi{display:inline-block;cursor:pointer;width:45px;height:20px;border-radius:10px;-webkit-animation:cpCHCi 0.5s linear;animation:cpCHCi 0.5s linear;background:#67ac5b;border:1px solid #67ac5b;}/*!sc*/\ndata-styled.g178[id=\"toggle__ToggleWrapper-sc-th0yzv-0\"]{content:\"gslBUi,\"}/*!sc*/\n.hbpQfU{display:inline-block;position:relative;left:5px;width:14px;height:18px;background-size:contain;background-repeat:no-repeat;background-position:center;background-image:url(\"/static/images/icons/2.0/white/checkmark.svg\");opacity:1;-webkit-transition:opacity 0.5s;transition:opacity 0.5s;}/*!sc*/\ndata-styled.g179[id=\"toggle__ToggleCheckmark-sc-th0yzv-1\"]{content:\"hbpQfU,\"}/*!sc*/\n.fArqYf{display:inline-block;position:relative;width:18px;height:18px;border-radius:9px;background-color:#ffffff;left:11px;-webkit-transition:left 0.5s;transition:left 0.5s;}/*!sc*/\ndata-styled.g180[id=\"toggle__ToggleToggle-sc-th0yzv-2\"]{content:\"fArqYf,\"}/*!sc*/\n.eipfdL{width:100%;border-left:1px solid #828db1;margin-top:12px;will-change:max-height;max-height:0px;}/*!sc*/\ndata-styled.g189[id=\"mobile-profile-menu__HeaderProfileMenuList-sc-c6el3s-0\"]{content:\"eipfdL,\"}/*!sc*/\n.eidcBU{color:#333333;padding:0 24px;margin:12px 0;list-style-type:none;border-right:1px solid transparent;font-weight:400;}/*!sc*/\ndata-styled.g190[id=\"mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1\"]{content:\"eidcBU,\"}/*!sc*/\n.elfMjy{font-size:13px;cursor:pointer;color:#333333;display:inline-block;}/*!sc*/\n.elfMjy:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n.hKoOWf{font-size:13px;cursor:pointer;color:#333333;display:inline-block;font-weight:600;}/*!sc*/\n.hKoOWf:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n.fIeyGw{font-size:13px;cursor:pointer;color:#333333;display:inline-block;font-weight:600;margin-bottom:24px;}/*!sc*/\n.fIeyGw:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\ndata-styled.g191[id=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0\"]{content:\"elfMjy,hKoOWf,fIeyGw,\"}/*!sc*/\n.dlnRUd{margin-left:24px;}/*!sc*/\ndata-styled.g192[id=\"mobile-header-dynamic-categories-connected__MobileHeaderDropdownSecondLevelLinksWrapper-sc-rlj3br-0\"]{content:\"dlnRUd,\"}/*!sc*/\n.eSAgkB{margin-left:24px;}/*!sc*/\ndata-styled.g194[id=\"mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0\"]{content:\"eSAgkB,\"}/*!sc*/\n.hHsZTR{margin-bottom:24px;}/*!sc*/\ndata-styled.g195[id=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1\"]{content:\"hHsZTR,\"}/*!sc*/\n.gAQIST{left:0;right:0;z-index:100;cursor:auto;max-height:0px;overflow:hidden;position:absolute;-webkit-transition:max-height .4s;transition:max-height .4s;background-color:transparent;box-shadow:0 5px 6px 0 #B0B3BB;}/*!sc*/\ndata-styled.g197[id=\"common__DesktopHeaderDropdownWrapper-sc-170boom-0\"]{content:\"gAQIST,\"}/*!sc*/\n.cTBSVf{width:50%;float:left;}/*!sc*/\n.cTBSVf:not(:last-child){padding-right:12px;}/*!sc*/\ndata-styled.g198[id=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1\"]{content:\"cTBSVf,\"}/*!sc*/\n.fWKIzC{font-size:13px;cursor:pointer;color:#333333;display:inline-block;font-weight:600;margin-bottom:3px;}/*!sc*/\n.fWKIzC:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n.kUjwEN{font-size:13px;cursor:pointer;color:#333333;display:inline-block;}/*!sc*/\n.kUjwEN:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\ndata-styled.g199[id=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2\"]{content:\"fWKIzC,kUjwEN,\"}/*!sc*/\n.cdqTz{margin-top:18px;background-color:#fcfcfd;}/*!sc*/\ndata-styled.g200[id=\"desktop-header-dropdown__DesktopHeaderDropdownInnerWrapper-sc-y1g0lx-0\"]{content:\"cdqTz,\"}/*!sc*/\n.dvhoXp:not(:last-child){margin-bottom:24px;}/*!sc*/\n.dvhoXp a{line-height:0;}/*!sc*/\ndata-styled.g201[id=\"header-action-link__CtaWrapper-sc-1yhrwj5-0\"]{content:\"dvhoXp,\"}/*!sc*/\n.hHnCBT{float:left;width:calc((100% / 3) - 0.1px);}/*!sc*/\n.hHnCBT:not(:last-child){padding-right:12px;}/*!sc*/\ndata-styled.g202[id=\"desktop-header-dropdown-material-categories__CategoriesColumn-sc-1ousnfb-0\"]{content:\"hHnCBT,\"}/*!sc*/\n.edSpfo:not(:last-child){margin-bottom:24px;}/*!sc*/\ndata-styled.g203[id=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1\"]{content:\"edSpfo,\"}/*!sc*/\n.czLQLd{float:left;width:calc((100% / 3) - 0.1px);}/*!sc*/\n.czLQLd:not(:last-child){padding-right:12px;}/*!sc*/\ndata-styled.g204[id=\"desktop-header-suppliers-dropdown__Column-sc-1gypbt4-0\"]{content:\"czLQLd,\"}/*!sc*/\n.CVmbS{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/\ndata-styled.g208[id=\"bubble__BubbleWrapper-sc-i30r9c-0\"]{content:\"CVmbS,\"}/*!sc*/\n.hWwxLn{height:112px;}/*!sc*/\n@media (max-width:991.98px){.hWwxLn{display:none;}}/*!sc*/\ndata-styled.g211[id=\"main-content-spacer__MainContentSpacer-sc-1g5s1bz-0\"]{content:\"hWwxLn,\"}/*!sc*/\n.greBxI{padding:24px 0;}/*!sc*/\n@media (max-width:767.98px){.greBxI{padding:12px 0;}}/*!sc*/\ndata-styled.g218[id=\"footer__FooterWrapper-sc-1vgte7v-0\"]{content:\"greBxI,\"}/*!sc*/\n@media (max-width:767.98px){.hZBBnE{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}/*!sc*/\ndata-styled.g219[id=\"footer__FooterMiddleWrapper-sc-1vgte7v-1\"]{content:\"hZBBnE,\"}/*!sc*/\n.jdQCEK{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0 auto;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;max-width:1170px;}/*!sc*/\n@media (max-width:767.98px){.jdQCEK{display:block;overflow:hidden;}}/*!sc*/\ndata-styled.g220[id=\"footer__FooterResponsiveWrapper-sc-1vgte7v-2\"]{content:\"jdQCEK,\"}/*!sc*/\n.hutcBS{position:fixed;background-color:#ffffff;padding:24px;max-width:660px;z-index:100;bottom:12px;box-shadow:0px 2px 5px #b0b3bb;border-radius:4px;left:calc(-50vw + 50%);right:calc(-50vw + 50%);margin-left:auto;margin-right:auto;}/*!sc*/\ndata-styled.g221[id=\"cookie-banner__CookieBannerWrapper-sc-1n3o3md-0\"]{content:\"hutcBS,\"}/*!sc*/\n.drTDou{background-color:#6a77a2;z-index:10;}/*!sc*/\ndata-styled.g253[id=\"desktop-header-search-bar__SearchButton-sc-n2cbkq-1\"]{content:\"drTDou,\"}/*!sc*/\n.iAiHqb{background-color:#ffffff;border-radius:4px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:38px;}/*!sc*/\ndata-styled.g255[id=\"desktop-header-search-bar__DesktopHeaderSearchBarInputBlockWrapper-sc-n2cbkq-3\"]{content:\"iAiHqb,\"}/*!sc*/\n.cQdUuW{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:relative;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/\ndata-styled.g256[id=\"desktop-header-search-bar__DesktopHeaderSearchInputWrapper-sc-n2cbkq-4\"]{content:\"cQdUuW,\"}/*!sc*/\n.ioBjKD{border:none;margin-left:12px;width:100%;}/*!sc*/\n.ioBjKD::-webkit-input-placeholder{color:#bdbdbd;opacity:1;}/*!sc*/\n.ioBjKD::-moz-placeholder{color:#bdbdbd;opacity:1;}/*!sc*/\n.ioBjKD:-ms-input-placeholder{color:#bdbdbd;opacity:1;}/*!sc*/\n.ioBjKD::placeholder{color:#bdbdbd;opacity:1;}/*!sc*/\n.ioBjKD::-ms-clear{display:none;}/*!sc*/\n.ioBjKD:focus{outline:none;}/*!sc*/\ndata-styled.g257[id=\"desktop-header-search-bar__DesktopHeaderSearchInputField-sc-n2cbkq-5\"]{content:\"ioBjKD,\"}/*!sc*/\n.fuuwzT{position:relative;}/*!sc*/\ndata-styled.g258[id=\"desktop-header-search-bar__DesktopHeaderAutoSuggestionsWrapper-sc-n2cbkq-6\"]{content:\"fuuwzT,\"}/*!sc*/\n.hvBjgr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;}/*!sc*/\ndata-styled.g263[id=\"mobile-header-user-not-signed-in__MobileHeaderUserNotSignedInWrapper-sc-195838o-0\"]{content:\"hvBjgr,\"}/*!sc*/\n.lpgqvm{color:#ff8200;background-color:#fcfcfd;border:2px solid #ff8200;max-width:303px;}/*!sc*/\ndata-styled.g264[id=\"mobile-header-user-not-signed-in__MobileHeaderUserSignUpButton-sc-195838o-1\"]{content:\"lpgqvm,\"}/*!sc*/\n.bTObyH{color:#67ac5b;margin-bottom:12px;background-color:#fcfcfd;border:2px solid #67ac5b;max-width:303px;}/*!sc*/\ndata-styled.g265[id=\"mobile-header-user-not-signed-in__MobileHeaderUserSignInButton-sc-195838o-2\"]{content:\"bTObyH,\"}/*!sc*/\n.evPxyJ{list-style:none;overflow-y:auto;padding:0 36px;}/*!sc*/\ndata-styled.g266[id=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBar-sc-ssinjx-0\"]{content:\"evPxyJ,\"}/*!sc*/\n.bxYrpi{cursor:auto;max-height:0;overflow:hidden;background-color:#fcfcfd;}/*!sc*/\ndata-styled.g267[id=\"mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1\"]{content:\"bxYrpi,\"}/*!sc*/\n.bjzJUu{-webkit-flex:1;-ms-flex:1;flex:1;color:#526193;will-change:font-weight;font-weight:400;}/*!sc*/\ndata-styled.g268[id=\"mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2\"]{content:\"bjzJUu,\"}/*!sc*/\n.ghkwNZ{border-left:1px #526193 solid;}/*!sc*/\ndata-styled.g270[id=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4\"]{content:\"ghkwNZ,\"}/*!sc*/\n.lgzuuz{font-size:16px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;padding:3px 6px 18px 0;}/*!sc*/\n.kYgdAl{font-size:16px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;padding:3px 6px 18px 0;}/*!sc*/\n.kYgdAl:nth-last-child(2):not(:only-child),.kYgdAl:last-child:not(:only-child){padding-bottom:0px;}/*!sc*/\ndata-styled.g271[id=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5\"]{content:\"lgzuuz,kYgdAl,\"}/*!sc*/\n.kDpNZQ{background-color:#fcfcfd;}/*!sc*/\ndata-styled.g272[id=\"mobile-header__MobileHeaderWrapper-sc-dvud91-0\"]{content:\"kDpNZQ,\"}/*!sc*/\n.iiDvup{background-color:#526193;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;color:#ffffff;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:12px;height:62px;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/\n@media screen and (max-width:575.98px){.iiDvup{height:45px;-webkit-box-pack:unset;-webkit-justify-content:unset;-ms-flex-pack:unset;justify-content:unset;}}/*!sc*/\ndata-styled.g273[id=\"mobile-header__MobileHeaderStaticBar-sc-dvud91-1\"]{content:\"iiDvup,\"}/*!sc*/\n.cmjpNo{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:auto;padding:0 12px;}/*!sc*/\n@media screen and (max-width:767.98px){.cmjpNo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/\ndata-styled.g274[id=\"mobile-header__MobileHeaderStaticBarSearchIconWrapper-sc-dvud91-2\"]{content:\"cmjpNo,\"}/*!sc*/\n.hpPhjx{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:24px 0;position:relative;height:calc(100vh - 62px - 72px);}/*!sc*/\n@media screen and (max-width:575.98px){.hpPhjx{height:calc(100vh - 45px - 72px);}}/*!sc*/\ndata-styled.g275[id=\"mobile-header__MobileHeaderMenuList-sc-dvud91-3\"]{content:\"hpPhjx,\"}/*!sc*/\n.tMWkf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 36px;list-style:none;}/*!sc*/\ndata-styled.g276[id=\"mobile-header__MobileHeaderMenuListItem-sc-dvud91-4\"]{content:\"tMWkf,\"}/*!sc*/\n.CjJpx{position:relative;height:calc(100vh - 62px);-webkit-transition:margin-top 0.3s ease-out;transition:margin-top 0.3s ease-out;margin-top:-100vh;}/*!sc*/\n@media screen and (max-width:575.98px){.CjJpx{height:calc(100vh - 45px);}}/*!sc*/\ndata-styled.g277[id=\"mobile-header__MobileHeaderSlideDownHeader-sc-dvud91-5\"]{content:\"CjJpx,\"}/*!sc*/\n.cwmMhq{overflow:hidden;}/*!sc*/\ndata-styled.g278[id=\"mobile-header__MobileHeaderSlideDownWrapper-sc-dvud91-6\"]{content:\"cwmMhq,\"}/*!sc*/\n.igiZBr{background-color:#526193;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/\ndata-styled.g279[id=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBar-sc-vppewv-0\"]{content:\"igiZBr,\"}/*!sc*/\n.hPDTUs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;width:100%;max-width:654px;}/*!sc*/\ndata-styled.g280[id=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItems-sc-vppewv-1\"]{content:\"hPDTUs,\"}/*!sc*/\n.goozRc{color:#ffffff;border-bottom:1px solid rgba(255,255,255,0);}/*!sc*/\n.goozRc:hover{border-bottom:1px solid rgba(255,255,255,9);}/*!sc*/\ndata-styled.g281[id=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemLink-sc-vppewv-2\"]{content:\"goozRc,\"}/*!sc*/\n.gbNQTp{text-align:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g282[id=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemStyledButton-sc-vppewv-3\"]{content:\"gbNQTp,\"}/*!sc*/\n.bKWUBi{color:white;display:block;font-size:15px;border-bottom:1px solid rgba(255,255,255,0);}/*!sc*/\n.bKWUBi:after{content:'';width:10px;height:10px;display:inline-block;background-size:contain;background-position:center;background-repeat:no-repeat;margin-left:6px;background-image:url(\"/static/images/icons/2.0/white/arrow-down.svg\");}/*!sc*/\n.bKWUBi:hover{border-bottom:1px solid rgba(255,255,255,9);}/*!sc*/\ndata-styled.g283[id=\"desktop-header-navigation-links__DesktopHeaderNavigationDropdownText-sc-vppewv-4\"]{content:\"bKWUBi,\"}/*!sc*/\n.bPjIbr{float:left;}/*!sc*/\n@media (max-width:991.98px){.bPjIbr{width:130px;}}/*!sc*/\ndata-styled.g289[id=\"desktop-header-static-bar__HeaderLogoImage-sc-1aton5n-0\"]{content:\"bPjIbr,\"}/*!sc*/\n.KFXRI{position:fixed;left:0;right:0;top:0;z-index:3;background-color:#526193;}/*!sc*/\ndata-styled.g291[id=\"desktop-header-static-bar__DesktopHeaderStaticBar-sc-1aton5n-2\"]{content:\"KFXRI,\"}/*!sc*/\n.kHEXRD{padding-top:3px;padding-bottom:18px;}/*!sc*/\ndata-styled.g292[id=\"desktop-header-static-bar__DesktopHeadersLinksWrapper-sc-1aton5n-3\"]{content:\"kHEXRD,\"}/*!sc*/\n.cVRwqg{-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/\ndata-styled.g293[id=\"desktop-header-static-bar__DesktopHeaderLogoSection-sc-1aton5n-4\"]{content:\"cVRwqg,\"}/*!sc*/\n.gigTJA{max-width:554px;-webkit-flex:3;-ms-flex:3;flex:3;margin:0 60px;}/*!sc*/\n@media (max-width:991.98px){.gigTJA{margin:0 12px;}}/*!sc*/\ndata-styled.g294[id=\"desktop-header-static-bar__DesktopHeaderSearchBarSection-sc-1aton5n-5\"]{content:\"gigTJA,\"}/*!sc*/\n.IRYso{-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;min-width:282px;}/*!sc*/\ndata-styled.g295[id=\"desktop-header-static-bar__DesktopHeaderControlIconsSection-sc-1aton5n-6\"]{content:\"IRYso,\"}/*!sc*/\n.gWelzZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g296[id=\"desktop-header-static-bar__DesktopHeaderLanguagePanelWrapper-sc-1aton5n-7\"]{content:\"gWelzZ,\"}/*!sc*/\n.gBSUqi{cursor:pointer;margin-right:6px;}/*!sc*/\ndata-styled.g297[id=\"desktop-header-static-bar__DesktopHeaderCurrentLanguage-sc-1aton5n-8\"]{content:\"gBSUqi,\"}/*!sc*/\n.hMfFLt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:24px;}/*!sc*/\n@media (max-width:991.98px){.hMfFLt{margin-left:12px;}}/*!sc*/\ndata-styled.g298[id=\"desktop-header-static-bar__DesktopHeaderAuthControls-sc-1aton5n-9\"]{content:\"hMfFLt,\"}/*!sc*/\n.bga-dBn{width:100%;height:66px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0 auto;color:#ffffff;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:0 12px;}/*!sc*/\n@media (min-width:768px){.bga-dBn{padding-left:24px;padding-right:24px;}}/*!sc*/\n@media (min-width:1170px){.bga-dBn{max-width:1440px;margin-left:auto;margin-right:auto;}}/*!sc*/\ndata-styled.g299[id=\"desktop-header-static-bar__DesktopHeaderStaticBarInner-sc-1aton5n-10\"]{content:\"bga-dBn,\"}/*!sc*/\n.lpaaHC{margin-right:24px;}/*!sc*/\n@media (max-width:991.98px){.lpaaHC{margin-right:12px;}}/*!sc*/\ndata-styled.g301[id=\"desktop-header-static-bar__SignInText-sc-1aton5n-12\"]{content:\"lpaaHC,\"}/*!sc*/\n.ihiZJY{position:relative;}/*!sc*/\ndata-styled.g302[id=\"header__HeaderWrapper-sc-vi2mkw-0\"]{content:\"ihiZJY,\"}/*!sc*/\n@media (max-width:767.98px){.iOXrTY{display:none;}}/*!sc*/\n@media (max-width:991.98px){.iOXrTY{display:none;}}/*!sc*/\ndata-styled.g303[id=\"header__DesktopHeaderWrapper-sc-vi2mkw-1\"]{content:\"iOXrTY,\"}/*!sc*/\n.eWjGyj{width:100%;z-index:4;display:none;}/*!sc*/\n@media (max-width:991.98px){.eWjGyj{display:block;}}/*!sc*/\n@media (max-width:767.98px){.eWjGyj{display:block;}}/*!sc*/\ndata-styled.g304[id=\"header__MobileHeaderWrapper-sc-vi2mkw-2\"]{content:\"eWjGyj,\"}/*!sc*/\n.ewHqQp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;height:90px;}/*!sc*/\n@media (max-width:575.98px){.ewHqQp{height:44px;}}/*!sc*/\ndata-styled.g305[id=\"campaigns__CampaignBannerWrapper-sc-a2pwr6-0\"]{content:\"ewHqQp,\"}/*!sc*/\n.dcaIxI{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/\ndata-styled.g344[id=\"adbutler__CampaignBannerWrapper-sc-1snm6gk-0\"]{content:\"dcaIxI,\"}/*!sc*/\n.fgLnFQ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0 auto;overflow:hidden;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:728px;height:90px;}/*!sc*/\n.fgLnFQ .adbutler-banner-wrapper:not(:empty) ~ *{display:none;}/*!sc*/\n.fgLnFQ img{width:auto;height:auto;}/*!sc*/\n@media (max-width:575.98px){.fgLnFQ{height:61px;}}/*!sc*/\ndata-styled.g345[id=\"adbutler__CampaignBannerInnerWrapper-sc-1snm6gk-1\"]{content:\"fgLnFQ,\"}/*!sc*/\n.hucmjH{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;cursor:pointer;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:16px;height:16px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:8px;border:1px solid #3880E5;}/*!sc*/\ndata-styled.g583[id=\"radio-button__RadioButtonOuter-sc-mwb92w-0\"]{content:\"hucmjH,\"}/*!sc*/\n.jXbQYq{width:10px;height:10px;border-radius:5px;background-color:#3880E5;}/*!sc*/\ndata-styled.g584[id=\"radio-button__RadioButtonInner-sc-mwb92w-1\"]{content:\"jXbQYq,\"}/*!sc*/\n.dDcZzF{color:#fcfcfd;margin:36px 0;}/*!sc*/\ndata-styled.g585[id=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0\"]{content:\"dDcZzF,\"}/*!sc*/\n.hXYfhe{color:#ffffff;font-size:16px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;border-radius:2px;-webkit-flex:1;-ms-flex:1;flex:1;margin-right:24px;border:1px solid #48A43F;background-color:#67ac5b;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:6px;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/\n.hXYfhe:hover{background-color:#48A43F;}/*!sc*/\ndata-styled.g586[id=\"advanced-search-sidebar-action-button__ActionButton-sc-15cfzym-0\"]{content:\"hXYfhe,\"}/*!sc*/\n.cwhWGZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;margin-top:24px;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/\ndata-styled.g587[id=\"advanced-search-sidebar-actions__ActionsWrapper-sc-qhfbni-0\"]{content:\"cwhWGZ,\"}/*!sc*/\n.hVhMIm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;opacity:.7;pointer-events:none;}/*!sc*/\ndata-styled.g588[id=\"advanced-search-sidebar-actions__ActionsText-sc-qhfbni-1\"]{content:\"hVhMIm,\"}/*!sc*/\n.iPlPmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g589[id=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0\"]{content:\"iPlPmm,\"}/*!sc*/\n.XbfDr{overflow-y:auto;-webkit-transition:margin-top .25s,max-height .15s;transition:margin-top .25s,max-height .15s;margin-top:24px;max-height:0px;margin-top:0;}/*!sc*/\ndata-styled.g590[id=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0\"]{content:\"XbfDr,\"}/*!sc*/\n.fdCHWk{position:relative;width:16px;height:16px;}/*!sc*/\n.fdCHWk:before,.fdCHWk:after{content:\"\";position:absolute;background-color:white;-webkit-transition:-webkit-transform 0.25s ease-out;-webkit-transition:transform 0.25s ease-out;transition:transform 0.25s ease-out;background-color:#3880e5;}/*!sc*/\n.fdCHWk:before{top:0;left:50%;width:4px;height:100%;margin-left:-2px;}/*!sc*/\n.fdCHWk:after{top:50%;left:0;width:100%;height:4px;margin-top:-2px;}/*!sc*/\ndata-styled.g591[id=\"plus-icon__PlusIcon-sc-13w6ro8-0\"]{content:\"fdCHWk,\"}/*!sc*/\n.gNwTRO{margin:4px 12px;-webkit-flex:1;-ms-flex:1;flex:1;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;}/*!sc*/\ndata-styled.g592[id=\"advanced-search-category-specific-settings-dropdown__FieldText-sc-113hj4-0\"]{content:\"gNwTRO,\"}/*!sc*/\n.epQYxF{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:12px;background:#ffffff;border:1px solid #bdbdbd;box-sizing:border-box;border-radius:4px;}/*!sc*/\ndata-styled.g593[id=\"advanced-search-category-specific-settings-dropdown__FieldWrapper-sc-113hj4-1\"]{content:\"epQYxF,\"}/*!sc*/\n.kRDCWz{position:relative;}/*!sc*/\ndata-styled.g594[id=\"advanced-search-category-specific-settings-dropdown__DropDownContainer-sc-113hj4-2\"]{content:\"kRDCWz,\"}/*!sc*/\n.huFKrQ{position:absolute;top:100%;z-index:2;width:100%;margin-top:-12px;padding:12px;padding-bottom:0;max-height:236px;overflow-y:auto;-webkit-transition:all .5s;transition:all .5s;opacity:0;visibility:hidden;background-color:#ffffff;border:1px solid #bdbdbd;box-sizing:border-box;box-shadow:0px 2px 5px #b0b3bb;border-radius:4px;}/*!sc*/\ndata-styled.g595[id=\"advanced-search-category-specific-settings-dropdown__DropDownItemsWrapper-sc-113hj4-3\"]{content:\"huFKrQ,\"}/*!sc*/\n.zzdEX{margin-right:12px;}/*!sc*/\ndata-styled.g599[id=\"advanced-search-category-specific-settings-dropdown__PlusIconContainer-sc-113hj4-7\"]{content:\"zzdEX,\"}/*!sc*/\n.cFpniu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g603[id=\"advanced-search-sidebar-suppliers__ItemHeaderWrapper-sc-12new5k-0\"]{content:\"cFpniu,\"}/*!sc*/\n.gdlobs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:12px 0;margin-bottom:12px;}/*!sc*/\n@media (max-width:991.98px){.gdlobs{display:none;}}/*!sc*/\ndata-styled.g616[id=\"collapse-toggle__CollapseToggleWrapper-sc-vxcac6-0\"]{content:\"gdlobs,\"}/*!sc*/\n.gFfIFF{display:block;}/*!sc*/\ndata-styled.g617[id=\"collapse-toggle__CollapseToggleOptionsIcon-sc-vxcac6-1\"]{content:\"gFfIFF,\"}/*!sc*/\n.iTeGNl{color:#526193;margin:0 6px;-webkit-flex:1;-ms-flex:1;flex:1;font-weight:600;display:block;}/*!sc*/\ndata-styled.g618[id=\"collapse-toggle__CollapseToggleTitle-sc-vxcac6-2\"]{content:\"iTeGNl,\"}/*!sc*/\n.cgzKyT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:white;border:1px solid #bdbdbd;border-radius:50%;width:40px;height:40px;cursor:pointer;-webkit-transform:rotate(180deg);-ms-transform:rotate(180deg);transform:rotate(180deg);}/*!sc*/\ndata-styled.g619[id=\"collapse-toggle__CollapseToggleArrowCircle-sc-vxcac6-3\"]{content:\"cgzKyT,\"}/*!sc*/\n.gyajYF{width:438px;padding:24px;border-radius:4px;background-color:#f2f2f2;}/*!sc*/\n@media (max-width:991.98px){.gyajYF{width:100%;}}/*!sc*/\n@media (max-width:767.98px){.gyajYF{display:none;display:none;}}/*!sc*/\n@media (max-width:575.98px){.gyajYF{padding:12px;}}/*!sc*/\ndata-styled.g620[id=\"sidebar__AdvancedSearchSidebarWrapper-sc-1v590t3-0\"]{content:\"gyajYF,\"}/*!sc*/\n.jnuTJQ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-radius:4px;background-color:#f2f2f2;max-width:1400px;margin:0 auto 24px auto;padding:12px 12px 0 12px;}/*!sc*/\n@media (max-width:991.98px){.jnuTJQ{overflow-x:auto;}}/*!sc*/\n@media (max-width:767.98px){.jnuTJQ{margin:12px 0 0 0;}}/*!sc*/\ndata-styled.g622[id=\"contextual-tags__ContextualTagsWrapper-sc-dg6jub-0\"]{content:\"jnuTJQ,\"}/*!sc*/\n.fsqjse{border-radius:4px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;margin-right:12px;margin-bottom:12px;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;background-color:#fcfcfd;border:1px solid #3880E5;padding:6px 12px;}/*!sc*/\ndata-styled.g623[id=\"contextual-tags__ContextualTagWrapper-sc-dg6jub-1\"]{content:\"fsqjse,\"}/*!sc*/\n@media (max-width:991.98px){.cSROfV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/\ndata-styled.g624[id=\"contextual-tags__ContextualTagsItemsWrapper-sc-dg6jub-2\"]{content:\"cSROfV,\"}/*!sc*/\n.fLLraV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:24px;}/*!sc*/\ndata-styled.g625[id=\"pagination__PaginationWrapper-sc-1s1bcvk-0\"]{content:\"fLLraV,\"}/*!sc*/\n.TXmbf{display:inline-block;}/*!sc*/\n@media (max-width:991.98px){.TXmbf{display:none;}}/*!sc*/\ndata-styled.g626[id=\"pagination__PaginationPagesText-sc-1s1bcvk-1\"]{content:\"TXmbf,\"}/*!sc*/\n.fLuqrw{position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g627[id=\"custom-dropdown__CustomDropdownWrapper-sc-1r4pk0f-0\"]{content:\"fLuqrw,\"}/*!sc*/\n.hxQNhN{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border:1px solid #e0e0e0;margin-right:6px;}/*!sc*/\ndata-styled.g628[id=\"custom-dropdown__CustomDropdown-sc-1r4pk0f-1\"]{content:\"hxQNhN,\"}/*!sc*/\n.grBuVO{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:36px;line-height:36px;background:#ffffff;cursor:pointer;border:1px solid #e0e0e0;}/*!sc*/\ndata-styled.g629[id=\"custom-dropdown__CustomDropdownTrigger-sc-1r4pk0f-2\"]{content:\"grBuVO,\"}/*!sc*/\n.cqRtVo{position:absolute;display:block;top:100%;left:0;right:0;border:1px solid #e0e0e0;border-top:0;background:#fff;-webkit-transition:all 0.5s;transition:all 0.5s;opacity:0;visibility:hidden;z-index:2;box-shadow:0 2px 5px 0 #bdbdbd;}/*!sc*/\ndata-styled.g630[id=\"custom-dropdown__CustomDropdownOptions-sc-1r4pk0f-3\"]{content:\"cqRtVo,\"}/*!sc*/\n.hwiCoG{position:relative;display:block;padding:0 12px 0 12px;line-height:36px;cursor:pointer;-webkit-transition:all 0.5s;transition:all 0.5s;font-size:12px;white-space:nowrap;text-overflow:ellipsis;overflow:hidden;}/*!sc*/\n.hwiCoG:hover{cursor:pointer;background-color:#e0e0e0;}/*!sc*/\ndata-styled.g631[id=\"custom-dropdown__CustomDropdownOption-sc-1r4pk0f-4\"]{content:\"hwiCoG,\"}/*!sc*/\n.kaSqTa{color:#4496ec;position:relative;display:block;padding:12px;cursor:pointer;-webkit-transition:all 0.5s;transition:all 0.5s;font-size:12px;}/*!sc*/\ndata-styled.g632[id=\"custom-dropdown__CustomDropdownInfo-sc-1r4pk0f-5\"]{content:\"kaSqTa,\"}/*!sc*/\n.dUfhYU{max-width:228px;}/*!sc*/\n.dUfhYU:hover{cursor:pointer;background-color:transparent;}/*!sc*/\ndata-styled.g633[id=\"custom-dropdown__CustomDropdownOptionCurrent-sc-1r4pk0f-6\"]{content:\"dUfhYU,\"}/*!sc*/\n.cwaUxH{color:#bdbdbd;}/*!sc*/\ndata-styled.g634[id=\"custom-dropdown__CustomDropdownOptionPlaceholder-sc-1r4pk0f-7\"]{content:\"cwaUxH,\"}/*!sc*/\n.kOKDxB{position:relative;height:10px;width:10px;margin-right:6px;}/*!sc*/\n.kOKDxB::before{content:\"\";position:absolute;bottom:0;width:2px;height:100%;left:-3px;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);background-color:#4496ec;}/*!sc*/\n.kOKDxB::after{content:\"\";position:absolute;bottom:0;width:2px;height:100%;left:3px;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);background-color:#4496ec;}/*!sc*/\ndata-styled.g635[id=\"custom-dropdown__CustomDropdownArrow-sc-1r4pk0f-8\"]{content:\"kOKDxB,\"}/*!sc*/\n.emgOuh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:solid 1px #e0e0e0;border-radius:2px;margin-bottom:6px;padding:12px 24px;background-color:#fcfcfd;}/*!sc*/\n@media (max-width:767.98px){.emgOuh{display:none;}}/*!sc*/\ndata-styled.g637[id=\"header-properties-dropdown__PropertiesDropdownWrapper-sc-jye0ar-0\"]{content:\"emgOuh,\"}/*!sc*/\n.cVjyqt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;background-color:#ffffff;border:solid 1px #e0e0e0;margin-bottom:6px;box-shadow:0 2px 5px 0 #bdbdbd;padding:12px 24px;}/*!sc*/\n@media (max-width:767.98px){.cVjyqt{padding:12px;}}/*!sc*/\n.dSEUZx{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;background-color:#ffffff;border:solid 1px #e0e0e0;margin-bottom:6px;box-shadow:0 2px 5px 0 #bdbdbd;padding:12px 24px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/\n@media (max-width:767.98px){.dSEUZx{padding:12px;}}/*!sc*/\ndata-styled.g641[id=\"materials-list__MaterialsListItem-sc-1ickte1-0\"]{content:\"cVjyqt,dSEUZx,\"}/*!sc*/\n.dtZnEZ{width:32%;overflow:hidden;}/*!sc*/\n@media (max-width:767.98px){.dtZnEZ{width:90%;}}/*!sc*/\ndata-styled.g642[id=\"materials-list__MaterialDataWrapper-sc-1ickte1-1\"]{content:\"dtZnEZ,\"}/*!sc*/\n.hTQFno{width:63%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:12px;}/*!sc*/\n@media (max-width:767.98px){.hTQFno{display:none;}}/*!sc*/\ndata-styled.g643[id=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2\"]{content:\"hTQFno,\"}/*!sc*/\n.bDcoHI{width:5%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;padding-left:12px;}/*!sc*/\n@media (max-width:767.98px){.bDcoHI{width:10%;}}/*!sc*/\ndata-styled.g644[id=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3\"]{content:\"bDcoHI,\"}/*!sc*/\n.fHnuKk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;margin:24px auto;}/*!sc*/\n@media (max-width:991.98px){.fHnuKk{display:none;}}/*!sc*/\ndata-styled.g650[id=\"navigation-component__AdvancedSearchNavigationComponentWrapper-sc-1j05mwq-0\"]{content:\"fHnuKk,\"}/*!sc*/\n.fmDqYN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;cursor:pointer;min-width:50%;position:relative;padding:12px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-top:1px solid #bdbdbd;border-left:1px solid #bdbdbd;border-bottom:1px solid #bdbdbd;box-shadow:0px 2px 2px rgba(0,0,0,0.25);background-color:#F1F4F1;}/*!sc*/\n.fmDqYN::after{content:\"\";width:16px;height:16px;bottom:-8px;display:block;position:absolute;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);border-right:1px solid #bdbdbd;background:#F1F4F1;border-bottom:1px solid #bdbdbd;}/*!sc*/\n.fmDqYN:last-child{border-right:1px solid #bdbdbd;border-radius:0px 8px 8px 0px;}/*!sc*/\n.fmDqYN:first-child{border-radius:8px 0px 0px 8px;}/*!sc*/\n.hmFsem{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;cursor:pointer;min-width:50%;position:relative;padding:12px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-top:1px solid #bdbdbd;border-left:1px solid #bdbdbd;border-bottom:1px solid #bdbdbd;box-shadow:inset 0px 1px 1px rgba(0,0,0,0.25);background-color:#F0F5F5;}/*!sc*/\n.hmFsem:last-child{border-right:1px solid #bdbdbd;border-radius:0px 8px 8px 0px;}/*!sc*/\n.hmFsem:first-child{border-radius:8px 0px 0px 8px;}/*!sc*/\ndata-styled.g651[id=\"navigation-component__AdvancedSearchNavigationItemWrapper-sc-1j05mwq-1\"]{content:\"fmDqYN,hmFsem,\"}/*!sc*/\n.bwwYIA{width:26px;height:26px;font-size:16px;color:#ffffff;text-align:center;border-radius:13px;margin-right:12px;background:#ff8200;}/*!sc*/\n.fgAGgQ{width:26px;height:26px;font-size:16px;color:#ffffff;text-align:center;border-radius:13px;margin-right:12px;background:#828282;}/*!sc*/\ndata-styled.g652[id=\"navigation-component__NavigationItemNumber-sc-1j05mwq-2\"]{content:\"bwwYIA,fgAGgQ,\"}/*!sc*/\n.jleRfd{margin-bottom:12px;}/*!sc*/\n@media (max-width:767.98px){.jleRfd{padding-left:12px;padding-right:12px;}}/*!sc*/\ndata-styled.g653[id=\"results-list-view__TopPositionBannerWrapper-sc-d70l4k-0\"]{content:\"jleRfd,\"}/*!sc*/\n.ifaaZC{position:relative;}/*!sc*/\n@media (max-width:767.98px){.ifaaZC{margin-top:12px;}}/*!sc*/\ndata-styled.g654[id=\"results-list-view__AdvancedSearchMainContentWrapper-sc-d70l4k-1\"]{content:\"ifaaZC,\"}/*!sc*/\n@media (max-width:575.98px){.dgFZRr{padding:0px 12px;}}/*!sc*/\ndata-styled.g655[id=\"results-list-view__AdvancedSearchAllertsWrapper-sc-d70l4k-2\"]{content:\"dgFZRr,\"}/*!sc*/\n@media (max-width:991.98px){.ixACSA{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}/*!sc*/\ndata-styled.g658[id=\"advanced-search__AdvancedSearchMainSectionWrapper-sc-1eqc1e8-1\"]{content:\"ixACSA,\"}/*!sc*/\n@-webkit-keyframes cpCHCi{from{background-color:#828282;border-color:#828282;}to{background-color:#67ac5b;border-color:#67ac5b;}}/*!sc*/\n@keyframes cpCHCi{from{background-color:#828282;border-color:#828282;}to{background-color:#67ac5b;border-color:#67ac5b;}}/*!sc*/\ndata-styled.g660[id=\"sc-keyframes-cpCHCi\"]{content:\"cpCHCi,\"}/*!sc*/\n</style></head><body><div id=\"__next\"><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"cookie-banner__CookieBannerWrapper-sc-1n3o3md-0 hutcBS\" data-test-item=\"cookie-banner\"><p class=\"text__Text-sc-f4nboj-0 ghQHoL\" size=\"28\">OUR COOKIE DISCLAIMER</p><hr class=\"separation-line__SeparationLine-sc-1gtqai2-0 separation-line__SeparationLineDefault-sc-1gtqai2-1 dLmbUA kwnPiJ\"/><p class=\"text__Text-sc-f4nboj-0 fEFHaQ\" size=\"15\">Matmatch uses cookies and similar technologies to improve your experience and measure your interactions with our website. We also use them to provide you more relevant information and improve our platform and search tools. If that’s okay, click “Accept all.” To change your preferences, click “Open cookie settings.” You will find more information about cookies on our <a href=\"/imprint#privacy-policy\" style=\"text-decoration:underline;\">privacy policy page<a></a>.</a></p><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonSuccess-sc-ekfcy0-5 lhTnpm gKwwSj\">Accept all</button><p class=\"text__Text-sc-f4nboj-0 fcGhiO\" color=\"#3880E5\" cursor=\"pointer\" size=\"15\">Open cookie settings</p></div></div><div class=\"header-container__HeaderContainer-sc-fi6wlh-0 bOrpEs\" data-app-header=\"true\"><div class=\"header__HeaderWrapper-sc-vi2mkw-0 ihiZJY\"><div class=\"header__DesktopHeaderWrapper-sc-vi2mkw-1 iOXrTY\"><div class=\"desktop-header-static-bar__DesktopHeaderStaticBar-sc-1aton5n-2 KFXRI\"><div class=\"desktop-header-static-bar__DesktopHeaderStaticBarInner-sc-1aton5n-10 bga-dBn\"><div class=\"desktop-header-static-bar__DesktopHeaderLogoSection-sc-1aton5n-4 cVRwqg\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 styled-link-styles__ImageLinkStyles-sc-l1ctuc-2 ipttFt jkkDbK desktop-header-static-bar__HeaderLogoImage-sc-1aton5n-0 bPjIbr\" height=\"37\" href=\"/\" src=\"/static/images/inlined/logo_inverted.svg\" width=\"167\"></a></div><div class=\"desktop-header-static-bar__DesktopHeaderSearchBarSection-sc-1aton5n-5 gigTJA\"><div class=\"desktop-header-search-bar__DesktopHeaderSearchBarWrapper-sc-n2cbkq-2 doqVZA\"><div class=\"desktop-header-search-bar__DesktopHeaderSearchBarInputBlockWrapper-sc-n2cbkq-3 iAiHqb\"><div class=\"desktop-header-search-bar__DesktopHeaderSearchInputWrapper-sc-n2cbkq-4 cQdUuW\"><input class=\"desktop-header-search-bar__DesktopHeaderSearchInputField-sc-n2cbkq-5 ioBjKD\" placeholder=\"e.g. Aluminium\" type=\"text\" value=\"\"/></div><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonDefault-sc-ekfcy0-2 desktop-header-search-bar__SearchButton-sc-n2cbkq-1 MSVaf kTlrHY drTDou\"><span class=\"icon__Icon-sc-1230ehg-0 EMFJO\" color=\"white\" size=\"24\" type=\"search\"></span></button></div><div class=\"desktop-header-search-bar__DesktopHeaderAutoSuggestionsWrapper-sc-n2cbkq-6 fuuwzT\"></div></div></div><div class=\"desktop-header-static-bar__DesktopHeaderControlIconsSection-sc-1aton5n-6 IRYso\"><div class=\"desktop-header-static-bar__DesktopHeaderLanguagePanelWrapper-sc-1aton5n-7 gWelzZ\"><div class=\"desktop-header-static-bar__DesktopHeaderCurrentLanguage-sc-1aton5n-8 gBSUqi\"></div><div class=\"bubble__BubbleWrapper-sc-i30r9c-0 CVmbS\"><span class=\"icon__Icon-sc-1230ehg-0 desktop-header-static-bar__GlobeIcon-sc-1aton5n-11 gpNPvA language-picker-globe-icon\" color=\"2.0/white\" size=\"24\" type=\"ios-world-outline\"></span></div></div><div class=\"desktop-header-static-bar__DesktopHeaderAuthControls-sc-1aton5n-9 hMfFLt\"><div class=\"bubble__BubbleWrapper-sc-i30r9c-0 CVmbS\"><p class=\"text__Text-sc-f4nboj-0 desktop-header-static-bar__SignInText-sc-1aton5n-12 hJBnMN lpaaHC\" color=\"#ffffff\" cursor=\"pointer\" data-test-item=\"sign-in-button\" size=\"16\">Sign in</p><a data-test-item=\"sign-up-link\" href=\"/sign-up\" rel=\"noreferrer\" target=\"_blank\"><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonSpecial-sc-ekfcy0-4 MSVaf juQzaQ login-interaction-elem\"><p class=\"text__Text-sc-f4nboj-0 kFbVgZ\" color=\"white\">Register</p></button></a></div></div></div></div><div class=\"desktop-header-static-bar__DesktopHeadersLinksWrapper-sc-1aton5n-3 kHEXRD\"><div class=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBar-sc-vppewv-0 igiZBr\"><div class=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItems-sc-vppewv-1 hPDTUs\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 jUHcrU\"><div class=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemStyledButton-sc-vppewv-3 gbNQTp\"><p class=\"desktop-header-navigation-links__DesktopHeaderNavigationDropdownText-sc-vppewv-4 bKWUBi\" color=\"#ffffff\">Materials</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"common__DesktopHeaderDropdownWrapper-sc-170boom-0 gAQIST\"><div class=\"desktop-header-dropdown__DesktopHeaderDropdownInnerWrapper-sc-y1g0lx-0 cdqTz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperStaticContentNoFlex-sc-14fw43j-5 cJNByu flfCwz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 hrfsee\"><div class=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1 cTBSVf\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Categories</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 cdlmON\"><div class=\"desktop-header-dropdown-material-categories__CategoriesColumn-sc-1ousnfb-0 hHnCBT\"><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=biological-material&amp;view=result-list\">Biological Material</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=wood&amp;view=result-list\">Wood</a></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=ceramic&amp;view=result-list\">Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=carbon&amp;view=result-list\">Carbon</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=engineering-ceramic&amp;view=result-list\">Engineering Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=natural-ceramic&amp;view=result-list\">Natural Ceramic</a></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=composite&amp;view=result-list\">Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=ceramic-matrix-composite&amp;view=result-list\">Ceramic Matrix Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=metal-matrix-composite&amp;view=result-list\">Metal Matrix Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=polymer-matrix-composite&amp;view=result-list\">Polymer Matrix Composite</a></div></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesColumn-sc-1ousnfb-0 hHnCBT\"><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=glass&amp;view=result-list\">Glass</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=glass-ceramic&amp;view=result-list\">Glass Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=lead-glass&amp;view=result-list\">Lead Glass</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=silicate-glass&amp;view=result-list\">Silicate Glass</a></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=polymer&amp;view=result-list\">Polymer</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=elastomer&amp;view=result-list\">Elastomer</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=thermoplastic&amp;view=result-list\">Thermoplastic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=thermosetting&amp;view=result-list\">Thermosetting</a></div></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesColumn-sc-1ousnfb-0 hHnCBT\"><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=metal&amp;view=result-list\">Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=aluminium&amp;view=result-list\">Aluminium</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=clad---bimetal&amp;view=result-list\">Clad / Bimetal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=cobalt&amp;view=result-list\">Cobalt</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=copper&amp;view=result-list\">Copper</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=iron&amp;view=result-list\">Iron</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=magnesium&amp;view=result-list\">Magnesium</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=manganese&amp;view=result-list\">Manganese</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=nickel&amp;view=result-list\">Nickel</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=noble-metal&amp;view=result-list\">Noble Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=other-metal&amp;view=result-list\">Other Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=refractory-metal&amp;view=result-list\">Refractory Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=steel&amp;view=result-list\">Steel</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=titanium&amp;view=result-list\">Titanium</a></div></div></div></div></div><div class=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1 cTBSVf\"><div class=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1 cTBSVf\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 zDQjJ\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Tools</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/tools/unit-converter\">Unit Converter</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/tools/hardness-converter\">Hardness Converter</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search\">Advanced Search</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/application\">Application Search</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"https://go.matmatch.com/sncurves\">Fatigue Data</a></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 zDQjJ\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Guides</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/guide/sustainable-materials-selection\">Sustainable Materials Selection</a></div></div></div><div class=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1 cTBSVf\"><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/advanced-search\"><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonSpecial-sc-ekfcy0-4 kPiOHq juQzaQ\">Advanced Search</button></a></div><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/blog/learn-with-matmatch/\"><img alt=\"Learn with Matmatch\" src=\"https://matmatch.com/blog/wp-content/uploads/2020/05/learn-with-matmatch-menu.png\" style=\"min-width:100%\"/></a></div><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/guide/sustainable-materials-selection\"><img alt=\"Learn about sustainable materials selection\" src=\"https://matmatch.com/blog/wp-content/uploads/2020/12/sustainable-materials-selection-menu.jpg\" style=\"min-width:100%\"/></a></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 kneKJ\"><span class=\"icon__Icon-sc-1230ehg-0 bZBKhy\" color=\"2.0/default\" size=\"30\" type=\"arrow-up\"></span></div></div></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 jUHcrU\"><div class=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemStyledButton-sc-vppewv-3 gbNQTp\"><p class=\"desktop-header-navigation-links__DesktopHeaderNavigationDropdownText-sc-vppewv-4 bKWUBi\" color=\"#ffffff\">For Suppliers</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"common__DesktopHeaderDropdownWrapper-sc-170boom-0 gAQIST\"><div class=\"desktop-header-dropdown__DesktopHeaderDropdownInnerWrapper-sc-y1g0lx-0 cdqTz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperStaticContentNoFlex-sc-14fw43j-5 cJNByu flfCwz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 hrfsee\"><div class=\"desktop-header-suppliers-dropdown__Column-sc-1gypbt4-0 czLQLd\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Matmatch Suppliers</p><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/supplier\">List Your Materials</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/partners\">Matmatch Partners</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/supplier-resources\">Resources</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/advertise\">Advertise</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/advertising-media-kit\">Media Kit (Advertising)</a></div></div></div><div class=\"desktop-header-suppliers-dropdown__Column-sc-1gypbt4-0 czLQLd\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Case Studies</p><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/case-study/ampco-metal\">AMPCO METAL</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/case-study/dew\">Deutsche Edelstahlwerke</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/case-study/phon-tech\">Phon Tech</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/case-study/ceratizit\">CERATIZIT</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></div></div></div><div class=\"desktop-header-suppliers-dropdown__Column-sc-1gypbt4-0 czLQLd\"><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/supplier\"><img alt=\"Grow with Matmatch\" src=\"https://matmatch.com/blog/wp-content/uploads/2020/10/grow-with-matmatch-cta.jpg\" style=\"max-width:60%\"/></a></div><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"https://go.matmatch.com/advertise?headerImage\"><img alt=\"Advertise\" src=\"https://matmatch.com/blog/wp-content/uploads/2021/02/media-cta.jpg\" style=\"max-width:60%\"/></a></div><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/supplier-resources\"><img alt=\"Resources\" src=\"https://matmatch.com/blog/wp-content/uploads/2020/10/marketing-resources-cta.jpg\" style=\"max-width:60%\"/></a></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 kneKJ\"><span class=\"icon__Icon-sc-1230ehg-0 bZBKhy\" color=\"2.0/default\" size=\"30\" type=\"arrow-up\"></span></div></div></div></div></div></div><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 eYFpTR desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemLink-sc-vppewv-2 goozRc\" href=\"/resources\">Resources</a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 eYFpTR desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemLink-sc-vppewv-2 goozRc\" href=\"/about\">About us</a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 eYFpTR desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemLink-sc-vppewv-2 goozRc\" href=\"/services/get-connected\">Get Connected</a></div></div></div></div></div><div class=\"header__MobileHeaderWrapper-sc-vi2mkw-2 eWjGyj\"><div class=\"mobile-header__MobileHeaderWrapper-sc-dvud91-0 kDpNZQ\"><div class=\"mobile-header__MobileHeaderStaticBar-sc-dvud91-1 iiDvup\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 styled-link-styles__ImageLinkStyles-sc-l1ctuc-2 eePTOF dOZIXC\" height=\"22\" href=\"/\" src=\"/static/images/inlined/logo_inverted.svg\" width=\"95\"></a><div class=\"mobile-header__MobileHeaderStaticBarSearchIconWrapper-sc-dvud91-2 cmjpNo\"><span class=\"icon__Icon-sc-1230ehg-0 cXnjPW\" color=\"2.0/white\" type=\"ios-search-strong\"></span></div><span class=\"icon__Icon-sc-1230ehg-0 eyhBpa\" color=\"2.0/white\" size=\"22\" type=\"android-menu\"></span></div><div class=\"mobile-header__MobileHeaderSlideDownWrapper-sc-dvud91-6 cwmMhq\"><div class=\"mobile-header__MobileHeaderSlideDownHeader-sc-dvud91-5 CjJpx\"><ul class=\"mobile-header__MobileHeaderMenuList-sc-dvud91-3 hpPhjx\"><li class=\"mobile-header__MobileHeaderMenuListItem-sc-dvud91-4 tMWkf\"><div class=\"mobile-header-user-not-signed-in__MobileHeaderUserNotSignedInWrapper-sc-195838o-0 hvBjgr\"><button class=\"button__BaseButton-sc-ekfcy0-0 mobile-header-user-not-signed-in__MobileHeaderUserSignInButton-sc-195838o-2 NWGvI bTObyH\">Sign in</button><button class=\"button__BaseButton-sc-ekfcy0-0 mobile-header-user-not-signed-in__MobileHeaderUserSignUpButton-sc-195838o-1 NWGvI lpgqvm\">Register</button><p class=\"text__Text-sc-f4nboj-0 cJojhb\">You are not signed in</p></div></li><li class=\"mobile-header__MobileHeaderMenuListItem-sc-dvud91-4 tMWkf\"><ul class=\"list__List-sc-7ainlj-0 mobile-profile-menu__HeaderProfileMenuList-sc-c6el3s-0 uluvW eipfdL\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"/messages\"><li class=\"list__ListItem-sc-7ainlj-1 mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1 RbSSA eidcBU\">Messages</li></a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"/account\"><li class=\"list__ListItem-sc-7ainlj-1 mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1 RbSSA eidcBU\">Profile</li></a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"/account/settings\"><li class=\"list__ListItem-sc-7ainlj-1 mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1 RbSSA eidcBU\">Settings</li></a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"/advanced-search?categories=steel&amp;tags=form%3Abar#\"><li class=\"list__ListItem-sc-7ainlj-1 mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1 RbSSA eidcBU\">Sign out</li></a></ul></li><hr class=\"separation-line__SeparationLine-sc-1gtqai2-0 separation-line__SeparationLineDefault-sc-1gtqai2-1 cVgbLf kwnPiJ\"/><li class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBar-sc-ssinjx-0 evPxyJ\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Categories</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-categories-connected__MobileHeaderDropdownSecondLevelLinksWrapper-sc-rlj3br-0 cJNByu dlnRUd\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=biological-material\">Biological Material</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=wood\">Wood</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=ceramic\">Ceramic</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=carbon\">Carbon</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=engineering-ceramic\">Engineering Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=natural-ceramic\">Natural Ceramic</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=composite\">Composite</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=ceramic-matrix-composite\">Ceramic Matrix Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=metal-matrix-composite\">Metal Matrix Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=polymer-matrix-composite\">Polymer Matrix Composite</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=glass\">Glass</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=glass-ceramic\">Glass Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=lead-glass\">Lead Glass</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=silicate-glass\">Silicate Glass</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=polymer\">Polymer</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=elastomer\">Elastomer</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=thermoplastic\">Thermoplastic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=thermosetting\">Thermosetting</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=metal\">Metal</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=aluminium\">Aluminium</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=clad---bimetal\">Clad / Bimetal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=cobalt\">Cobalt</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=copper\">Copper</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=iron\">Iron</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=magnesium\">Magnesium</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=manganese\">Manganese</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=nickel\">Nickel</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=noble-metal\">Noble Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=other-metal\">Other Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=refractory-metal\">Refractory Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=steel\">Steel</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=titanium\">Titanium</a></div></div></div></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Matmatch Suppliers</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0 cJNByu eSAgkB\"><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/supplier\">List Your Materials</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/partners\">Matmatch Partners</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/supplier-resources\">Resources</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/advertise\">Advertise</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/advertising-media-kit\">Media Kit (Advertising)</a></div></div></div></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Case Studies</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0 cJNByu eSAgkB\"><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/case-study/ampco-metal\">AMPCO METAL</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/case-study/dew\">Deutsche Edelstahlwerke</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/case-study/phon-tech\">Phon Tech</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/case-study/ceratizit\">CERATIZIT</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></div></div></div></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Tools</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0 cJNByu eSAgkB\"><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/tools/unit-converter\">Unit Converter</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/tools/hardness-converter\">Hardness Converter</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search\">Advanced Search</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/application\">Application Search</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/sncurves\">Fatigue Data</a></div></div></div></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Guides</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0 cJNByu eSAgkB\"><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/guide/sustainable-materials-selection\">Sustainable Materials Selection</a></div></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarWrapper-sc-ssinjx-3 cJNByu\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 dSdjdP\" color=\"#526193\">Resources</p></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarWrapper-sc-ssinjx-3 cJNByu\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 dSdjdP\" color=\"#526193\">About us</p></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarWrapper-sc-ssinjx-3 cJNByu\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 dSdjdP\" color=\"#526193\">Get Connected</p></div></div></li></ul></div></div></div></div></div></div><div class=\"main-content-spacer__MainContentSpacer-sc-1g5s1bz-0 hWwxLn\"></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperStaticContentNoFlex-sc-14fw43j-5 cJNByu flfCwz\" style=\"padding-bottom:0\"><div class=\"contextual-tags__ContextualTagsWrapper-sc-dg6jub-0 jnuTJQ\"><div class=\"contextual-tags__ContextualTagsItemsWrapper-sc-dg6jub-2 cSROfV\"><div class=\"contextual-tags__ContextualTagWrapper-sc-dg6jub-1 fsqjse\"><p class=\"text__Text-sc-f4nboj-0 ehJUxb\" color=\"#4f4f4f\" size=\"16\">Bar</p><svg class=\"icon__Svg-sc-1230ehg-1 caVxgD\" cursor=\"pointer\" fill=\"#3880E5\" height=\"20\" viewbox=\"0 0 30 30\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#close-71610fd5--sprite\"></use></svg></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 wrappers__WrapperStaticContent-sc-14fw43j-4 advanced-search__AdvancedSearchMainSectionWrapper-sc-1eqc1e8-1 cJNByu hFcCJB hzZiwD ixACSA\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperSidebar-sc-14fw43j-10 sidebar__AdvancedSearchSidebarWrapper-sc-1v590t3-0 kqTmue fUzxei gyajYF\" width=\"438\"><div class=\"collapse-toggle__CollapseToggleWrapper-sc-vxcac6-0 gdlobs\"><svg class=\"icon__Svg-sc-1230ehg-1 jWARuS collapse-toggle__CollapseToggleOptionsIcon-sc-vxcac6-1 gFfIFF\" fill=\"#526193\" height=\"20\" viewbox=\"0 0 30 30\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#options-4de2f7a5--sprite\"></use></svg><div class=\"collapse-toggle__CollapseToggleTitle-sc-vxcac6-2 iTeGNl\">FILTERS</div><div class=\"collapse-toggle__CollapseToggleArrowCircle-sc-vxcac6-3 cgzKyT\"><svg class=\"icon__Svg-sc-1230ehg-1 fXOOJz\" fill=\"#3880e5\" height=\"32\" viewbox=\"0 0 30 30\" width=\"32\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#arrow-dropright-circle-d7d58289--sprite\"></use></svg></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Categories </p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 UxvCa dMXLyl\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 cgTHVD\" color=\"#333333\" size=\"13\">All</p></div><ul class=\"tree-renderer__TreeWrapper-sc-wdfwzn-0 djLvdn\"><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Biological Material</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Ceramic</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Composite</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Glass</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div checked=\"\" class=\"check-box__MinusCheckboxDesign-sc-1ptpc08-1 dsaEue\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Metal</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">2214</span></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Polymer</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div></ul></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Material properties </p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"><div></div></div><div class=\"advanced-search-sidebar-actions__ActionsWrapper-sc-qhfbni-0 cwhWGZ\"><button class=\"advanced-search-sidebar-action-button__ActionButton-sc-15cfzym-0 hXYfhe\">Add a material property<span class=\"icon__Icon-sc-1230ehg-0 eiXgPa\" color=\"2.0/white\" size=\"10\" type=\"plus\"></span></button><p class=\"text__Text-sc-f4nboj-0 advanced-search-sidebar-actions__ActionsText-sc-qhfbni-1 ldWNpx hVhMIm\" color=\"#3880E5\" cursor=\"pointer\" disabled=\"\" size=\"13\">Clear all</p></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Metal Filters</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"><div class=\"guided-tour-step-category-specific-settings\"><p class=\"text__Text-sc-f4nboj-0 LLywI\" color=\"#333333\" size=\"13\">Shape / Form</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"advanced-search-category-specific-settings-dropdown__FieldWrapper-sc-113hj4-1 epQYxF\"><p class=\"text__Text-sc-f4nboj-0 advanced-search-category-specific-settings-dropdown__FieldText-sc-113hj4-0 hjtwVq gNwTRO\" color=\"#333333\" size=\"16\">Bar</p><span><span style=\"cursor:help;display:block;flex-direction:column;z-index:100\"><span class=\"icon__Icon-sc-1230ehg-0 kXkjMs\" color=\"2.0/default\" size=\"12\" type=\"close\"></span></span></span><span><span style=\"cursor:help;display:block;flex-direction:column;z-index:100\"><div class=\"advanced-search-category-specific-settings-dropdown__PlusIconContainer-sc-113hj4-7 zzdEX\"><div class=\"plus-icon__PlusIcon-sc-13w6ro8-0 fdCHWk\" size=\"16\"></div></div></span></span></div><div class=\"advanced-search-category-specific-settings-dropdown__DropDownContainer-sc-113hj4-2 kRDCWz\"><div class=\"advanced-search-category-specific-settings-dropdown__DropDownItemsWrapper-sc-113hj4-3 huFKrQ\"></div></div></div></div></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><p class=\"text__Text-sc-f4nboj-0 hLVIHw\" color=\"#526193\">SYSTEM MEASUREMENTS</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bcLXBB dMXLyl\"><div class=\"radio-button__RadioButtonOuter-sc-mwb92w-0 hucmjH\"><div class=\"radio-button__RadioButtonInner-sc-mwb92w-1 jXbQYq\"></div></div><p class=\"text__Text-sc-f4nboj-0 KmEHA\" color=\"#333333\" size=\"13\">Metric</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE dMXLyl\"><div class=\"radio-button__RadioButtonOuter-sc-mwb92w-0 hucmjH\"></div><p class=\"text__Text-sc-f4nboj-0 KmEHA\" color=\"#333333\" size=\"13\">Imperial</p></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Suppliers </p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 zDQjJ cwHZQB\"><div class=\"advanced-search-sidebar-suppliers__ItemHeaderWrapper-sc-12new5k-0 cFpniu\"><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Include materials without suppliers</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 dTGKOg hFcCJB\"><div checked=\"\" class=\"toggle__ToggleWrapper-sc-th0yzv-0 gslBUi\"><div checked=\"\" class=\"toggle__ToggleCheckmark-sc-th0yzv-1 hbpQfU\"></div><div checked=\"\" class=\"toggle__ToggleToggle-sc-th0yzv-2 fArqYf\"></div></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Deutsche Edelstahlwerke (DEW)</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">93</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Ugitech</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">50</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Sverdrup Steel AS</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">20</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Salomon's Metalen</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">16</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Hempel Special Metals</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">4</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">VDM Metals</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">1</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Dongguan songshun mould steel Co., Ltd.</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">13</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Ambica Steels Limited</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">10</span></div></div></div><div class=\"advanced-search-sidebar-actions__ActionsWrapper-sc-qhfbni-0 cwhWGZ\"><button class=\"advanced-search-sidebar-action-button__ActionButton-sc-15cfzym-0 hXYfhe\">See all suppliers</button><p class=\"text__Text-sc-f4nboj-0 advanced-search-sidebar-actions__ActionsText-sc-qhfbni-1 ldWNpx hVhMIm\" color=\"#3880E5\" cursor=\"pointer\" disabled=\"\" size=\"13\">Clear all</p></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Applications </p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"></div><div class=\"advanced-search-sidebar-actions__ActionsWrapper-sc-qhfbni-0 cwhWGZ\"><button class=\"advanced-search-sidebar-action-button__ActionButton-sc-15cfzym-0 hXYfhe\">Add an application<span class=\"icon__Icon-sc-1230ehg-0 eiXgPa\" color=\"2.0/white\" size=\"10\" type=\"plus\"></span></button><p class=\"text__Text-sc-f4nboj-0 advanced-search-sidebar-actions__ActionsText-sc-qhfbni-1 ldWNpx hVhMIm\" color=\"#3880E5\" cursor=\"pointer\" disabled=\"\" size=\"13\">Clear all</p></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperMainContent-sc-14fw43j-9 results-list-view__AdvancedSearchMainContentWrapper-sc-d70l4k-1 cJNByu prlvG ifaaZC\"><div class=\"results-list-view__TopPositionBannerWrapper-sc-d70l4k-0 jleRfd\"><div class=\"campaigns__CampaignBannerWrapper-sc-a2pwr6-0 ewHqQp\" height=\"90\"></div></div><div class=\"results-list-view__AdvancedSearchAllertsWrapper-sc-d70l4k-2 dgFZRr\"></div><div class=\"navigation-component__AdvancedSearchNavigationComponentWrapper-sc-1j05mwq-0 fHnuKk\"><div class=\"navigation-component__AdvancedSearchNavigationItemWrapper-sc-1j05mwq-1 fmDqYN\"><div class=\"navigation-component__NavigationItemNumber-sc-1j05mwq-2 bwwYIA\">1</div><p class=\"text__Text-sc-f4nboj-0 eUTBqM\" color=\"#ff8200\" size=\"16\">RESULT LIST</p></div><div class=\"navigation-component__AdvancedSearchNavigationItemWrapper-sc-1j05mwq-1 hmFsem\"><div class=\"navigation-component__NavigationItemNumber-sc-1j05mwq-2 fgAGgQ\">2</div><p class=\"text__Text-sc-f4nboj-0 hMWWGw\" color=\"#828282\" size=\"16\">VISUALISE IN ASHBY</p></div></div><div class=\"header-properties-dropdown__PropertiesDropdownWrapper-sc-jye0ar-0 emgOuh\"><div style=\"width:32%\">Material</div><div style=\"flex:1\"><div class=\"custom-dropdown__CustomDropdownWrapper-sc-1r4pk0f-0 fLuqrw\"><div class=\"custom-dropdown__CustomDropdown-sc-1r4pk0f-1 hxQNhN\"><div class=\"custom-dropdown__CustomDropdownTrigger-sc-1r4pk0f-2 grBuVO\"><span class=\"custom-dropdown__CustomDropdownOption-sc-1r4pk0f-4 custom-dropdown__CustomDropdownOptionCurrent-sc-1r4pk0f-6 custom-dropdown__CustomDropdownOptionPlaceholder-sc-1r4pk0f-7 hwiCoG dUfhYU cwaUxH\">- Property</span><div class=\"custom-dropdown__CustomDropdownArrow-sc-1r4pk0f-8 kOKDxB\"></div></div><div class=\"custom-dropdown__CustomDropdownOptions-sc-1r4pk0f-3 cqRtVo\"><span class=\"custom-dropdown__CustomDropdownInfo-sc-1r4pk0f-5 kaSqTa\">No items</span></div></div><span class=\"icon__Icon-sc-1230ehg-0 custom-dropdown__SortingIcon-sc-1r4pk0f-9 kTando\" color=\"2.0/multicolor\" cursor=\"unset\" size=\"20\" type=\"default\"></span></div></div><div style=\"flex:1\"><div class=\"custom-dropdown__CustomDropdownWrapper-sc-1r4pk0f-0 fLuqrw\"><div class=\"custom-dropdown__CustomDropdown-sc-1r4pk0f-1 hxQNhN\"><div class=\"custom-dropdown__CustomDropdownTrigger-sc-1r4pk0f-2 grBuVO\"><span class=\"custom-dropdown__CustomDropdownOption-sc-1r4pk0f-4 custom-dropdown__CustomDropdownOptionCurrent-sc-1r4pk0f-6 custom-dropdown__CustomDropdownOptionPlaceholder-sc-1r4pk0f-7 hwiCoG dUfhYU cwaUxH\">- Property</span><div class=\"custom-dropdown__CustomDropdownArrow-sc-1r4pk0f-8 kOKDxB\"></div></div><div class=\"custom-dropdown__CustomDropdownOptions-sc-1r4pk0f-3 cqRtVo\"><span class=\"custom-dropdown__CustomDropdownInfo-sc-1r4pk0f-5 kaSqTa\">No items</span></div></div><span class=\"icon__Icon-sc-1230ehg-0 custom-dropdown__SortingIcon-sc-1r4pk0f-9 kTando\" color=\"2.0/multicolor\" cursor=\"unset\" size=\"20\" type=\"default\"></span></div></div><div style=\"flex:1\"><div class=\"custom-dropdown__CustomDropdownWrapper-sc-1r4pk0f-0 fLuqrw\"><div class=\"custom-dropdown__CustomDropdown-sc-1r4pk0f-1 hxQNhN\"><div class=\"custom-dropdown__CustomDropdownTrigger-sc-1r4pk0f-2 grBuVO\"><span class=\"custom-dropdown__CustomDropdownOption-sc-1r4pk0f-4 custom-dropdown__CustomDropdownOptionCurrent-sc-1r4pk0f-6 custom-dropdown__CustomDropdownOptionPlaceholder-sc-1r4pk0f-7 hwiCoG dUfhYU cwaUxH\">- Property</span><div class=\"custom-dropdown__CustomDropdownArrow-sc-1r4pk0f-8 kOKDxB\"></div></div><div class=\"custom-dropdown__CustomDropdownOptions-sc-1r4pk0f-3 cqRtVo\"><span class=\"custom-dropdown__CustomDropdownInfo-sc-1r4pk0f-5 kaSqTa\">No items</span></div></div><span class=\"icon__Icon-sc-1230ehg-0 custom-dropdown__SortingIcon-sc-1r4pk0f-9 kTando\" color=\"2.0/multicolor\" cursor=\"unset\" size=\"20\" type=\"default\"></span></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Superaustenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/destb19-acidur-4529\" target=\"_blank\">Acidur 4529</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests11-acidur-4401-at-\" target=\"_blank\">Acidur 4401 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests12-acidur-4435-at-\" target=\"_blank\">Acidur 4435 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests13-acidur-4541-at-\" target=\"_blank\">Acidur 4541 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests14-acidur-4571-at-\" target=\"_blank\">Acidur 4571 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 dSEUZx\"><div class=\"adbutler__CampaignBannerWrapper-sc-1snm6gk-0 dcaIxI\"><div class=\"adbutler__CampaignBannerInnerWrapper-sc-1snm6gk-1 fgLnFQ\" height=\"90\" id=\"advanced_search_slot\"><a href=\"https://go.matmatch.com/advertise\"><img src=\"/static/images/lorem-ipsum.png\"/></a></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests11a-acidur-4404-at-\" target=\"_blank\">Acidur 4404 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests9-acidur-4301-at-\" target=\"_blank\">Acidur 4301 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests9a-acidur-4307-at-\" target=\"_blank\">Acidur 4307 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests10-acidur-4305-at-\" target=\"_blank\">Acidur 4305 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Superaustenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/vdmm023-vdm-alloy-926\" target=\"_blank\">VDM® Alloy 926</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/vdmm-vdm-metals\" size=\"13\" target=\"_blank\">VDM Metals</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests7-acidur-4418-qt900-\" target=\"_blank\">Acidur 4418 QT900 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Duplex Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests15-acidur-4462-at-\" target=\"_blank\">Acidur 4462 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests7a-acidur-4418-qt760-\" target=\"_blank\">Acidur 4418 QT760 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Duplex Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/ugit0076-ugima-4460-cold-finished\" target=\"_blank\">UGIMA® 4460 Cold Finished</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/ugit-ugitech\" size=\"13\" target=\"_blank\">Ugitech</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Duplex Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/ugit0077-ugima-4460-cold-finished-and-drawn\" target=\"_blank\">UGIMA® 4460 Cold Finished and Drawn</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/ugit-ugitech\" size=\"13\" target=\"_blank\">Ugitech</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Precipitation Hardening Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/ugit0129-ugi-4545-air-h1025\" target=\"_blank\">UGI® 4545 AIR H1025</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/ugit-ugitech\" size=\"13\" target=\"_blank\">Ugitech</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests1-corrodur-4021-qt800-\" target=\"_blank\">Corrodur 4021 QT800 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests3-corrodur-4034-annealed-\" target=\"_blank\">Corrodur 4034 Annealed </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests4-acidur-4057-qt800-\" target=\"_blank\">Acidur 4057 QT800 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Precipitation Hardening Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests8-acidur-4542-p800-\" target=\"_blank\">Acidur 4542 P800 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"pagination__PaginationWrapper-sc-1s1bcvk-0 fLLraV\"><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonPrimary-sc-ekfcy0-1 eGHzTm nqeas\" data-test-item=\"prev-page\" disabled=\"\"></button><div class=\"pagination__PaginationPagesText-sc-1s1bcvk-1 TXmbf\">Page 1 of 111</div><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonPrimary-sc-ekfcy0-1 ljvJNw nqeas\" data-test-item=\"next-page\"></button></div></div></div><div class=\"footer-container__FooterContainer-sc-16jfcf3-0 kUuTvA\"><div class=\"static-page-wrappers__StaticPageContentWrapper-sc-fz58vx-1 fGzocz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer__FooterWrapper-sc-1vgte7v-0 cJNByu greBxI\"><div class=\"footer__FooterResponsiveWrapper-sc-1vgte7v-2 jdQCEK\"><div class=\"footer-matmatch-logo-and-gdpr__NameAndDescriptionWrapper-sc-1mbx1ll-0 lcDCgL\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListHeading-sc-17tjnty-1 cJNByu gFyZtw\"><p class=\"text__Text-sc-f4nboj-0 tenyk\" color=\"#526193\" size=\"20\">MATMATCH</p></div><p class=\"text__Text-sc-f4nboj-0 hjtwVq\" color=\"#333333\" size=\"16\">We connect engineers, product designers and procurement teams with the best materials and suppliers for their job.</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListWrapper-sc-17tjnty-0 cJNByu iIAlRS\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListHeading-sc-17tjnty-1 cJNByu gFyZtw\"><p class=\"text__Text-sc-f4nboj-0 tenyk\" color=\"#526193\" size=\"20\">COMPANY</p></div><ul class=\"list__List-sc-7ainlj-0 uluvW\"><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/about\">About us</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"https://matmatch-gmbh.jobs.personio.de/\">Career</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/resources\">Resources</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/supplier\">For suppliers</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"https://go.matmatch.com/advertise\">Advertise</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></li></ul></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListWrapper-sc-17tjnty-0 cJNByu iIAlRS\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListHeading-sc-17tjnty-1 cJNByu gFyZtw\"><p class=\"text__Text-sc-f4nboj-0 tenyk\" color=\"#526193\" size=\"20\">GENERAL</p></div><ul class=\"list__List-sc-7ainlj-0 uluvW\"><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/imprint\">Legal</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/imprint#privacy-policy\">Privacy</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/imprint#tnc-buyers\">Terms &amp; Conditions</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"https://www.plansee.com/en/about-us/whistleblower-system.html\">Whistleblower System</a></li></ul></div><ul class=\"list__List-sc-7ainlj-0 footer-social-links__SocialLinksList-sc-1hjdthk-0 uluvW hwyVjw\"><li class=\"footer-social-links__SocialLinksListItem-sc-1hjdthk-1 jkNDpJ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"https://www.linkedin.com/company/matmatch\"><span class=\"icon__Icon-sc-1230ehg-0 duJtpp\" color=\"2.0/footer\" fill=\"#526193\" size=\"30\" type=\"social-linkedin\"></span></a></li><li class=\"footer-social-links__SocialLinksListItem-sc-1hjdthk-1 jkNDpJ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"https://twitter.com/MatmatchGmbH\"><span class=\"icon__Icon-sc-1230ehg-0 UGQFe\" color=\"2.0/footer\" fill=\"#526193\" size=\"30\" type=\"social-twitter\"></span></a></li><li class=\"footer-social-links__SocialLinksListItem-sc-1hjdthk-1 jkNDpJ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"https://www.facebook.com/MatmatchGmbH/\"><span class=\"icon__Icon-sc-1230ehg-0 bfOfuL\" color=\"2.0/footer\" fill=\"#526193\" size=\"30\" type=\"social-facebook\"></span></a></li></ul></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer__FooterWrapper-sc-1vgte7v-0 cJNByu greBxI\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 footer__FooterMiddleWrapper-sc-1vgte7v-1 kXMRZj cdLigN hZBBnE\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListHeading-sc-17tjnty-1 cJNByu gFyZtw\"><p class=\"text__Text-sc-f4nboj-0 tenyk\" color=\"#526193\" size=\"20\">CONTACT US</p></div><ul class=\"list__List-sc-7ainlj-0 uluvW\"><li class=\"list__ListItem-sc-7ainlj-1 cJazBI\"><span class=\"icon__Icon-sc-1230ehg-0 cnxXUV\" color=\"2.0/footer\" cursor=\"default\" size=\"16\" type=\"ios-telephone\"></span><p class=\"text__Text-sc-f4nboj-0 GTisG\" color=\"#333333\" size=\"16\">+49 89 262075200</p></li><li class=\"list__ListItem-sc-7ainlj-1 gJZFKn\"><span class=\"icon__Icon-sc-1230ehg-0 jLgsnQ\" color=\"2.0/footer\" cursor=\"default\" size=\"16\" type=\"ios-location\"></span><p class=\"text__Text-sc-f4nboj-0 GTisG\" color=\"#333333\" size=\"16\">Leopoldstraße 250 A, 80807 Munich</p></li></ul></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer__FooterWrapper-sc-1vgte7v-0 cJNByu greBxI\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 kXMRZj\"><hr class=\"separation-line__SeparationLine-sc-1gtqai2-0 separation-line__SeparationLineDefault-sc-1gtqai2-1 dLmbUA kwnPiJ\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 footer-copyright__FooterCopyrightWrapper-sc-p1jkef-0 eHEnyb cdLigN jHUSlK\"><p class=\"text__Text-sc-f4nboj-0 cgTHVD\" color=\"#333333\" size=\"13\">© <!-- -->2021<!-- --> Matmatch GmbH, All rights reserved.</p><p class=\"text__Text-sc-f4nboj-0 cgTHVD\" color=\"#333333\" size=\"13\">Made with ♥ in Munich!</p></div></div></div></div></div></div></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"initialProps\":{\"initialI18nStore\":{\"en\":{\"account\":{\"forgot-password\":\"Forgot password?\",\"forgot-password-description\":\"In case you forgot your password you can request to reset it here.\",\"forgot-password-cta\":\"Request reset link\",\"delete-account-error\":\"Some problems were occurred while deleting your account.\",\"next-step\":{\"title\":\"Almost Done!\",\"description\":\"An email has been sent to you with the link to reset you password.\",\"cta\":\"Back to sign in\",\"title-second\":\"Now check your inbox\",\"description-second\":\"Please check your inbox, an email with the password reset link has been sent to {{email}}!\"},\"settings\":{\"title\":\"Settings\",\"reset-password-description\":\"If you would like to change your password, please click the button below. We will e-mail you a link you can use to set a new password.\",\"reset-password-cta\":\"Reset Password\",\"delete-account\":\"Delete Account\"},\"my-saved-materials\":\"My saved materials\",\"all-saved-materials\":\"See all saved materials\",\"search-and-save-materials\":\"Search and save material data sheets\",\"my-saved-searches\":\"My saved searches\",\"all-saved-searches\":\"See all saved searches\",\"latest-articles\":\"Latest articles\",\"my-matmatch-account\":\"My Matmatch Account\",\"my-supplier-network\":\"My Supplier Network\",\"info-box-message\":\"Do you need help with your project or choosing the right material?\",\"industry-leads-in-country\":\"Industry leaders in {{country}} you may know\",\"industry-leads\":\"Industry leaders you may know\",\"see-all-suppliers\":\"See all our Suppliers\",\"title\":\"My Account\",\"edit-profile\":{\"title\":\"Edit Profile\"}},\"common\":{\"register\":\"Register\",\"property\":\"Property\",\"welcome-back\":\"Welcome back\",\"property-name\":\"Property Name\",\"interaction\":\"Interaction\",\"event-date\":\"Event Date\",\"material-name\":\"Material Name\",\"contact\":\"Contact\",\"finish\":\"Finish\",\"system-measurements\":\"System Measurements\",\"metric\":\"Metric\",\"imperial\":\"Imperial\",\"audience\":\"Audience\",\"or\":\"or\",\"eg\":\"e.g.\",\"and\":\"and\",\"next\":\"Next\",\"privacy\":\"Privacy\",\"removed\":\"Removed\",\"undo\":\"Undo\",\"value\":\"Value\",\"biography\":\"Biography\",\"type\":\"Type\",\"near-me\":\"Near me\",\"legal\":\"Legal\",\"career\":\"Career\",\"back-to-results\":\"Back to results\",\"save-changes\":\"Save changes\",\"show\":\"Show\",\"materials\":\"Materials\",\"searches\":\"Searches\",\"send\":\"Send\",\"unit\":\"Unit\",\"code\":\"Code\",\"result\":\"Result\",\"name\":\"Name\",\"locations\":\"Locations\",\"save\":\"Save\",\"more\":\"More\",\"read\":\"Read\",\"properties\":\"Properties\",\"industries\":\"Industries\",\"add\":\"Add\",\"less\":\"Less\",\"blog\":\"Blog\",\"resources\":\"Resources\",\"see-all\":\"See all\",\"blog-articles\":\"Blog Articles\",\"further-reading\":\"Further reading\",\"learn\":\"Learn with Matmatch\",\"clear\":\"Clear\",\"general\":\"General\",\"applications\":\"Applications\",\"grades-title\":\"Grades provided by the supplier\",\"additionally\":\"Additionally\",\"message\":\"Message\",\"headquarters\":\"Headquarters\",\"website\":\"Website\",\"revenue\":\"Revenue\",\"close\":\"Close\",\"new\":\"New\",\"select\":\"Select\",\"select-all\":\"Select all\",\"search\":\"Search\",\"language\":\"Language\",\"units\":\"Units\",\"forgot\":\"Forgot\",\"forgot-password\":\"Did you forget your password?\",\"converted-value\":\"Converted value\",\"phone\":\"Phone\",\"phone-call\":\"Phone call\",\"phone-contact\":\"Phone contact\",\"claim-profile\":\"Claim this profile\",\"delete\":\"Delete\",\"status\":\"Status\",\"subject\":\"Subject\",\"subject-edit-if-needed\":\"Subject (edit if needed)\",\"account\":\"Account\",\"add-new\":\"Add New\",\"settings\":\"Settings\",\"dashboard\":\"Dashboard\",\"profile\":\"Profile\",\"edit-profile\":\"Edit profile\",\"about-us\":\"About us\",\"partners\":\"Partners\",\"sign-in\":\"Sign in\",\"ask-now\":\"Ask now\",\"sign-up\":\"Sign up\",\"sign-out\":\"Sign out\",\"subscribe\":\"Subscribe\",\"publish\":\"Publish\",\"unpublish\":\"Unpublish\",\"report\":\"Report\",\"published\":\"Published\",\"companies\":\"Companies\",\"unpublished\":\"Unpublished\",\"first-name\":\"First Name\",\"last-name\":\"Last Name\",\"full-name\":\"Full Name\",\"company\":\"Company\",\"suppliers\":\"Suppliers\",\"required\":\"Required\",\"should-be-number\":\"Should be a number\",\"email\":\"Email\",\"job-title\":\"Job Title\",\"for-suppliers\":\"For suppliers\",\"please-select\":\"Please select\",\"internal\":\"Internal\",\"country\":\"Country\",\"industry\":\"Industry\",\"categories\":\"Categories\",\"phone-number\":\"Phone number\",\"manage-companies\":\"Manage companies\",\"messages-admin\":\"Manage messages\",\"telephone\":\"Telephone\",\"email-address\":\"Email address\",\"country-code\":\"Country code\",\"phone-code\":\"Code\",\"terms-and-conditions\":\"Terms \\u0026 Conditions\",\"whistleblower-system\":\"Whistleblower System\",\"nothing-found\":\"Nothing found\",\"employees\":\"Employees\",\"from\":\"from \",\"here\":\"here\",\"download\":\"Download\",\"advanced-search\":\"Advanced Search\",\"revenue-yearly\":\"Revenue (yearly)\",\"contact-us\":\"Contact us\",\"contact-me\":\"Contact me\",\"book-meeting\":\"Book a meeting\",\"material-page-data-set-description\":\"Chemical composition and material properties of {{materialName}}.\",\"material-page-data-set-description-sources\":\"Chemical composition and material properties of {{materialName}}. Also available for download in XLSX and PDF. Data provided by {{sources}}\",\"contact-suppliers\":\"Contact suppliers\",\"wizard-tabs-headline\":\"Customize your search with filters\",\"wizard-tabs-headline-2\":\"Select a {{text, lowercase}} as a search filter\",\"wizard-tabs-headline-3\":\"Define property values\",\"cookies-policy\":\"In order to understand how our website is used and to be able to present you with an interest-related offer, we use cookies and other technologies. You will find more information about cookies on the privacy policy page.\",\"back\":\"Back\",\"cancel\":\"Cancel\",\"consultation-times\":\"Consultation times: Mon-Fri 9am - 5pm CET\",\"follow\":\"Follow\",\"following\":\"Following\",\"follow-suppliers\":\"Follow suppliers!\",\"collapse-menu\":\"Collapse menu\",\"footer-description\":\"We connect engineers, product designers and procurement teams with the best materials and suppliers for their job.\",\"information-and-services\":\"Information and services\",\"no-dropdown-items\":\"No items\",\"advertise\":\"Advertise\",\"media-kit\":\"Media Kit (Advertising)\",\"filters\":\"Filters\",\"material-review\":{\"title\":\"Material review\",\"unpublished-count\":\"{{count}} unpublished materials\",\"publish-cta\":\"Publish {{count}}\",\"publish-selected\":\"Publish {{count}} Selected\",\"publish-all\":\"Publish All Materials\",\"last-update\":\"Last update\",\"report-message-placeholder\":\"Please describe what data needs to be changed, added or removed\",\"report-sent\":\"Report sent\",\"report-sent-message\":\"Thank you for your report. We will review it as quickly as possible.\",\"no-unpublished-materials-message\":\"Nothing to do here. We will notify you if there are actions to be taken!\",\"show-published-text\":\"Show published materials\",\"no-published-materials-message\":\"No published materials available.\",\"publish-all-triggered\":\"You have successfully triggered publishing of all materials. The process may take several minutes!\",\"publish-all-triggered-title\":\"Publishing...\"},\"countries\":{\"china\":\"China\",\"america\":\"America\",\"germany\":\"Germany\",\"india\":\"India\",\"other\":\"Other regions\"},\"discover-materials\":{\"title\":\"Discover, compare and evaluate over \\u003cspan\\u003e{{count}}\\u003c/span\\u003e materials\"},\"supplier-materials\":{\"action-label\":\"See all materials by this supplier\"},\"book-form\":{\"success-message\":{\"processing-request\":\"Processing request\",\"title\":\"Your request has been processed\",\"message-one\":\"Thanks for booking a consultation with us, you will receive an email with the instructions within the next two days\",\"message-two\":\"Did you know that by creating a Matmatch account your request process is easier and takes less time, you also will be able to save your materials and access or new developed tools.\"}},\"contact-form\":{\"meta-title\":\"Contact Form\",\"important\":\"Important\",\"automatic-account-creation-warning\":\"By entering your information here, you will automatically create Matmatch account, needed to contact our suppliers.\",\"headline\":\"Get in touch with Matmatch\",\"company-headline\":\"Contact {{company}}\",\"company-subject\":\"I'm interested in {{material}} and would like to get in touch with you.\",\"supplier-page-subject\":\"I'm interested in your products and would like to get in touch with you.\",\"first-name-placeholder\":\"Enter Your first name\",\"full-name-placeholder\":\"Enter Your full name\",\"last-name-placeholder\":\"Enter Your last name\",\"company-placeholder\":\"What company do you work for?\",\"job-title-placeholder\":\"What is your job title?\",\"phone-placeholder\":\"Your phone number\",\"email-placeholder\":\"Your email address\",\"company-message-placeholder\":\"I'm interested in {{material}} and would like to get in touch with you.\",\"terms-and-conditions\":\"In addition to the \\u003ca href='/imprint#privacy-policy' target='_blank'\\u003eTerms and Conditions\\u003c/a\\u003e I consent to share the content provided on this form with third parties (Suppliers) to provide Quotes and additional material information to me. This site is protected by reCAPTCHA and the Google  \\u003ca href='https://policies.google.com/privacy'\\u003ePrivacy Policy\\u003c/a\\u003e and \\u003ca href='https://policies.google.com/terms'\\u003eTerms of Service\\u003c/a\\u003e apply.\",\"noCompanySubject1\":\"I have questions about this material\",\"noCompanySubject2\":\"I'm searching for a material\",\"noCompanySubject3\":\"I'm searching for a supplier\",\"message-placeholder\":\"Please include all important information for your request, for example:\",\"message-placeholder-advice1\":\"- Material type\",\"message-placeholder-advice2\":\"- Purpose of application\",\"message-placeholder-advice3\":\"- Mandatory material properties\",\"message-placeholder-advice4\":\"- Shape and dimension\",\"success-title\":\"Message sent\",\"send-failed-title\":\"Message send failed!\",\"fill-the-form-below\":\"Fill the form below\",\"success-message\":\"We will get back to you as quickly as possible.\",\"success-company-message\":\"Thank you for your message, {{contact}} will be in touch shortly\",\"success-contact-form-sign-up-message\":\"Your request was sent to Matmatch Supplier. Please follow the link sent to your e-mail to confirm your request and join the Matmatch network.\",\"success-contact-form-message-board-intro\":\"You can keep track of all your messages from your Matmatch account:\",\"success-contact-form-message-board-link\":\"Message Board\",\"send-failed-company-message\":\"Sorry, but your message has not been sent. Some technical error or backend failure. We're fixing it.\",\"supplier-indicator-title\":\"Fill the form to connect with our suppliers for this material\",\"tell-us-what-you-want\":\"Hi, how can we help?\",\"technical-question\":\"I have a technical question.\",\"quotes-question\":\"I would like a quote.\",\"quotes-form-header-text\":\"Our suppliers are more likely to reply with more specific information. So, please be as detailed as possible and we will ensure you a quick response\",\"form-message-placeholder\":\"Write your request here. Provide us as much information as possible.\",\"company-email-placeholder\":\"Write (desirably) company email here.\",\"personal-information\":\"Personal information\",\"technical-requirements\":\"Technical requirements\",\"location-details\":\"Location\",\"attach-file-or-specs\":\"Attach file or specs \",\"feature-is-unavailable\":\"We are sorry. This feature is coming soon\",\"next-step\":\"Next\",\"optional\":\"Optional\",\"requested-material\":\"Requested material\",\"intended-application-or-usage\":\"Intended application/use\",\"material-form\":\"Form\",\"material-dimensions\":\"Dimensions\",\"material-quantity\":\"Quantity\",\"shipping-country\":\"Shipping country\",\"first-name\":\"First name\",\"last-name\":\"Last name\",\"phone\":\"Phone\",\"country-code\":\"Country code\",\"phone-code\":\"Code\",\"company\":\"Company\",\"company-email\":\"Company email\",\"job-title\":\"Job title\",\"message\":\"Add a comment or additional technical requirement\",\"private-email-warning\":\"Suppliers are more likely to reply if you provide a company email address\",\"additional-request-information\":\"Additional request information\",\"material-color\":\"Material color\",\"material-length\":\"Length\",\"material-width\":\"Width\",\"material-thickness\":\"Thickness\",\"material-diameter\":\"Diameter\",\"particle-size\":\"Particle size\",\"describe-your-material\":\"Short description of the material\",\"material-general-description\":\"Add a comment or additional technical requirement\",\"create-account\":\"Would you like to send requests more quickly in the future and access additional Matmatch features? Then create your Matmatch account now - it just takes a click.\",\"material-shapes-info\":\"You see only supported material shapes in dropdown menu above. If you want other shape, please choose 'Other' and describe desired shape in corresponding fields. If you don't see 'Other' option, supplier doesn't produce custom material shapes for selected material.\",\"describe-custom-form\":\"Describe custom form here\",\"contact-user\":\"Contact user\",\"contact-users\":\"Contact {{ number }} users\",\"one-more-step-popup-header\":\"One more step\",\"one-more-step-popup-message\":\"Please \\u003cb\\u003echeck your email mailbox\\u003c/b\\u003e and verify your account for your request to reach the supplier and for you to receive replies.\",\"type-or-select-shipping-location\":\"Type or select a shipping location\",\"company-website\":\"Company website\",\"company-website-placeholder\":\"Your company website\",\"form-section-name-suppliers\":\"{{sectionNumber}}. Suppliers ({{count}})\",\"form-section-technical-information\":\"{{sectionNumber}}. Technical information\",\"form-section-personal-information\":\"{{sectionNumber}}. Personal information\",\"send-request\":\"Send request\",\"send-message\":\"Send message\",\"material-request-form-title\":\"Material request\",\"alert-error-fill-required-fields-title\":\"Fill all required fields\",\"alert-error-fill-required-fields-text\":\"Please fill all the required fields in order to send the request to our supplier!\",\"view-request-for\":\"View request for {{materialName}}\",\"request-more-details\":\"Request more details\",\"quotation-request-form-title\":\"Request a quotation\",\"technical-question-form-title\":\"Ask a technical question\",\"your-question\":\"Your question (please provide as much detail as possible)\",\"your-message\":\"Your message (please provide as much detail as possible)\",\"supplier-profile-contact-form-title\":\"Contact {{companyName}}\"},\"contact-forms-items\":{\"granule\":\"Granule\",\"powder\":\"Powder\",\"pellet\":\"Pellet\",\"film\":\"Film\",\"sheet\":\"Sheet\",\"filament\":\"Filament\",\"other\":\"Other\"},\"contact-box\":{\"supplied-by\":\"Material Supplied by\",\"any-questions\":\"Do you have any questions?\",\"contact-mat-sci\":\"Contact our Material Scientists\",\"contact-supplier\":\"Contact Supplier\",\"contact-specific-supplier\":\"Contact {{name}} now\",\"contact-specific-supplier-promo\":\"Do you have a question about this material?\",\"contact-suppliers\":\"Contact Suppliers ({{num}})\",\"contact-partner\":\"Contact {{type}}\",\"send-us-question\":\"Send us a message\",\"more-details\":\"More Details\",\"send-a-question-to\":\"Send a question to\",\"any-doubt\":\"Any doubt?\",\"send-a-question-for-free\":\"Any questions?\",\"send-a-message\":\"Send a message\",\"write-your-message-here\":\"Write your message here\",\"request-quotation\":\"Request a quotation\",\"ask-supplier-technical-question\":\"Ask the supplier a technical question\",\"ask-a-technical-question\":\"Ask a technical question\"},\"supplier-indicator-contact-box\":{\"title\":\"Find a supplier\",\"contact\":\"Send your requirements\",\"info\":\"We can help you find a supplier of {{materialName}}\",\"note\":\"We will evaluate your request and get back to you soon.\"},\"show-more\":{\"show-all\":\"Show all\",\"show-less\":\"Show less\"},\"pagination\":{\"previous\":\"Previous\",\"next\":\"Next\",\"pages-info\":\"Page {{num}} of {{total}}\"},\"saved-materials\":{\"see-list\":\"See list\",\"saved-items\":\"Saved items\",\"saved-materials\":\"Saved Materials\",\"new-material-saved\":\"New material saved\",\"not-registered-yet\":\"Not registered yet?\",\"auth-box-heading\":\"Save your materials and searches permanently!\",\"auth-box-text\":\"Sign in or sign up for a free account to permanently save materials and searches.\",\"saved-materials-mobile-text\":\"Save materials by pressing the star icon that you can find on search results list.\"},\"saved-searches\":{\"save-search\":\"Save search\",\"popup\":{\"title\":\"Name you search\",\"description\":\"Give a name to your search before saving it\",\"input-placeholder\":\"Search name\"}},\"saved-items\":{\"box-title\":\"My saved items\",\"saved-items\":\"Saved items\",\"new-item-saved\":\"New item saved\"},\"accept-terms-and-newsletter\":{\"title\":\"Privacy \\u0026 terms\",\"heading\":\"Please agree to our terms\",\"terms\":\"To continue you need to agree with our \\u003ca href='/imprint#tnc-buyers'\\u003eTerms and Conditions\\u003c/a\\u003e and our \\u003ca href='imprint#privacy-policy'\\u003ePrivacy Policy\\u003c/a\\u003e\",\"newsletter\":\"I would like to receive the Matmatch newsletter\",\"accept\":\"Accept and continue\"},\"comparison\":{\"compare\":\"Compare\",\"text\":\"{{count}} materials selected for comparison.\",\"disabled\":\"Please select two or more materials for comparison\",\"search-results\":\"Search results\",\"section-standards\":\"Standards\",\"section-equivalent-standards\":\"Equivalent standards\",\"section-chemical-composition\":\"Chemical composition\"},\"supported-languages\":{\"english\":\"English\",\"german\":\"German\",\"spanish\":\"Spanish\"},\"account-form\":{\"bio-placeholder\":\"Say something about yourself or add a link to a social profile\",\"submit-button-text\":\"Update information\",\"account-update-success\":\"You have successfully update Your account!\"},\"chemical-table\":{\"element\":\"Element\",\"weight\":\"Weight %\",\"comment\":\"Comment\"},\"company-type\":{\"DATA_PROVIDER\":\"Data provider\",\"ASSOCIATION\":\"Association\",\"SUPER_ASSOCIATION\":\"Association\",\"CONSULTANCIES\":\"Consultancy\",\"MANUFACTURER_AND_PROCESSOR\":\"Manufacturer and Processor\",\"MANUFACTURER\":\"Manufacturer\",\"MANUFACTURER_AND_DISTRIBUTOR\":\"Manufacturer and Distributor\",\"PROCESSOR\":\"Processor\",\"DISTRIBUTOR\":\"Distributor\",\"MATERIAL_SOURCE\":\"Material source\",\"MANUFACTURER_AND_PROCESSOR_AND_DISTRIBUTOR\":\"Manufacturer, Processor and Distributor\"},\"retired-material\":{\"title\":\"This material is no longer available. Search below to find a relevant alternative material.\",\"title-superseded\":\"The material: '{{material}}' you were looking for has been superseded by the one below.\"},\"supplier\":{\"qualified-label\":\"Matmatch qualified supplier\"},\"application\":{\"meta\":{\"industry-title\":\"Find Materials by Industry and Application\",\"search-results\":\"Materials for {{industry}} - {{application}}\",\"navigation\":\"Find Materials - {{industry}}\"},\"application\":\"Application\",\"title\":\"Discover materials from your industry\",\"description\":\"Build better products by discovering new materials for your industry. Search directly for an application or browse our catalogue below.\",\"search-input-placeholder\":\"e.g. Aerospace, Aerospace Electric Equipment, Turbine Blades ...\",\"no-results\":\"No results for your application!\",\"no-properties\":\"No properties available\",\"no-properties-selected-message\":\"You should select at least 1 property to see the chart!\",\"reset-filters\":\"Reset filters\",\"radar-chart-materials-message\":\"You should apply at least 3 properties for radar chart!\",\"radar-chart-max-amount-of-materials\":\"Maximum number ({{amount}}) of materials for this type of chart achieved!\",\"available-properties\":\"Available properties\",\"textual-comparison-cta\":\"Go to textual comparison\",\"meta-title\":\"Applications\",\"search-by-application\":\"Application Search\",\"default-breadcrumbs-category-name\":\"Industries\",\"comparison-scroll-to-the-right\":\"Please, scroll to the right to see the comparison\"},\"new-features-presentation\":{\"saved-search-presentation-popup-body\":\"You can now save your searches on Matmatch to access them quickly in the future. Simply use the \\\"Save search\\\" button on the right side of the screen on search results page.\",\"saved-search-presentation-popup-header\":\"Hey, did you know?\",\"dismiss\":\"Dismiss\",\"see-the-feature\":\"See the feature\"},\"tools\":{\"tools\":\"Tools\",\"unit-converter\":{\"title\":\"Unit converter\",\"title-landing\":\"Convert {{fromUnit}} to {{toUnit}}\",\"meta-description-landing\":\"Convert {{fromUnit}} to {{toUnit}} and other {{unitCategory}} units with this easy-to-use online unit converter.\",\"header-landing\":\"Convert from {{fromUnit}} to {{toUnit}}\",\"description\":\"Convert data between a wide variety of different units in just a few clicks. You can currently convert dielectric strength, temperature, pressure, thermal conductivity, energy, electrical resistivity, stress, power, volume and density units.\",\"description-landing\":\"To convert from {{fromUnit}} to {{toUnit}} enter the desired value for {{fromUnit}} below and the tool will convert it to {{toUnit}} and all other available units. You can also select and convert other types of units. \\u003cbr/\\u003e\\u003cbr/\\u003e\\u003cstrong\\u003e{{formula}}\\u003c/strong\\u003e\",\"other-units-title\":\"{{selectedUnitValue}} {{fromUnit}} is also equivalent to:\",\"converter-title\":\"Chose type of unit for conversion\",\"group-placeholder\":\"Choose a group\",\"properties-message\":\"Did you know? You can now search materials by their properties. Try it\",\"quick-conversions\":\"Quick conversion chart of {{fromUnit}} to {{toUnit}}:\"},\"hardness-converter\":{\"meta-title\":\"Hardness Converter\",\"meta-description\":\"Convert values between different hardness testing methods based on the material category.\",\"title\":\"Hardness Converter\",\"description\":\"Convert values between different hardness testing methods based on the material category. The converted values are extrapolated from test data and collated tabular data, so should be take as approximations.\",\"material-category\":\"Material\",\"material-category-placeholder\":\"Select a Material Category\",\"testing-method\":\"Testing Method\",\"testing-method-placeholder\":\"Select testing method\",\"wrong-input-range\":\"Please enter a value between {{min}} and {{max}}\",\"info-message\":\"All converted values are given as approximations and are for reference only.\",\"found-materials\":\"There are {{count}} materials in our database matching the value you converted\",\"view-materials\":\"View matching materials \\u003ca href='{{url}}'\\u003enow\\u003c/a\\u003e.\"}},\"services\":{\"title\":\"Services\",\"get-connected\":\"Get connected\",\"material-consultancy\":\"Material consultancy\"},\"messages\":\"Messages\",\"roles\":{\"USER\":\"Website user\",\"BETA_USER\":\"Beta website user\",\"SUPPLIER_BETA_USER\":\"Beta Dashboard user\",\"SUPPLIER_CONTACT\":\"Message User\",\"SUPPLIER_USER\":\"Dashboard User\"},\"book-demo\":{\"form\":{\"subscription-label\":\"I would like to receive email news and updates from Matmatch\",\"checkbox-label\":\"By clicking below, you consent to allow Matmatch to store and process the personal information submitted above to provide you with more information about listing as a supplier on Matmatch.\",\"privacy-label\":\"View our \\u003ca href='/imprint#privacy-policy'\\u003eprivacy policy\\u003c/a\\u003e for more information on how your data is used.\"}},\"supplier-dashboard\":{\"menu-item-dashboard-home\":\"Dashboard Home\",\"menu-item-messages-board\":\"Messages Board\",\"menu-item-messages-admin\":\"Messages Admin\",\"menu-item-audience\":\"Audience ({{ numOfEventTypes }})\",\"menu-item-performance\":\"Performance\",\"menu-item-performance-temp\":\"Performance (Temp)\",\"menu-item-visibility\":\"Visibility\",\"menu-item-materials\":\"Materials\",\"menu-item-webinar-audience\":\"Webinar audience\",\"not-available-for-mobile\":\"Our analytics board is not supported in mobile version. You may access it on your PC or tablet.\",\"menu-item-support\":\"Supplier Support\",\"menu-item-contact-us\":\"Contact Us\",\"menu-item-faq\":\"FAQ\",\"geo-chart-item-compare-views\":\"Compare views\",\"geo-chart-item-content-views\":\"Content views\",\"geo-chart-item-material-views\":\"Material views\",\"geo-chart-item-profile-views\":\"Profile views\",\"table-header-material-name\":\"Material name\",\"table-header-count\":\"Count\",\"table-header-page-views\":\"Page views\",\"table-header-most-compared-material\":\"Most Compared material\",\"table-header-compared-material-producer\":\"Material producer\",\"table-header-company-name\":\"Company\",\"table-header-employee-count\":\"Employees\",\"table-header-visits\":\"Visits\",\"table-header-visitors\":\"Visitors\",\"table-header-count-views\":\"Views\",\"table-header-count-registered-views\":\"Views from Registered Users\",\"table-header-count-downloads\":\"Downloads\",\"table-header-count-copies\":\"Copies\",\"table-header-count-comparisons\":\"Comparisons\",\"table-header-date\":\"Date\",\"table-header-size\":\"Size\",\"table-header-keyword\":\"Keyword\",\"table-header-clicks\":\"Clicks\",\"table-header-impressions\":\"Impressions\",\"table-header-compared-materials\":\"Compared with\",\"table-header-compared-companies\":\"Compared suppliers\",\"table-header-compared-properties\":\"Compared properties\",\"table-header-supplier\":\"Supplier\",\"table-header-country\":\"Country\",\"table-header-city\":\"City\",\"table-comparison-expand\":\"Expand\",\"table-comparison-collapse\":\"Collapse\",\"table-header-full-name\":\"Name\",\"table-header-job-title\":\"Job Title\",\"table-header-status\":\"Status\",\"table-header-registered-date\":\"Registered On\",\"table-header-email\":\"E-mail\",\"table-header-grade\":\"Grade\",\"table-header-shape\":\"Shape\",\"table-header-equivalentMaterials\":\"Equivalent Materials\",\"table-header-standards\":\"Standard / Norm\",\"material-performance-by-interaction-type\":{\"title\":\"Material performance by interaction type\",\"tooltip\":\"Control metrics showing how people interact with your content on Matmatch.\"},\"material-details\":{\"title\":\"Material details\",\"tooltip\":\"See the detailed information of your material page performance on Matmatch.\"},\"material-comparisons\":{\"title\":\"Material comparisons\",\"tooltip\":\"See the detailed information of your materials that were compared with other materials on Matmatch.\"},\"visibility-by-type\":{\"title\":\"Visibility by type\",\"tooltip\":\"Control metrics showing how often your content is found on Matmatch.\"},\"visibility-by-country\":{\"title\":\"Visibility by country\",\"tooltip\":\"Control metrics showing countries of people accessing your content on Matmatch.\"},\"most-visited-materials\":{\"title\":\"Most visited materials\",\"tooltip\":\"See your best performing Material Pages.\"},\"top-compared-materials\":{\"title\":\"Top compared materials\",\"tooltip\":\"See your most compared Material Pages.\"},\"visibility-by-companies\":{\"title\":\"Large companies visiting your materials\",\"tooltip\":\"See the biggest companies that were accessing your content on Matmatch. Companies are identified based on visitor IP address.\"},\"top-google-keywords\":{\"title\":\"Top Google keywords\",\"tooltip\":\"Control metrics showing keywords entered in google search before accessing your content on Matmatch.\"},\"linked-materials-details\":{\"title\":\"Linked material details\",\"tooltip\":\"See the detailed information of material page performance on Matmatch where your company details have been shown.\"},\"day\":\"Day\",\"week\":\"Week\",\"month\":\"Month\",\"nothing-found\":\"No data available for the selected period\",\"sorry\":\"Sorry\",\"dashboard-not-available-for-mobiles\":\"This section is not available for mobile device yet. Try the desktop version for the full experience.\",\"attention-demo-mode\":\"Attention: you are in demo mode, static data is shown!\",\"webinars-label\":\"Webinars\",\"webinars-title\":\"Webinar registrants\"},\"go-to-message-board\":\"Go to message board\",\"sorry\":\"Sorry...\",\"cookies\":{\"banner-title\":\"Our cookie disclaimer\",\"accept\":\"Accept all\",\"open-settings\":\"Open cookie settings\",\"confirm\":\"Confirm my choices\",\"settings\":\"Cookie settings\",\"popup-description\":\"You can control how Matmatch use cookies and similar technologies by making choices below. But note that if you disable cookies and similar technologies entirely, Matmatch may not function properly.\",\"consent-title\":\"Necessary\",\"consent-description\":\"These cookies are required, and they are used to enable core functionality on Matmatch. Without them the site could not operate, so they cannot be disabled.\",\"preferences-title\":\"Preferences\",\"preferences-description\":\"These cookies enable Matmatch to deliver a more personalised experience to your interests on the platform.\",\"statistics-title\":\"Statistics\",\"statistics-description\":\"These cookies are used to analyze site usage to measure and improve performance. Without them Matmatch cannot know what content is most valued and how often unique visitors return to the site, making it hard to improve the information and services we offer to you.\",\"tracking-title\":\"Marketing\",\"tracking-description\":\"These cookies are used to enable Matmatch to serve content more relevant to your interests both on and off the platform.\",\"banner-disclaimer\":\"Matmatch uses cookies and similar technologies to improve your experience and measure your interactions with our website. We also use them to provide you more relevant information and improve our platform and search tools. If that’s okay, click “Accept all.” To change your preferences, click “Open cookie settings.” You will find more information about cookies on our \\u003ca style='text-decoration:underline;' href='/imprint#privacy-policy'\\u003eprivacy policy page\\u003ca/\\u003e.\"},\"sustainability\":{\"share-text\":\"Share this page\",\"pdf\":{\"question\":\"Download a PDF copy\",\"text\":\"Receive a copy of this article in PDF format via email\",\"button\":\"Get it now\",\"pop-up\":\"By clicking below you consent to allow Matmatch to store and process the personal information submitted above to provide you the content requested. View our privacy policy for more information on how your data is used.\"},\"how-to-source-title\":\"Get in touch\"}},\"navigation\":{\"20\":{\"header\":{\"materials\":\"Materials\",\"for-suppliers\":\"For Suppliers\",\"about-us\":\"About us\",\"get-connected\":\"Get Connected\",\"3d-printing-hub\":\"3D Printing\"}},\"companies-list\":\"Companies list\",\"material-review\":\"Material review\"},\"sign-in-up\":{\"password\":\"Password\",\"save-password\":\"Save password\",\"sign-in-up\":\"Sign In / Up\",\"not-signed-in\":\"You are not signed in\",\"view-my-profile\":\"View my Profile\",\"open-profile-menu\":\"Open profile menu\",\"close-profile-menu\":\"Close profile menu\",\"create-account-now\":\"Create your account now\",\"sign-in\":{\"password-placeholder\":\"Type your password\",\"new-to-matmatch\":\"New to Matmatch?\",\"email-placeholder\":\"Enter the address you signed up with\",\"welcome-back-message\":\"To sign in to your Matmatch account, please enter your email and password.\"},\"set-password\":{\"title\":\"Set a password\",\"password-placeholder\":\"Set your new password\",\"hint\":\"Your password should be at least 8 characters long.\"},\"forgot-password\":{\"title\":\"Forgot password?\",\"request-reset\":\"Request reset link\",\"email-placeholder\":\"Enter your e-mail address\",\"hint\":\"In case you forgot your password you can request to reset it here.\",\"instructions\":{\"one\":\"1. To reset a password, please enter your email address. Then click “Send me reset link” button.\",\"two\":\"2. Check your inbox for a password reset email. Click on the URL provided in the email and enter a new password.\",\"three\":\"3. If you don’t know your email address or it is no longer valid, please create a new Matmatch account \"}},\"success-popup\":{\"almost-done\":\"Almost done!\",\"back-to-sign-in\":\"Back to sign in\",\"back-to-matmatch\":\"Back to matmatch.com\",\"confirmation-mail-note\":\"We’ve sent you a confirmation email to {{email}}. Please click the link in the email to activate your account.\"},\"sign-up\":{\"signup-failed\":\"Signup failed\",\"create-account\":\"Create account\",\"create-your-account\":\"Create your account\",\"email-placeholder\":\"Your email address\",\"already-account\":\"Already have an account?\",\"last-name-placeholder\":\"Enter your last name\",\"first-name-placeholder\":\"Enter your first name\",\"newsletter-label\":\"I would like to receive the Matmatch e-mail newsletter\",\"terms-and-conditions-label\":\"I have read and agreed to the Matmatch \\u003ca href='/imprint#tnc-buyers'\\u003eTerms and Conditions\\u003c/a\\u003e and \\u003ca href='/imprint#privacy-policy'\\u003ePrivacy Policy.\\u003c/a\\u003e\",\"signup-failed-message\":\"Oops! Something went wrong during the signup process. We will investigate and fix the issue as fast as possible.\",\"do-you-work-for-material-supplier\":\"Do you work for a material supplier?\"},\"sign-in-page\":{\"meta-title\":\"Sign In\",\"title\":\"Sign In\"},\"sign-up-page\":{\"meta-title\":\"Sign Up\",\"title\":\"Create an account\"},\"activation-page\":{\"meta-title\":\"Account Activation\",\"activated-title\":\"Done!\",\"activated-message\":\"Your new password has been set and the account has been activated.\",\"sign-in\":\"Sign In\",\"account\":\"Account\"},\"info\":{\"sign-in-to-download\":\"Sign in or create your free Matmatch account to download this datasheet. A free account includes access to hundreds of thousands of detailed technical datasheets.\",\"sign-in-description\":\"Registered users have full access to all premium features for free.\",\"company-email-tooltip\":\"Matmatch is a platform that connects professionals in the materials industry. Please provide your valid company address.\"},\"value-propositions\":{\"title\":\"Create your Matmatch account for free and enjoy all premium features\",\"suppliers-title\":\"Our material data comes directly from material suppliers and verified data partners\",\"values\":{\"one\":{\"value\":\"Unlimited datasheet downloads.\",\"description\":\"Download technical datasheets for thousands of materials in .pdf and .xlsx formats.\"},\"two\":{\"value\":\"Ashby charts interactivity.\",\"description\":\" Get more technical data about material upon clicking.\"},\"three\":{\"value\":\"Ashby chart image.\",\"description\":\"Export Ashby chart in .png format.\"},\"four\":{\"value\":\"Property charts.\",\"description\":\"View material behaviour under different temperatures.\"},\"five\":{\"value\":\"SN-curves.\",\"description\":\"Request fatigue data (S-N curve) for different materials.\"},\"six\":{\"value\":\"Supplier contact.\",\"description\":\"Get in touch with suppliers and keep track of all your messages from the Matmatch message board.\"}}},\"premium-features\":{\"registered-only\":\"This feature is for registered users only\"}},\"advanced-search\":{\"common\":{\"categories\":\"Categories\",\"properties\":\"Properties\",\"nothing-added\":\"Nothing added\",\"more-search-options\":\"More search options\",\"title\":\"Advanced Search - Matmatch\",\"suppliers\":\"Suppliers\",\"applications\":\"Applications\",\"download-chart-as-png\":\"Download as .PNG\",\"teaser-description\":\"Sign up to get access to this premium feature for free.\"},\"sidebar\":{\"labels-title\":\"Search result for\",\"clear-all\":\"Clear all\",\"show-all\":\"Show all\",\"all\":\"All\",\"properties\":{\"cta\":\"Add a material property\"},\"suppliers\":{\"cta\":\"See all suppliers\"},\"applications\":{\"cta\":\"Add an application\"}},\"alerts\":{\"category-specific-filter-disabled\":{\"description\":\"Some filter options have been disabled following your previous selection.\"},\"selecting-materials-info\":{\"title\":\"Compare Materials Tip!\",\"description\":\"Select two or more Materials by pressing the checkbox on the right and then press the \\\"Compare and Visualise\\\" button.\"},\"all-categories-selected\":{\"title\":\"All Material Categories have now been selected.\"},\"properties-disabled\":{\"title\":\"Properties disabled\",\"description\":\"The following properties: [ {{properties}} ] are not linked to the existing material categories.\"},\"properties-disabled-due-applied-filters\":{\"title\":\"Properties disabled\",\"description\":\"The following properties: [ {{properties}} ] have been disabled due to applied filters.\"},\"categories-disabled\":{\"title\":\"Material categories disabled\",\"description\":\"The following categories: [ {{categories}} ] have been disabled due to applied filters.\"},\"no-materials-left\":{\"title\":\"All materials have been filtered out.\",\"description\":\"Please re-adjust the slider filters, or add additional categories to bring back some materials.\"},\"material-retired\":{\"title\":\"Warning!\",\"description\":\"This material is no longer available. Search below to find a relevant alternative material.\"}},\"main-content\":{\"supplied-by\":\"Supplied by: \",\"supplied-by-matmatch\":\"{{number}} Matmatch suppliers\",\"supplied-by-matmatch-singular\":\"{{number}} Matmatch supplier\"},\"comparison\":{\"compare-count\":\"Compare ({{count}})\",\"compare-materials\":\"Compare Materials\",\"compare-and-visualise\":\"Compare and Visualise\",\"materials-selected\":\"{{count}} materials selected\"},\"categories\":{\"popup\":{\"title\":\"Material categories\",\"selected-categories\":\"Selected Categories\"}},\"properties\":{\"popup\":{\"title\":\"Material properties\",\"search-placeholder\":\"Property Search\"}},\"suppliers\":{\"popup\":{\"title\":\"Material suppliers\",\"selected-suppliers\":\"Selected Suppliers\"}},\"header\":{\"property-placeholder\":\"- Property\",\"no-properties-in-sidebar-info\":\"You have no properties to compare, add some properties in the sidebar first.\"},\"category-specific-title\":{\"metal\":\"Metal Filters\",\"polymer\":\"Polymer Filters\",\"ceramic\":\"Ceramic Filters\",\"composite\":\"Composite Filters\"},\"category-specific-settings\":{\"forms\":\"Shape / Form\",\"modifications\":\"Modification\",\"fillers\":\"Filler\",\"processing\":\"Processing\",\"certifications\":\"Certification Group\",\"primary-phase\":\"Primary Phase\",\"secondary-phase\":\"Secondary Phase\",\"tooltip-add-forms\":\"Add a shape filter\",\"tooltip-add-modifications\":\"Add a modification filter\",\"tooltip-add-fillers\":\"Add a filler filter\",\"tooltip-add-processing\":\"Add a processing filter\",\"tooltip-add-certifications\":\"Add a certification filter\",\"tooltip-add-primary-phase\":\"Add a primary phase filter\",\"tooltip-add-secondary-phase\":\"Add a secondary phase filter\",\"tooltip-clear-all\":\"Clear all\"},\"applications\":{\"popup\":{\"selected-applications\":\"Selected applications\",\"no-applications\":\"No Applications found for these Materials!\"}},\"contextual-tags\":{\"results-number\":\"{{count}} results for\"},\"no-results\":{\"title\":\"Sorry, no results found\",\"text\":\"Try searching again by typing a material name in the search bar or choose a filter to add.\"},\"navigation\":{\"result-list\":\"Result list\",\"plot-materials\":\"Visualise in Ashby\"},\"plot-materials\":{\"title\":\"Setup Ashby Chart\",\"x-axis\":\"Change X - Axis\",\"y-axis\":\"Change Y - Axis\"}},\"search-and-filters\":{\"advanced-filters\":\"Advanced filters\",\"resetFilter\":\"Reset filter\",\"only-with-supplier\":\"Show materials with suppliers\",\"only-with-supplier-short\":\"Only with suppliers\",\"searchTips\":{\"headline\":\"\\u003cb\\u003eSearch tips:\\u003c/b\\u003e\",\"noMatches\":\"Sorry, no matches found for \\u003cb\\u003e{{text}}\\u003c/b\\u003e\",\"tip1\":\"Reduce the number of search terms\",\"tip2\":\"Try alternative spellings for your search terms\",\"tip3\":\"Use different search terms\"},\"wizard\":{\"inputPlaceholder\":\"Type to filter the list\"},\"search-bar-placeholders\":{\"1\":\"Aluminium\",\"2\":\"Density\",\"3\":\"Elastic Modulus\",\"4\":\"High carbon steel\",\"5\":\"AISI 201\",\"6\":\"Thermal diffusivity\",\"7\":\"Tungsten alloy\",\"empty-submission-error\":\"Type a material name or category to start a search\",\"default\":\"Type a material name, property, category or supplier\"},\"search\":\"Search\",\"results\":\"Results\",\"search-bar\":{\"title\":\"Make better material decisions\",\"sub-title\":\"Find and compare materials for your projects.\",\"filters\":{\"property\":{\"title\":\"Search by property\",\"text\":\"Find materials that meet specific requirements\"},\"category\":{\"title\":\"Search by category\",\"text\":\"Explore different materials in a certain category\"},\"supplier\":{\"title\":\"Search by supplier\",\"text\":\"Discover materials offered by a specific supplier\"}}}},\"ashby-chart\":{\"breadcrumbs-level-one\":\"All categories\",\"download-as-png\":\"Download Ashby chart as PNG: \",\"data-point\":{\"header-materials\":\"Materials\",\"supplier\":\"Supplied by:\"}}}},\"initialLanguage\":\"en\",\"i18nServerInstance\":null,\"pageProps\":{\"data\":{\"labels\":[],\"queryParams\":\"categories=steel\\u0026tags=form:bar\",\"unitsSystem\":\"metric\",\"categories\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"humanReadableId\":\"Biological Material\",\"label\":\"Biological Material\",\"disabled\":true,\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"humanReadableId\":\"Wood\",\"label\":\"Wood\",\"disabled\":true}]},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"humanReadableId\":\"Ceramic\",\"label\":\"Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"humanReadableId\":\"Carbon\",\"label\":\"Carbon\",\"disabled\":true,\"children\":[{\"id\":\"carbon-nanotube\",\"nodeId\":\"carbon-nanotube\",\"humanReadableId\":\"Carbon Nanotube\",\"label\":\"Carbon Nanotube\",\"disabled\":true},{\"id\":\"diamond\",\"nodeId\":\"diamond\",\"humanReadableId\":\"Diamond\",\"label\":\"Diamond\",\"disabled\":true,\"children\":[{\"id\":\"natural-diamond\",\"nodeId\":\"natural-diamond\",\"humanReadableId\":\"Natural Diamond\",\"label\":\"Natural Diamond\",\"disabled\":true},{\"id\":\"synthetic-diamond\",\"nodeId\":\"synthetic-diamond\",\"humanReadableId\":\"Synthetic Diamond\",\"label\":\"Synthetic Diamond\",\"disabled\":true}]},{\"id\":\"graphene\",\"nodeId\":\"graphene\",\"humanReadableId\":\"Graphene\",\"label\":\"Graphene\",\"disabled\":true},{\"id\":\"graphite\",\"nodeId\":\"graphite\",\"humanReadableId\":\"Graphite\",\"label\":\"Graphite\",\"disabled\":true}]},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"humanReadableId\":\"Engineering Ceramic\",\"label\":\"Engineering Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"non-oxide-based\",\"nodeId\":\"non-oxide-based\",\"humanReadableId\":\"Non Oxide Based\",\"label\":\"Non Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"boride-based\",\"nodeId\":\"boride-based\",\"humanReadableId\":\"Boride Based\",\"label\":\"Boride Based\",\"disabled\":true},{\"id\":\"carbide-based\",\"nodeId\":\"carbide-based\",\"humanReadableId\":\"Carbide Based\",\"label\":\"Carbide Based\",\"disabled\":true,\"children\":[{\"id\":\"boron-carbide\",\"nodeId\":\"boron-carbide\",\"humanReadableId\":\"Boron Carbide\",\"label\":\"Boron Carbide\",\"disabled\":true},{\"id\":\"silicon-carbide\",\"nodeId\":\"silicon-carbide\",\"humanReadableId\":\"Silicon Carbide\",\"label\":\"Silicon Carbide\",\"disabled\":true},{\"id\":\"tantalum-carbide\",\"nodeId\":\"tantalum-carbide\",\"humanReadableId\":\"Tantalum Carbide\",\"label\":\"Tantalum Carbide\",\"disabled\":true},{\"id\":\"titanium-carbide\",\"nodeId\":\"titanium-carbide\",\"humanReadableId\":\"Titanium Carbide\",\"label\":\"Titanium Carbide\",\"disabled\":true},{\"id\":\"tungsten-carbide\",\"nodeId\":\"tungsten-carbide\",\"humanReadableId\":\"Tungsten Carbide\",\"label\":\"Tungsten Carbide\",\"disabled\":true},{\"id\":\"zirconium-carbide\",\"nodeId\":\"zirconium-carbide\",\"humanReadableId\":\"Zirconium Carbide\",\"label\":\"Zirconium Carbide\",\"disabled\":true}]},{\"id\":\"nitride-based\",\"nodeId\":\"nitride-based\",\"humanReadableId\":\"Nitride Based\",\"label\":\"Nitride Based\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nitirde\",\"nodeId\":\"aluminium-nitirde\",\"humanReadableId\":\"Aluminium Nitirde\",\"label\":\"Aluminium Nitirde\",\"disabled\":true},{\"id\":\"boron-nitride\",\"nodeId\":\"boron-nitride\",\"humanReadableId\":\"Boron Nitride\",\"label\":\"Boron Nitride\",\"disabled\":true},{\"id\":\"silicon-nitride\",\"nodeId\":\"silicon-nitride\",\"humanReadableId\":\"Silicon Nitride\",\"label\":\"Silicon Nitride\",\"disabled\":true},{\"id\":\"titanium-nitride\",\"nodeId\":\"titanium-nitride\",\"humanReadableId\":\"Titanium Nitride\",\"label\":\"Titanium Nitride\",\"disabled\":true}]},{\"id\":\"silicate-based\",\"nodeId\":\"silicate-based\",\"humanReadableId\":\"Silicate Based\",\"label\":\"Silicate Based\",\"disabled\":true},{\"id\":\"sulfide-based\",\"nodeId\":\"sulfide-based\",\"humanReadableId\":\"Sulfide Based\",\"label\":\"Sulfide Based\",\"disabled\":true,\"children\":[{\"id\":\"bismuth-sulfide\",\"nodeId\":\"bismuth-sulfide\",\"humanReadableId\":\"Bismuth Sulfide\",\"label\":\"Bismuth Sulfide\",\"disabled\":true},{\"id\":\"copper-sulfide\",\"nodeId\":\"copper-sulfide\",\"humanReadableId\":\"Copper Sulfide\",\"label\":\"Copper Sulfide\",\"disabled\":true},{\"id\":\"iron-sulfide\",\"nodeId\":\"iron-sulfide\",\"humanReadableId\":\"Iron Sulfide\",\"label\":\"Iron Sulfide\",\"disabled\":true},{\"id\":\"manganese-sulfide\",\"nodeId\":\"manganese-sulfide\",\"humanReadableId\":\"Manganese Sulfide\",\"label\":\"Manganese Sulfide\",\"disabled\":true},{\"id\":\"molybdenum-disulfide\",\"nodeId\":\"molybdenum-disulfide\",\"humanReadableId\":\"Molybdenum Disulfide\",\"label\":\"Molybdenum Disulfide\",\"disabled\":true},{\"id\":\"multiphase-metal-sulfide\",\"nodeId\":\"multiphase-metal-sulfide\",\"humanReadableId\":\"Multiphase Metal Sulfide\",\"label\":\"Multiphase Metal Sulfide\",\"disabled\":true},{\"id\":\"tin-sulfide\",\"nodeId\":\"tin-sulfide\",\"humanReadableId\":\"Tin Sulfide\",\"label\":\"Tin Sulfide\",\"disabled\":true},{\"id\":\"tungsten-disulfide\",\"nodeId\":\"tungsten-disulfide\",\"humanReadableId\":\"Tungsten Disulfide\",\"label\":\"Tungsten Disulfide\",\"disabled\":true},{\"id\":\"zinc-sulfide\",\"nodeId\":\"zinc-sulfide\",\"humanReadableId\":\"Zinc Sulfide\",\"label\":\"Zinc Sulfide\",\"disabled\":true}]}]},{\"id\":\"oxide-based\",\"nodeId\":\"oxide-based\",\"humanReadableId\":\"Oxide Based\",\"label\":\"Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"advanced-ceramic-oxides\",\"nodeId\":\"advanced-ceramic-oxides\",\"humanReadableId\":\"Advanced Ceramic Oxides\",\"label\":\"Advanced Ceramic Oxides\",\"disabled\":true},{\"id\":\"aluminium-oxide\",\"nodeId\":\"aluminium-oxide\",\"humanReadableId\":\"Aluminium Oxide\",\"label\":\"Aluminium Oxide\",\"disabled\":true},{\"id\":\"beryllium-oxide\",\"nodeId\":\"beryllium-oxide\",\"humanReadableId\":\"Beryllium Oxide\",\"label\":\"Beryllium Oxide\",\"disabled\":true},{\"id\":\"ferrite\",\"nodeId\":\"ferrite\",\"humanReadableId\":\"Ferrite\",\"label\":\"Ferrite\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-silicate\",\"nodeId\":\"aluminium-silicate\",\"humanReadableId\":\"Aluminium Silicate\",\"label\":\"Aluminium Silicate\",\"disabled\":true},{\"id\":\"magnesium-silicate\",\"nodeId\":\"magnesium-silicate\",\"humanReadableId\":\"Magnesium Silicate\",\"label\":\"Magnesium Silicate\",\"disabled\":true},{\"id\":\"zirconium-silicate\",\"nodeId\":\"zirconium-silicate\",\"humanReadableId\":\"Zirconium Silicate\",\"label\":\"Zirconium Silicate\",\"disabled\":true}]},{\"id\":\"titanium-oxide\",\"nodeId\":\"titanium-oxide\",\"humanReadableId\":\"Titanium Oxide\",\"label\":\"Titanium Oxide\",\"disabled\":true},{\"id\":\"zirconium-oxide\",\"nodeId\":\"zirconium-oxide\",\"humanReadableId\":\"Zirconium Oxide\",\"label\":\"Zirconium Oxide\",\"disabled\":true}]},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"multi-oxide-ceramics\",\"nodeId\":\"multi-oxide-ceramics\",\"humanReadableId\":\"Multi-Oxide Ceramics\",\"label\":\"Multi-Oxide Ceramics\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide-\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true},{\"id\":\"ytterbium-oxide\",\"nodeId\":\"ytterbium-oxide\",\"humanReadableId\":\"Ytterbium Oxide\",\"label\":\"Ytterbium Oxide\",\"disabled\":true},{\"id\":\"yttrium-oxide\",\"nodeId\":\"yttrium-oxide\",\"humanReadableId\":\"Yttrium Oxide\",\"label\":\"Yttrium Oxide\",\"disabled\":true}]}]},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"humanReadableId\":\"Natural Ceramic\",\"label\":\"Natural Ceramic\",\"disabled\":true}]},{\"id\":\"composite\",\"nodeId\":\"composite\",\"humanReadableId\":\"Composite\",\"label\":\"Composite\",\"disabled\":true,\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"humanReadableId\":\"Ceramic Matrix Composite\",\"label\":\"Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"carbide-based-ceramic-matrix-composite\",\"nodeId\":\"carbide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Carbide Based Ceramic Matrix Composite\",\"label\":\"Carbide Based Ceramic Matrix Composite\",\"disabled\":true},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite-\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true}]},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"humanReadableId\":\"Metal Matrix Composite\",\"label\":\"Metal Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-matrix-composite\",\"nodeId\":\"aluminium-matrix-composite\",\"humanReadableId\":\"Aluminium Matrix Composite\",\"label\":\"Aluminium Matrix Composite\",\"disabled\":true},{\"id\":\"beryllium-matrix-composite\",\"nodeId\":\"beryllium-matrix-composite\",\"humanReadableId\":\"Beryllium Matrix Composite\",\"label\":\"Beryllium Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-matrix-composite\",\"nodeId\":\"cobalt-matrix-composite\",\"humanReadableId\":\"Cobalt Matrix Composite\",\"label\":\"Cobalt Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-and-nickel-matrix-composite\",\"nodeId\":\"cobalt-and-nickel-matrix-composite\",\"humanReadableId\":\"Cobalt and Nickel Matrix Composite\",\"label\":\"Cobalt and Nickel Matrix Composite\",\"disabled\":true},{\"id\":\"iron-matrix-composite\",\"nodeId\":\"iron-matrix-composite\",\"humanReadableId\":\"Iron Matrix Composite\",\"label\":\"Iron Matrix Composite\",\"disabled\":true},{\"id\":\"nickel-matrix-composite\",\"nodeId\":\"nickel-matrix-composite\",\"humanReadableId\":\"Nickel Matrix Composite\",\"label\":\"Nickel Matrix Composite\",\"disabled\":true}]},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"humanReadableId\":\"Polymer Matrix Composite\",\"label\":\"Polymer Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"thermoset-polymer-matrix-composite\",\"nodeId\":\"thermoset-polymer-matrix-composite\",\"humanReadableId\":\"Thermoset Polymer Matrix Composite\",\"label\":\"Thermoset Polymer Matrix Composite\",\"disabled\":true}]}]},{\"id\":\"glass\",\"nodeId\":\"glass\",\"humanReadableId\":\"Glass\",\"label\":\"Glass\",\"disabled\":true,\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"humanReadableId\":\"Glass Ceramic\",\"label\":\"Glass Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"las-glass-ceramic\",\"nodeId\":\"las-glass-ceramic\",\"humanReadableId\":\"LAS Glass Ceramic\",\"label\":\"LAS Glass Ceramic\",\"disabled\":true}]},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"humanReadableId\":\"Lead Glass\",\"label\":\"Lead Glass\",\"disabled\":true},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"humanReadableId\":\"Silicate Glass\",\"label\":\"Silicate Glass\",\"disabled\":true,\"children\":[{\"id\":\"aluminosilicate\",\"nodeId\":\"aluminosilicate\",\"humanReadableId\":\"Aluminosilicate\",\"label\":\"Aluminosilicate\",\"disabled\":true},{\"id\":\"borosilicate\",\"nodeId\":\"borosilicate\",\"humanReadableId\":\"Borosilicate\",\"label\":\"Borosilicate\",\"disabled\":true},{\"id\":\"fused-quartz\",\"nodeId\":\"fused-quartz\",\"humanReadableId\":\"Fused Quartz\",\"label\":\"Fused Quartz\",\"disabled\":true},{\"id\":\"soda-lime-silicate\",\"nodeId\":\"soda-lime-silicate\",\"humanReadableId\":\"Soda Lime Silicate\",\"label\":\"Soda Lime Silicate\",\"disabled\":true}]}]},{\"id\":\"metal\",\"nodeId\":\"metal\",\"humanReadableId\":\"Metal\",\"label\":\"Metal\",\"partiallyChecked\":true,\"materialsCount\":2214,\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"humanReadableId\":\"Aluminium\",\"label\":\"Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-master-alloy\",\"nodeId\":\"aluminium-master-alloy\",\"humanReadableId\":\"Aluminium Master Alloy\",\"label\":\"Aluminium Master Alloy\",\"disabled\":true},{\"id\":\"cast-aluminium\",\"nodeId\":\"cast-aluminium\",\"humanReadableId\":\"Cast Aluminium\",\"label\":\"Cast Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1xx-x\",\"nodeId\":\"1xx-x\",\"humanReadableId\":\"1xx.x\",\"label\":\"1xx.x\",\"disabled\":true},{\"id\":\"2xx-x\",\"nodeId\":\"2xx-x\",\"humanReadableId\":\"2xx.x\",\"label\":\"2xx.x\",\"disabled\":true},{\"id\":\"3xx-x\",\"nodeId\":\"3xx-x\",\"humanReadableId\":\"3xx.x\",\"label\":\"3xx.x\",\"disabled\":true},{\"id\":\"4xx-x\",\"nodeId\":\"4xx-x\",\"humanReadableId\":\"4xx.x\",\"label\":\"4xx.x\",\"disabled\":true},{\"id\":\"5xx-x\",\"nodeId\":\"5xx-x\",\"humanReadableId\":\"5xx.x\",\"label\":\"5xx.x\",\"disabled\":true},{\"id\":\"7xx-x\",\"nodeId\":\"7xx-x\",\"humanReadableId\":\"7xx.x\",\"label\":\"7xx.x\",\"disabled\":true},{\"id\":\"8xx-x\",\"nodeId\":\"8xx-x\",\"humanReadableId\":\"8xx.x\",\"label\":\"8xx.x\",\"disabled\":true}]},{\"id\":\"wrought-aluminium\",\"nodeId\":\"wrought-aluminium\",\"humanReadableId\":\"Wrought Aluminium\",\"label\":\"Wrought Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1000-series\",\"nodeId\":\"1000-series\",\"humanReadableId\":\"1000 Series\",\"label\":\"1000 Series\",\"disabled\":true},{\"id\":\"2000-series\",\"nodeId\":\"2000-series\",\"humanReadableId\":\"2000 Series\",\"label\":\"2000 Series\",\"disabled\":true},{\"id\":\"3000-series\",\"nodeId\":\"3000-series\",\"humanReadableId\":\"3000 Series\",\"label\":\"3000 Series\",\"disabled\":true},{\"id\":\"4000-series\",\"nodeId\":\"4000-series\",\"humanReadableId\":\"4000 Series\",\"label\":\"4000 Series\",\"disabled\":true},{\"id\":\"5000-series\",\"nodeId\":\"5000-series\",\"humanReadableId\":\"5000 Series\",\"label\":\"5000 Series\",\"disabled\":true},{\"id\":\"6000-series\",\"nodeId\":\"6000-series\",\"humanReadableId\":\"6000 Series\",\"label\":\"6000 Series\",\"disabled\":true},{\"id\":\"7000-series\",\"nodeId\":\"7000-series\",\"humanReadableId\":\"7000 Series\",\"label\":\"7000 Series\",\"disabled\":true},{\"id\":\"8000-series\",\"nodeId\":\"8000-series\",\"humanReadableId\":\"8000 Series\",\"label\":\"8000 Series\",\"disabled\":true}]}]},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"humanReadableId\":\"Clad / Bimetal\",\"label\":\"Clad / Bimetal\",\"disabled\":true},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"humanReadableId\":\"Cobalt\",\"label\":\"Cobalt\",\"disabled\":true,\"children\":[{\"id\":\"cobalt-chromium\",\"nodeId\":\"cobalt-chromium\",\"humanReadableId\":\"Cobalt Chromium\",\"label\":\"Cobalt Chromium\",\"disabled\":true},{\"id\":\"cobalt-chromium-molybdenum\",\"nodeId\":\"cobalt-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Chromium Molybdenum\",\"label\":\"Cobalt Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-chromium-nickel-tungsten\",\"nodeId\":\"cobalt-chromium-nickel-tungsten\",\"humanReadableId\":\"Cobalt Chromium Nickel Tungsten\",\"label\":\"Cobalt Chromium Nickel Tungsten\",\"disabled\":true},{\"id\":\"cobalt-chromium-tungsten\",\"nodeId\":\"cobalt-chromium-tungsten\",\"humanReadableId\":\"Cobalt Chromium Tungsten\",\"label\":\"Cobalt Chromium Tungsten\",\"disabled\":true},{\"id\":\"cobalt-nickel-chromium-molybdenum\",\"nodeId\":\"cobalt-nickel-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Nickel Chromium Molybdenum\",\"label\":\"Cobalt Nickel Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-superalloy\",\"nodeId\":\"cobalt-superalloy\",\"humanReadableId\":\"Cobalt Superalloy\",\"label\":\"Cobalt Superalloy\",\"disabled\":true},{\"id\":\"unclassified-cobalt-alloy\",\"nodeId\":\"unclassified-cobalt-alloy\",\"humanReadableId\":\"Unclassified Cobalt Alloy\",\"label\":\"Unclassified Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"copper\",\"nodeId\":\"copper\",\"humanReadableId\":\"Copper\",\"label\":\"Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper\",\"nodeId\":\"cast-copper\",\"humanReadableId\":\"Cast Copper\",\"label\":\"Cast Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass\",\"nodeId\":\"cast-copper-brass\",\"humanReadableId\":\"Cast Copper Brass\",\"label\":\"Cast Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass-yellow-brass\",\"nodeId\":\"cast-copper-brass-yellow-brass\",\"humanReadableId\":\"Cast Copper Brass Yellow Brass\",\"label\":\"Cast Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"cast-copper-silicon-brass\",\"nodeId\":\"cast-copper-silicon-brass\",\"humanReadableId\":\"Cast Copper Silicon Brass\",\"label\":\"Cast Copper Silicon Brass\",\"disabled\":true},{\"id\":\"copper-bismuth-alloy\",\"nodeId\":\"copper-bismuth-alloy\",\"humanReadableId\":\"Copper Bismuth Alloy\",\"label\":\"Copper Bismuth Alloy\",\"disabled\":true},{\"id\":\"red-brass\",\"nodeId\":\"red-brass\",\"humanReadableId\":\"Red Brass\",\"label\":\"Red Brass\",\"disabled\":true}]},{\"id\":\"cast-copper-bronze\",\"nodeId\":\"cast-copper-bronze\",\"humanReadableId\":\"Cast Copper Bronze\",\"label\":\"Cast Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-bronze-aluminium-bronze\",\"nodeId\":\"cast-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Cast Copper Bronze Aluminium Bronze\",\"label\":\"Cast Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"leaded-tin-bronze\",\"nodeId\":\"leaded-tin-bronze\",\"humanReadableId\":\"Leaded Tin Bronze\",\"label\":\"Leaded Tin Bronze\",\"disabled\":true},{\"id\":\"nickel-tin-bronze\",\"nodeId\":\"nickel-tin-bronze\",\"humanReadableId\":\"Nickel Tin Bronze\",\"label\":\"Nickel Tin Bronze\",\"disabled\":true},{\"id\":\"tin-bronze\",\"nodeId\":\"tin-bronze\",\"humanReadableId\":\"Tin Bronze\",\"label\":\"Tin Bronze\",\"disabled\":true}]},{\"id\":\"cast-copper-high-copper-alloy\",\"nodeId\":\"cast-copper-high-copper-alloy\",\"humanReadableId\":\"Cast Copper High Copper Alloy\",\"label\":\"Cast Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"cast-copper-nickel-grade\",\"nodeId\":\"cast-copper-nickel-grade\",\"humanReadableId\":\"Cast Copper Nickel Grade\",\"label\":\"Cast Copper Nickel Grade\",\"disabled\":true},{\"id\":\"cast-copper-nickel-silver-grade\",\"nodeId\":\"cast-copper-nickel-silver-grade\",\"humanReadableId\":\"Cast Copper Nickel Silver Grade\",\"label\":\"Cast Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"cast-copper-pure---low-alloyed-copper\",\"nodeId\":\"cast-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Cast Copper Pure / Low Alloyed Copper\",\"label\":\"Cast Copper Pure / Low Alloyed Copper\",\"disabled\":true},{\"id\":\"copper-lead-alloy\",\"nodeId\":\"copper-lead-alloy\",\"humanReadableId\":\"Copper-Lead Alloy\",\"label\":\"Copper-Lead Alloy\",\"disabled\":true},{\"id\":\"special-alloy\",\"nodeId\":\"special-alloy\",\"humanReadableId\":\"Special Alloy\",\"label\":\"Special Alloy\",\"disabled\":true}]},{\"id\":\"welding\",\"nodeId\":\"welding\",\"humanReadableId\":\"Welding\",\"label\":\"Welding\",\"disabled\":true},{\"id\":\"wrought-copper\",\"nodeId\":\"wrought-copper\",\"humanReadableId\":\"Wrought Copper\",\"label\":\"Wrought Copper\",\"disabled\":true,\"children\":[{\"id\":\"unclassified-wrought-copper\",\"nodeId\":\"unclassified-wrought-copper\",\"humanReadableId\":\"Unclassified Wrought Copper\",\"label\":\"Unclassified Wrought Copper\",\"disabled\":true},{\"id\":\"wrought-copper-brass\",\"nodeId\":\"wrought-copper-brass\",\"humanReadableId\":\"Wrought Copper Brass\",\"label\":\"Wrought Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"leaded-brass\",\"nodeId\":\"leaded-brass\",\"humanReadableId\":\"Leaded Brass\",\"label\":\"Leaded Brass\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"tin-brass\",\"nodeId\":\"tin-brass\",\"humanReadableId\":\"Tin Brass\",\"label\":\"Tin Brass\",\"disabled\":true},{\"id\":\"wrought-copper-brass-yellow-brass\",\"nodeId\":\"wrought-copper-brass-yellow-brass\",\"humanReadableId\":\"Wrought Copper Brass Yellow Brass\",\"label\":\"Wrought Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"yellow-wrought-brass\",\"nodeId\":\"yellow-wrought-brass\",\"humanReadableId\":\"Yellow Wrought Brass\",\"label\":\"Yellow Wrought Brass\",\"disabled\":true}]},{\"id\":\"wrought-copper-bronze\",\"nodeId\":\"wrought-copper-bronze\",\"humanReadableId\":\"Wrought Copper Bronze\",\"label\":\"Wrought Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"copper-silver-zinc-alloy\",\"nodeId\":\"copper-silver-zinc-alloy\",\"humanReadableId\":\"Copper Silver Zinc Alloy\",\"label\":\"Copper Silver Zinc Alloy\",\"disabled\":true},{\"id\":\"leaded-phosphor-bronze\",\"nodeId\":\"leaded-phosphor-bronze\",\"humanReadableId\":\"Leaded Phosphor Bronze\",\"label\":\"Leaded Phosphor Bronze\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy-\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"phosphor-bronze\",\"nodeId\":\"phosphor-bronze\",\"humanReadableId\":\"Phosphor Bronze\",\"label\":\"Phosphor Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-aluminium-bronze\",\"nodeId\":\"wrought-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Aluminium Bronze\",\"label\":\"Wrought Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-silicon-bronze\",\"nodeId\":\"wrought-copper-bronze-silicon-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Silicon Bronze\",\"label\":\"Wrought Copper Bronze Silicon Bronze\",\"disabled\":true}]},{\"id\":\"wrought-copper-high-copper-alloy\",\"nodeId\":\"wrought-copper-high-copper-alloy\",\"humanReadableId\":\"Wrought Copper High Copper Alloy\",\"label\":\"Wrought Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-grade\",\"nodeId\":\"wrought-copper-nickel-grade\",\"humanReadableId\":\"Wrought Copper Nickel Grade\",\"label\":\"Wrought Copper Nickel Grade\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-silver-grade\",\"nodeId\":\"wrought-copper-nickel-silver-grade\",\"humanReadableId\":\"Wrought Copper Nickel Silver Grade\",\"label\":\"Wrought Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"wrought-copper-pure---low-alloyed-copper\",\"nodeId\":\"wrought-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Wrought Copper Pure / Low Alloyed Copper\",\"label\":\"Wrought Copper Pure / Low Alloyed Copper\",\"disabled\":true}]}]},{\"id\":\"iron\",\"nodeId\":\"iron\",\"humanReadableId\":\"Iron\",\"label\":\"Iron\",\"disabled\":true,\"children\":[{\"id\":\"alloy-iron\",\"nodeId\":\"alloy-iron\",\"humanReadableId\":\"Alloy Iron\",\"label\":\"Alloy Iron\",\"disabled\":true},{\"id\":\"cast-iron\",\"nodeId\":\"cast-iron\",\"humanReadableId\":\"Cast Iron\",\"label\":\"Cast Iron\",\"disabled\":true,\"children\":[{\"id\":\"ductile--nodular--cast-iron\",\"nodeId\":\"ductile--nodular--cast-iron\",\"humanReadableId\":\"Ductile (Nodular) Cast Iron\",\"label\":\"Ductile (Nodular) Cast Iron\",\"disabled\":true},{\"id\":\"grey-cast-iron\",\"nodeId\":\"grey-cast-iron\",\"humanReadableId\":\"Grey Cast Iron\",\"label\":\"Grey Cast Iron\",\"disabled\":true},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true},{\"id\":\"other-cast-iron-alloy\",\"nodeId\":\"other-cast-iron-alloy\",\"humanReadableId\":\"Other Cast Iron Alloy\",\"label\":\"Other Cast Iron Alloy\",\"disabled\":true},{\"id\":\"white-cast-iron\",\"nodeId\":\"white-cast-iron\",\"humanReadableId\":\"White Cast Iron\",\"label\":\"White Cast Iron\",\"disabled\":true}]},{\"id\":\"ferromolybdenum\",\"nodeId\":\"ferromolybdenum\",\"humanReadableId\":\"Ferromolybdenum\",\"label\":\"Ferromolybdenum\",\"disabled\":true},{\"id\":\"ferrosilicon\",\"nodeId\":\"ferrosilicon\",\"humanReadableId\":\"Ferrosilicon\",\"label\":\"Ferrosilicon\",\"disabled\":true},{\"id\":\"ferrovanadium\",\"nodeId\":\"ferrovanadium\",\"humanReadableId\":\"Ferrovanadium\",\"label\":\"Ferrovanadium\",\"disabled\":true},{\"id\":\"iron-alloy\",\"nodeId\":\"iron-alloy\",\"humanReadableId\":\"Iron Alloy\",\"label\":\"Iron Alloy\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nickel-cobalt-iron-alloy\",\"nodeId\":\"aluminium-nickel-cobalt-iron-alloy\",\"humanReadableId\":\"Aluminium Nickel Cobalt Iron Alloy\",\"label\":\"Aluminium Nickel Cobalt Iron Alloy\",\"disabled\":true},{\"id\":\"miscellaneous-iron-alloy\",\"nodeId\":\"miscellaneous-iron-alloy\",\"humanReadableId\":\"Miscellaneous Iron Alloy\",\"label\":\"Miscellaneous Iron Alloy\",\"disabled\":true},{\"id\":\"soft-magnetic-iron\",\"nodeId\":\"soft-magnetic-iron\",\"humanReadableId\":\"Soft Magnetic Iron\",\"label\":\"Soft Magnetic Iron\",\"disabled\":true}]},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron-\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true}]},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"humanReadableId\":\"Magnesium\",\"label\":\"Magnesium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-grade\",\"nodeId\":\"aluminium-grade\",\"humanReadableId\":\"Aluminium Grade\",\"label\":\"Aluminium Grade\",\"disabled\":true},{\"id\":\"cast-aluminium-manganese-grade\",\"nodeId\":\"cast-aluminium-manganese-grade\",\"humanReadableId\":\"Cast Aluminium Manganese Grade\",\"label\":\"Cast Aluminium Manganese Grade\",\"disabled\":true},{\"id\":\"cast-rare-earth-grade\",\"nodeId\":\"cast-rare-earth-grade\",\"humanReadableId\":\"Cast Rare Earth Grade\",\"label\":\"Cast Rare Earth Grade\",\"disabled\":true},{\"id\":\"cast-wrought-aluminium-zinc-grade\",\"nodeId\":\"cast-wrought-aluminium-zinc-grade\",\"humanReadableId\":\"Cast/Wrought Aluminium Zinc Grade\",\"label\":\"Cast/Wrought Aluminium Zinc Grade\",\"disabled\":true},{\"id\":\"cast-wrought-unclassified-grade\",\"nodeId\":\"cast-wrought-unclassified-grade\",\"humanReadableId\":\"Cast/Wrought Unclassified Grade\",\"label\":\"Cast/Wrought Unclassified Grade\",\"disabled\":true},{\"id\":\"pure-magnesium\",\"nodeId\":\"pure-magnesium\",\"humanReadableId\":\"Pure Magnesium\",\"label\":\"Pure Magnesium\",\"disabled\":true},{\"id\":\"rare-earth-grade\",\"nodeId\":\"rare-earth-grade\",\"humanReadableId\":\"Rare Earth Grade\",\"label\":\"Rare Earth Grade\",\"disabled\":true},{\"id\":\"wrought-zinc-grade\",\"nodeId\":\"wrought-zinc-grade\",\"humanReadableId\":\"Wrought Zinc Grade\",\"label\":\"Wrought Zinc Grade\",\"disabled\":true},{\"id\":\"yttrium-grade\",\"nodeId\":\"yttrium-grade\",\"humanReadableId\":\"Yttrium Grade\",\"label\":\"Yttrium Grade\",\"disabled\":true},{\"id\":\"zinc-grade\",\"nodeId\":\"zinc-grade\",\"humanReadableId\":\"Zinc Grade\",\"label\":\"Zinc Grade\",\"disabled\":true}]},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"humanReadableId\":\"Manganese\",\"label\":\"Manganese\",\"disabled\":true},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"humanReadableId\":\"Nickel\",\"label\":\"Nickel\",\"disabled\":true,\"children\":[{\"id\":\"nickel-chromium-alloy\",\"nodeId\":\"nickel-chromium-alloy\",\"humanReadableId\":\"Nickel Chromium Alloy\",\"label\":\"Nickel Chromium Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-cobalt-alloy\",\"nodeId\":\"nickel-chromium-cobalt-alloy\",\"humanReadableId\":\"Nickel Chromium Cobalt Alloy\",\"label\":\"Nickel Chromium Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-iron-alloy\",\"nodeId\":\"nickel-chromium-iron-alloy\",\"humanReadableId\":\"Nickel Chromium Iron Alloy\",\"label\":\"Nickel Chromium Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-molybdenum-alloy\",\"nodeId\":\"nickel-chromium-molybdenum-alloy\",\"humanReadableId\":\"Nickel Chromium Molybdenum Alloy\",\"label\":\"Nickel Chromium Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-cobalt-alloy\",\"nodeId\":\"nickel-cobalt-alloy\",\"humanReadableId\":\"Nickel Cobalt Alloy\",\"label\":\"Nickel Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-copper-alloy\",\"nodeId\":\"nickel-copper-alloy\",\"humanReadableId\":\"Nickel Copper Alloy\",\"label\":\"Nickel Copper Alloy\",\"disabled\":true},{\"id\":\"nickel-iron-alloy\",\"nodeId\":\"nickel-iron-alloy\",\"humanReadableId\":\"Nickel Iron Alloy\",\"label\":\"Nickel Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-molybdenum-alloy\",\"nodeId\":\"nickel-molybdenum-alloy\",\"humanReadableId\":\"Nickel Molybdenum Alloy\",\"label\":\"Nickel Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-superalloy\",\"nodeId\":\"nickel-superalloy\",\"humanReadableId\":\"Nickel Superalloy\",\"label\":\"Nickel Superalloy\",\"disabled\":true},{\"id\":\"nickel-welding-filler\",\"nodeId\":\"nickel-welding-filler\",\"humanReadableId\":\"Nickel Welding Filler\",\"label\":\"Nickel Welding Filler\",\"disabled\":true},{\"id\":\"other-nickel-alloy\",\"nodeId\":\"other-nickel-alloy\",\"humanReadableId\":\"Other Nickel Alloy\",\"label\":\"Other Nickel Alloy\",\"disabled\":true},{\"id\":\"pure-low-nickel-alloy\",\"nodeId\":\"pure-low-nickel-alloy\",\"humanReadableId\":\"Pure/Low Nickel Alloy\",\"label\":\"Pure/Low Nickel Alloy\",\"disabled\":true}]},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"humanReadableId\":\"Noble Metal\",\"label\":\"Noble Metal\",\"disabled\":true,\"children\":[{\"id\":\"gold\",\"nodeId\":\"gold\",\"humanReadableId\":\"Gold\",\"label\":\"Gold\",\"disabled\":true},{\"id\":\"iridium\",\"nodeId\":\"iridium\",\"humanReadableId\":\"Iridium\",\"label\":\"Iridium\",\"disabled\":true},{\"id\":\"palladium\",\"nodeId\":\"palladium\",\"humanReadableId\":\"Palladium\",\"label\":\"Palladium\",\"disabled\":true},{\"id\":\"platinum\",\"nodeId\":\"platinum\",\"humanReadableId\":\"Platinum\",\"label\":\"Platinum\",\"disabled\":true},{\"id\":\"rhodium\",\"nodeId\":\"rhodium\",\"humanReadableId\":\"Rhodium\",\"label\":\"Rhodium\",\"disabled\":true},{\"id\":\"silver\",\"nodeId\":\"silver\",\"humanReadableId\":\"Silver\",\"label\":\"Silver\",\"disabled\":true}]},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"humanReadableId\":\"Other Metal\",\"label\":\"Other Metal\",\"disabled\":true,\"children\":[{\"id\":\"beryllium\",\"nodeId\":\"beryllium\",\"humanReadableId\":\"Beryllium\",\"label\":\"Beryllium\",\"disabled\":true},{\"id\":\"cadmium\",\"nodeId\":\"cadmium\",\"humanReadableId\":\"Cadmium\",\"label\":\"Cadmium\",\"disabled\":true},{\"id\":\"chromium\",\"nodeId\":\"chromium\",\"humanReadableId\":\"Chromium\",\"label\":\"Chromium\",\"disabled\":true},{\"id\":\"lead\",\"nodeId\":\"lead\",\"humanReadableId\":\"Lead\",\"label\":\"Lead\",\"disabled\":true,\"children\":[{\"id\":\"lead-antimony\",\"nodeId\":\"lead-antimony\",\"humanReadableId\":\"Lead Antimony\",\"label\":\"Lead Antimony\",\"disabled\":true},{\"id\":\"lead-tin\",\"nodeId\":\"lead-tin\",\"humanReadableId\":\"Lead Tin\",\"label\":\"Lead Tin\",\"disabled\":true},{\"id\":\"pure-low-alloyed-lead\",\"nodeId\":\"pure-low-alloyed-lead\",\"humanReadableId\":\"Pure/Low Alloyed Lead\",\"label\":\"Pure/Low Alloyed Lead\",\"disabled\":true}]},{\"id\":\"lithium\",\"nodeId\":\"lithium\",\"humanReadableId\":\"Lithium\",\"label\":\"Lithium\",\"disabled\":true},{\"id\":\"neodymium\",\"nodeId\":\"neodymium\",\"humanReadableId\":\"Neodymium\",\"label\":\"Neodymium\",\"disabled\":true,\"children\":[{\"id\":\"neodymium-iron-boron-alloy\",\"nodeId\":\"neodymium-iron-boron-alloy\",\"humanReadableId\":\"Neodymium Iron Boron Alloy\",\"label\":\"Neodymium Iron Boron Alloy\",\"disabled\":true}]},{\"id\":\"samarium\",\"nodeId\":\"samarium\",\"humanReadableId\":\"Samarium\",\"label\":\"Samarium\",\"disabled\":true,\"children\":[{\"id\":\"samarium-cobalt-alloy\",\"nodeId\":\"samarium-cobalt-alloy\",\"humanReadableId\":\"Samarium Cobalt Alloy\",\"label\":\"Samarium Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"tin\",\"nodeId\":\"tin\",\"humanReadableId\":\"Tin\",\"label\":\"Tin\",\"disabled\":true,\"children\":[{\"id\":\"pure-low-alloyed-tin\",\"nodeId\":\"pure-low-alloyed-tin\",\"humanReadableId\":\"Pure/Low Alloyed Tin\",\"label\":\"Pure/Low Alloyed Tin\",\"disabled\":true},{\"id\":\"tin-antimony\",\"nodeId\":\"tin-antimony\",\"humanReadableId\":\"Tin Antimony\",\"label\":\"Tin Antimony\",\"disabled\":true},{\"id\":\"tin-lead\",\"nodeId\":\"tin-lead\",\"humanReadableId\":\"Tin Lead\",\"label\":\"Tin Lead\",\"disabled\":true},{\"id\":\"unclassified-tin\",\"nodeId\":\"unclassified-tin\",\"humanReadableId\":\"Unclassified Tin\",\"label\":\"Unclassified Tin\",\"disabled\":true}]},{\"id\":\"zinc\",\"nodeId\":\"zinc\",\"humanReadableId\":\"Zinc\",\"label\":\"Zinc\",\"disabled\":true,\"children\":[{\"id\":\"unalloyed-zinc\",\"nodeId\":\"unalloyed-zinc\",\"humanReadableId\":\"Unalloyed Zinc\",\"label\":\"Unalloyed Zinc\",\"disabled\":true},{\"id\":\"unclassified-zinc\",\"nodeId\":\"unclassified-zinc\",\"humanReadableId\":\"Unclassified Zinc\",\"label\":\"Unclassified Zinc\",\"disabled\":true},{\"id\":\"zinc-aluminium\",\"nodeId\":\"zinc-aluminium\",\"humanReadableId\":\"Zinc Aluminium\",\"label\":\"Zinc Aluminium\",\"disabled\":true}]}]},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"humanReadableId\":\"Refractory Metal\",\"label\":\"Refractory Metal\",\"disabled\":true,\"children\":[{\"id\":\"hafnium\",\"nodeId\":\"hafnium\",\"humanReadableId\":\"Hafnium\",\"label\":\"Hafnium\",\"disabled\":true},{\"id\":\"molybdenum\",\"nodeId\":\"molybdenum\",\"humanReadableId\":\"Molybdenum\",\"label\":\"Molybdenum\",\"disabled\":true},{\"id\":\"niobium\",\"nodeId\":\"niobium\",\"humanReadableId\":\"Niobium\",\"label\":\"Niobium\",\"disabled\":true},{\"id\":\"rhenium\",\"nodeId\":\"rhenium\",\"humanReadableId\":\"Rhenium\",\"label\":\"Rhenium\",\"disabled\":true},{\"id\":\"tantalum\",\"nodeId\":\"tantalum\",\"humanReadableId\":\"Tantalum\",\"label\":\"Tantalum\",\"disabled\":true},{\"id\":\"tungsten\",\"nodeId\":\"tungsten\",\"humanReadableId\":\"Tungsten\",\"label\":\"Tungsten\",\"disabled\":true},{\"id\":\"vanadium\",\"nodeId\":\"vanadium\",\"humanReadableId\":\"Vanadium\",\"label\":\"Vanadium\",\"disabled\":true},{\"id\":\"zirconium\",\"nodeId\":\"zirconium\",\"humanReadableId\":\"Zirconium\",\"label\":\"Zirconium\",\"disabled\":true}]},{\"id\":\"steel\",\"nodeId\":\"steel\",\"humanReadableId\":\"Steel\",\"label\":\"Steel\",\"checked\":true,\"children\":[{\"id\":\"alloy-steel\",\"nodeId\":\"alloy-steel\",\"humanReadableId\":\"Alloy Steel\",\"label\":\"Alloy Steel\",\"checked\":true,\"children\":[{\"id\":\"chromium-molybdenum-steel\",\"nodeId\":\"chromium-molybdenum-steel\",\"humanReadableId\":\"Chromium Molybdenum Steel\",\"label\":\"Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"chromium-molybdenum-vanadium-steel\",\"nodeId\":\"chromium-molybdenum-vanadium-steel\",\"humanReadableId\":\"Chromium Molybdenum Vanadium Steel\",\"label\":\"Chromium Molybdenum Vanadium Steel\",\"checked\":true},{\"id\":\"chromium-steel\",\"nodeId\":\"chromium-steel\",\"humanReadableId\":\"Chromium Steel\",\"label\":\"Chromium Steel\",\"checked\":true},{\"id\":\"chromium-vanadium-steel\",\"nodeId\":\"chromium-vanadium-steel\",\"humanReadableId\":\"Chromium Vanadium Steel\",\"label\":\"Chromium Vanadium Steel\",\"checked\":true},{\"id\":\"manganese-steel\",\"nodeId\":\"manganese-steel\",\"humanReadableId\":\"Manganese Steel\",\"label\":\"Manganese Steel\",\"checked\":true},{\"id\":\"molybdenum-steel\",\"nodeId\":\"molybdenum-steel\",\"humanReadableId\":\"Molybdenum Steel\",\"label\":\"Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-molybdenum-steel\",\"nodeId\":\"nickel-chromium-molybdenum-steel\",\"humanReadableId\":\"Nickel Chromium Molybdenum Steel\",\"label\":\"Nickel Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-steel\",\"nodeId\":\"nickel-chromium-steel\",\"humanReadableId\":\"Nickel Chromium Steel\",\"label\":\"Nickel Chromium Steel\",\"checked\":true},{\"id\":\"nickel-molybdenum-steel\",\"nodeId\":\"nickel-molybdenum-steel\",\"humanReadableId\":\"Nickel Molybdenum Steel\",\"label\":\"Nickel Molybdenum Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"nickel-steel\",\"nodeId\":\"nickel-steel\",\"humanReadableId\":\"Nickel Steel\",\"label\":\"Nickel Steel\",\"checked\":true},{\"id\":\"nitriding-steel\",\"nodeId\":\"nitriding-steel\",\"humanReadableId\":\"Nitriding Steel\",\"label\":\"Nitriding Steel\",\"checked\":true},{\"id\":\"silicon-manganese-steel\",\"nodeId\":\"silicon-manganese-steel\",\"humanReadableId\":\"Silicon Manganese Steel\",\"label\":\"Silicon Manganese Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"silicon-steel\",\"nodeId\":\"silicon-steel\",\"humanReadableId\":\"Silicon Steel\",\"label\":\"Silicon Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"unclassified-low-alloy-steel\",\"nodeId\":\"unclassified-low-alloy-steel\",\"humanReadableId\":\"Unclassified Low Alloy Steel\",\"label\":\"Unclassified Low Alloy Steel\",\"checked\":true}]},{\"id\":\"carbon-steel\",\"nodeId\":\"carbon-steel\",\"humanReadableId\":\"Carbon Steel\",\"label\":\"Carbon Steel\",\"checked\":true,\"children\":[{\"id\":\"high-carbon-steel\",\"nodeId\":\"high-carbon-steel\",\"humanReadableId\":\"High Carbon Steel\",\"label\":\"High Carbon Steel\",\"checked\":true},{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true},{\"id\":\"medium-carbon-steel\",\"nodeId\":\"medium-carbon-steel\",\"humanReadableId\":\"Medium Carbon Steel\",\"label\":\"Medium Carbon Steel\",\"checked\":true},{\"id\":\"unclassified-carbon-steel\",\"nodeId\":\"unclassified-carbon-steel\",\"humanReadableId\":\"Unclassified Carbon Steel\",\"label\":\"Unclassified Carbon Steel\",\"checked\":true}]},{\"id\":\"low-alloy-steel\",\"nodeId\":\"low-alloy-steel\",\"humanReadableId\":\"Low Alloy Steel\",\"label\":\"Low Alloy Steel\",\"checked\":true,\"disabled\":true,\"children\":[{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel-\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"disabled\":true}]},{\"id\":\"maraging-steel\",\"nodeId\":\"maraging-steel\",\"humanReadableId\":\"Maraging Steel\",\"label\":\"Maraging Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"stainless-steel\",\"nodeId\":\"stainless-steel\",\"humanReadableId\":\"Stainless Steel\",\"label\":\"Stainless Steel\",\"checked\":true,\"children\":[{\"id\":\"austenitic-stainless-steel\",\"nodeId\":\"austenitic-stainless-steel\",\"humanReadableId\":\"Austenitic Stainless Steel\",\"label\":\"Austenitic Stainless Steel\",\"checked\":true},{\"id\":\"duplex-stainless-steel\",\"nodeId\":\"duplex-stainless-steel\",\"humanReadableId\":\"Duplex Stainless Steel\",\"label\":\"Duplex Stainless Steel\",\"checked\":true},{\"id\":\"ferritic-stainless-steel\",\"nodeId\":\"ferritic-stainless-steel\",\"humanReadableId\":\"Ferritic Stainless Steel\",\"label\":\"Ferritic Stainless Steel\",\"checked\":true},{\"id\":\"martensitic-stainless-steel\",\"nodeId\":\"martensitic-stainless-steel\",\"humanReadableId\":\"Martensitic Stainless Steel\",\"label\":\"Martensitic Stainless Steel\",\"checked\":true},{\"id\":\"precipitation-hardening-stainless-steel\",\"nodeId\":\"precipitation-hardening-stainless-steel\",\"humanReadableId\":\"Precipitation Hardening Stainless Steel\",\"label\":\"Precipitation Hardening Stainless Steel\",\"checked\":true},{\"id\":\"superaustenitic-stainless-steel\",\"nodeId\":\"superaustenitic-stainless-steel\",\"humanReadableId\":\"Superaustenitic Stainless Steel\",\"label\":\"Superaustenitic Stainless Steel\",\"checked\":true},{\"id\":\"unclassified-stainless-steel\",\"nodeId\":\"unclassified-stainless-steel\",\"humanReadableId\":\"Unclassified Stainless Steel\",\"label\":\"Unclassified Stainless Steel\",\"checked\":true}]},{\"id\":\"tool-and-machining-steel\",\"nodeId\":\"tool-and-machining-steel\",\"humanReadableId\":\"Tool And Machining Steel\",\"label\":\"Tool And Machining Steel\",\"checked\":true}]},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"humanReadableId\":\"Titanium\",\"label\":\"Titanium\",\"disabled\":true,\"children\":[{\"id\":\"alpha-alloy\",\"nodeId\":\"alpha-alloy\",\"humanReadableId\":\"Alpha Alloy\",\"label\":\"Alpha Alloy\",\"disabled\":true},{\"id\":\"alpha-beta-alloy\",\"nodeId\":\"alpha-beta-alloy\",\"humanReadableId\":\"Alpha Beta Alloy\",\"label\":\"Alpha Beta Alloy\",\"disabled\":true},{\"id\":\"beta-alloy\",\"nodeId\":\"beta-alloy\",\"humanReadableId\":\"Beta Alloy\",\"label\":\"Beta Alloy\",\"disabled\":true},{\"id\":\"low-alloy-titanium\",\"nodeId\":\"low-alloy-titanium\",\"humanReadableId\":\"Low Alloy Titanium\",\"label\":\"Low Alloy Titanium\",\"disabled\":true},{\"id\":\"near-alpha-alloy\",\"nodeId\":\"near-alpha-alloy\",\"humanReadableId\":\"Near Alpha Alloy\",\"label\":\"Near Alpha Alloy\",\"disabled\":true},{\"id\":\"pure-titanium\",\"nodeId\":\"pure-titanium\",\"humanReadableId\":\"Pure Titanium\",\"label\":\"Pure Titanium\",\"disabled\":true}]}]},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"humanReadableId\":\"Polymer\",\"label\":\"Polymer\",\"disabled\":true,\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"humanReadableId\":\"Elastomer\",\"label\":\"Elastomer\",\"disabled\":true,\"children\":[{\"id\":\"butadiene-rubber--br-\",\"nodeId\":\"butadiene-rubber--br-\",\"humanReadableId\":\"Butadiene Rubber (BR)\",\"label\":\"Butadiene Rubber (BR)\",\"disabled\":true},{\"id\":\"chloroprene-rubber--cr-\",\"nodeId\":\"chloroprene-rubber--cr-\",\"humanReadableId\":\"Chloroprene Rubber (CR)\",\"label\":\"Chloroprene Rubber (CR)\",\"disabled\":true},{\"id\":\"ethylene-propylene-diene-rubber--epdm-\",\"nodeId\":\"ethylene-propylene-diene-rubber--epdm-\",\"humanReadableId\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"label\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"disabled\":true},{\"id\":\"ethylene-propylene-rubber--epr-\",\"nodeId\":\"ethylene-propylene-rubber--epr-\",\"humanReadableId\":\"Ethylene Propylene Rubber (EPR)\",\"label\":\"Ethylene Propylene Rubber (EPR)\",\"disabled\":true},{\"id\":\"fluorosilicone-rubber--fvmq-\",\"nodeId\":\"fluorosilicone-rubber--fvmq-\",\"humanReadableId\":\"Fluorosilicone Rubber (FVMQ)\",\"label\":\"Fluorosilicone Rubber (FVMQ)\",\"disabled\":true},{\"id\":\"natural-rubber--nr-\",\"nodeId\":\"natural-rubber--nr-\",\"humanReadableId\":\"Natural Rubber (NR)\",\"label\":\"Natural Rubber (NR)\",\"disabled\":true},{\"id\":\"nitrile-rubber--nbr-\",\"nodeId\":\"nitrile-rubber--nbr-\",\"humanReadableId\":\"Nitrile Rubber (NBR)\",\"label\":\"Nitrile Rubber (NBR)\",\"disabled\":true},{\"id\":\"styrene-butadiene-rubber--sbr-\",\"nodeId\":\"styrene-butadiene-rubber--sbr-\",\"humanReadableId\":\"Styrene Butadiene Rubber (SBR)\",\"label\":\"Styrene Butadiene Rubber (SBR)\",\"disabled\":true},{\"id\":\"thermoplastic-elastomer--tpe-\",\"nodeId\":\"thermoplastic-elastomer--tpe-\",\"humanReadableId\":\"Thermoplastic Elastomer (TPE)\",\"label\":\"Thermoplastic Elastomer (TPE)\",\"disabled\":true,\"children\":[{\"id\":\"elastomeric-alloy--tpv-\",\"nodeId\":\"elastomeric-alloy--tpv-\",\"humanReadableId\":\"Elastomeric Alloy (TPV)\",\"label\":\"Elastomeric Alloy (TPV)\",\"disabled\":true},{\"id\":\"styrene-butadiene-styrene--sbs-\",\"nodeId\":\"styrene-butadiene-styrene--sbs-\",\"humanReadableId\":\"Styrene Butadiene Styrene (SBS)\",\"label\":\"Styrene Butadiene Styrene (SBS)\",\"disabled\":true},{\"id\":\"thermoplastic-copolyester--tpc-\",\"nodeId\":\"thermoplastic-copolyester--tpc-\",\"humanReadableId\":\"Thermoplastic Copolyester (TPC)\",\"label\":\"Thermoplastic Copolyester (TPC)\",\"disabled\":true},{\"id\":\"thermoplastic-polyamide--tpa-\",\"nodeId\":\"thermoplastic-polyamide--tpa-\",\"humanReadableId\":\"Thermoplastic Polyamide (TPA)\",\"label\":\"Thermoplastic Polyamide (TPA)\",\"disabled\":true},{\"id\":\"thermoplastic-polyester-elastomer--tpee-\",\"nodeId\":\"thermoplastic-polyester-elastomer--tpee-\",\"humanReadableId\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"label\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"disabled\":true},{\"id\":\"thermoplastic-polyolefin--tpo-\",\"nodeId\":\"thermoplastic-polyolefin--tpo-\",\"humanReadableId\":\"Thermoplastic Polyolefin (TPO)\",\"label\":\"Thermoplastic Polyolefin (TPO)\",\"disabled\":true},{\"id\":\"thermoplastic-polyurethane--tpu-\",\"nodeId\":\"thermoplastic-polyurethane--tpu-\",\"humanReadableId\":\"Thermoplastic Polyurethane (TPU)\",\"label\":\"Thermoplastic Polyurethane (TPU)\",\"disabled\":true},{\"id\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"nodeId\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"humanReadableId\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"label\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"disabled\":true}]}]},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"humanReadableId\":\"Thermoplastic\",\"label\":\"Thermoplastic\",\"disabled\":true,\"children\":[{\"id\":\"acrylic\",\"nodeId\":\"acrylic\",\"humanReadableId\":\"Acrylic\",\"label\":\"Acrylic\",\"disabled\":true,\"children\":[{\"id\":\"polyacrylonitrile--pan-\",\"nodeId\":\"polyacrylonitrile--pan-\",\"humanReadableId\":\"Polyacrylonitrile (PAN)\",\"label\":\"Polyacrylonitrile (PAN)\",\"disabled\":true},{\"id\":\"polymethyl-methacrylate--pmma-\",\"nodeId\":\"polymethyl-methacrylate--pmma-\",\"humanReadableId\":\"Polymethyl methacrylate (PMMA)\",\"label\":\"Polymethyl methacrylate (PMMA)\",\"disabled\":true}]},{\"id\":\"fluoropolymer\",\"nodeId\":\"fluoropolymer\",\"humanReadableId\":\"Fluoropolymer\",\"label\":\"Fluoropolymer\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"nodeId\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"humanReadableId\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"label\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"disabled\":true},{\"id\":\"fluorinated-ethylene-propylene--fep-\",\"nodeId\":\"fluorinated-ethylene-propylene--fep-\",\"humanReadableId\":\"Fluorinated ethylene propylene (FEP)\",\"label\":\"Fluorinated ethylene propylene (FEP)\",\"disabled\":true},{\"id\":\"polytetrafluoroethylene--ptfe-\",\"nodeId\":\"polytetrafluoroethylene--ptfe-\",\"humanReadableId\":\"Polytetrafluoroethylene (PTFE)\",\"label\":\"Polytetrafluoroethylene (PTFE)\",\"disabled\":true},{\"id\":\"polyvinylidenefluoride--pvdf-\",\"nodeId\":\"polyvinylidenefluoride--pvdf-\",\"humanReadableId\":\"Polyvinylidenefluoride (PVDF)\",\"label\":\"Polyvinylidenefluoride (PVDF)\",\"disabled\":true}]},{\"id\":\"liquid-crystal-polymers--lcp-\",\"nodeId\":\"liquid-crystal-polymers--lcp-\",\"humanReadableId\":\"Liquid Crystal Polymers (LCP)\",\"label\":\"Liquid Crystal Polymers (LCP)\",\"disabled\":true},{\"id\":\"polyamide--pa-\",\"nodeId\":\"polyamide--pa-\",\"humanReadableId\":\"Polyamide (PA)\",\"label\":\"Polyamide (PA)\",\"disabled\":true,\"children\":[{\"id\":\"aramide\",\"nodeId\":\"aramide\",\"humanReadableId\":\"Aramide\",\"label\":\"Aramide\",\"disabled\":true},{\"id\":\"copolyamide-6-66--pa6-66-\",\"nodeId\":\"copolyamide-6-66--pa6-66-\",\"humanReadableId\":\"Copolyamide 6/66 (PA6/66)\",\"label\":\"Copolyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"other-polyamide--pa-\",\"nodeId\":\"other-polyamide--pa-\",\"humanReadableId\":\"Other Polyamide (PA)\",\"label\":\"Other Polyamide (PA)\",\"disabled\":true},{\"id\":\"polyamide-1010--pa1010-\",\"nodeId\":\"polyamide-1010--pa1010-\",\"humanReadableId\":\"Polyamide 1010 (PA1010)\",\"label\":\"Polyamide 1010 (PA1010)\",\"disabled\":true},{\"id\":\"polyamide-1012--pa1012-\",\"nodeId\":\"polyamide-1012--pa1012-\",\"humanReadableId\":\"Polyamide 1012 (PA1012)\",\"label\":\"Polyamide 1012 (PA1012)\",\"disabled\":true},{\"id\":\"polyamide-11--pa11-\",\"nodeId\":\"polyamide-11--pa11-\",\"humanReadableId\":\"Polyamide 11 (PA11)\",\"label\":\"Polyamide 11 (PA11)\",\"disabled\":true},{\"id\":\"polyamide-12--pa12-\",\"nodeId\":\"polyamide-12--pa12-\",\"humanReadableId\":\"Polyamide 12 (PA12)\",\"label\":\"Polyamide 12 (PA12)\",\"disabled\":true},{\"id\":\"polyamide-410--pa410-\",\"nodeId\":\"polyamide-410--pa410-\",\"humanReadableId\":\"Polyamide 410 (PA410)\",\"label\":\"Polyamide 410 (PA410)\",\"disabled\":true},{\"id\":\"polyamide-46--pa46-\",\"nodeId\":\"polyamide-46--pa46-\",\"humanReadableId\":\"Polyamide 46 (PA46)\",\"label\":\"Polyamide 46 (PA46)\",\"disabled\":true},{\"id\":\"polyamide-6--pa6-\",\"nodeId\":\"polyamide-6--pa6-\",\"humanReadableId\":\"Polyamide 6 (PA6)\",\"label\":\"Polyamide 6 (PA6)\",\"disabled\":true,\"children\":[{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t-\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true}]},{\"id\":\"polyamide-6-66--pa6-66-\",\"nodeId\":\"polyamide-6-66--pa6-66-\",\"humanReadableId\":\"Polyamide 6/66 (PA6/66)\",\"label\":\"Polyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"polyamide-610--pa610-\",\"nodeId\":\"polyamide-610--pa610-\",\"humanReadableId\":\"Polyamide 610 (PA610)\",\"label\":\"Polyamide 610 (PA610)\",\"disabled\":true},{\"id\":\"polyamide-612--pa612-\",\"nodeId\":\"polyamide-612--pa612-\",\"humanReadableId\":\"Polyamide 612 (PA612)\",\"label\":\"Polyamide 612 (PA612)\",\"disabled\":true},{\"id\":\"polyamide-66--pa66-\",\"nodeId\":\"polyamide-66--pa66-\",\"humanReadableId\":\"Polyamide 66 (PA66)\",\"label\":\"Polyamide 66 (PA66)\",\"disabled\":true},{\"id\":\"polyphthalamide--ppa-\",\"nodeId\":\"polyphthalamide--ppa-\",\"humanReadableId\":\"Polyphthalamide (PPA)\",\"label\":\"Polyphthalamide (PPA)\",\"disabled\":true,\"children\":[{\"id\":\"copolyamide-66-6i--pa66-6i-\",\"nodeId\":\"copolyamide-66-6i--pa66-6i-\",\"humanReadableId\":\"Copolyamide 66/6I (PA66/6I)\",\"label\":\"Copolyamide 66/6I (PA66/6I)\",\"disabled\":true},{\"id\":\"copolyamide-6t-66--pa6t-66-\",\"nodeId\":\"copolyamide-6t-66--pa6t-66-\",\"humanReadableId\":\"Copolyamide 6T/66 (PA6T/66)\",\"label\":\"Copolyamide 6T/66 (PA6T/66)\",\"disabled\":true},{\"id\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"nodeId\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"humanReadableId\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"label\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"disabled\":true},{\"id\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"nodeId\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"humanReadableId\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"label\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"disabled\":true},{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t--\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true},{\"id\":\"polyamide-6t--pa6t-\",\"nodeId\":\"polyamide-6t--pa6t-\",\"humanReadableId\":\"Polyamide 6T (PA6T)\",\"label\":\"Polyamide 6T (PA6T)\",\"disabled\":true},{\"id\":\"polyamide-mxd6--pamxd6-\",\"nodeId\":\"polyamide-mxd6--pamxd6-\",\"humanReadableId\":\"Polyamide MXD6 (PAMXD6)\",\"label\":\"Polyamide MXD6 (PAMXD6)\",\"disabled\":true},{\"id\":\"polyamide-pa6-6t--pa6-6t-\",\"nodeId\":\"polyamide-pa6-6t--pa6-6t-\",\"humanReadableId\":\"Polyamide PA6/6T (PA6/6T)\",\"label\":\"Polyamide PA6/6T (PA6/6T)\",\"disabled\":true}]}]},{\"id\":\"polyaryletherketone--paek-\",\"nodeId\":\"polyaryletherketone--paek-\",\"humanReadableId\":\"Polyaryletherketone (PAEK)\",\"label\":\"Polyaryletherketone (PAEK)\",\"disabled\":true,\"children\":[{\"id\":\"polyether-ketone--pek-\",\"nodeId\":\"polyether-ketone--pek-\",\"humanReadableId\":\"Polyether Ketone (PEK)\",\"label\":\"Polyether Ketone (PEK)\",\"disabled\":true},{\"id\":\"polyetherether-ketone--peek-\",\"nodeId\":\"polyetherether-ketone--peek-\",\"humanReadableId\":\"Polyetherether Ketone (PEEK)\",\"label\":\"Polyetherether Ketone (PEEK)\",\"disabled\":true},{\"id\":\"polyetherketoneketone--pekk-\",\"nodeId\":\"polyetherketoneketone--pekk-\",\"humanReadableId\":\"Polyetherketoneketone (PEKK)\",\"label\":\"Polyetherketoneketone (PEKK)\",\"disabled\":true}]},{\"id\":\"polycarbonate--pc-\",\"nodeId\":\"polycarbonate--pc-\",\"humanReadableId\":\"Polycarbonate (PC)\",\"label\":\"Polycarbonate (PC)\",\"disabled\":true},{\"id\":\"polyester\",\"nodeId\":\"polyester\",\"humanReadableId\":\"Polyester\",\"label\":\"Polyester\",\"disabled\":true,\"children\":[{\"id\":\"polybutylene-terephthalate--pbt-\",\"nodeId\":\"polybutylene-terephthalate--pbt-\",\"humanReadableId\":\"Polybutylene Terephthalate (PBT)\",\"label\":\"Polybutylene Terephthalate (PBT)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate--pet-\",\"nodeId\":\"polyethylene-terephthalate--pet-\",\"humanReadableId\":\"Polyethylene Terephthalate (PET)\",\"label\":\"Polyethylene Terephthalate (PET)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate-glycol--petg-\",\"nodeId\":\"polyethylene-terephthalate-glycol--petg-\",\"humanReadableId\":\"Polyethylene Terephthalate Glycol (PETG)\",\"label\":\"Polyethylene Terephthalate Glycol (PETG)\",\"disabled\":true},{\"id\":\"polyglycolicide--pga-\",\"nodeId\":\"polyglycolicide--pga-\",\"humanReadableId\":\"Polyglycolicide (PGA)\",\"label\":\"Polyglycolicide (PGA)\",\"disabled\":true},{\"id\":\"polytrimethylene-terephthalate--ptt-\",\"nodeId\":\"polytrimethylene-terephthalate--ptt-\",\"humanReadableId\":\"Polytrimethylene Terephthalate (PTT)\",\"label\":\"Polytrimethylene Terephthalate (PTT)\",\"disabled\":true}]},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe-\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true},{\"id\":\"polyimide--pi-\",\"nodeId\":\"polyimide--pi-\",\"humanReadableId\":\"Polyimide (PI)\",\"label\":\"Polyimide (PI)\",\"disabled\":true,\"children\":[{\"id\":\"polyamidimide--pai-\",\"nodeId\":\"polyamidimide--pai-\",\"humanReadableId\":\"Polyamidimide (PAI)\",\"label\":\"Polyamidimide (PAI)\",\"disabled\":true},{\"id\":\"polybenzimidazole--pbi-\",\"nodeId\":\"polybenzimidazole--pbi-\",\"humanReadableId\":\"Polybenzimidazole (PBI)\",\"label\":\"Polybenzimidazole (PBI)\",\"disabled\":true},{\"id\":\"polyetherimide--pei-\",\"nodeId\":\"polyetherimide--pei-\",\"humanReadableId\":\"Polyetherimide (PEI)\",\"label\":\"Polyetherimide (PEI)\",\"disabled\":true}]},{\"id\":\"polyketone--pk-\",\"nodeId\":\"polyketone--pk-\",\"humanReadableId\":\"Polyketone (PK)\",\"label\":\"Polyketone (PK)\",\"disabled\":true},{\"id\":\"polylactic-acid--pla-\",\"nodeId\":\"polylactic-acid--pla-\",\"humanReadableId\":\"Polylactic Acid (PLA)\",\"label\":\"Polylactic Acid (PLA)\",\"disabled\":true},{\"id\":\"polymer-blend\",\"nodeId\":\"polymer-blend\",\"humanReadableId\":\"Polymer Blend\",\"label\":\"Polymer Blend\",\"disabled\":true},{\"id\":\"polyolefin--po-\",\"nodeId\":\"polyolefin--po-\",\"humanReadableId\":\"Polyolefin (PO)\",\"label\":\"Polyolefin (PO)\",\"disabled\":true,\"children\":[{\"id\":\"polybutene--pb-\",\"nodeId\":\"polybutene--pb-\",\"humanReadableId\":\"Polybutene (PB)\",\"label\":\"Polybutene (PB)\",\"disabled\":true},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe--\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"children\":[{\"id\":\"high-density-polyethylene--pe-hd-\",\"nodeId\":\"high-density-polyethylene--pe-hd-\",\"humanReadableId\":\"High Density Polyethylene (PE-HD)\",\"label\":\"High Density Polyethylene (PE-HD)\",\"disabled\":true},{\"id\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"nodeId\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"humanReadableId\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"label\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"disabled\":true},{\"id\":\"linear-low-density-polyethylene--pe-lld-\",\"nodeId\":\"linear-low-density-polyethylene--pe-lld-\",\"humanReadableId\":\"Linear Low Density Polyethylene (PE-LLD)\",\"label\":\"Linear Low Density Polyethylene (PE-LLD)\",\"disabled\":true},{\"id\":\"low-density-polyethylene--pe-ld-\",\"nodeId\":\"low-density-polyethylene--pe-ld-\",\"humanReadableId\":\"Low Density Polyethylene (PE-LD)\",\"label\":\"Low Density Polyethylene (PE-LD)\",\"disabled\":true},{\"id\":\"medium-density-polyethylene--pe-md-\",\"nodeId\":\"medium-density-polyethylene--pe-md-\",\"humanReadableId\":\"Medium Density Polyethylene (PE-MD)\",\"label\":\"Medium Density Polyethylene (PE-MD)\",\"disabled\":true},{\"id\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"nodeId\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"humanReadableId\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"label\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"disabled\":true},{\"id\":\"very-low-density-polyethylene--pe-vld-\",\"nodeId\":\"very-low-density-polyethylene--pe-vld-\",\"humanReadableId\":\"Very Low Density Polyethylene (PE-VLD)\",\"label\":\"Very Low Density Polyethylene (PE-VLD)\",\"disabled\":true}]},{\"id\":\"polymethylpentene--pmp-\",\"nodeId\":\"polymethylpentene--pmp-\",\"humanReadableId\":\"Polymethylpentene (PMP)\",\"label\":\"Polymethylpentene (PMP)\",\"disabled\":true},{\"id\":\"polypropylene--pp-\",\"nodeId\":\"polypropylene--pp-\",\"humanReadableId\":\"Polypropylene (PP)\",\"label\":\"Polypropylene (PP)\",\"disabled\":true}]},{\"id\":\"polyoxymethylene--pom-\",\"nodeId\":\"polyoxymethylene--pom-\",\"humanReadableId\":\"Polyoxymethylene (POM)\",\"label\":\"Polyoxymethylene (POM)\",\"disabled\":true},{\"id\":\"polyphenyl\",\"nodeId\":\"polyphenyl\",\"humanReadableId\":\"Polyphenyl\",\"label\":\"Polyphenyl\",\"disabled\":true,\"children\":[{\"id\":\"polyphenyl-ether--ppe-\",\"nodeId\":\"polyphenyl-ether--ppe-\",\"humanReadableId\":\"Polyphenyl Ether (PPE)\",\"label\":\"Polyphenyl Ether (PPE)\",\"disabled\":true},{\"id\":\"polyphenylene-oxide--ppo-\",\"nodeId\":\"polyphenylene-oxide--ppo-\",\"humanReadableId\":\"Polyphenylene Oxide (PPO)\",\"label\":\"Polyphenylene Oxide (PPO)\",\"disabled\":true},{\"id\":\"polyphenylene-sulfide--pps-\",\"nodeId\":\"polyphenylene-sulfide--pps-\",\"humanReadableId\":\"Polyphenylene Sulfide (PPS)\",\"label\":\"Polyphenylene Sulfide (PPS)\",\"disabled\":true}]},{\"id\":\"polysaccharide\",\"nodeId\":\"polysaccharide\",\"humanReadableId\":\"Polysaccharide\",\"label\":\"Polysaccharide\",\"disabled\":true},{\"id\":\"polysulphones\",\"nodeId\":\"polysulphones\",\"humanReadableId\":\"Polysulphones\",\"label\":\"Polysulphones\",\"disabled\":true,\"children\":[{\"id\":\"polyether-sulfone--pes-\",\"nodeId\":\"polyether-sulfone--pes-\",\"humanReadableId\":\"Polyether Sulfone (PES)\",\"label\":\"Polyether Sulfone (PES)\",\"disabled\":true},{\"id\":\"polyphenylsulphone--ppsu-\",\"nodeId\":\"polyphenylsulphone--ppsu-\",\"humanReadableId\":\"Polyphenylsulphone (PPSU)\",\"label\":\"Polyphenylsulphone (PPSU)\",\"disabled\":true},{\"id\":\"polysulphone--psu-\",\"nodeId\":\"polysulphone--psu-\",\"humanReadableId\":\"Polysulphone (PSU)\",\"label\":\"Polysulphone (PSU)\",\"disabled\":true},{\"id\":\"polysulphone-general--psu-\",\"nodeId\":\"polysulphone-general--psu-\",\"humanReadableId\":\"Polysulphone General (PSU)\",\"label\":\"Polysulphone General (PSU)\",\"disabled\":true}]},{\"id\":\"styrene\",\"nodeId\":\"styrene\",\"humanReadableId\":\"Styrene\",\"label\":\"Styrene\",\"disabled\":true,\"children\":[{\"id\":\"acrylonitrile-butadiene-styrene--abs-\",\"nodeId\":\"acrylonitrile-butadiene-styrene--abs-\",\"humanReadableId\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"label\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"disabled\":true},{\"id\":\"acrylonitrile-styrene-acrylate--asa-\",\"nodeId\":\"acrylonitrile-styrene-acrylate--asa-\",\"humanReadableId\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"label\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"disabled\":true},{\"id\":\"high-impact-polystyrene--hips-\",\"nodeId\":\"high-impact-polystyrene--hips-\",\"humanReadableId\":\"High Impact Polystyrene (HIPS)\",\"label\":\"High Impact Polystyrene (HIPS)\",\"disabled\":true},{\"id\":\"methacrylate-butadiene-styrene--mbs-\",\"nodeId\":\"methacrylate-butadiene-styrene--mbs-\",\"humanReadableId\":\"Methacrylate Butadiene Styrene (MBS)\",\"label\":\"Methacrylate Butadiene Styrene (MBS)\",\"disabled\":true},{\"id\":\"polystyrene--ps-\",\"nodeId\":\"polystyrene--ps-\",\"humanReadableId\":\"Polystyrene (PS)\",\"label\":\"Polystyrene (PS)\",\"disabled\":true},{\"id\":\"styrene-acrylonitrile--san-\",\"nodeId\":\"styrene-acrylonitrile--san-\",\"humanReadableId\":\"Styrene Acrylonitrile (SAN)\",\"label\":\"Styrene Acrylonitrile (SAN)\",\"disabled\":true}]},{\"id\":\"vinyl\",\"nodeId\":\"vinyl\",\"humanReadableId\":\"Vinyl\",\"label\":\"Vinyl\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-vinyl-acetate--evac-\",\"nodeId\":\"ethylene-vinyl-acetate--evac-\",\"humanReadableId\":\"Ethylene Vinyl Acetate (EVAC)\",\"label\":\"Ethylene Vinyl Acetate (EVAC)\",\"disabled\":true},{\"id\":\"polyvinyl-chloride--pvc-\",\"nodeId\":\"polyvinyl-chloride--pvc-\",\"humanReadableId\":\"Polyvinyl Chloride (PVC)\",\"label\":\"Polyvinyl Chloride (PVC)\",\"disabled\":true}]}]},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"humanReadableId\":\"Thermosetting\",\"label\":\"Thermosetting\",\"disabled\":true,\"children\":[{\"id\":\"amino-resin\",\"nodeId\":\"amino-resin\",\"humanReadableId\":\"Amino Resin\",\"label\":\"Amino Resin\",\"disabled\":true,\"children\":[{\"id\":\"bismaleimide--bmi-\",\"nodeId\":\"bismaleimide--bmi-\",\"humanReadableId\":\"Bismaleimide (BMI)\",\"label\":\"Bismaleimide (BMI)\",\"disabled\":true},{\"id\":\"melamine-formaldehyde--mf-\",\"nodeId\":\"melamine-formaldehyde--mf-\",\"humanReadableId\":\"Melamine formaldehyde (MF)\",\"label\":\"Melamine formaldehyde (MF)\",\"disabled\":true}]},{\"id\":\"epoxy-resin--ep-\",\"nodeId\":\"epoxy-resin--ep-\",\"humanReadableId\":\"Epoxy Resin (EP)\",\"label\":\"Epoxy Resin (EP)\",\"disabled\":true},{\"id\":\"phenol-formaldehyde-resin--pf-\",\"nodeId\":\"phenol-formaldehyde-resin--pf-\",\"humanReadableId\":\"Phenol Formaldehyde Resin (PF)\",\"label\":\"Phenol Formaldehyde Resin (PF)\",\"disabled\":true},{\"id\":\"phthalonitrile--pn-\",\"nodeId\":\"phthalonitrile--pn-\",\"humanReadableId\":\"Phthalonitrile (PN)\",\"label\":\"Phthalonitrile (PN)\",\"disabled\":true},{\"id\":\"polyester-resin--up-\",\"nodeId\":\"polyester-resin--up-\",\"humanReadableId\":\"Polyester Resin (UP)\",\"label\":\"Polyester Resin (UP)\",\"disabled\":true},{\"id\":\"vinyl-ester-resin--ve-\",\"nodeId\":\"vinyl-ester-resin--ve-\",\"humanReadableId\":\"Vinyl Ester Resin (VE)\",\"label\":\"Vinyl Ester Resin (VE)\",\"disabled\":true}]}]}],\"propertySections\":[],\"suppliers\":[{\"id\":\"dest\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"materialsCount\":93},{\"id\":\"ugit\",\"label\":\"Ugitech\",\"materialsCount\":50},{\"id\":\"sver\",\"label\":\"Sverdrup Steel AS\",\"materialsCount\":20},{\"id\":\"salo\",\"label\":\"Salomon's Metalen\",\"materialsCount\":16},{\"id\":\"hemp\",\"label\":\"Hempel Special Metals\",\"materialsCount\":4},{\"id\":\"vdmm\",\"label\":\"VDM Metals\",\"materialsCount\":1},{\"id\":\"song\",\"label\":\"Dongguan songshun mould steel Co., Ltd.\",\"materialsCount\":13},{\"id\":\"ambi\",\"label\":\"Ambica Steels Limited\",\"materialsCount\":10}],\"supplierMaterialsOnly\":false,\"polymerFilter\":{\"disabled\":true},\"tags\":[{\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}],\"specification\":{\"queryParams\":\"categories=steel\\u0026tags=form:bar\",\"clauses\":[{\"type\":\"tags\",\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}]},\"context\":{\"unitsSystem\":\"metric\",\"categories\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"humanReadableId\":\"Biological Material\",\"label\":\"Biological Material\",\"disabled\":true,\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"humanReadableId\":\"Wood\",\"label\":\"Wood\",\"disabled\":true}]},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"humanReadableId\":\"Ceramic\",\"label\":\"Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"humanReadableId\":\"Carbon\",\"label\":\"Carbon\",\"disabled\":true,\"children\":[{\"id\":\"carbon-nanotube\",\"nodeId\":\"carbon-nanotube\",\"humanReadableId\":\"Carbon Nanotube\",\"label\":\"Carbon Nanotube\",\"disabled\":true},{\"id\":\"diamond\",\"nodeId\":\"diamond\",\"humanReadableId\":\"Diamond\",\"label\":\"Diamond\",\"disabled\":true,\"children\":[{\"id\":\"natural-diamond\",\"nodeId\":\"natural-diamond\",\"humanReadableId\":\"Natural Diamond\",\"label\":\"Natural Diamond\",\"disabled\":true},{\"id\":\"synthetic-diamond\",\"nodeId\":\"synthetic-diamond\",\"humanReadableId\":\"Synthetic Diamond\",\"label\":\"Synthetic Diamond\",\"disabled\":true}]},{\"id\":\"graphene\",\"nodeId\":\"graphene\",\"humanReadableId\":\"Graphene\",\"label\":\"Graphene\",\"disabled\":true},{\"id\":\"graphite\",\"nodeId\":\"graphite\",\"humanReadableId\":\"Graphite\",\"label\":\"Graphite\",\"disabled\":true}]},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"humanReadableId\":\"Engineering Ceramic\",\"label\":\"Engineering Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"non-oxide-based\",\"nodeId\":\"non-oxide-based\",\"humanReadableId\":\"Non Oxide Based\",\"label\":\"Non Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"boride-based\",\"nodeId\":\"boride-based\",\"humanReadableId\":\"Boride Based\",\"label\":\"Boride Based\",\"disabled\":true},{\"id\":\"carbide-based\",\"nodeId\":\"carbide-based\",\"humanReadableId\":\"Carbide Based\",\"label\":\"Carbide Based\",\"disabled\":true,\"children\":[{\"id\":\"boron-carbide\",\"nodeId\":\"boron-carbide\",\"humanReadableId\":\"Boron Carbide\",\"label\":\"Boron Carbide\",\"disabled\":true},{\"id\":\"silicon-carbide\",\"nodeId\":\"silicon-carbide\",\"humanReadableId\":\"Silicon Carbide\",\"label\":\"Silicon Carbide\",\"disabled\":true},{\"id\":\"tantalum-carbide\",\"nodeId\":\"tantalum-carbide\",\"humanReadableId\":\"Tantalum Carbide\",\"label\":\"Tantalum Carbide\",\"disabled\":true},{\"id\":\"titanium-carbide\",\"nodeId\":\"titanium-carbide\",\"humanReadableId\":\"Titanium Carbide\",\"label\":\"Titanium Carbide\",\"disabled\":true},{\"id\":\"tungsten-carbide\",\"nodeId\":\"tungsten-carbide\",\"humanReadableId\":\"Tungsten Carbide\",\"label\":\"Tungsten Carbide\",\"disabled\":true},{\"id\":\"zirconium-carbide\",\"nodeId\":\"zirconium-carbide\",\"humanReadableId\":\"Zirconium Carbide\",\"label\":\"Zirconium Carbide\",\"disabled\":true}]},{\"id\":\"nitride-based\",\"nodeId\":\"nitride-based\",\"humanReadableId\":\"Nitride Based\",\"label\":\"Nitride Based\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nitirde\",\"nodeId\":\"aluminium-nitirde\",\"humanReadableId\":\"Aluminium Nitirde\",\"label\":\"Aluminium Nitirde\",\"disabled\":true},{\"id\":\"boron-nitride\",\"nodeId\":\"boron-nitride\",\"humanReadableId\":\"Boron Nitride\",\"label\":\"Boron Nitride\",\"disabled\":true},{\"id\":\"silicon-nitride\",\"nodeId\":\"silicon-nitride\",\"humanReadableId\":\"Silicon Nitride\",\"label\":\"Silicon Nitride\",\"disabled\":true},{\"id\":\"titanium-nitride\",\"nodeId\":\"titanium-nitride\",\"humanReadableId\":\"Titanium Nitride\",\"label\":\"Titanium Nitride\",\"disabled\":true}]},{\"id\":\"silicate-based\",\"nodeId\":\"silicate-based\",\"humanReadableId\":\"Silicate Based\",\"label\":\"Silicate Based\",\"disabled\":true},{\"id\":\"sulfide-based\",\"nodeId\":\"sulfide-based\",\"humanReadableId\":\"Sulfide Based\",\"label\":\"Sulfide Based\",\"disabled\":true,\"children\":[{\"id\":\"bismuth-sulfide\",\"nodeId\":\"bismuth-sulfide\",\"humanReadableId\":\"Bismuth Sulfide\",\"label\":\"Bismuth Sulfide\",\"disabled\":true},{\"id\":\"copper-sulfide\",\"nodeId\":\"copper-sulfide\",\"humanReadableId\":\"Copper Sulfide\",\"label\":\"Copper Sulfide\",\"disabled\":true},{\"id\":\"iron-sulfide\",\"nodeId\":\"iron-sulfide\",\"humanReadableId\":\"Iron Sulfide\",\"label\":\"Iron Sulfide\",\"disabled\":true},{\"id\":\"manganese-sulfide\",\"nodeId\":\"manganese-sulfide\",\"humanReadableId\":\"Manganese Sulfide\",\"label\":\"Manganese Sulfide\",\"disabled\":true},{\"id\":\"molybdenum-disulfide\",\"nodeId\":\"molybdenum-disulfide\",\"humanReadableId\":\"Molybdenum Disulfide\",\"label\":\"Molybdenum Disulfide\",\"disabled\":true},{\"id\":\"multiphase-metal-sulfide\",\"nodeId\":\"multiphase-metal-sulfide\",\"humanReadableId\":\"Multiphase Metal Sulfide\",\"label\":\"Multiphase Metal Sulfide\",\"disabled\":true},{\"id\":\"tin-sulfide\",\"nodeId\":\"tin-sulfide\",\"humanReadableId\":\"Tin Sulfide\",\"label\":\"Tin Sulfide\",\"disabled\":true},{\"id\":\"tungsten-disulfide\",\"nodeId\":\"tungsten-disulfide\",\"humanReadableId\":\"Tungsten Disulfide\",\"label\":\"Tungsten Disulfide\",\"disabled\":true},{\"id\":\"zinc-sulfide\",\"nodeId\":\"zinc-sulfide\",\"humanReadableId\":\"Zinc Sulfide\",\"label\":\"Zinc Sulfide\",\"disabled\":true}]}]},{\"id\":\"oxide-based\",\"nodeId\":\"oxide-based\",\"humanReadableId\":\"Oxide Based\",\"label\":\"Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"advanced-ceramic-oxides\",\"nodeId\":\"advanced-ceramic-oxides\",\"humanReadableId\":\"Advanced Ceramic Oxides\",\"label\":\"Advanced Ceramic Oxides\",\"disabled\":true},{\"id\":\"aluminium-oxide\",\"nodeId\":\"aluminium-oxide\",\"humanReadableId\":\"Aluminium Oxide\",\"label\":\"Aluminium Oxide\",\"disabled\":true},{\"id\":\"beryllium-oxide\",\"nodeId\":\"beryllium-oxide\",\"humanReadableId\":\"Beryllium Oxide\",\"label\":\"Beryllium Oxide\",\"disabled\":true},{\"id\":\"ferrite\",\"nodeId\":\"ferrite\",\"humanReadableId\":\"Ferrite\",\"label\":\"Ferrite\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-silicate\",\"nodeId\":\"aluminium-silicate\",\"humanReadableId\":\"Aluminium Silicate\",\"label\":\"Aluminium Silicate\",\"disabled\":true},{\"id\":\"magnesium-silicate\",\"nodeId\":\"magnesium-silicate\",\"humanReadableId\":\"Magnesium Silicate\",\"label\":\"Magnesium Silicate\",\"disabled\":true},{\"id\":\"zirconium-silicate\",\"nodeId\":\"zirconium-silicate\",\"humanReadableId\":\"Zirconium Silicate\",\"label\":\"Zirconium Silicate\",\"disabled\":true}]},{\"id\":\"titanium-oxide\",\"nodeId\":\"titanium-oxide\",\"humanReadableId\":\"Titanium Oxide\",\"label\":\"Titanium Oxide\",\"disabled\":true},{\"id\":\"zirconium-oxide\",\"nodeId\":\"zirconium-oxide\",\"humanReadableId\":\"Zirconium Oxide\",\"label\":\"Zirconium Oxide\",\"disabled\":true}]},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"multi-oxide-ceramics\",\"nodeId\":\"multi-oxide-ceramics\",\"humanReadableId\":\"Multi-Oxide Ceramics\",\"label\":\"Multi-Oxide Ceramics\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide-\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true},{\"id\":\"ytterbium-oxide\",\"nodeId\":\"ytterbium-oxide\",\"humanReadableId\":\"Ytterbium Oxide\",\"label\":\"Ytterbium Oxide\",\"disabled\":true},{\"id\":\"yttrium-oxide\",\"nodeId\":\"yttrium-oxide\",\"humanReadableId\":\"Yttrium Oxide\",\"label\":\"Yttrium Oxide\",\"disabled\":true}]}]},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"humanReadableId\":\"Natural Ceramic\",\"label\":\"Natural Ceramic\",\"disabled\":true}]},{\"id\":\"composite\",\"nodeId\":\"composite\",\"humanReadableId\":\"Composite\",\"label\":\"Composite\",\"disabled\":true,\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"humanReadableId\":\"Ceramic Matrix Composite\",\"label\":\"Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"carbide-based-ceramic-matrix-composite\",\"nodeId\":\"carbide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Carbide Based Ceramic Matrix Composite\",\"label\":\"Carbide Based Ceramic Matrix Composite\",\"disabled\":true},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite-\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true}]},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"humanReadableId\":\"Metal Matrix Composite\",\"label\":\"Metal Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-matrix-composite\",\"nodeId\":\"aluminium-matrix-composite\",\"humanReadableId\":\"Aluminium Matrix Composite\",\"label\":\"Aluminium Matrix Composite\",\"disabled\":true},{\"id\":\"beryllium-matrix-composite\",\"nodeId\":\"beryllium-matrix-composite\",\"humanReadableId\":\"Beryllium Matrix Composite\",\"label\":\"Beryllium Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-matrix-composite\",\"nodeId\":\"cobalt-matrix-composite\",\"humanReadableId\":\"Cobalt Matrix Composite\",\"label\":\"Cobalt Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-and-nickel-matrix-composite\",\"nodeId\":\"cobalt-and-nickel-matrix-composite\",\"humanReadableId\":\"Cobalt and Nickel Matrix Composite\",\"label\":\"Cobalt and Nickel Matrix Composite\",\"disabled\":true},{\"id\":\"iron-matrix-composite\",\"nodeId\":\"iron-matrix-composite\",\"humanReadableId\":\"Iron Matrix Composite\",\"label\":\"Iron Matrix Composite\",\"disabled\":true},{\"id\":\"nickel-matrix-composite\",\"nodeId\":\"nickel-matrix-composite\",\"humanReadableId\":\"Nickel Matrix Composite\",\"label\":\"Nickel Matrix Composite\",\"disabled\":true}]},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"humanReadableId\":\"Polymer Matrix Composite\",\"label\":\"Polymer Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"thermoset-polymer-matrix-composite\",\"nodeId\":\"thermoset-polymer-matrix-composite\",\"humanReadableId\":\"Thermoset Polymer Matrix Composite\",\"label\":\"Thermoset Polymer Matrix Composite\",\"disabled\":true}]}]},{\"id\":\"glass\",\"nodeId\":\"glass\",\"humanReadableId\":\"Glass\",\"label\":\"Glass\",\"disabled\":true,\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"humanReadableId\":\"Glass Ceramic\",\"label\":\"Glass Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"las-glass-ceramic\",\"nodeId\":\"las-glass-ceramic\",\"humanReadableId\":\"LAS Glass Ceramic\",\"label\":\"LAS Glass Ceramic\",\"disabled\":true}]},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"humanReadableId\":\"Lead Glass\",\"label\":\"Lead Glass\",\"disabled\":true},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"humanReadableId\":\"Silicate Glass\",\"label\":\"Silicate Glass\",\"disabled\":true,\"children\":[{\"id\":\"aluminosilicate\",\"nodeId\":\"aluminosilicate\",\"humanReadableId\":\"Aluminosilicate\",\"label\":\"Aluminosilicate\",\"disabled\":true},{\"id\":\"borosilicate\",\"nodeId\":\"borosilicate\",\"humanReadableId\":\"Borosilicate\",\"label\":\"Borosilicate\",\"disabled\":true},{\"id\":\"fused-quartz\",\"nodeId\":\"fused-quartz\",\"humanReadableId\":\"Fused Quartz\",\"label\":\"Fused Quartz\",\"disabled\":true},{\"id\":\"soda-lime-silicate\",\"nodeId\":\"soda-lime-silicate\",\"humanReadableId\":\"Soda Lime Silicate\",\"label\":\"Soda Lime Silicate\",\"disabled\":true}]}]},{\"id\":\"metal\",\"nodeId\":\"metal\",\"humanReadableId\":\"Metal\",\"label\":\"Metal\",\"partiallyChecked\":true,\"materialsCount\":2214,\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"humanReadableId\":\"Aluminium\",\"label\":\"Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-master-alloy\",\"nodeId\":\"aluminium-master-alloy\",\"humanReadableId\":\"Aluminium Master Alloy\",\"label\":\"Aluminium Master Alloy\",\"disabled\":true},{\"id\":\"cast-aluminium\",\"nodeId\":\"cast-aluminium\",\"humanReadableId\":\"Cast Aluminium\",\"label\":\"Cast Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1xx-x\",\"nodeId\":\"1xx-x\",\"humanReadableId\":\"1xx.x\",\"label\":\"1xx.x\",\"disabled\":true},{\"id\":\"2xx-x\",\"nodeId\":\"2xx-x\",\"humanReadableId\":\"2xx.x\",\"label\":\"2xx.x\",\"disabled\":true},{\"id\":\"3xx-x\",\"nodeId\":\"3xx-x\",\"humanReadableId\":\"3xx.x\",\"label\":\"3xx.x\",\"disabled\":true},{\"id\":\"4xx-x\",\"nodeId\":\"4xx-x\",\"humanReadableId\":\"4xx.x\",\"label\":\"4xx.x\",\"disabled\":true},{\"id\":\"5xx-x\",\"nodeId\":\"5xx-x\",\"humanReadableId\":\"5xx.x\",\"label\":\"5xx.x\",\"disabled\":true},{\"id\":\"7xx-x\",\"nodeId\":\"7xx-x\",\"humanReadableId\":\"7xx.x\",\"label\":\"7xx.x\",\"disabled\":true},{\"id\":\"8xx-x\",\"nodeId\":\"8xx-x\",\"humanReadableId\":\"8xx.x\",\"label\":\"8xx.x\",\"disabled\":true}]},{\"id\":\"wrought-aluminium\",\"nodeId\":\"wrought-aluminium\",\"humanReadableId\":\"Wrought Aluminium\",\"label\":\"Wrought Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1000-series\",\"nodeId\":\"1000-series\",\"humanReadableId\":\"1000 Series\",\"label\":\"1000 Series\",\"disabled\":true},{\"id\":\"2000-series\",\"nodeId\":\"2000-series\",\"humanReadableId\":\"2000 Series\",\"label\":\"2000 Series\",\"disabled\":true},{\"id\":\"3000-series\",\"nodeId\":\"3000-series\",\"humanReadableId\":\"3000 Series\",\"label\":\"3000 Series\",\"disabled\":true},{\"id\":\"4000-series\",\"nodeId\":\"4000-series\",\"humanReadableId\":\"4000 Series\",\"label\":\"4000 Series\",\"disabled\":true},{\"id\":\"5000-series\",\"nodeId\":\"5000-series\",\"humanReadableId\":\"5000 Series\",\"label\":\"5000 Series\",\"disabled\":true},{\"id\":\"6000-series\",\"nodeId\":\"6000-series\",\"humanReadableId\":\"6000 Series\",\"label\":\"6000 Series\",\"disabled\":true},{\"id\":\"7000-series\",\"nodeId\":\"7000-series\",\"humanReadableId\":\"7000 Series\",\"label\":\"7000 Series\",\"disabled\":true},{\"id\":\"8000-series\",\"nodeId\":\"8000-series\",\"humanReadableId\":\"8000 Series\",\"label\":\"8000 Series\",\"disabled\":true}]}]},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"humanReadableId\":\"Clad / Bimetal\",\"label\":\"Clad / Bimetal\",\"disabled\":true},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"humanReadableId\":\"Cobalt\",\"label\":\"Cobalt\",\"disabled\":true,\"children\":[{\"id\":\"cobalt-chromium\",\"nodeId\":\"cobalt-chromium\",\"humanReadableId\":\"Cobalt Chromium\",\"label\":\"Cobalt Chromium\",\"disabled\":true},{\"id\":\"cobalt-chromium-molybdenum\",\"nodeId\":\"cobalt-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Chromium Molybdenum\",\"label\":\"Cobalt Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-chromium-nickel-tungsten\",\"nodeId\":\"cobalt-chromium-nickel-tungsten\",\"humanReadableId\":\"Cobalt Chromium Nickel Tungsten\",\"label\":\"Cobalt Chromium Nickel Tungsten\",\"disabled\":true},{\"id\":\"cobalt-chromium-tungsten\",\"nodeId\":\"cobalt-chromium-tungsten\",\"humanReadableId\":\"Cobalt Chromium Tungsten\",\"label\":\"Cobalt Chromium Tungsten\",\"disabled\":true},{\"id\":\"cobalt-nickel-chromium-molybdenum\",\"nodeId\":\"cobalt-nickel-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Nickel Chromium Molybdenum\",\"label\":\"Cobalt Nickel Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-superalloy\",\"nodeId\":\"cobalt-superalloy\",\"humanReadableId\":\"Cobalt Superalloy\",\"label\":\"Cobalt Superalloy\",\"disabled\":true},{\"id\":\"unclassified-cobalt-alloy\",\"nodeId\":\"unclassified-cobalt-alloy\",\"humanReadableId\":\"Unclassified Cobalt Alloy\",\"label\":\"Unclassified Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"copper\",\"nodeId\":\"copper\",\"humanReadableId\":\"Copper\",\"label\":\"Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper\",\"nodeId\":\"cast-copper\",\"humanReadableId\":\"Cast Copper\",\"label\":\"Cast Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass\",\"nodeId\":\"cast-copper-brass\",\"humanReadableId\":\"Cast Copper Brass\",\"label\":\"Cast Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass-yellow-brass\",\"nodeId\":\"cast-copper-brass-yellow-brass\",\"humanReadableId\":\"Cast Copper Brass Yellow Brass\",\"label\":\"Cast Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"cast-copper-silicon-brass\",\"nodeId\":\"cast-copper-silicon-brass\",\"humanReadableId\":\"Cast Copper Silicon Brass\",\"label\":\"Cast Copper Silicon Brass\",\"disabled\":true},{\"id\":\"copper-bismuth-alloy\",\"nodeId\":\"copper-bismuth-alloy\",\"humanReadableId\":\"Copper Bismuth Alloy\",\"label\":\"Copper Bismuth Alloy\",\"disabled\":true},{\"id\":\"red-brass\",\"nodeId\":\"red-brass\",\"humanReadableId\":\"Red Brass\",\"label\":\"Red Brass\",\"disabled\":true}]},{\"id\":\"cast-copper-bronze\",\"nodeId\":\"cast-copper-bronze\",\"humanReadableId\":\"Cast Copper Bronze\",\"label\":\"Cast Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-bronze-aluminium-bronze\",\"nodeId\":\"cast-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Cast Copper Bronze Aluminium Bronze\",\"label\":\"Cast Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"leaded-tin-bronze\",\"nodeId\":\"leaded-tin-bronze\",\"humanReadableId\":\"Leaded Tin Bronze\",\"label\":\"Leaded Tin Bronze\",\"disabled\":true},{\"id\":\"nickel-tin-bronze\",\"nodeId\":\"nickel-tin-bronze\",\"humanReadableId\":\"Nickel Tin Bronze\",\"label\":\"Nickel Tin Bronze\",\"disabled\":true},{\"id\":\"tin-bronze\",\"nodeId\":\"tin-bronze\",\"humanReadableId\":\"Tin Bronze\",\"label\":\"Tin Bronze\",\"disabled\":true}]},{\"id\":\"cast-copper-high-copper-alloy\",\"nodeId\":\"cast-copper-high-copper-alloy\",\"humanReadableId\":\"Cast Copper High Copper Alloy\",\"label\":\"Cast Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"cast-copper-nickel-grade\",\"nodeId\":\"cast-copper-nickel-grade\",\"humanReadableId\":\"Cast Copper Nickel Grade\",\"label\":\"Cast Copper Nickel Grade\",\"disabled\":true},{\"id\":\"cast-copper-nickel-silver-grade\",\"nodeId\":\"cast-copper-nickel-silver-grade\",\"humanReadableId\":\"Cast Copper Nickel Silver Grade\",\"label\":\"Cast Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"cast-copper-pure---low-alloyed-copper\",\"nodeId\":\"cast-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Cast Copper Pure / Low Alloyed Copper\",\"label\":\"Cast Copper Pure / Low Alloyed Copper\",\"disabled\":true},{\"id\":\"copper-lead-alloy\",\"nodeId\":\"copper-lead-alloy\",\"humanReadableId\":\"Copper-Lead Alloy\",\"label\":\"Copper-Lead Alloy\",\"disabled\":true},{\"id\":\"special-alloy\",\"nodeId\":\"special-alloy\",\"humanReadableId\":\"Special Alloy\",\"label\":\"Special Alloy\",\"disabled\":true}]},{\"id\":\"welding\",\"nodeId\":\"welding\",\"humanReadableId\":\"Welding\",\"label\":\"Welding\",\"disabled\":true},{\"id\":\"wrought-copper\",\"nodeId\":\"wrought-copper\",\"humanReadableId\":\"Wrought Copper\",\"label\":\"Wrought Copper\",\"disabled\":true,\"children\":[{\"id\":\"unclassified-wrought-copper\",\"nodeId\":\"unclassified-wrought-copper\",\"humanReadableId\":\"Unclassified Wrought Copper\",\"label\":\"Unclassified Wrought Copper\",\"disabled\":true},{\"id\":\"wrought-copper-brass\",\"nodeId\":\"wrought-copper-brass\",\"humanReadableId\":\"Wrought Copper Brass\",\"label\":\"Wrought Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"leaded-brass\",\"nodeId\":\"leaded-brass\",\"humanReadableId\":\"Leaded Brass\",\"label\":\"Leaded Brass\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"tin-brass\",\"nodeId\":\"tin-brass\",\"humanReadableId\":\"Tin Brass\",\"label\":\"Tin Brass\",\"disabled\":true},{\"id\":\"wrought-copper-brass-yellow-brass\",\"nodeId\":\"wrought-copper-brass-yellow-brass\",\"humanReadableId\":\"Wrought Copper Brass Yellow Brass\",\"label\":\"Wrought Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"yellow-wrought-brass\",\"nodeId\":\"yellow-wrought-brass\",\"humanReadableId\":\"Yellow Wrought Brass\",\"label\":\"Yellow Wrought Brass\",\"disabled\":true}]},{\"id\":\"wrought-copper-bronze\",\"nodeId\":\"wrought-copper-bronze\",\"humanReadableId\":\"Wrought Copper Bronze\",\"label\":\"Wrought Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"copper-silver-zinc-alloy\",\"nodeId\":\"copper-silver-zinc-alloy\",\"humanReadableId\":\"Copper Silver Zinc Alloy\",\"label\":\"Copper Silver Zinc Alloy\",\"disabled\":true},{\"id\":\"leaded-phosphor-bronze\",\"nodeId\":\"leaded-phosphor-bronze\",\"humanReadableId\":\"Leaded Phosphor Bronze\",\"label\":\"Leaded Phosphor Bronze\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy-\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"phosphor-bronze\",\"nodeId\":\"phosphor-bronze\",\"humanReadableId\":\"Phosphor Bronze\",\"label\":\"Phosphor Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-aluminium-bronze\",\"nodeId\":\"wrought-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Aluminium Bronze\",\"label\":\"Wrought Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-silicon-bronze\",\"nodeId\":\"wrought-copper-bronze-silicon-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Silicon Bronze\",\"label\":\"Wrought Copper Bronze Silicon Bronze\",\"disabled\":true}]},{\"id\":\"wrought-copper-high-copper-alloy\",\"nodeId\":\"wrought-copper-high-copper-alloy\",\"humanReadableId\":\"Wrought Copper High Copper Alloy\",\"label\":\"Wrought Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-grade\",\"nodeId\":\"wrought-copper-nickel-grade\",\"humanReadableId\":\"Wrought Copper Nickel Grade\",\"label\":\"Wrought Copper Nickel Grade\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-silver-grade\",\"nodeId\":\"wrought-copper-nickel-silver-grade\",\"humanReadableId\":\"Wrought Copper Nickel Silver Grade\",\"label\":\"Wrought Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"wrought-copper-pure---low-alloyed-copper\",\"nodeId\":\"wrought-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Wrought Copper Pure / Low Alloyed Copper\",\"label\":\"Wrought Copper Pure / Low Alloyed Copper\",\"disabled\":true}]}]},{\"id\":\"iron\",\"nodeId\":\"iron\",\"humanReadableId\":\"Iron\",\"label\":\"Iron\",\"disabled\":true,\"children\":[{\"id\":\"alloy-iron\",\"nodeId\":\"alloy-iron\",\"humanReadableId\":\"Alloy Iron\",\"label\":\"Alloy Iron\",\"disabled\":true},{\"id\":\"cast-iron\",\"nodeId\":\"cast-iron\",\"humanReadableId\":\"Cast Iron\",\"label\":\"Cast Iron\",\"disabled\":true,\"children\":[{\"id\":\"ductile--nodular--cast-iron\",\"nodeId\":\"ductile--nodular--cast-iron\",\"humanReadableId\":\"Ductile (Nodular) Cast Iron\",\"label\":\"Ductile (Nodular) Cast Iron\",\"disabled\":true},{\"id\":\"grey-cast-iron\",\"nodeId\":\"grey-cast-iron\",\"humanReadableId\":\"Grey Cast Iron\",\"label\":\"Grey Cast Iron\",\"disabled\":true},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true},{\"id\":\"other-cast-iron-alloy\",\"nodeId\":\"other-cast-iron-alloy\",\"humanReadableId\":\"Other Cast Iron Alloy\",\"label\":\"Other Cast Iron Alloy\",\"disabled\":true},{\"id\":\"white-cast-iron\",\"nodeId\":\"white-cast-iron\",\"humanReadableId\":\"White Cast Iron\",\"label\":\"White Cast Iron\",\"disabled\":true}]},{\"id\":\"ferromolybdenum\",\"nodeId\":\"ferromolybdenum\",\"humanReadableId\":\"Ferromolybdenum\",\"label\":\"Ferromolybdenum\",\"disabled\":true},{\"id\":\"ferrosilicon\",\"nodeId\":\"ferrosilicon\",\"humanReadableId\":\"Ferrosilicon\",\"label\":\"Ferrosilicon\",\"disabled\":true},{\"id\":\"ferrovanadium\",\"nodeId\":\"ferrovanadium\",\"humanReadableId\":\"Ferrovanadium\",\"label\":\"Ferrovanadium\",\"disabled\":true},{\"id\":\"iron-alloy\",\"nodeId\":\"iron-alloy\",\"humanReadableId\":\"Iron Alloy\",\"label\":\"Iron Alloy\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nickel-cobalt-iron-alloy\",\"nodeId\":\"aluminium-nickel-cobalt-iron-alloy\",\"humanReadableId\":\"Aluminium Nickel Cobalt Iron Alloy\",\"label\":\"Aluminium Nickel Cobalt Iron Alloy\",\"disabled\":true},{\"id\":\"miscellaneous-iron-alloy\",\"nodeId\":\"miscellaneous-iron-alloy\",\"humanReadableId\":\"Miscellaneous Iron Alloy\",\"label\":\"Miscellaneous Iron Alloy\",\"disabled\":true},{\"id\":\"soft-magnetic-iron\",\"nodeId\":\"soft-magnetic-iron\",\"humanReadableId\":\"Soft Magnetic Iron\",\"label\":\"Soft Magnetic Iron\",\"disabled\":true}]},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron-\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true}]},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"humanReadableId\":\"Magnesium\",\"label\":\"Magnesium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-grade\",\"nodeId\":\"aluminium-grade\",\"humanReadableId\":\"Aluminium Grade\",\"label\":\"Aluminium Grade\",\"disabled\":true},{\"id\":\"cast-aluminium-manganese-grade\",\"nodeId\":\"cast-aluminium-manganese-grade\",\"humanReadableId\":\"Cast Aluminium Manganese Grade\",\"label\":\"Cast Aluminium Manganese Grade\",\"disabled\":true},{\"id\":\"cast-rare-earth-grade\",\"nodeId\":\"cast-rare-earth-grade\",\"humanReadableId\":\"Cast Rare Earth Grade\",\"label\":\"Cast Rare Earth Grade\",\"disabled\":true},{\"id\":\"cast-wrought-aluminium-zinc-grade\",\"nodeId\":\"cast-wrought-aluminium-zinc-grade\",\"humanReadableId\":\"Cast/Wrought Aluminium Zinc Grade\",\"label\":\"Cast/Wrought Aluminium Zinc Grade\",\"disabled\":true},{\"id\":\"cast-wrought-unclassified-grade\",\"nodeId\":\"cast-wrought-unclassified-grade\",\"humanReadableId\":\"Cast/Wrought Unclassified Grade\",\"label\":\"Cast/Wrought Unclassified Grade\",\"disabled\":true},{\"id\":\"pure-magnesium\",\"nodeId\":\"pure-magnesium\",\"humanReadableId\":\"Pure Magnesium\",\"label\":\"Pure Magnesium\",\"disabled\":true},{\"id\":\"rare-earth-grade\",\"nodeId\":\"rare-earth-grade\",\"humanReadableId\":\"Rare Earth Grade\",\"label\":\"Rare Earth Grade\",\"disabled\":true},{\"id\":\"wrought-zinc-grade\",\"nodeId\":\"wrought-zinc-grade\",\"humanReadableId\":\"Wrought Zinc Grade\",\"label\":\"Wrought Zinc Grade\",\"disabled\":true},{\"id\":\"yttrium-grade\",\"nodeId\":\"yttrium-grade\",\"humanReadableId\":\"Yttrium Grade\",\"label\":\"Yttrium Grade\",\"disabled\":true},{\"id\":\"zinc-grade\",\"nodeId\":\"zinc-grade\",\"humanReadableId\":\"Zinc Grade\",\"label\":\"Zinc Grade\",\"disabled\":true}]},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"humanReadableId\":\"Manganese\",\"label\":\"Manganese\",\"disabled\":true},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"humanReadableId\":\"Nickel\",\"label\":\"Nickel\",\"disabled\":true,\"children\":[{\"id\":\"nickel-chromium-alloy\",\"nodeId\":\"nickel-chromium-alloy\",\"humanReadableId\":\"Nickel Chromium Alloy\",\"label\":\"Nickel Chromium Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-cobalt-alloy\",\"nodeId\":\"nickel-chromium-cobalt-alloy\",\"humanReadableId\":\"Nickel Chromium Cobalt Alloy\",\"label\":\"Nickel Chromium Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-iron-alloy\",\"nodeId\":\"nickel-chromium-iron-alloy\",\"humanReadableId\":\"Nickel Chromium Iron Alloy\",\"label\":\"Nickel Chromium Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-molybdenum-alloy\",\"nodeId\":\"nickel-chromium-molybdenum-alloy\",\"humanReadableId\":\"Nickel Chromium Molybdenum Alloy\",\"label\":\"Nickel Chromium Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-cobalt-alloy\",\"nodeId\":\"nickel-cobalt-alloy\",\"humanReadableId\":\"Nickel Cobalt Alloy\",\"label\":\"Nickel Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-copper-alloy\",\"nodeId\":\"nickel-copper-alloy\",\"humanReadableId\":\"Nickel Copper Alloy\",\"label\":\"Nickel Copper Alloy\",\"disabled\":true},{\"id\":\"nickel-iron-alloy\",\"nodeId\":\"nickel-iron-alloy\",\"humanReadableId\":\"Nickel Iron Alloy\",\"label\":\"Nickel Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-molybdenum-alloy\",\"nodeId\":\"nickel-molybdenum-alloy\",\"humanReadableId\":\"Nickel Molybdenum Alloy\",\"label\":\"Nickel Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-superalloy\",\"nodeId\":\"nickel-superalloy\",\"humanReadableId\":\"Nickel Superalloy\",\"label\":\"Nickel Superalloy\",\"disabled\":true},{\"id\":\"nickel-welding-filler\",\"nodeId\":\"nickel-welding-filler\",\"humanReadableId\":\"Nickel Welding Filler\",\"label\":\"Nickel Welding Filler\",\"disabled\":true},{\"id\":\"other-nickel-alloy\",\"nodeId\":\"other-nickel-alloy\",\"humanReadableId\":\"Other Nickel Alloy\",\"label\":\"Other Nickel Alloy\",\"disabled\":true},{\"id\":\"pure-low-nickel-alloy\",\"nodeId\":\"pure-low-nickel-alloy\",\"humanReadableId\":\"Pure/Low Nickel Alloy\",\"label\":\"Pure/Low Nickel Alloy\",\"disabled\":true}]},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"humanReadableId\":\"Noble Metal\",\"label\":\"Noble Metal\",\"disabled\":true,\"children\":[{\"id\":\"gold\",\"nodeId\":\"gold\",\"humanReadableId\":\"Gold\",\"label\":\"Gold\",\"disabled\":true},{\"id\":\"iridium\",\"nodeId\":\"iridium\",\"humanReadableId\":\"Iridium\",\"label\":\"Iridium\",\"disabled\":true},{\"id\":\"palladium\",\"nodeId\":\"palladium\",\"humanReadableId\":\"Palladium\",\"label\":\"Palladium\",\"disabled\":true},{\"id\":\"platinum\",\"nodeId\":\"platinum\",\"humanReadableId\":\"Platinum\",\"label\":\"Platinum\",\"disabled\":true},{\"id\":\"rhodium\",\"nodeId\":\"rhodium\",\"humanReadableId\":\"Rhodium\",\"label\":\"Rhodium\",\"disabled\":true},{\"id\":\"silver\",\"nodeId\":\"silver\",\"humanReadableId\":\"Silver\",\"label\":\"Silver\",\"disabled\":true}]},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"humanReadableId\":\"Other Metal\",\"label\":\"Other Metal\",\"disabled\":true,\"children\":[{\"id\":\"beryllium\",\"nodeId\":\"beryllium\",\"humanReadableId\":\"Beryllium\",\"label\":\"Beryllium\",\"disabled\":true},{\"id\":\"cadmium\",\"nodeId\":\"cadmium\",\"humanReadableId\":\"Cadmium\",\"label\":\"Cadmium\",\"disabled\":true},{\"id\":\"chromium\",\"nodeId\":\"chromium\",\"humanReadableId\":\"Chromium\",\"label\":\"Chromium\",\"disabled\":true},{\"id\":\"lead\",\"nodeId\":\"lead\",\"humanReadableId\":\"Lead\",\"label\":\"Lead\",\"disabled\":true,\"children\":[{\"id\":\"lead-antimony\",\"nodeId\":\"lead-antimony\",\"humanReadableId\":\"Lead Antimony\",\"label\":\"Lead Antimony\",\"disabled\":true},{\"id\":\"lead-tin\",\"nodeId\":\"lead-tin\",\"humanReadableId\":\"Lead Tin\",\"label\":\"Lead Tin\",\"disabled\":true},{\"id\":\"pure-low-alloyed-lead\",\"nodeId\":\"pure-low-alloyed-lead\",\"humanReadableId\":\"Pure/Low Alloyed Lead\",\"label\":\"Pure/Low Alloyed Lead\",\"disabled\":true}]},{\"id\":\"lithium\",\"nodeId\":\"lithium\",\"humanReadableId\":\"Lithium\",\"label\":\"Lithium\",\"disabled\":true},{\"id\":\"neodymium\",\"nodeId\":\"neodymium\",\"humanReadableId\":\"Neodymium\",\"label\":\"Neodymium\",\"disabled\":true,\"children\":[{\"id\":\"neodymium-iron-boron-alloy\",\"nodeId\":\"neodymium-iron-boron-alloy\",\"humanReadableId\":\"Neodymium Iron Boron Alloy\",\"label\":\"Neodymium Iron Boron Alloy\",\"disabled\":true}]},{\"id\":\"samarium\",\"nodeId\":\"samarium\",\"humanReadableId\":\"Samarium\",\"label\":\"Samarium\",\"disabled\":true,\"children\":[{\"id\":\"samarium-cobalt-alloy\",\"nodeId\":\"samarium-cobalt-alloy\",\"humanReadableId\":\"Samarium Cobalt Alloy\",\"label\":\"Samarium Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"tin\",\"nodeId\":\"tin\",\"humanReadableId\":\"Tin\",\"label\":\"Tin\",\"disabled\":true,\"children\":[{\"id\":\"pure-low-alloyed-tin\",\"nodeId\":\"pure-low-alloyed-tin\",\"humanReadableId\":\"Pure/Low Alloyed Tin\",\"label\":\"Pure/Low Alloyed Tin\",\"disabled\":true},{\"id\":\"tin-antimony\",\"nodeId\":\"tin-antimony\",\"humanReadableId\":\"Tin Antimony\",\"label\":\"Tin Antimony\",\"disabled\":true},{\"id\":\"tin-lead\",\"nodeId\":\"tin-lead\",\"humanReadableId\":\"Tin Lead\",\"label\":\"Tin Lead\",\"disabled\":true},{\"id\":\"unclassified-tin\",\"nodeId\":\"unclassified-tin\",\"humanReadableId\":\"Unclassified Tin\",\"label\":\"Unclassified Tin\",\"disabled\":true}]},{\"id\":\"zinc\",\"nodeId\":\"zinc\",\"humanReadableId\":\"Zinc\",\"label\":\"Zinc\",\"disabled\":true,\"children\":[{\"id\":\"unalloyed-zinc\",\"nodeId\":\"unalloyed-zinc\",\"humanReadableId\":\"Unalloyed Zinc\",\"label\":\"Unalloyed Zinc\",\"disabled\":true},{\"id\":\"unclassified-zinc\",\"nodeId\":\"unclassified-zinc\",\"humanReadableId\":\"Unclassified Zinc\",\"label\":\"Unclassified Zinc\",\"disabled\":true},{\"id\":\"zinc-aluminium\",\"nodeId\":\"zinc-aluminium\",\"humanReadableId\":\"Zinc Aluminium\",\"label\":\"Zinc Aluminium\",\"disabled\":true}]}]},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"humanReadableId\":\"Refractory Metal\",\"label\":\"Refractory Metal\",\"disabled\":true,\"children\":[{\"id\":\"hafnium\",\"nodeId\":\"hafnium\",\"humanReadableId\":\"Hafnium\",\"label\":\"Hafnium\",\"disabled\":true},{\"id\":\"molybdenum\",\"nodeId\":\"molybdenum\",\"humanReadableId\":\"Molybdenum\",\"label\":\"Molybdenum\",\"disabled\":true},{\"id\":\"niobium\",\"nodeId\":\"niobium\",\"humanReadableId\":\"Niobium\",\"label\":\"Niobium\",\"disabled\":true},{\"id\":\"rhenium\",\"nodeId\":\"rhenium\",\"humanReadableId\":\"Rhenium\",\"label\":\"Rhenium\",\"disabled\":true},{\"id\":\"tantalum\",\"nodeId\":\"tantalum\",\"humanReadableId\":\"Tantalum\",\"label\":\"Tantalum\",\"disabled\":true},{\"id\":\"tungsten\",\"nodeId\":\"tungsten\",\"humanReadableId\":\"Tungsten\",\"label\":\"Tungsten\",\"disabled\":true},{\"id\":\"vanadium\",\"nodeId\":\"vanadium\",\"humanReadableId\":\"Vanadium\",\"label\":\"Vanadium\",\"disabled\":true},{\"id\":\"zirconium\",\"nodeId\":\"zirconium\",\"humanReadableId\":\"Zirconium\",\"label\":\"Zirconium\",\"disabled\":true}]},{\"id\":\"steel\",\"nodeId\":\"steel\",\"humanReadableId\":\"Steel\",\"label\":\"Steel\",\"checked\":true,\"children\":[{\"id\":\"alloy-steel\",\"nodeId\":\"alloy-steel\",\"humanReadableId\":\"Alloy Steel\",\"label\":\"Alloy Steel\",\"checked\":true,\"children\":[{\"id\":\"chromium-molybdenum-steel\",\"nodeId\":\"chromium-molybdenum-steel\",\"humanReadableId\":\"Chromium Molybdenum Steel\",\"label\":\"Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"chromium-molybdenum-vanadium-steel\",\"nodeId\":\"chromium-molybdenum-vanadium-steel\",\"humanReadableId\":\"Chromium Molybdenum Vanadium Steel\",\"label\":\"Chromium Molybdenum Vanadium Steel\",\"checked\":true},{\"id\":\"chromium-steel\",\"nodeId\":\"chromium-steel\",\"humanReadableId\":\"Chromium Steel\",\"label\":\"Chromium Steel\",\"checked\":true},{\"id\":\"chromium-vanadium-steel\",\"nodeId\":\"chromium-vanadium-steel\",\"humanReadableId\":\"Chromium Vanadium Steel\",\"label\":\"Chromium Vanadium Steel\",\"checked\":true},{\"id\":\"manganese-steel\",\"nodeId\":\"manganese-steel\",\"humanReadableId\":\"Manganese Steel\",\"label\":\"Manganese Steel\",\"checked\":true},{\"id\":\"molybdenum-steel\",\"nodeId\":\"molybdenum-steel\",\"humanReadableId\":\"Molybdenum Steel\",\"label\":\"Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-molybdenum-steel\",\"nodeId\":\"nickel-chromium-molybdenum-steel\",\"humanReadableId\":\"Nickel Chromium Molybdenum Steel\",\"label\":\"Nickel Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-steel\",\"nodeId\":\"nickel-chromium-steel\",\"humanReadableId\":\"Nickel Chromium Steel\",\"label\":\"Nickel Chromium Steel\",\"checked\":true},{\"id\":\"nickel-molybdenum-steel\",\"nodeId\":\"nickel-molybdenum-steel\",\"humanReadableId\":\"Nickel Molybdenum Steel\",\"label\":\"Nickel Molybdenum Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"nickel-steel\",\"nodeId\":\"nickel-steel\",\"humanReadableId\":\"Nickel Steel\",\"label\":\"Nickel Steel\",\"checked\":true},{\"id\":\"nitriding-steel\",\"nodeId\":\"nitriding-steel\",\"humanReadableId\":\"Nitriding Steel\",\"label\":\"Nitriding Steel\",\"checked\":true},{\"id\":\"silicon-manganese-steel\",\"nodeId\":\"silicon-manganese-steel\",\"humanReadableId\":\"Silicon Manganese Steel\",\"label\":\"Silicon Manganese Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"silicon-steel\",\"nodeId\":\"silicon-steel\",\"humanReadableId\":\"Silicon Steel\",\"label\":\"Silicon Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"unclassified-low-alloy-steel\",\"nodeId\":\"unclassified-low-alloy-steel\",\"humanReadableId\":\"Unclassified Low Alloy Steel\",\"label\":\"Unclassified Low Alloy Steel\",\"checked\":true}]},{\"id\":\"carbon-steel\",\"nodeId\":\"carbon-steel\",\"humanReadableId\":\"Carbon Steel\",\"label\":\"Carbon Steel\",\"checked\":true,\"children\":[{\"id\":\"high-carbon-steel\",\"nodeId\":\"high-carbon-steel\",\"humanReadableId\":\"High Carbon Steel\",\"label\":\"High Carbon Steel\",\"checked\":true},{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true},{\"id\":\"medium-carbon-steel\",\"nodeId\":\"medium-carbon-steel\",\"humanReadableId\":\"Medium Carbon Steel\",\"label\":\"Medium Carbon Steel\",\"checked\":true},{\"id\":\"unclassified-carbon-steel\",\"nodeId\":\"unclassified-carbon-steel\",\"humanReadableId\":\"Unclassified Carbon Steel\",\"label\":\"Unclassified Carbon Steel\",\"checked\":true}]},{\"id\":\"low-alloy-steel\",\"nodeId\":\"low-alloy-steel\",\"humanReadableId\":\"Low Alloy Steel\",\"label\":\"Low Alloy Steel\",\"checked\":true,\"disabled\":true,\"children\":[{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel-\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"disabled\":true}]},{\"id\":\"maraging-steel\",\"nodeId\":\"maraging-steel\",\"humanReadableId\":\"Maraging Steel\",\"label\":\"Maraging Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"stainless-steel\",\"nodeId\":\"stainless-steel\",\"humanReadableId\":\"Stainless Steel\",\"label\":\"Stainless Steel\",\"checked\":true,\"children\":[{\"id\":\"austenitic-stainless-steel\",\"nodeId\":\"austenitic-stainless-steel\",\"humanReadableId\":\"Austenitic Stainless Steel\",\"label\":\"Austenitic Stainless Steel\",\"checked\":true},{\"id\":\"duplex-stainless-steel\",\"nodeId\":\"duplex-stainless-steel\",\"humanReadableId\":\"Duplex Stainless Steel\",\"label\":\"Duplex Stainless Steel\",\"checked\":true},{\"id\":\"ferritic-stainless-steel\",\"nodeId\":\"ferritic-stainless-steel\",\"humanReadableId\":\"Ferritic Stainless Steel\",\"label\":\"Ferritic Stainless Steel\",\"checked\":true},{\"id\":\"martensitic-stainless-steel\",\"nodeId\":\"martensitic-stainless-steel\",\"humanReadableId\":\"Martensitic Stainless Steel\",\"label\":\"Martensitic Stainless Steel\",\"checked\":true},{\"id\":\"precipitation-hardening-stainless-steel\",\"nodeId\":\"precipitation-hardening-stainless-steel\",\"humanReadableId\":\"Precipitation Hardening Stainless Steel\",\"label\":\"Precipitation Hardening Stainless Steel\",\"checked\":true},{\"id\":\"superaustenitic-stainless-steel\",\"nodeId\":\"superaustenitic-stainless-steel\",\"humanReadableId\":\"Superaustenitic Stainless Steel\",\"label\":\"Superaustenitic Stainless Steel\",\"checked\":true},{\"id\":\"unclassified-stainless-steel\",\"nodeId\":\"unclassified-stainless-steel\",\"humanReadableId\":\"Unclassified Stainless Steel\",\"label\":\"Unclassified Stainless Steel\",\"checked\":true}]},{\"id\":\"tool-and-machining-steel\",\"nodeId\":\"tool-and-machining-steel\",\"humanReadableId\":\"Tool And Machining Steel\",\"label\":\"Tool And Machining Steel\",\"checked\":true}]},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"humanReadableId\":\"Titanium\",\"label\":\"Titanium\",\"disabled\":true,\"children\":[{\"id\":\"alpha-alloy\",\"nodeId\":\"alpha-alloy\",\"humanReadableId\":\"Alpha Alloy\",\"label\":\"Alpha Alloy\",\"disabled\":true},{\"id\":\"alpha-beta-alloy\",\"nodeId\":\"alpha-beta-alloy\",\"humanReadableId\":\"Alpha Beta Alloy\",\"label\":\"Alpha Beta Alloy\",\"disabled\":true},{\"id\":\"beta-alloy\",\"nodeId\":\"beta-alloy\",\"humanReadableId\":\"Beta Alloy\",\"label\":\"Beta Alloy\",\"disabled\":true},{\"id\":\"low-alloy-titanium\",\"nodeId\":\"low-alloy-titanium\",\"humanReadableId\":\"Low Alloy Titanium\",\"label\":\"Low Alloy Titanium\",\"disabled\":true},{\"id\":\"near-alpha-alloy\",\"nodeId\":\"near-alpha-alloy\",\"humanReadableId\":\"Near Alpha Alloy\",\"label\":\"Near Alpha Alloy\",\"disabled\":true},{\"id\":\"pure-titanium\",\"nodeId\":\"pure-titanium\",\"humanReadableId\":\"Pure Titanium\",\"label\":\"Pure Titanium\",\"disabled\":true}]}]},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"humanReadableId\":\"Polymer\",\"label\":\"Polymer\",\"disabled\":true,\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"humanReadableId\":\"Elastomer\",\"label\":\"Elastomer\",\"disabled\":true,\"children\":[{\"id\":\"butadiene-rubber--br-\",\"nodeId\":\"butadiene-rubber--br-\",\"humanReadableId\":\"Butadiene Rubber (BR)\",\"label\":\"Butadiene Rubber (BR)\",\"disabled\":true},{\"id\":\"chloroprene-rubber--cr-\",\"nodeId\":\"chloroprene-rubber--cr-\",\"humanReadableId\":\"Chloroprene Rubber (CR)\",\"label\":\"Chloroprene Rubber (CR)\",\"disabled\":true},{\"id\":\"ethylene-propylene-diene-rubber--epdm-\",\"nodeId\":\"ethylene-propylene-diene-rubber--epdm-\",\"humanReadableId\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"label\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"disabled\":true},{\"id\":\"ethylene-propylene-rubber--epr-\",\"nodeId\":\"ethylene-propylene-rubber--epr-\",\"humanReadableId\":\"Ethylene Propylene Rubber (EPR)\",\"label\":\"Ethylene Propylene Rubber (EPR)\",\"disabled\":true},{\"id\":\"fluorosilicone-rubber--fvmq-\",\"nodeId\":\"fluorosilicone-rubber--fvmq-\",\"humanReadableId\":\"Fluorosilicone Rubber (FVMQ)\",\"label\":\"Fluorosilicone Rubber (FVMQ)\",\"disabled\":true},{\"id\":\"natural-rubber--nr-\",\"nodeId\":\"natural-rubber--nr-\",\"humanReadableId\":\"Natural Rubber (NR)\",\"label\":\"Natural Rubber (NR)\",\"disabled\":true},{\"id\":\"nitrile-rubber--nbr-\",\"nodeId\":\"nitrile-rubber--nbr-\",\"humanReadableId\":\"Nitrile Rubber (NBR)\",\"label\":\"Nitrile Rubber (NBR)\",\"disabled\":true},{\"id\":\"styrene-butadiene-rubber--sbr-\",\"nodeId\":\"styrene-butadiene-rubber--sbr-\",\"humanReadableId\":\"Styrene Butadiene Rubber (SBR)\",\"label\":\"Styrene Butadiene Rubber (SBR)\",\"disabled\":true},{\"id\":\"thermoplastic-elastomer--tpe-\",\"nodeId\":\"thermoplastic-elastomer--tpe-\",\"humanReadableId\":\"Thermoplastic Elastomer (TPE)\",\"label\":\"Thermoplastic Elastomer (TPE)\",\"disabled\":true,\"children\":[{\"id\":\"elastomeric-alloy--tpv-\",\"nodeId\":\"elastomeric-alloy--tpv-\",\"humanReadableId\":\"Elastomeric Alloy (TPV)\",\"label\":\"Elastomeric Alloy (TPV)\",\"disabled\":true},{\"id\":\"styrene-butadiene-styrene--sbs-\",\"nodeId\":\"styrene-butadiene-styrene--sbs-\",\"humanReadableId\":\"Styrene Butadiene Styrene (SBS)\",\"label\":\"Styrene Butadiene Styrene (SBS)\",\"disabled\":true},{\"id\":\"thermoplastic-copolyester--tpc-\",\"nodeId\":\"thermoplastic-copolyester--tpc-\",\"humanReadableId\":\"Thermoplastic Copolyester (TPC)\",\"label\":\"Thermoplastic Copolyester (TPC)\",\"disabled\":true},{\"id\":\"thermoplastic-polyamide--tpa-\",\"nodeId\":\"thermoplastic-polyamide--tpa-\",\"humanReadableId\":\"Thermoplastic Polyamide (TPA)\",\"label\":\"Thermoplastic Polyamide (TPA)\",\"disabled\":true},{\"id\":\"thermoplastic-polyester-elastomer--tpee-\",\"nodeId\":\"thermoplastic-polyester-elastomer--tpee-\",\"humanReadableId\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"label\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"disabled\":true},{\"id\":\"thermoplastic-polyolefin--tpo-\",\"nodeId\":\"thermoplastic-polyolefin--tpo-\",\"humanReadableId\":\"Thermoplastic Polyolefin (TPO)\",\"label\":\"Thermoplastic Polyolefin (TPO)\",\"disabled\":true},{\"id\":\"thermoplastic-polyurethane--tpu-\",\"nodeId\":\"thermoplastic-polyurethane--tpu-\",\"humanReadableId\":\"Thermoplastic Polyurethane (TPU)\",\"label\":\"Thermoplastic Polyurethane (TPU)\",\"disabled\":true},{\"id\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"nodeId\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"humanReadableId\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"label\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"disabled\":true}]}]},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"humanReadableId\":\"Thermoplastic\",\"label\":\"Thermoplastic\",\"disabled\":true,\"children\":[{\"id\":\"acrylic\",\"nodeId\":\"acrylic\",\"humanReadableId\":\"Acrylic\",\"label\":\"Acrylic\",\"disabled\":true,\"children\":[{\"id\":\"polyacrylonitrile--pan-\",\"nodeId\":\"polyacrylonitrile--pan-\",\"humanReadableId\":\"Polyacrylonitrile (PAN)\",\"label\":\"Polyacrylonitrile (PAN)\",\"disabled\":true},{\"id\":\"polymethyl-methacrylate--pmma-\",\"nodeId\":\"polymethyl-methacrylate--pmma-\",\"humanReadableId\":\"Polymethyl methacrylate (PMMA)\",\"label\":\"Polymethyl methacrylate (PMMA)\",\"disabled\":true}]},{\"id\":\"fluoropolymer\",\"nodeId\":\"fluoropolymer\",\"humanReadableId\":\"Fluoropolymer\",\"label\":\"Fluoropolymer\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"nodeId\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"humanReadableId\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"label\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"disabled\":true},{\"id\":\"fluorinated-ethylene-propylene--fep-\",\"nodeId\":\"fluorinated-ethylene-propylene--fep-\",\"humanReadableId\":\"Fluorinated ethylene propylene (FEP)\",\"label\":\"Fluorinated ethylene propylene (FEP)\",\"disabled\":true},{\"id\":\"polytetrafluoroethylene--ptfe-\",\"nodeId\":\"polytetrafluoroethylene--ptfe-\",\"humanReadableId\":\"Polytetrafluoroethylene (PTFE)\",\"label\":\"Polytetrafluoroethylene (PTFE)\",\"disabled\":true},{\"id\":\"polyvinylidenefluoride--pvdf-\",\"nodeId\":\"polyvinylidenefluoride--pvdf-\",\"humanReadableId\":\"Polyvinylidenefluoride (PVDF)\",\"label\":\"Polyvinylidenefluoride (PVDF)\",\"disabled\":true}]},{\"id\":\"liquid-crystal-polymers--lcp-\",\"nodeId\":\"liquid-crystal-polymers--lcp-\",\"humanReadableId\":\"Liquid Crystal Polymers (LCP)\",\"label\":\"Liquid Crystal Polymers (LCP)\",\"disabled\":true},{\"id\":\"polyamide--pa-\",\"nodeId\":\"polyamide--pa-\",\"humanReadableId\":\"Polyamide (PA)\",\"label\":\"Polyamide (PA)\",\"disabled\":true,\"children\":[{\"id\":\"aramide\",\"nodeId\":\"aramide\",\"humanReadableId\":\"Aramide\",\"label\":\"Aramide\",\"disabled\":true},{\"id\":\"copolyamide-6-66--pa6-66-\",\"nodeId\":\"copolyamide-6-66--pa6-66-\",\"humanReadableId\":\"Copolyamide 6/66 (PA6/66)\",\"label\":\"Copolyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"other-polyamide--pa-\",\"nodeId\":\"other-polyamide--pa-\",\"humanReadableId\":\"Other Polyamide (PA)\",\"label\":\"Other Polyamide (PA)\",\"disabled\":true},{\"id\":\"polyamide-1010--pa1010-\",\"nodeId\":\"polyamide-1010--pa1010-\",\"humanReadableId\":\"Polyamide 1010 (PA1010)\",\"label\":\"Polyamide 1010 (PA1010)\",\"disabled\":true},{\"id\":\"polyamide-1012--pa1012-\",\"nodeId\":\"polyamide-1012--pa1012-\",\"humanReadableId\":\"Polyamide 1012 (PA1012)\",\"label\":\"Polyamide 1012 (PA1012)\",\"disabled\":true},{\"id\":\"polyamide-11--pa11-\",\"nodeId\":\"polyamide-11--pa11-\",\"humanReadableId\":\"Polyamide 11 (PA11)\",\"label\":\"Polyamide 11 (PA11)\",\"disabled\":true},{\"id\":\"polyamide-12--pa12-\",\"nodeId\":\"polyamide-12--pa12-\",\"humanReadableId\":\"Polyamide 12 (PA12)\",\"label\":\"Polyamide 12 (PA12)\",\"disabled\":true},{\"id\":\"polyamide-410--pa410-\",\"nodeId\":\"polyamide-410--pa410-\",\"humanReadableId\":\"Polyamide 410 (PA410)\",\"label\":\"Polyamide 410 (PA410)\",\"disabled\":true},{\"id\":\"polyamide-46--pa46-\",\"nodeId\":\"polyamide-46--pa46-\",\"humanReadableId\":\"Polyamide 46 (PA46)\",\"label\":\"Polyamide 46 (PA46)\",\"disabled\":true},{\"id\":\"polyamide-6--pa6-\",\"nodeId\":\"polyamide-6--pa6-\",\"humanReadableId\":\"Polyamide 6 (PA6)\",\"label\":\"Polyamide 6 (PA6)\",\"disabled\":true,\"children\":[{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t-\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true}]},{\"id\":\"polyamide-6-66--pa6-66-\",\"nodeId\":\"polyamide-6-66--pa6-66-\",\"humanReadableId\":\"Polyamide 6/66 (PA6/66)\",\"label\":\"Polyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"polyamide-610--pa610-\",\"nodeId\":\"polyamide-610--pa610-\",\"humanReadableId\":\"Polyamide 610 (PA610)\",\"label\":\"Polyamide 610 (PA610)\",\"disabled\":true},{\"id\":\"polyamide-612--pa612-\",\"nodeId\":\"polyamide-612--pa612-\",\"humanReadableId\":\"Polyamide 612 (PA612)\",\"label\":\"Polyamide 612 (PA612)\",\"disabled\":true},{\"id\":\"polyamide-66--pa66-\",\"nodeId\":\"polyamide-66--pa66-\",\"humanReadableId\":\"Polyamide 66 (PA66)\",\"label\":\"Polyamide 66 (PA66)\",\"disabled\":true},{\"id\":\"polyphthalamide--ppa-\",\"nodeId\":\"polyphthalamide--ppa-\",\"humanReadableId\":\"Polyphthalamide (PPA)\",\"label\":\"Polyphthalamide (PPA)\",\"disabled\":true,\"children\":[{\"id\":\"copolyamide-66-6i--pa66-6i-\",\"nodeId\":\"copolyamide-66-6i--pa66-6i-\",\"humanReadableId\":\"Copolyamide 66/6I (PA66/6I)\",\"label\":\"Copolyamide 66/6I (PA66/6I)\",\"disabled\":true},{\"id\":\"copolyamide-6t-66--pa6t-66-\",\"nodeId\":\"copolyamide-6t-66--pa6t-66-\",\"humanReadableId\":\"Copolyamide 6T/66 (PA6T/66)\",\"label\":\"Copolyamide 6T/66 (PA6T/66)\",\"disabled\":true},{\"id\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"nodeId\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"humanReadableId\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"label\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"disabled\":true},{\"id\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"nodeId\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"humanReadableId\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"label\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"disabled\":true},{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t--\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true},{\"id\":\"polyamide-6t--pa6t-\",\"nodeId\":\"polyamide-6t--pa6t-\",\"humanReadableId\":\"Polyamide 6T (PA6T)\",\"label\":\"Polyamide 6T (PA6T)\",\"disabled\":true},{\"id\":\"polyamide-mxd6--pamxd6-\",\"nodeId\":\"polyamide-mxd6--pamxd6-\",\"humanReadableId\":\"Polyamide MXD6 (PAMXD6)\",\"label\":\"Polyamide MXD6 (PAMXD6)\",\"disabled\":true},{\"id\":\"polyamide-pa6-6t--pa6-6t-\",\"nodeId\":\"polyamide-pa6-6t--pa6-6t-\",\"humanReadableId\":\"Polyamide PA6/6T (PA6/6T)\",\"label\":\"Polyamide PA6/6T (PA6/6T)\",\"disabled\":true}]}]},{\"id\":\"polyaryletherketone--paek-\",\"nodeId\":\"polyaryletherketone--paek-\",\"humanReadableId\":\"Polyaryletherketone (PAEK)\",\"label\":\"Polyaryletherketone (PAEK)\",\"disabled\":true,\"children\":[{\"id\":\"polyether-ketone--pek-\",\"nodeId\":\"polyether-ketone--pek-\",\"humanReadableId\":\"Polyether Ketone (PEK)\",\"label\":\"Polyether Ketone (PEK)\",\"disabled\":true},{\"id\":\"polyetherether-ketone--peek-\",\"nodeId\":\"polyetherether-ketone--peek-\",\"humanReadableId\":\"Polyetherether Ketone (PEEK)\",\"label\":\"Polyetherether Ketone (PEEK)\",\"disabled\":true},{\"id\":\"polyetherketoneketone--pekk-\",\"nodeId\":\"polyetherketoneketone--pekk-\",\"humanReadableId\":\"Polyetherketoneketone (PEKK)\",\"label\":\"Polyetherketoneketone (PEKK)\",\"disabled\":true}]},{\"id\":\"polycarbonate--pc-\",\"nodeId\":\"polycarbonate--pc-\",\"humanReadableId\":\"Polycarbonate (PC)\",\"label\":\"Polycarbonate (PC)\",\"disabled\":true},{\"id\":\"polyester\",\"nodeId\":\"polyester\",\"humanReadableId\":\"Polyester\",\"label\":\"Polyester\",\"disabled\":true,\"children\":[{\"id\":\"polybutylene-terephthalate--pbt-\",\"nodeId\":\"polybutylene-terephthalate--pbt-\",\"humanReadableId\":\"Polybutylene Terephthalate (PBT)\",\"label\":\"Polybutylene Terephthalate (PBT)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate--pet-\",\"nodeId\":\"polyethylene-terephthalate--pet-\",\"humanReadableId\":\"Polyethylene Terephthalate (PET)\",\"label\":\"Polyethylene Terephthalate (PET)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate-glycol--petg-\",\"nodeId\":\"polyethylene-terephthalate-glycol--petg-\",\"humanReadableId\":\"Polyethylene Terephthalate Glycol (PETG)\",\"label\":\"Polyethylene Terephthalate Glycol (PETG)\",\"disabled\":true},{\"id\":\"polyglycolicide--pga-\",\"nodeId\":\"polyglycolicide--pga-\",\"humanReadableId\":\"Polyglycolicide (PGA)\",\"label\":\"Polyglycolicide (PGA)\",\"disabled\":true},{\"id\":\"polytrimethylene-terephthalate--ptt-\",\"nodeId\":\"polytrimethylene-terephthalate--ptt-\",\"humanReadableId\":\"Polytrimethylene Terephthalate (PTT)\",\"label\":\"Polytrimethylene Terephthalate (PTT)\",\"disabled\":true}]},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe-\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true},{\"id\":\"polyimide--pi-\",\"nodeId\":\"polyimide--pi-\",\"humanReadableId\":\"Polyimide (PI)\",\"label\":\"Polyimide (PI)\",\"disabled\":true,\"children\":[{\"id\":\"polyamidimide--pai-\",\"nodeId\":\"polyamidimide--pai-\",\"humanReadableId\":\"Polyamidimide (PAI)\",\"label\":\"Polyamidimide (PAI)\",\"disabled\":true},{\"id\":\"polybenzimidazole--pbi-\",\"nodeId\":\"polybenzimidazole--pbi-\",\"humanReadableId\":\"Polybenzimidazole (PBI)\",\"label\":\"Polybenzimidazole (PBI)\",\"disabled\":true},{\"id\":\"polyetherimide--pei-\",\"nodeId\":\"polyetherimide--pei-\",\"humanReadableId\":\"Polyetherimide (PEI)\",\"label\":\"Polyetherimide (PEI)\",\"disabled\":true}]},{\"id\":\"polyketone--pk-\",\"nodeId\":\"polyketone--pk-\",\"humanReadableId\":\"Polyketone (PK)\",\"label\":\"Polyketone (PK)\",\"disabled\":true},{\"id\":\"polylactic-acid--pla-\",\"nodeId\":\"polylactic-acid--pla-\",\"humanReadableId\":\"Polylactic Acid (PLA)\",\"label\":\"Polylactic Acid (PLA)\",\"disabled\":true},{\"id\":\"polymer-blend\",\"nodeId\":\"polymer-blend\",\"humanReadableId\":\"Polymer Blend\",\"label\":\"Polymer Blend\",\"disabled\":true},{\"id\":\"polyolefin--po-\",\"nodeId\":\"polyolefin--po-\",\"humanReadableId\":\"Polyolefin (PO)\",\"label\":\"Polyolefin (PO)\",\"disabled\":true,\"children\":[{\"id\":\"polybutene--pb-\",\"nodeId\":\"polybutene--pb-\",\"humanReadableId\":\"Polybutene (PB)\",\"label\":\"Polybutene (PB)\",\"disabled\":true},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe--\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"children\":[{\"id\":\"high-density-polyethylene--pe-hd-\",\"nodeId\":\"high-density-polyethylene--pe-hd-\",\"humanReadableId\":\"High Density Polyethylene (PE-HD)\",\"label\":\"High Density Polyethylene (PE-HD)\",\"disabled\":true},{\"id\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"nodeId\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"humanReadableId\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"label\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"disabled\":true},{\"id\":\"linear-low-density-polyethylene--pe-lld-\",\"nodeId\":\"linear-low-density-polyethylene--pe-lld-\",\"humanReadableId\":\"Linear Low Density Polyethylene (PE-LLD)\",\"label\":\"Linear Low Density Polyethylene (PE-LLD)\",\"disabled\":true},{\"id\":\"low-density-polyethylene--pe-ld-\",\"nodeId\":\"low-density-polyethylene--pe-ld-\",\"humanReadableId\":\"Low Density Polyethylene (PE-LD)\",\"label\":\"Low Density Polyethylene (PE-LD)\",\"disabled\":true},{\"id\":\"medium-density-polyethylene--pe-md-\",\"nodeId\":\"medium-density-polyethylene--pe-md-\",\"humanReadableId\":\"Medium Density Polyethylene (PE-MD)\",\"label\":\"Medium Density Polyethylene (PE-MD)\",\"disabled\":true},{\"id\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"nodeId\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"humanReadableId\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"label\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"disabled\":true},{\"id\":\"very-low-density-polyethylene--pe-vld-\",\"nodeId\":\"very-low-density-polyethylene--pe-vld-\",\"humanReadableId\":\"Very Low Density Polyethylene (PE-VLD)\",\"label\":\"Very Low Density Polyethylene (PE-VLD)\",\"disabled\":true}]},{\"id\":\"polymethylpentene--pmp-\",\"nodeId\":\"polymethylpentene--pmp-\",\"humanReadableId\":\"Polymethylpentene (PMP)\",\"label\":\"Polymethylpentene (PMP)\",\"disabled\":true},{\"id\":\"polypropylene--pp-\",\"nodeId\":\"polypropylene--pp-\",\"humanReadableId\":\"Polypropylene (PP)\",\"label\":\"Polypropylene (PP)\",\"disabled\":true}]},{\"id\":\"polyoxymethylene--pom-\",\"nodeId\":\"polyoxymethylene--pom-\",\"humanReadableId\":\"Polyoxymethylene (POM)\",\"label\":\"Polyoxymethylene (POM)\",\"disabled\":true},{\"id\":\"polyphenyl\",\"nodeId\":\"polyphenyl\",\"humanReadableId\":\"Polyphenyl\",\"label\":\"Polyphenyl\",\"disabled\":true,\"children\":[{\"id\":\"polyphenyl-ether--ppe-\",\"nodeId\":\"polyphenyl-ether--ppe-\",\"humanReadableId\":\"Polyphenyl Ether (PPE)\",\"label\":\"Polyphenyl Ether (PPE)\",\"disabled\":true},{\"id\":\"polyphenylene-oxide--ppo-\",\"nodeId\":\"polyphenylene-oxide--ppo-\",\"humanReadableId\":\"Polyphenylene Oxide (PPO)\",\"label\":\"Polyphenylene Oxide (PPO)\",\"disabled\":true},{\"id\":\"polyphenylene-sulfide--pps-\",\"nodeId\":\"polyphenylene-sulfide--pps-\",\"humanReadableId\":\"Polyphenylene Sulfide (PPS)\",\"label\":\"Polyphenylene Sulfide (PPS)\",\"disabled\":true}]},{\"id\":\"polysaccharide\",\"nodeId\":\"polysaccharide\",\"humanReadableId\":\"Polysaccharide\",\"label\":\"Polysaccharide\",\"disabled\":true},{\"id\":\"polysulphones\",\"nodeId\":\"polysulphones\",\"humanReadableId\":\"Polysulphones\",\"label\":\"Polysulphones\",\"disabled\":true,\"children\":[{\"id\":\"polyether-sulfone--pes-\",\"nodeId\":\"polyether-sulfone--pes-\",\"humanReadableId\":\"Polyether Sulfone (PES)\",\"label\":\"Polyether Sulfone (PES)\",\"disabled\":true},{\"id\":\"polyphenylsulphone--ppsu-\",\"nodeId\":\"polyphenylsulphone--ppsu-\",\"humanReadableId\":\"Polyphenylsulphone (PPSU)\",\"label\":\"Polyphenylsulphone (PPSU)\",\"disabled\":true},{\"id\":\"polysulphone--psu-\",\"nodeId\":\"polysulphone--psu-\",\"humanReadableId\":\"Polysulphone (PSU)\",\"label\":\"Polysulphone (PSU)\",\"disabled\":true},{\"id\":\"polysulphone-general--psu-\",\"nodeId\":\"polysulphone-general--psu-\",\"humanReadableId\":\"Polysulphone General (PSU)\",\"label\":\"Polysulphone General (PSU)\",\"disabled\":true}]},{\"id\":\"styrene\",\"nodeId\":\"styrene\",\"humanReadableId\":\"Styrene\",\"label\":\"Styrene\",\"disabled\":true,\"children\":[{\"id\":\"acrylonitrile-butadiene-styrene--abs-\",\"nodeId\":\"acrylonitrile-butadiene-styrene--abs-\",\"humanReadableId\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"label\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"disabled\":true},{\"id\":\"acrylonitrile-styrene-acrylate--asa-\",\"nodeId\":\"acrylonitrile-styrene-acrylate--asa-\",\"humanReadableId\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"label\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"disabled\":true},{\"id\":\"high-impact-polystyrene--hips-\",\"nodeId\":\"high-impact-polystyrene--hips-\",\"humanReadableId\":\"High Impact Polystyrene (HIPS)\",\"label\":\"High Impact Polystyrene (HIPS)\",\"disabled\":true},{\"id\":\"methacrylate-butadiene-styrene--mbs-\",\"nodeId\":\"methacrylate-butadiene-styrene--mbs-\",\"humanReadableId\":\"Methacrylate Butadiene Styrene (MBS)\",\"label\":\"Methacrylate Butadiene Styrene (MBS)\",\"disabled\":true},{\"id\":\"polystyrene--ps-\",\"nodeId\":\"polystyrene--ps-\",\"humanReadableId\":\"Polystyrene (PS)\",\"label\":\"Polystyrene (PS)\",\"disabled\":true},{\"id\":\"styrene-acrylonitrile--san-\",\"nodeId\":\"styrene-acrylonitrile--san-\",\"humanReadableId\":\"Styrene Acrylonitrile (SAN)\",\"label\":\"Styrene Acrylonitrile (SAN)\",\"disabled\":true}]},{\"id\":\"vinyl\",\"nodeId\":\"vinyl\",\"humanReadableId\":\"Vinyl\",\"label\":\"Vinyl\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-vinyl-acetate--evac-\",\"nodeId\":\"ethylene-vinyl-acetate--evac-\",\"humanReadableId\":\"Ethylene Vinyl Acetate (EVAC)\",\"label\":\"Ethylene Vinyl Acetate (EVAC)\",\"disabled\":true},{\"id\":\"polyvinyl-chloride--pvc-\",\"nodeId\":\"polyvinyl-chloride--pvc-\",\"humanReadableId\":\"Polyvinyl Chloride (PVC)\",\"label\":\"Polyvinyl Chloride (PVC)\",\"disabled\":true}]}]},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"humanReadableId\":\"Thermosetting\",\"label\":\"Thermosetting\",\"disabled\":true,\"children\":[{\"id\":\"amino-resin\",\"nodeId\":\"amino-resin\",\"humanReadableId\":\"Amino Resin\",\"label\":\"Amino Resin\",\"disabled\":true,\"children\":[{\"id\":\"bismaleimide--bmi-\",\"nodeId\":\"bismaleimide--bmi-\",\"humanReadableId\":\"Bismaleimide (BMI)\",\"label\":\"Bismaleimide (BMI)\",\"disabled\":true},{\"id\":\"melamine-formaldehyde--mf-\",\"nodeId\":\"melamine-formaldehyde--mf-\",\"humanReadableId\":\"Melamine formaldehyde (MF)\",\"label\":\"Melamine formaldehyde (MF)\",\"disabled\":true}]},{\"id\":\"epoxy-resin--ep-\",\"nodeId\":\"epoxy-resin--ep-\",\"humanReadableId\":\"Epoxy Resin (EP)\",\"label\":\"Epoxy Resin (EP)\",\"disabled\":true},{\"id\":\"phenol-formaldehyde-resin--pf-\",\"nodeId\":\"phenol-formaldehyde-resin--pf-\",\"humanReadableId\":\"Phenol Formaldehyde Resin (PF)\",\"label\":\"Phenol Formaldehyde Resin (PF)\",\"disabled\":true},{\"id\":\"phthalonitrile--pn-\",\"nodeId\":\"phthalonitrile--pn-\",\"humanReadableId\":\"Phthalonitrile (PN)\",\"label\":\"Phthalonitrile (PN)\",\"disabled\":true},{\"id\":\"polyester-resin--up-\",\"nodeId\":\"polyester-resin--up-\",\"humanReadableId\":\"Polyester Resin (UP)\",\"label\":\"Polyester Resin (UP)\",\"disabled\":true},{\"id\":\"vinyl-ester-resin--ve-\",\"nodeId\":\"vinyl-ester-resin--ve-\",\"humanReadableId\":\"Vinyl Ester Resin (VE)\",\"label\":\"Vinyl Ester Resin (VE)\",\"disabled\":true}]}]}],\"categorySpecificFilter\":{\"name\":\"metal\",\"disabled\":false,\"forms\":[{\"id\":\"bar\",\"label\":\"Bar\",\"checked\":true},{\"id\":\"billet\",\"label\":\"Billet\"},{\"id\":\"casting\",\"label\":\"Casting\",\"disabled\":true},{\"id\":\"coil\",\"label\":\"Coil\"},{\"id\":\"disc\",\"label\":\"Disc\",\"disabled\":true},{\"id\":\"flat\",\"label\":\"Flat\"},{\"id\":\"flat-bar\",\"label\":\"Flat Bar\"},{\"id\":\"foil\",\"label\":\"Foil\"},{\"id\":\"forging\",\"label\":\"Forging\"},{\"id\":\"full-section\",\"label\":\"Full Section\",\"disabled\":true},{\"id\":\"half-round-bar\",\"label\":\"Half Round Bar\",\"disabled\":true},{\"id\":\"hexagonal-bar\",\"label\":\"Hexagonal Bar\"},{\"id\":\"hexagonal-bright-bar\",\"label\":\"Hexagonal Bright Bar\",\"disabled\":true},{\"id\":\"hexagonal-rod\",\"label\":\"Hexagonal Rod\"},{\"id\":\"hexagonal-wire\",\"label\":\"Hexagonal Wire\"},{\"id\":\"hollow-bar\",\"label\":\"Hollow Bar\",\"disabled\":true},{\"id\":\"ingot\",\"label\":\"Ingot\",\"disabled\":true},{\"id\":\"pipe\",\"label\":\"Pipe\",\"disabled\":true},{\"id\":\"plate\",\"label\":\"Plate\"},{\"id\":\"powder\",\"label\":\"Powder\",\"disabled\":true},{\"id\":\"profile\",\"label\":\"Profile\"},{\"id\":\"profile-wire\",\"label\":\"Profile Wire\",\"disabled\":true},{\"id\":\"rod\",\"label\":\"Rod\"},{\"id\":\"round-bar\",\"label\":\"Round Bar\"},{\"id\":\"round-bright-bar\",\"label\":\"Round Bright Bar\",\"disabled\":true},{\"id\":\"round-rod\",\"label\":\"Round Rod\"},{\"id\":\"round-wire\",\"label\":\"Round Wire\"},{\"id\":\"seamless-tube\",\"label\":\"Seamless Tube\"},{\"id\":\"sheet\",\"label\":\"Sheet\"},{\"id\":\"spring\",\"label\":\"Spring\",\"disabled\":true},{\"id\":\"squar-bar\",\"label\":\"Squar Bar\",\"disabled\":true},{\"id\":\"square-bar\",\"label\":\"Square Bar\"},{\"id\":\"strip\",\"label\":\"Strip\"},{\"id\":\"tube\",\"label\":\"Tube\"},{\"id\":\"welded-tube\",\"label\":\"Welded Tube\",\"disabled\":true},{\"id\":\"wire\",\"label\":\"Wire\"}],\"fillers\":[],\"modifications\":[],\"processing\":[],\"certifications\":[],\"primaryPhase\":[],\"secondaryPhase\":[]},\"tags\":[{\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}],\"suppliers\":[{\"id\":\"dest\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"materialsCount\":93},{\"id\":\"ugit\",\"label\":\"Ugitech\",\"materialsCount\":50},{\"id\":\"sver\",\"label\":\"Sverdrup Steel AS\",\"materialsCount\":20},{\"id\":\"salo\",\"label\":\"Salomon's Metalen\",\"materialsCount\":16},{\"id\":\"hemp\",\"label\":\"Hempel Special Metals\",\"materialsCount\":4},{\"id\":\"vdmm\",\"label\":\"VDM Metals\",\"materialsCount\":1},{\"id\":\"song\",\"label\":\"Dongguan songshun mould steel Co., Ltd.\",\"materialsCount\":13},{\"id\":\"ambi\",\"label\":\"Ambica Steels Limited\",\"materialsCount\":10}]},\"results\":{\"materials\":{\"data\":[{\"id\":\"DESTB19\",\"label\":\"Acidur 4529\",\"url\":\"/materials/destb19-acidur-4529\",\"category\":{\"id\":\"superaustenitic-stainless-steel\",\"label\":\"Superaustenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS11\",\"label\":\"Acidur 4401 +AT \",\"url\":\"/materials/dests11-acidur-4401-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS12\",\"label\":\"Acidur 4435 +AT \",\"url\":\"/materials/dests12-acidur-4435-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS13\",\"label\":\"Acidur 4541 +AT \",\"url\":\"/materials/dests13-acidur-4541-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS14\",\"label\":\"Acidur 4571 +AT \",\"url\":\"/materials/dests14-acidur-4571-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS11A\",\"label\":\"Acidur 4404 +AT \",\"url\":\"/materials/dests11a-acidur-4404-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS9\",\"label\":\"Acidur 4301 +AT \",\"url\":\"/materials/dests9-acidur-4301-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS9A\",\"label\":\"Acidur 4307 +AT \",\"url\":\"/materials/dests9a-acidur-4307-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS10\",\"label\":\"Acidur 4305 +AT \",\"url\":\"/materials/dests10-acidur-4305-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"VDMM023\",\"label\":\"VDM® Alloy 926\",\"url\":\"/materials/vdmm023-vdm-alloy-926\",\"category\":{\"id\":\"superaustenitic-stainless-steel\",\"label\":\"Superaustenitic Stainless Steel\"},\"supplier\":{\"id\":\"VDMM\",\"label\":\"VDM Metals\",\"url\":\"/suppliers/vdmm-vdm-metals\"}},{\"id\":\"DESTS7\",\"label\":\"Acidur 4418 QT900 \",\"url\":\"/materials/dests7-acidur-4418-qt900-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS15\",\"label\":\"Acidur 4462 +AT \",\"url\":\"/materials/dests15-acidur-4462-at-\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS7A\",\"label\":\"Acidur 4418 QT760 \",\"url\":\"/materials/dests7a-acidur-4418-qt760-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"UGIT0076\",\"label\":\"UGIMA® 4460 Cold Finished\",\"url\":\"/materials/ugit0076-ugima-4460-cold-finished\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"UGIT0077\",\"label\":\"UGIMA® 4460 Cold Finished and Drawn\",\"url\":\"/materials/ugit0077-ugima-4460-cold-finished-and-drawn\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"UGIT0129\",\"label\":\"UGI® 4545 AIR H1025\",\"url\":\"/materials/ugit0129-ugi-4545-air-h1025\",\"category\":{\"id\":\"precipitation-hardening-stainless-steel\",\"label\":\"Precipitation Hardening Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"DESTS1\",\"label\":\"Corrodur 4021 QT800 \",\"url\":\"/materials/dests1-corrodur-4021-qt800-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS3\",\"label\":\"Corrodur 4034 Annealed \",\"url\":\"/materials/dests3-corrodur-4034-annealed-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS4\",\"label\":\"Acidur 4057 QT800 \",\"url\":\"/materials/dests4-acidur-4057-qt800-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS8\",\"label\":\"Acidur 4542 P800 \",\"url\":\"/materials/dests8-acidur-4542-p800-\",\"category\":{\"id\":\"precipitation-hardening-stainless-steel\",\"label\":\"Precipitation Hardening Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}}],\"materialsCount\":2214,\"page\":1}}},\"namespacesRequired\":[\"account\",\"common\",\"navigation\",\"sign-in-up\",\"advanced-search\",\"search-and-filters\",\"ashby-chart\"]},\"pathname\":\"/advanced-search\",\"host\":\"matmatch.com\",\"auth\":{\"oauth2Google\":false,\"oauth2Linkedin\":false,\"promotionalEmails\":false,\"acceptedTerms\":false}},\"initialState\":{\"company\":{},\"actionMessage\":{\"messageCode\":null,\"messageType\":null,\"messageText\":\"\",\"messageTranslationKey\":\"\",\"errorObj\":null,\"showPopup\":false,\"showMessage\":false,\"endPoint\":null},\"user\":{\"oauth2Google\":false,\"oauth2Linkedin\":false,\"promotionalEmails\":false,\"acceptedTerms\":false},\"companyUser\":{},\"companyUsers\":[],\"roles\":[],\"form\":{},\"popup\":{\"open\":false,\"popupComponent\":\"\",\"info\":{},\"companyCodes\":[],\"fieldsValues\":{},\"formConfiguration\":{},\"prePopulatedDataFetched\":false,\"signupEmail\":null},\"auth\":{\"isAuthenticated\":false,\"isLoginPopupVisible\":false,\"isRequestingLogin\":false,\"loginError\":\"\",\"isSignupPopupVisible\":false,\"isRequestingSignup\":false,\"isSignupSuccessPopupVisible\":false,\"signupError\":\"\",\"signupEmail\":\"\",\"isAuthPopupVisible\":false,\"form\":\"\",\"autoActionParams\":null,\"activePremiumFeature\":\"\"},\"targetUrl\":null,\"deviceWidth\":null,\"navigation\":{\"openOverlay\":false,\"categoriesTree\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"name\":\"Material category\",\"label\":\"Biological Material\",\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"name\":\"Material category\",\"label\":\"Wood\"}],\"materialsCount\":1},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"name\":\"Material category\",\"label\":\"Ceramic\",\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"name\":\"Material category\",\"label\":\"Carbon\"},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"name\":\"Material category\",\"label\":\"Engineering Ceramic\"},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"name\":\"Material category\",\"label\":\"Natural Ceramic\"}],\"materialsCount\":305},{\"id\":\"composite\",\"nodeId\":\"composite\",\"name\":\"Material category\",\"label\":\"Composite\",\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"name\":\"Material category\",\"label\":\"Ceramic Matrix Composite\"},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"name\":\"Material category\",\"label\":\"Metal Matrix Composite\"},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"name\":\"Material category\",\"label\":\"Polymer Matrix Composite\"}],\"materialsCount\":367},{\"id\":\"glass\",\"nodeId\":\"glass\",\"name\":\"Material category\",\"label\":\"Glass\",\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"name\":\"Material category\",\"label\":\"Glass Ceramic\"},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"name\":\"Material category\",\"label\":\"Lead Glass\"},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"name\":\"Material category\",\"label\":\"Silicate Glass\"}],\"materialsCount\":364},{\"id\":\"metal\",\"nodeId\":\"metal\",\"name\":\"Material category\",\"label\":\"Metal\",\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"name\":\"Material category\",\"label\":\"Aluminium\"},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"name\":\"Material category\",\"label\":\"Clad / Bimetal\"},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"name\":\"Material category\",\"label\":\"Cobalt\"},{\"id\":\"copper\",\"nodeId\":\"copper\",\"name\":\"Material category\",\"label\":\"Copper\"},{\"id\":\"iron\",\"nodeId\":\"iron\",\"name\":\"Material category\",\"label\":\"Iron\"},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"name\":\"Material category\",\"label\":\"Magnesium\"},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"name\":\"Material category\",\"label\":\"Manganese\"},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"name\":\"Material category\",\"label\":\"Nickel\"},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"name\":\"Material category\",\"label\":\"Noble Metal\"},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"name\":\"Material category\",\"label\":\"Other Metal\"},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"name\":\"Material category\",\"label\":\"Refractory Metal\"},{\"id\":\"steel\",\"nodeId\":\"steel\",\"name\":\"Material category\",\"label\":\"Steel\"},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"name\":\"Material category\",\"label\":\"Titanium\"}],\"materialsCount\":23895},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"name\":\"Material category\",\"label\":\"Polymer\",\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"name\":\"Material category\",\"label\":\"Elastomer\"},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"name\":\"Material category\",\"label\":\"Thermoplastic\"},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"name\":\"Material category\",\"label\":\"Thermosetting\"}],\"materialsCount\":6385}],\"expandedMenuIds\":[]},\"footerCompanies\":{\"loggedInSupplier\":{},\"suppliers\":[]},\"dynamicFilters\":{\"query\":\"\",\"appliedFilters\":[],\"filterDefinition\":{\"name\":\"root\",\"children\":[]}},\"autoSuggestions\":[],\"contactFormSuccess\":{\"formSubmitted\":false,\"success\":false,\"done\":false},\"newsletter\":{\"userSubscribed\":false},\"comparison\":{\"orderCounter\":0,\"selection\":{}},\"experiment\":null,\"previewMaterial\":null,\"supplierMaterials\":{\"report\":null,\"materials\":[],\"publishedCount\":0,\"approvalStatus\":\"unpublished\",\"showPublishAllTriggeredPopup\":false},\"reviewCompany\":null,\"applications\":{\"applicationListView\":[],\"materialsView\":{\"query\":\"\",\"materials\":[],\"filters\":[],\"appliedFilters\":[],\"breadcrumbs\":[],\"filterGroups\":[]},\"visualisedMaterials\":[],\"visualisedProperties\":[],\"selectedMaterialsForComparison\":[],\"selectedPropertiesForCharts\":[],\"selectedPropertiesForChartsLegendData\":[],\"selectedMaterialsForCharts\":[],\"chartType\":\"\",\"chartData\":{},\"compareData\":{},\"selectedApplication\":\"\",\"totalResults\":0,\"comparisonId\":\"\"},\"autoAction\":{\"apiUrl\":[],\"infoMessageTranslationKey\":\"\",\"successRedirect\":\"\",\"successApiUrl\":\"\",\"successApiMethod\":\"\",\"failedRedirect\":\"\",\"failedAction\":\"\",\"successAction\":\"\",\"eventsAnalyticsObj\":null},\"savedSuppliers\":{\"items\":[],\"openAuthPopup\":false,\"savingItem\":null},\"advancedSearch\":{\"labels\":[],\"queryParams\":\"categories=steel\\u0026tags=form:bar\",\"categories\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"humanReadableId\":\"Biological Material\",\"label\":\"Biological Material\",\"disabled\":true,\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"humanReadableId\":\"Wood\",\"label\":\"Wood\",\"disabled\":true}]},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"humanReadableId\":\"Ceramic\",\"label\":\"Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"humanReadableId\":\"Carbon\",\"label\":\"Carbon\",\"disabled\":true,\"children\":[{\"id\":\"carbon-nanotube\",\"nodeId\":\"carbon-nanotube\",\"humanReadableId\":\"Carbon Nanotube\",\"label\":\"Carbon Nanotube\",\"disabled\":true},{\"id\":\"diamond\",\"nodeId\":\"diamond\",\"humanReadableId\":\"Diamond\",\"label\":\"Diamond\",\"disabled\":true,\"children\":[{\"id\":\"natural-diamond\",\"nodeId\":\"natural-diamond\",\"humanReadableId\":\"Natural Diamond\",\"label\":\"Natural Diamond\",\"disabled\":true},{\"id\":\"synthetic-diamond\",\"nodeId\":\"synthetic-diamond\",\"humanReadableId\":\"Synthetic Diamond\",\"label\":\"Synthetic Diamond\",\"disabled\":true}]},{\"id\":\"graphene\",\"nodeId\":\"graphene\",\"humanReadableId\":\"Graphene\",\"label\":\"Graphene\",\"disabled\":true},{\"id\":\"graphite\",\"nodeId\":\"graphite\",\"humanReadableId\":\"Graphite\",\"label\":\"Graphite\",\"disabled\":true}]},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"humanReadableId\":\"Engineering Ceramic\",\"label\":\"Engineering Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"non-oxide-based\",\"nodeId\":\"non-oxide-based\",\"humanReadableId\":\"Non Oxide Based\",\"label\":\"Non Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"boride-based\",\"nodeId\":\"boride-based\",\"humanReadableId\":\"Boride Based\",\"label\":\"Boride Based\",\"disabled\":true},{\"id\":\"carbide-based\",\"nodeId\":\"carbide-based\",\"humanReadableId\":\"Carbide Based\",\"label\":\"Carbide Based\",\"disabled\":true,\"children\":[{\"id\":\"boron-carbide\",\"nodeId\":\"boron-carbide\",\"humanReadableId\":\"Boron Carbide\",\"label\":\"Boron Carbide\",\"disabled\":true},{\"id\":\"silicon-carbide\",\"nodeId\":\"silicon-carbide\",\"humanReadableId\":\"Silicon Carbide\",\"label\":\"Silicon Carbide\",\"disabled\":true},{\"id\":\"tantalum-carbide\",\"nodeId\":\"tantalum-carbide\",\"humanReadableId\":\"Tantalum Carbide\",\"label\":\"Tantalum Carbide\",\"disabled\":true},{\"id\":\"titanium-carbide\",\"nodeId\":\"titanium-carbide\",\"humanReadableId\":\"Titanium Carbide\",\"label\":\"Titanium Carbide\",\"disabled\":true},{\"id\":\"tungsten-carbide\",\"nodeId\":\"tungsten-carbide\",\"humanReadableId\":\"Tungsten Carbide\",\"label\":\"Tungsten Carbide\",\"disabled\":true},{\"id\":\"zirconium-carbide\",\"nodeId\":\"zirconium-carbide\",\"humanReadableId\":\"Zirconium Carbide\",\"label\":\"Zirconium Carbide\",\"disabled\":true}]},{\"id\":\"nitride-based\",\"nodeId\":\"nitride-based\",\"humanReadableId\":\"Nitride Based\",\"label\":\"Nitride Based\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nitirde\",\"nodeId\":\"aluminium-nitirde\",\"humanReadableId\":\"Aluminium Nitirde\",\"label\":\"Aluminium Nitirde\",\"disabled\":true},{\"id\":\"boron-nitride\",\"nodeId\":\"boron-nitride\",\"humanReadableId\":\"Boron Nitride\",\"label\":\"Boron Nitride\",\"disabled\":true},{\"id\":\"silicon-nitride\",\"nodeId\":\"silicon-nitride\",\"humanReadableId\":\"Silicon Nitride\",\"label\":\"Silicon Nitride\",\"disabled\":true},{\"id\":\"titanium-nitride\",\"nodeId\":\"titanium-nitride\",\"humanReadableId\":\"Titanium Nitride\",\"label\":\"Titanium Nitride\",\"disabled\":true}]},{\"id\":\"silicate-based\",\"nodeId\":\"silicate-based\",\"humanReadableId\":\"Silicate Based\",\"label\":\"Silicate Based\",\"disabled\":true},{\"id\":\"sulfide-based\",\"nodeId\":\"sulfide-based\",\"humanReadableId\":\"Sulfide Based\",\"label\":\"Sulfide Based\",\"disabled\":true,\"children\":[{\"id\":\"bismuth-sulfide\",\"nodeId\":\"bismuth-sulfide\",\"humanReadableId\":\"Bismuth Sulfide\",\"label\":\"Bismuth Sulfide\",\"disabled\":true},{\"id\":\"copper-sulfide\",\"nodeId\":\"copper-sulfide\",\"humanReadableId\":\"Copper Sulfide\",\"label\":\"Copper Sulfide\",\"disabled\":true},{\"id\":\"iron-sulfide\",\"nodeId\":\"iron-sulfide\",\"humanReadableId\":\"Iron Sulfide\",\"label\":\"Iron Sulfide\",\"disabled\":true},{\"id\":\"manganese-sulfide\",\"nodeId\":\"manganese-sulfide\",\"humanReadableId\":\"Manganese Sulfide\",\"label\":\"Manganese Sulfide\",\"disabled\":true},{\"id\":\"molybdenum-disulfide\",\"nodeId\":\"molybdenum-disulfide\",\"humanReadableId\":\"Molybdenum Disulfide\",\"label\":\"Molybdenum Disulfide\",\"disabled\":true},{\"id\":\"multiphase-metal-sulfide\",\"nodeId\":\"multiphase-metal-sulfide\",\"humanReadableId\":\"Multiphase Metal Sulfide\",\"label\":\"Multiphase Metal Sulfide\",\"disabled\":true},{\"id\":\"tin-sulfide\",\"nodeId\":\"tin-sulfide\",\"humanReadableId\":\"Tin Sulfide\",\"label\":\"Tin Sulfide\",\"disabled\":true},{\"id\":\"tungsten-disulfide\",\"nodeId\":\"tungsten-disulfide\",\"humanReadableId\":\"Tungsten Disulfide\",\"label\":\"Tungsten Disulfide\",\"disabled\":true},{\"id\":\"zinc-sulfide\",\"nodeId\":\"zinc-sulfide\",\"humanReadableId\":\"Zinc Sulfide\",\"label\":\"Zinc Sulfide\",\"disabled\":true}]}]},{\"id\":\"oxide-based\",\"nodeId\":\"oxide-based\",\"humanReadableId\":\"Oxide Based\",\"label\":\"Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"advanced-ceramic-oxides\",\"nodeId\":\"advanced-ceramic-oxides\",\"humanReadableId\":\"Advanced Ceramic Oxides\",\"label\":\"Advanced Ceramic Oxides\",\"disabled\":true},{\"id\":\"aluminium-oxide\",\"nodeId\":\"aluminium-oxide\",\"humanReadableId\":\"Aluminium Oxide\",\"label\":\"Aluminium Oxide\",\"disabled\":true},{\"id\":\"beryllium-oxide\",\"nodeId\":\"beryllium-oxide\",\"humanReadableId\":\"Beryllium Oxide\",\"label\":\"Beryllium Oxide\",\"disabled\":true},{\"id\":\"ferrite\",\"nodeId\":\"ferrite\",\"humanReadableId\":\"Ferrite\",\"label\":\"Ferrite\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-silicate\",\"nodeId\":\"aluminium-silicate\",\"humanReadableId\":\"Aluminium Silicate\",\"label\":\"Aluminium Silicate\",\"disabled\":true},{\"id\":\"magnesium-silicate\",\"nodeId\":\"magnesium-silicate\",\"humanReadableId\":\"Magnesium Silicate\",\"label\":\"Magnesium Silicate\",\"disabled\":true},{\"id\":\"zirconium-silicate\",\"nodeId\":\"zirconium-silicate\",\"humanReadableId\":\"Zirconium Silicate\",\"label\":\"Zirconium Silicate\",\"disabled\":true}]},{\"id\":\"titanium-oxide\",\"nodeId\":\"titanium-oxide\",\"humanReadableId\":\"Titanium Oxide\",\"label\":\"Titanium Oxide\",\"disabled\":true},{\"id\":\"zirconium-oxide\",\"nodeId\":\"zirconium-oxide\",\"humanReadableId\":\"Zirconium Oxide\",\"label\":\"Zirconium Oxide\",\"disabled\":true}]},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"multi-oxide-ceramics\",\"nodeId\":\"multi-oxide-ceramics\",\"humanReadableId\":\"Multi-Oxide Ceramics\",\"label\":\"Multi-Oxide Ceramics\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide-\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true},{\"id\":\"ytterbium-oxide\",\"nodeId\":\"ytterbium-oxide\",\"humanReadableId\":\"Ytterbium Oxide\",\"label\":\"Ytterbium Oxide\",\"disabled\":true},{\"id\":\"yttrium-oxide\",\"nodeId\":\"yttrium-oxide\",\"humanReadableId\":\"Yttrium Oxide\",\"label\":\"Yttrium Oxide\",\"disabled\":true}]}]},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"humanReadableId\":\"Natural Ceramic\",\"label\":\"Natural Ceramic\",\"disabled\":true}]},{\"id\":\"composite\",\"nodeId\":\"composite\",\"humanReadableId\":\"Composite\",\"label\":\"Composite\",\"disabled\":true,\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"humanReadableId\":\"Ceramic Matrix Composite\",\"label\":\"Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"carbide-based-ceramic-matrix-composite\",\"nodeId\":\"carbide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Carbide Based Ceramic Matrix Composite\",\"label\":\"Carbide Based Ceramic Matrix Composite\",\"disabled\":true},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite-\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true}]},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"humanReadableId\":\"Metal Matrix Composite\",\"label\":\"Metal Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-matrix-composite\",\"nodeId\":\"aluminium-matrix-composite\",\"humanReadableId\":\"Aluminium Matrix Composite\",\"label\":\"Aluminium Matrix Composite\",\"disabled\":true},{\"id\":\"beryllium-matrix-composite\",\"nodeId\":\"beryllium-matrix-composite\",\"humanReadableId\":\"Beryllium Matrix Composite\",\"label\":\"Beryllium Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-matrix-composite\",\"nodeId\":\"cobalt-matrix-composite\",\"humanReadableId\":\"Cobalt Matrix Composite\",\"label\":\"Cobalt Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-and-nickel-matrix-composite\",\"nodeId\":\"cobalt-and-nickel-matrix-composite\",\"humanReadableId\":\"Cobalt and Nickel Matrix Composite\",\"label\":\"Cobalt and Nickel Matrix Composite\",\"disabled\":true},{\"id\":\"iron-matrix-composite\",\"nodeId\":\"iron-matrix-composite\",\"humanReadableId\":\"Iron Matrix Composite\",\"label\":\"Iron Matrix Composite\",\"disabled\":true},{\"id\":\"nickel-matrix-composite\",\"nodeId\":\"nickel-matrix-composite\",\"humanReadableId\":\"Nickel Matrix Composite\",\"label\":\"Nickel Matrix Composite\",\"disabled\":true}]},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"humanReadableId\":\"Polymer Matrix Composite\",\"label\":\"Polymer Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"thermoset-polymer-matrix-composite\",\"nodeId\":\"thermoset-polymer-matrix-composite\",\"humanReadableId\":\"Thermoset Polymer Matrix Composite\",\"label\":\"Thermoset Polymer Matrix Composite\",\"disabled\":true}]}]},{\"id\":\"glass\",\"nodeId\":\"glass\",\"humanReadableId\":\"Glass\",\"label\":\"Glass\",\"disabled\":true,\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"humanReadableId\":\"Glass Ceramic\",\"label\":\"Glass Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"las-glass-ceramic\",\"nodeId\":\"las-glass-ceramic\",\"humanReadableId\":\"LAS Glass Ceramic\",\"label\":\"LAS Glass Ceramic\",\"disabled\":true}]},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"humanReadableId\":\"Lead Glass\",\"label\":\"Lead Glass\",\"disabled\":true},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"humanReadableId\":\"Silicate Glass\",\"label\":\"Silicate Glass\",\"disabled\":true,\"children\":[{\"id\":\"aluminosilicate\",\"nodeId\":\"aluminosilicate\",\"humanReadableId\":\"Aluminosilicate\",\"label\":\"Aluminosilicate\",\"disabled\":true},{\"id\":\"borosilicate\",\"nodeId\":\"borosilicate\",\"humanReadableId\":\"Borosilicate\",\"label\":\"Borosilicate\",\"disabled\":true},{\"id\":\"fused-quartz\",\"nodeId\":\"fused-quartz\",\"humanReadableId\":\"Fused Quartz\",\"label\":\"Fused Quartz\",\"disabled\":true},{\"id\":\"soda-lime-silicate\",\"nodeId\":\"soda-lime-silicate\",\"humanReadableId\":\"Soda Lime Silicate\",\"label\":\"Soda Lime Silicate\",\"disabled\":true}]}]},{\"id\":\"metal\",\"nodeId\":\"metal\",\"humanReadableId\":\"Metal\",\"label\":\"Metal\",\"partiallyChecked\":true,\"materialsCount\":2214,\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"humanReadableId\":\"Aluminium\",\"label\":\"Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-master-alloy\",\"nodeId\":\"aluminium-master-alloy\",\"humanReadableId\":\"Aluminium Master Alloy\",\"label\":\"Aluminium Master Alloy\",\"disabled\":true},{\"id\":\"cast-aluminium\",\"nodeId\":\"cast-aluminium\",\"humanReadableId\":\"Cast Aluminium\",\"label\":\"Cast Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1xx-x\",\"nodeId\":\"1xx-x\",\"humanReadableId\":\"1xx.x\",\"label\":\"1xx.x\",\"disabled\":true},{\"id\":\"2xx-x\",\"nodeId\":\"2xx-x\",\"humanReadableId\":\"2xx.x\",\"label\":\"2xx.x\",\"disabled\":true},{\"id\":\"3xx-x\",\"nodeId\":\"3xx-x\",\"humanReadableId\":\"3xx.x\",\"label\":\"3xx.x\",\"disabled\":true},{\"id\":\"4xx-x\",\"nodeId\":\"4xx-x\",\"humanReadableId\":\"4xx.x\",\"label\":\"4xx.x\",\"disabled\":true},{\"id\":\"5xx-x\",\"nodeId\":\"5xx-x\",\"humanReadableId\":\"5xx.x\",\"label\":\"5xx.x\",\"disabled\":true},{\"id\":\"7xx-x\",\"nodeId\":\"7xx-x\",\"humanReadableId\":\"7xx.x\",\"label\":\"7xx.x\",\"disabled\":true},{\"id\":\"8xx-x\",\"nodeId\":\"8xx-x\",\"humanReadableId\":\"8xx.x\",\"label\":\"8xx.x\",\"disabled\":true}]},{\"id\":\"wrought-aluminium\",\"nodeId\":\"wrought-aluminium\",\"humanReadableId\":\"Wrought Aluminium\",\"label\":\"Wrought Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1000-series\",\"nodeId\":\"1000-series\",\"humanReadableId\":\"1000 Series\",\"label\":\"1000 Series\",\"disabled\":true},{\"id\":\"2000-series\",\"nodeId\":\"2000-series\",\"humanReadableId\":\"2000 Series\",\"label\":\"2000 Series\",\"disabled\":true},{\"id\":\"3000-series\",\"nodeId\":\"3000-series\",\"humanReadableId\":\"3000 Series\",\"label\":\"3000 Series\",\"disabled\":true},{\"id\":\"4000-series\",\"nodeId\":\"4000-series\",\"humanReadableId\":\"4000 Series\",\"label\":\"4000 Series\",\"disabled\":true},{\"id\":\"5000-series\",\"nodeId\":\"5000-series\",\"humanReadableId\":\"5000 Series\",\"label\":\"5000 Series\",\"disabled\":true},{\"id\":\"6000-series\",\"nodeId\":\"6000-series\",\"humanReadableId\":\"6000 Series\",\"label\":\"6000 Series\",\"disabled\":true},{\"id\":\"7000-series\",\"nodeId\":\"7000-series\",\"humanReadableId\":\"7000 Series\",\"label\":\"7000 Series\",\"disabled\":true},{\"id\":\"8000-series\",\"nodeId\":\"8000-series\",\"humanReadableId\":\"8000 Series\",\"label\":\"8000 Series\",\"disabled\":true}]}]},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"humanReadableId\":\"Clad / Bimetal\",\"label\":\"Clad / Bimetal\",\"disabled\":true},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"humanReadableId\":\"Cobalt\",\"label\":\"Cobalt\",\"disabled\":true,\"children\":[{\"id\":\"cobalt-chromium\",\"nodeId\":\"cobalt-chromium\",\"humanReadableId\":\"Cobalt Chromium\",\"label\":\"Cobalt Chromium\",\"disabled\":true},{\"id\":\"cobalt-chromium-molybdenum\",\"nodeId\":\"cobalt-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Chromium Molybdenum\",\"label\":\"Cobalt Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-chromium-nickel-tungsten\",\"nodeId\":\"cobalt-chromium-nickel-tungsten\",\"humanReadableId\":\"Cobalt Chromium Nickel Tungsten\",\"label\":\"Cobalt Chromium Nickel Tungsten\",\"disabled\":true},{\"id\":\"cobalt-chromium-tungsten\",\"nodeId\":\"cobalt-chromium-tungsten\",\"humanReadableId\":\"Cobalt Chromium Tungsten\",\"label\":\"Cobalt Chromium Tungsten\",\"disabled\":true},{\"id\":\"cobalt-nickel-chromium-molybdenum\",\"nodeId\":\"cobalt-nickel-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Nickel Chromium Molybdenum\",\"label\":\"Cobalt Nickel Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-superalloy\",\"nodeId\":\"cobalt-superalloy\",\"humanReadableId\":\"Cobalt Superalloy\",\"label\":\"Cobalt Superalloy\",\"disabled\":true},{\"id\":\"unclassified-cobalt-alloy\",\"nodeId\":\"unclassified-cobalt-alloy\",\"humanReadableId\":\"Unclassified Cobalt Alloy\",\"label\":\"Unclassified Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"copper\",\"nodeId\":\"copper\",\"humanReadableId\":\"Copper\",\"label\":\"Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper\",\"nodeId\":\"cast-copper\",\"humanReadableId\":\"Cast Copper\",\"label\":\"Cast Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass\",\"nodeId\":\"cast-copper-brass\",\"humanReadableId\":\"Cast Copper Brass\",\"label\":\"Cast Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass-yellow-brass\",\"nodeId\":\"cast-copper-brass-yellow-brass\",\"humanReadableId\":\"Cast Copper Brass Yellow Brass\",\"label\":\"Cast Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"cast-copper-silicon-brass\",\"nodeId\":\"cast-copper-silicon-brass\",\"humanReadableId\":\"Cast Copper Silicon Brass\",\"label\":\"Cast Copper Silicon Brass\",\"disabled\":true},{\"id\":\"copper-bismuth-alloy\",\"nodeId\":\"copper-bismuth-alloy\",\"humanReadableId\":\"Copper Bismuth Alloy\",\"label\":\"Copper Bismuth Alloy\",\"disabled\":true},{\"id\":\"red-brass\",\"nodeId\":\"red-brass\",\"humanReadableId\":\"Red Brass\",\"label\":\"Red Brass\",\"disabled\":true}]},{\"id\":\"cast-copper-bronze\",\"nodeId\":\"cast-copper-bronze\",\"humanReadableId\":\"Cast Copper Bronze\",\"label\":\"Cast Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-bronze-aluminium-bronze\",\"nodeId\":\"cast-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Cast Copper Bronze Aluminium Bronze\",\"label\":\"Cast Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"leaded-tin-bronze\",\"nodeId\":\"leaded-tin-bronze\",\"humanReadableId\":\"Leaded Tin Bronze\",\"label\":\"Leaded Tin Bronze\",\"disabled\":true},{\"id\":\"nickel-tin-bronze\",\"nodeId\":\"nickel-tin-bronze\",\"humanReadableId\":\"Nickel Tin Bronze\",\"label\":\"Nickel Tin Bronze\",\"disabled\":true},{\"id\":\"tin-bronze\",\"nodeId\":\"tin-bronze\",\"humanReadableId\":\"Tin Bronze\",\"label\":\"Tin Bronze\",\"disabled\":true}]},{\"id\":\"cast-copper-high-copper-alloy\",\"nodeId\":\"cast-copper-high-copper-alloy\",\"humanReadableId\":\"Cast Copper High Copper Alloy\",\"label\":\"Cast Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"cast-copper-nickel-grade\",\"nodeId\":\"cast-copper-nickel-grade\",\"humanReadableId\":\"Cast Copper Nickel Grade\",\"label\":\"Cast Copper Nickel Grade\",\"disabled\":true},{\"id\":\"cast-copper-nickel-silver-grade\",\"nodeId\":\"cast-copper-nickel-silver-grade\",\"humanReadableId\":\"Cast Copper Nickel Silver Grade\",\"label\":\"Cast Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"cast-copper-pure---low-alloyed-copper\",\"nodeId\":\"cast-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Cast Copper Pure / Low Alloyed Copper\",\"label\":\"Cast Copper Pure / Low Alloyed Copper\",\"disabled\":true},{\"id\":\"copper-lead-alloy\",\"nodeId\":\"copper-lead-alloy\",\"humanReadableId\":\"Copper-Lead Alloy\",\"label\":\"Copper-Lead Alloy\",\"disabled\":true},{\"id\":\"special-alloy\",\"nodeId\":\"special-alloy\",\"humanReadableId\":\"Special Alloy\",\"label\":\"Special Alloy\",\"disabled\":true}]},{\"id\":\"welding\",\"nodeId\":\"welding\",\"humanReadableId\":\"Welding\",\"label\":\"Welding\",\"disabled\":true},{\"id\":\"wrought-copper\",\"nodeId\":\"wrought-copper\",\"humanReadableId\":\"Wrought Copper\",\"label\":\"Wrought Copper\",\"disabled\":true,\"children\":[{\"id\":\"unclassified-wrought-copper\",\"nodeId\":\"unclassified-wrought-copper\",\"humanReadableId\":\"Unclassified Wrought Copper\",\"label\":\"Unclassified Wrought Copper\",\"disabled\":true},{\"id\":\"wrought-copper-brass\",\"nodeId\":\"wrought-copper-brass\",\"humanReadableId\":\"Wrought Copper Brass\",\"label\":\"Wrought Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"leaded-brass\",\"nodeId\":\"leaded-brass\",\"humanReadableId\":\"Leaded Brass\",\"label\":\"Leaded Brass\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"tin-brass\",\"nodeId\":\"tin-brass\",\"humanReadableId\":\"Tin Brass\",\"label\":\"Tin Brass\",\"disabled\":true},{\"id\":\"wrought-copper-brass-yellow-brass\",\"nodeId\":\"wrought-copper-brass-yellow-brass\",\"humanReadableId\":\"Wrought Copper Brass Yellow Brass\",\"label\":\"Wrought Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"yellow-wrought-brass\",\"nodeId\":\"yellow-wrought-brass\",\"humanReadableId\":\"Yellow Wrought Brass\",\"label\":\"Yellow Wrought Brass\",\"disabled\":true}]},{\"id\":\"wrought-copper-bronze\",\"nodeId\":\"wrought-copper-bronze\",\"humanReadableId\":\"Wrought Copper Bronze\",\"label\":\"Wrought Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"copper-silver-zinc-alloy\",\"nodeId\":\"copper-silver-zinc-alloy\",\"humanReadableId\":\"Copper Silver Zinc Alloy\",\"label\":\"Copper Silver Zinc Alloy\",\"disabled\":true},{\"id\":\"leaded-phosphor-bronze\",\"nodeId\":\"leaded-phosphor-bronze\",\"humanReadableId\":\"Leaded Phosphor Bronze\",\"label\":\"Leaded Phosphor Bronze\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy-\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"phosphor-bronze\",\"nodeId\":\"phosphor-bronze\",\"humanReadableId\":\"Phosphor Bronze\",\"label\":\"Phosphor Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-aluminium-bronze\",\"nodeId\":\"wrought-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Aluminium Bronze\",\"label\":\"Wrought Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-silicon-bronze\",\"nodeId\":\"wrought-copper-bronze-silicon-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Silicon Bronze\",\"label\":\"Wrought Copper Bronze Silicon Bronze\",\"disabled\":true}]},{\"id\":\"wrought-copper-high-copper-alloy\",\"nodeId\":\"wrought-copper-high-copper-alloy\",\"humanReadableId\":\"Wrought Copper High Copper Alloy\",\"label\":\"Wrought Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-grade\",\"nodeId\":\"wrought-copper-nickel-grade\",\"humanReadableId\":\"Wrought Copper Nickel Grade\",\"label\":\"Wrought Copper Nickel Grade\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-silver-grade\",\"nodeId\":\"wrought-copper-nickel-silver-grade\",\"humanReadableId\":\"Wrought Copper Nickel Silver Grade\",\"label\":\"Wrought Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"wrought-copper-pure---low-alloyed-copper\",\"nodeId\":\"wrought-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Wrought Copper Pure / Low Alloyed Copper\",\"label\":\"Wrought Copper Pure / Low Alloyed Copper\",\"disabled\":true}]}]},{\"id\":\"iron\",\"nodeId\":\"iron\",\"humanReadableId\":\"Iron\",\"label\":\"Iron\",\"disabled\":true,\"children\":[{\"id\":\"alloy-iron\",\"nodeId\":\"alloy-iron\",\"humanReadableId\":\"Alloy Iron\",\"label\":\"Alloy Iron\",\"disabled\":true},{\"id\":\"cast-iron\",\"nodeId\":\"cast-iron\",\"humanReadableId\":\"Cast Iron\",\"label\":\"Cast Iron\",\"disabled\":true,\"children\":[{\"id\":\"ductile--nodular--cast-iron\",\"nodeId\":\"ductile--nodular--cast-iron\",\"humanReadableId\":\"Ductile (Nodular) Cast Iron\",\"label\":\"Ductile (Nodular) Cast Iron\",\"disabled\":true},{\"id\":\"grey-cast-iron\",\"nodeId\":\"grey-cast-iron\",\"humanReadableId\":\"Grey Cast Iron\",\"label\":\"Grey Cast Iron\",\"disabled\":true},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true},{\"id\":\"other-cast-iron-alloy\",\"nodeId\":\"other-cast-iron-alloy\",\"humanReadableId\":\"Other Cast Iron Alloy\",\"label\":\"Other Cast Iron Alloy\",\"disabled\":true},{\"id\":\"white-cast-iron\",\"nodeId\":\"white-cast-iron\",\"humanReadableId\":\"White Cast Iron\",\"label\":\"White Cast Iron\",\"disabled\":true}]},{\"id\":\"ferromolybdenum\",\"nodeId\":\"ferromolybdenum\",\"humanReadableId\":\"Ferromolybdenum\",\"label\":\"Ferromolybdenum\",\"disabled\":true},{\"id\":\"ferrosilicon\",\"nodeId\":\"ferrosilicon\",\"humanReadableId\":\"Ferrosilicon\",\"label\":\"Ferrosilicon\",\"disabled\":true},{\"id\":\"ferrovanadium\",\"nodeId\":\"ferrovanadium\",\"humanReadableId\":\"Ferrovanadium\",\"label\":\"Ferrovanadium\",\"disabled\":true},{\"id\":\"iron-alloy\",\"nodeId\":\"iron-alloy\",\"humanReadableId\":\"Iron Alloy\",\"label\":\"Iron Alloy\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nickel-cobalt-iron-alloy\",\"nodeId\":\"aluminium-nickel-cobalt-iron-alloy\",\"humanReadableId\":\"Aluminium Nickel Cobalt Iron Alloy\",\"label\":\"Aluminium Nickel Cobalt Iron Alloy\",\"disabled\":true},{\"id\":\"miscellaneous-iron-alloy\",\"nodeId\":\"miscellaneous-iron-alloy\",\"humanReadableId\":\"Miscellaneous Iron Alloy\",\"label\":\"Miscellaneous Iron Alloy\",\"disabled\":true},{\"id\":\"soft-magnetic-iron\",\"nodeId\":\"soft-magnetic-iron\",\"humanReadableId\":\"Soft Magnetic Iron\",\"label\":\"Soft Magnetic Iron\",\"disabled\":true}]},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron-\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true}]},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"humanReadableId\":\"Magnesium\",\"label\":\"Magnesium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-grade\",\"nodeId\":\"aluminium-grade\",\"humanReadableId\":\"Aluminium Grade\",\"label\":\"Aluminium Grade\",\"disabled\":true},{\"id\":\"cast-aluminium-manganese-grade\",\"nodeId\":\"cast-aluminium-manganese-grade\",\"humanReadableId\":\"Cast Aluminium Manganese Grade\",\"label\":\"Cast Aluminium Manganese Grade\",\"disabled\":true},{\"id\":\"cast-rare-earth-grade\",\"nodeId\":\"cast-rare-earth-grade\",\"humanReadableId\":\"Cast Rare Earth Grade\",\"label\":\"Cast Rare Earth Grade\",\"disabled\":true},{\"id\":\"cast-wrought-aluminium-zinc-grade\",\"nodeId\":\"cast-wrought-aluminium-zinc-grade\",\"humanReadableId\":\"Cast/Wrought Aluminium Zinc Grade\",\"label\":\"Cast/Wrought Aluminium Zinc Grade\",\"disabled\":true},{\"id\":\"cast-wrought-unclassified-grade\",\"nodeId\":\"cast-wrought-unclassified-grade\",\"humanReadableId\":\"Cast/Wrought Unclassified Grade\",\"label\":\"Cast/Wrought Unclassified Grade\",\"disabled\":true},{\"id\":\"pure-magnesium\",\"nodeId\":\"pure-magnesium\",\"humanReadableId\":\"Pure Magnesium\",\"label\":\"Pure Magnesium\",\"disabled\":true},{\"id\":\"rare-earth-grade\",\"nodeId\":\"rare-earth-grade\",\"humanReadableId\":\"Rare Earth Grade\",\"label\":\"Rare Earth Grade\",\"disabled\":true},{\"id\":\"wrought-zinc-grade\",\"nodeId\":\"wrought-zinc-grade\",\"humanReadableId\":\"Wrought Zinc Grade\",\"label\":\"Wrought Zinc Grade\",\"disabled\":true},{\"id\":\"yttrium-grade\",\"nodeId\":\"yttrium-grade\",\"humanReadableId\":\"Yttrium Grade\",\"label\":\"Yttrium Grade\",\"disabled\":true},{\"id\":\"zinc-grade\",\"nodeId\":\"zinc-grade\",\"humanReadableId\":\"Zinc Grade\",\"label\":\"Zinc Grade\",\"disabled\":true}]},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"humanReadableId\":\"Manganese\",\"label\":\"Manganese\",\"disabled\":true},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"humanReadableId\":\"Nickel\",\"label\":\"Nickel\",\"disabled\":true,\"children\":[{\"id\":\"nickel-chromium-alloy\",\"nodeId\":\"nickel-chromium-alloy\",\"humanReadableId\":\"Nickel Chromium Alloy\",\"label\":\"Nickel Chromium Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-cobalt-alloy\",\"nodeId\":\"nickel-chromium-cobalt-alloy\",\"humanReadableId\":\"Nickel Chromium Cobalt Alloy\",\"label\":\"Nickel Chromium Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-iron-alloy\",\"nodeId\":\"nickel-chromium-iron-alloy\",\"humanReadableId\":\"Nickel Chromium Iron Alloy\",\"label\":\"Nickel Chromium Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-molybdenum-alloy\",\"nodeId\":\"nickel-chromium-molybdenum-alloy\",\"humanReadableId\":\"Nickel Chromium Molybdenum Alloy\",\"label\":\"Nickel Chromium Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-cobalt-alloy\",\"nodeId\":\"nickel-cobalt-alloy\",\"humanReadableId\":\"Nickel Cobalt Alloy\",\"label\":\"Nickel Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-copper-alloy\",\"nodeId\":\"nickel-copper-alloy\",\"humanReadableId\":\"Nickel Copper Alloy\",\"label\":\"Nickel Copper Alloy\",\"disabled\":true},{\"id\":\"nickel-iron-alloy\",\"nodeId\":\"nickel-iron-alloy\",\"humanReadableId\":\"Nickel Iron Alloy\",\"label\":\"Nickel Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-molybdenum-alloy\",\"nodeId\":\"nickel-molybdenum-alloy\",\"humanReadableId\":\"Nickel Molybdenum Alloy\",\"label\":\"Nickel Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-superalloy\",\"nodeId\":\"nickel-superalloy\",\"humanReadableId\":\"Nickel Superalloy\",\"label\":\"Nickel Superalloy\",\"disabled\":true},{\"id\":\"nickel-welding-filler\",\"nodeId\":\"nickel-welding-filler\",\"humanReadableId\":\"Nickel Welding Filler\",\"label\":\"Nickel Welding Filler\",\"disabled\":true},{\"id\":\"other-nickel-alloy\",\"nodeId\":\"other-nickel-alloy\",\"humanReadableId\":\"Other Nickel Alloy\",\"label\":\"Other Nickel Alloy\",\"disabled\":true},{\"id\":\"pure-low-nickel-alloy\",\"nodeId\":\"pure-low-nickel-alloy\",\"humanReadableId\":\"Pure/Low Nickel Alloy\",\"label\":\"Pure/Low Nickel Alloy\",\"disabled\":true}]},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"humanReadableId\":\"Noble Metal\",\"label\":\"Noble Metal\",\"disabled\":true,\"children\":[{\"id\":\"gold\",\"nodeId\":\"gold\",\"humanReadableId\":\"Gold\",\"label\":\"Gold\",\"disabled\":true},{\"id\":\"iridium\",\"nodeId\":\"iridium\",\"humanReadableId\":\"Iridium\",\"label\":\"Iridium\",\"disabled\":true},{\"id\":\"palladium\",\"nodeId\":\"palladium\",\"humanReadableId\":\"Palladium\",\"label\":\"Palladium\",\"disabled\":true},{\"id\":\"platinum\",\"nodeId\":\"platinum\",\"humanReadableId\":\"Platinum\",\"label\":\"Platinum\",\"disabled\":true},{\"id\":\"rhodium\",\"nodeId\":\"rhodium\",\"humanReadableId\":\"Rhodium\",\"label\":\"Rhodium\",\"disabled\":true},{\"id\":\"silver\",\"nodeId\":\"silver\",\"humanReadableId\":\"Silver\",\"label\":\"Silver\",\"disabled\":true}]},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"humanReadableId\":\"Other Metal\",\"label\":\"Other Metal\",\"disabled\":true,\"children\":[{\"id\":\"beryllium\",\"nodeId\":\"beryllium\",\"humanReadableId\":\"Beryllium\",\"label\":\"Beryllium\",\"disabled\":true},{\"id\":\"cadmium\",\"nodeId\":\"cadmium\",\"humanReadableId\":\"Cadmium\",\"label\":\"Cadmium\",\"disabled\":true},{\"id\":\"chromium\",\"nodeId\":\"chromium\",\"humanReadableId\":\"Chromium\",\"label\":\"Chromium\",\"disabled\":true},{\"id\":\"lead\",\"nodeId\":\"lead\",\"humanReadableId\":\"Lead\",\"label\":\"Lead\",\"disabled\":true,\"children\":[{\"id\":\"lead-antimony\",\"nodeId\":\"lead-antimony\",\"humanReadableId\":\"Lead Antimony\",\"label\":\"Lead Antimony\",\"disabled\":true},{\"id\":\"lead-tin\",\"nodeId\":\"lead-tin\",\"humanReadableId\":\"Lead Tin\",\"label\":\"Lead Tin\",\"disabled\":true},{\"id\":\"pure-low-alloyed-lead\",\"nodeId\":\"pure-low-alloyed-lead\",\"humanReadableId\":\"Pure/Low Alloyed Lead\",\"label\":\"Pure/Low Alloyed Lead\",\"disabled\":true}]},{\"id\":\"lithium\",\"nodeId\":\"lithium\",\"humanReadableId\":\"Lithium\",\"label\":\"Lithium\",\"disabled\":true},{\"id\":\"neodymium\",\"nodeId\":\"neodymium\",\"humanReadableId\":\"Neodymium\",\"label\":\"Neodymium\",\"disabled\":true,\"children\":[{\"id\":\"neodymium-iron-boron-alloy\",\"nodeId\":\"neodymium-iron-boron-alloy\",\"humanReadableId\":\"Neodymium Iron Boron Alloy\",\"label\":\"Neodymium Iron Boron Alloy\",\"disabled\":true}]},{\"id\":\"samarium\",\"nodeId\":\"samarium\",\"humanReadableId\":\"Samarium\",\"label\":\"Samarium\",\"disabled\":true,\"children\":[{\"id\":\"samarium-cobalt-alloy\",\"nodeId\":\"samarium-cobalt-alloy\",\"humanReadableId\":\"Samarium Cobalt Alloy\",\"label\":\"Samarium Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"tin\",\"nodeId\":\"tin\",\"humanReadableId\":\"Tin\",\"label\":\"Tin\",\"disabled\":true,\"children\":[{\"id\":\"pure-low-alloyed-tin\",\"nodeId\":\"pure-low-alloyed-tin\",\"humanReadableId\":\"Pure/Low Alloyed Tin\",\"label\":\"Pure/Low Alloyed Tin\",\"disabled\":true},{\"id\":\"tin-antimony\",\"nodeId\":\"tin-antimony\",\"humanReadableId\":\"Tin Antimony\",\"label\":\"Tin Antimony\",\"disabled\":true},{\"id\":\"tin-lead\",\"nodeId\":\"tin-lead\",\"humanReadableId\":\"Tin Lead\",\"label\":\"Tin Lead\",\"disabled\":true},{\"id\":\"unclassified-tin\",\"nodeId\":\"unclassified-tin\",\"humanReadableId\":\"Unclassified Tin\",\"label\":\"Unclassified Tin\",\"disabled\":true}]},{\"id\":\"zinc\",\"nodeId\":\"zinc\",\"humanReadableId\":\"Zinc\",\"label\":\"Zinc\",\"disabled\":true,\"children\":[{\"id\":\"unalloyed-zinc\",\"nodeId\":\"unalloyed-zinc\",\"humanReadableId\":\"Unalloyed Zinc\",\"label\":\"Unalloyed Zinc\",\"disabled\":true},{\"id\":\"unclassified-zinc\",\"nodeId\":\"unclassified-zinc\",\"humanReadableId\":\"Unclassified Zinc\",\"label\":\"Unclassified Zinc\",\"disabled\":true},{\"id\":\"zinc-aluminium\",\"nodeId\":\"zinc-aluminium\",\"humanReadableId\":\"Zinc Aluminium\",\"label\":\"Zinc Aluminium\",\"disabled\":true}]}]},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"humanReadableId\":\"Refractory Metal\",\"label\":\"Refractory Metal\",\"disabled\":true,\"children\":[{\"id\":\"hafnium\",\"nodeId\":\"hafnium\",\"humanReadableId\":\"Hafnium\",\"label\":\"Hafnium\",\"disabled\":true},{\"id\":\"molybdenum\",\"nodeId\":\"molybdenum\",\"humanReadableId\":\"Molybdenum\",\"label\":\"Molybdenum\",\"disabled\":true},{\"id\":\"niobium\",\"nodeId\":\"niobium\",\"humanReadableId\":\"Niobium\",\"label\":\"Niobium\",\"disabled\":true},{\"id\":\"rhenium\",\"nodeId\":\"rhenium\",\"humanReadableId\":\"Rhenium\",\"label\":\"Rhenium\",\"disabled\":true},{\"id\":\"tantalum\",\"nodeId\":\"tantalum\",\"humanReadableId\":\"Tantalum\",\"label\":\"Tantalum\",\"disabled\":true},{\"id\":\"tungsten\",\"nodeId\":\"tungsten\",\"humanReadableId\":\"Tungsten\",\"label\":\"Tungsten\",\"disabled\":true},{\"id\":\"vanadium\",\"nodeId\":\"vanadium\",\"humanReadableId\":\"Vanadium\",\"label\":\"Vanadium\",\"disabled\":true},{\"id\":\"zirconium\",\"nodeId\":\"zirconium\",\"humanReadableId\":\"Zirconium\",\"label\":\"Zirconium\",\"disabled\":true}]},{\"id\":\"steel\",\"nodeId\":\"steel\",\"humanReadableId\":\"Steel\",\"label\":\"Steel\",\"checked\":true,\"children\":[{\"id\":\"alloy-steel\",\"nodeId\":\"alloy-steel\",\"humanReadableId\":\"Alloy Steel\",\"label\":\"Alloy Steel\",\"checked\":true,\"children\":[{\"id\":\"chromium-molybdenum-steel\",\"nodeId\":\"chromium-molybdenum-steel\",\"humanReadableId\":\"Chromium Molybdenum Steel\",\"label\":\"Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"chromium-molybdenum-vanadium-steel\",\"nodeId\":\"chromium-molybdenum-vanadium-steel\",\"humanReadableId\":\"Chromium Molybdenum Vanadium Steel\",\"label\":\"Chromium Molybdenum Vanadium Steel\",\"checked\":true},{\"id\":\"chromium-steel\",\"nodeId\":\"chromium-steel\",\"humanReadableId\":\"Chromium Steel\",\"label\":\"Chromium Steel\",\"checked\":true},{\"id\":\"chromium-vanadium-steel\",\"nodeId\":\"chromium-vanadium-steel\",\"humanReadableId\":\"Chromium Vanadium Steel\",\"label\":\"Chromium Vanadium Steel\",\"checked\":true},{\"id\":\"manganese-steel\",\"nodeId\":\"manganese-steel\",\"humanReadableId\":\"Manganese Steel\",\"label\":\"Manganese Steel\",\"checked\":true},{\"id\":\"molybdenum-steel\",\"nodeId\":\"molybdenum-steel\",\"humanReadableId\":\"Molybdenum Steel\",\"label\":\"Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-molybdenum-steel\",\"nodeId\":\"nickel-chromium-molybdenum-steel\",\"humanReadableId\":\"Nickel Chromium Molybdenum Steel\",\"label\":\"Nickel Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-steel\",\"nodeId\":\"nickel-chromium-steel\",\"humanReadableId\":\"Nickel Chromium Steel\",\"label\":\"Nickel Chromium Steel\",\"checked\":true},{\"id\":\"nickel-molybdenum-steel\",\"nodeId\":\"nickel-molybdenum-steel\",\"humanReadableId\":\"Nickel Molybdenum Steel\",\"label\":\"Nickel Molybdenum Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"nickel-steel\",\"nodeId\":\"nickel-steel\",\"humanReadableId\":\"Nickel Steel\",\"label\":\"Nickel Steel\",\"checked\":true},{\"id\":\"nitriding-steel\",\"nodeId\":\"nitriding-steel\",\"humanReadableId\":\"Nitriding Steel\",\"label\":\"Nitriding Steel\",\"checked\":true},{\"id\":\"silicon-manganese-steel\",\"nodeId\":\"silicon-manganese-steel\",\"humanReadableId\":\"Silicon Manganese Steel\",\"label\":\"Silicon Manganese Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"silicon-steel\",\"nodeId\":\"silicon-steel\",\"humanReadableId\":\"Silicon Steel\",\"label\":\"Silicon Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"unclassified-low-alloy-steel\",\"nodeId\":\"unclassified-low-alloy-steel\",\"humanReadableId\":\"Unclassified Low Alloy Steel\",\"label\":\"Unclassified Low Alloy Steel\",\"checked\":true}]},{\"id\":\"carbon-steel\",\"nodeId\":\"carbon-steel\",\"humanReadableId\":\"Carbon Steel\",\"label\":\"Carbon Steel\",\"checked\":true,\"children\":[{\"id\":\"high-carbon-steel\",\"nodeId\":\"high-carbon-steel\",\"humanReadableId\":\"High Carbon Steel\",\"label\":\"High Carbon Steel\",\"checked\":true},{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true},{\"id\":\"medium-carbon-steel\",\"nodeId\":\"medium-carbon-steel\",\"humanReadableId\":\"Medium Carbon Steel\",\"label\":\"Medium Carbon Steel\",\"checked\":true},{\"id\":\"unclassified-carbon-steel\",\"nodeId\":\"unclassified-carbon-steel\",\"humanReadableId\":\"Unclassified Carbon Steel\",\"label\":\"Unclassified Carbon Steel\",\"checked\":true}]},{\"id\":\"low-alloy-steel\",\"nodeId\":\"low-alloy-steel\",\"humanReadableId\":\"Low Alloy Steel\",\"label\":\"Low Alloy Steel\",\"checked\":true,\"disabled\":true,\"children\":[{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel-\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"disabled\":true}]},{\"id\":\"maraging-steel\",\"nodeId\":\"maraging-steel\",\"humanReadableId\":\"Maraging Steel\",\"label\":\"Maraging Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"stainless-steel\",\"nodeId\":\"stainless-steel\",\"humanReadableId\":\"Stainless Steel\",\"label\":\"Stainless Steel\",\"checked\":true,\"children\":[{\"id\":\"austenitic-stainless-steel\",\"nodeId\":\"austenitic-stainless-steel\",\"humanReadableId\":\"Austenitic Stainless Steel\",\"label\":\"Austenitic Stainless Steel\",\"checked\":true},{\"id\":\"duplex-stainless-steel\",\"nodeId\":\"duplex-stainless-steel\",\"humanReadableId\":\"Duplex Stainless Steel\",\"label\":\"Duplex Stainless Steel\",\"checked\":true},{\"id\":\"ferritic-stainless-steel\",\"nodeId\":\"ferritic-stainless-steel\",\"humanReadableId\":\"Ferritic Stainless Steel\",\"label\":\"Ferritic Stainless Steel\",\"checked\":true},{\"id\":\"martensitic-stainless-steel\",\"nodeId\":\"martensitic-stainless-steel\",\"humanReadableId\":\"Martensitic Stainless Steel\",\"label\":\"Martensitic Stainless Steel\",\"checked\":true},{\"id\":\"precipitation-hardening-stainless-steel\",\"nodeId\":\"precipitation-hardening-stainless-steel\",\"humanReadableId\":\"Precipitation Hardening Stainless Steel\",\"label\":\"Precipitation Hardening Stainless Steel\",\"checked\":true},{\"id\":\"superaustenitic-stainless-steel\",\"nodeId\":\"superaustenitic-stainless-steel\",\"humanReadableId\":\"Superaustenitic Stainless Steel\",\"label\":\"Superaustenitic Stainless Steel\",\"checked\":true},{\"id\":\"unclassified-stainless-steel\",\"nodeId\":\"unclassified-stainless-steel\",\"humanReadableId\":\"Unclassified Stainless Steel\",\"label\":\"Unclassified Stainless Steel\",\"checked\":true}]},{\"id\":\"tool-and-machining-steel\",\"nodeId\":\"tool-and-machining-steel\",\"humanReadableId\":\"Tool And Machining Steel\",\"label\":\"Tool And Machining Steel\",\"checked\":true}]},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"humanReadableId\":\"Titanium\",\"label\":\"Titanium\",\"disabled\":true,\"children\":[{\"id\":\"alpha-alloy\",\"nodeId\":\"alpha-alloy\",\"humanReadableId\":\"Alpha Alloy\",\"label\":\"Alpha Alloy\",\"disabled\":true},{\"id\":\"alpha-beta-alloy\",\"nodeId\":\"alpha-beta-alloy\",\"humanReadableId\":\"Alpha Beta Alloy\",\"label\":\"Alpha Beta Alloy\",\"disabled\":true},{\"id\":\"beta-alloy\",\"nodeId\":\"beta-alloy\",\"humanReadableId\":\"Beta Alloy\",\"label\":\"Beta Alloy\",\"disabled\":true},{\"id\":\"low-alloy-titanium\",\"nodeId\":\"low-alloy-titanium\",\"humanReadableId\":\"Low Alloy Titanium\",\"label\":\"Low Alloy Titanium\",\"disabled\":true},{\"id\":\"near-alpha-alloy\",\"nodeId\":\"near-alpha-alloy\",\"humanReadableId\":\"Near Alpha Alloy\",\"label\":\"Near Alpha Alloy\",\"disabled\":true},{\"id\":\"pure-titanium\",\"nodeId\":\"pure-titanium\",\"humanReadableId\":\"Pure Titanium\",\"label\":\"Pure Titanium\",\"disabled\":true}]}]},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"humanReadableId\":\"Polymer\",\"label\":\"Polymer\",\"disabled\":true,\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"humanReadableId\":\"Elastomer\",\"label\":\"Elastomer\",\"disabled\":true,\"children\":[{\"id\":\"butadiene-rubber--br-\",\"nodeId\":\"butadiene-rubber--br-\",\"humanReadableId\":\"Butadiene Rubber (BR)\",\"label\":\"Butadiene Rubber (BR)\",\"disabled\":true},{\"id\":\"chloroprene-rubber--cr-\",\"nodeId\":\"chloroprene-rubber--cr-\",\"humanReadableId\":\"Chloroprene Rubber (CR)\",\"label\":\"Chloroprene Rubber (CR)\",\"disabled\":true},{\"id\":\"ethylene-propylene-diene-rubber--epdm-\",\"nodeId\":\"ethylene-propylene-diene-rubber--epdm-\",\"humanReadableId\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"label\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"disabled\":true},{\"id\":\"ethylene-propylene-rubber--epr-\",\"nodeId\":\"ethylene-propylene-rubber--epr-\",\"humanReadableId\":\"Ethylene Propylene Rubber (EPR)\",\"label\":\"Ethylene Propylene Rubber (EPR)\",\"disabled\":true},{\"id\":\"fluorosilicone-rubber--fvmq-\",\"nodeId\":\"fluorosilicone-rubber--fvmq-\",\"humanReadableId\":\"Fluorosilicone Rubber (FVMQ)\",\"label\":\"Fluorosilicone Rubber (FVMQ)\",\"disabled\":true},{\"id\":\"natural-rubber--nr-\",\"nodeId\":\"natural-rubber--nr-\",\"humanReadableId\":\"Natural Rubber (NR)\",\"label\":\"Natural Rubber (NR)\",\"disabled\":true},{\"id\":\"nitrile-rubber--nbr-\",\"nodeId\":\"nitrile-rubber--nbr-\",\"humanReadableId\":\"Nitrile Rubber (NBR)\",\"label\":\"Nitrile Rubber (NBR)\",\"disabled\":true},{\"id\":\"styrene-butadiene-rubber--sbr-\",\"nodeId\":\"styrene-butadiene-rubber--sbr-\",\"humanReadableId\":\"Styrene Butadiene Rubber (SBR)\",\"label\":\"Styrene Butadiene Rubber (SBR)\",\"disabled\":true},{\"id\":\"thermoplastic-elastomer--tpe-\",\"nodeId\":\"thermoplastic-elastomer--tpe-\",\"humanReadableId\":\"Thermoplastic Elastomer (TPE)\",\"label\":\"Thermoplastic Elastomer (TPE)\",\"disabled\":true,\"children\":[{\"id\":\"elastomeric-alloy--tpv-\",\"nodeId\":\"elastomeric-alloy--tpv-\",\"humanReadableId\":\"Elastomeric Alloy (TPV)\",\"label\":\"Elastomeric Alloy (TPV)\",\"disabled\":true},{\"id\":\"styrene-butadiene-styrene--sbs-\",\"nodeId\":\"styrene-butadiene-styrene--sbs-\",\"humanReadableId\":\"Styrene Butadiene Styrene (SBS)\",\"label\":\"Styrene Butadiene Styrene (SBS)\",\"disabled\":true},{\"id\":\"thermoplastic-copolyester--tpc-\",\"nodeId\":\"thermoplastic-copolyester--tpc-\",\"humanReadableId\":\"Thermoplastic Copolyester (TPC)\",\"label\":\"Thermoplastic Copolyester (TPC)\",\"disabled\":true},{\"id\":\"thermoplastic-polyamide--tpa-\",\"nodeId\":\"thermoplastic-polyamide--tpa-\",\"humanReadableId\":\"Thermoplastic Polyamide (TPA)\",\"label\":\"Thermoplastic Polyamide (TPA)\",\"disabled\":true},{\"id\":\"thermoplastic-polyester-elastomer--tpee-\",\"nodeId\":\"thermoplastic-polyester-elastomer--tpee-\",\"humanReadableId\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"label\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"disabled\":true},{\"id\":\"thermoplastic-polyolefin--tpo-\",\"nodeId\":\"thermoplastic-polyolefin--tpo-\",\"humanReadableId\":\"Thermoplastic Polyolefin (TPO)\",\"label\":\"Thermoplastic Polyolefin (TPO)\",\"disabled\":true},{\"id\":\"thermoplastic-polyurethane--tpu-\",\"nodeId\":\"thermoplastic-polyurethane--tpu-\",\"humanReadableId\":\"Thermoplastic Polyurethane (TPU)\",\"label\":\"Thermoplastic Polyurethane (TPU)\",\"disabled\":true},{\"id\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"nodeId\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"humanReadableId\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"label\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"disabled\":true}]}]},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"humanReadableId\":\"Thermoplastic\",\"label\":\"Thermoplastic\",\"disabled\":true,\"children\":[{\"id\":\"acrylic\",\"nodeId\":\"acrylic\",\"humanReadableId\":\"Acrylic\",\"label\":\"Acrylic\",\"disabled\":true,\"children\":[{\"id\":\"polyacrylonitrile--pan-\",\"nodeId\":\"polyacrylonitrile--pan-\",\"humanReadableId\":\"Polyacrylonitrile (PAN)\",\"label\":\"Polyacrylonitrile (PAN)\",\"disabled\":true},{\"id\":\"polymethyl-methacrylate--pmma-\",\"nodeId\":\"polymethyl-methacrylate--pmma-\",\"humanReadableId\":\"Polymethyl methacrylate (PMMA)\",\"label\":\"Polymethyl methacrylate (PMMA)\",\"disabled\":true}]},{\"id\":\"fluoropolymer\",\"nodeId\":\"fluoropolymer\",\"humanReadableId\":\"Fluoropolymer\",\"label\":\"Fluoropolymer\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"nodeId\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"humanReadableId\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"label\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"disabled\":true},{\"id\":\"fluorinated-ethylene-propylene--fep-\",\"nodeId\":\"fluorinated-ethylene-propylene--fep-\",\"humanReadableId\":\"Fluorinated ethylene propylene (FEP)\",\"label\":\"Fluorinated ethylene propylene (FEP)\",\"disabled\":true},{\"id\":\"polytetrafluoroethylene--ptfe-\",\"nodeId\":\"polytetrafluoroethylene--ptfe-\",\"humanReadableId\":\"Polytetrafluoroethylene (PTFE)\",\"label\":\"Polytetrafluoroethylene (PTFE)\",\"disabled\":true},{\"id\":\"polyvinylidenefluoride--pvdf-\",\"nodeId\":\"polyvinylidenefluoride--pvdf-\",\"humanReadableId\":\"Polyvinylidenefluoride (PVDF)\",\"label\":\"Polyvinylidenefluoride (PVDF)\",\"disabled\":true}]},{\"id\":\"liquid-crystal-polymers--lcp-\",\"nodeId\":\"liquid-crystal-polymers--lcp-\",\"humanReadableId\":\"Liquid Crystal Polymers (LCP)\",\"label\":\"Liquid Crystal Polymers (LCP)\",\"disabled\":true},{\"id\":\"polyamide--pa-\",\"nodeId\":\"polyamide--pa-\",\"humanReadableId\":\"Polyamide (PA)\",\"label\":\"Polyamide (PA)\",\"disabled\":true,\"children\":[{\"id\":\"aramide\",\"nodeId\":\"aramide\",\"humanReadableId\":\"Aramide\",\"label\":\"Aramide\",\"disabled\":true},{\"id\":\"copolyamide-6-66--pa6-66-\",\"nodeId\":\"copolyamide-6-66--pa6-66-\",\"humanReadableId\":\"Copolyamide 6/66 (PA6/66)\",\"label\":\"Copolyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"other-polyamide--pa-\",\"nodeId\":\"other-polyamide--pa-\",\"humanReadableId\":\"Other Polyamide (PA)\",\"label\":\"Other Polyamide (PA)\",\"disabled\":true},{\"id\":\"polyamide-1010--pa1010-\",\"nodeId\":\"polyamide-1010--pa1010-\",\"humanReadableId\":\"Polyamide 1010 (PA1010)\",\"label\":\"Polyamide 1010 (PA1010)\",\"disabled\":true},{\"id\":\"polyamide-1012--pa1012-\",\"nodeId\":\"polyamide-1012--pa1012-\",\"humanReadableId\":\"Polyamide 1012 (PA1012)\",\"label\":\"Polyamide 1012 (PA1012)\",\"disabled\":true},{\"id\":\"polyamide-11--pa11-\",\"nodeId\":\"polyamide-11--pa11-\",\"humanReadableId\":\"Polyamide 11 (PA11)\",\"label\":\"Polyamide 11 (PA11)\",\"disabled\":true},{\"id\":\"polyamide-12--pa12-\",\"nodeId\":\"polyamide-12--pa12-\",\"humanReadableId\":\"Polyamide 12 (PA12)\",\"label\":\"Polyamide 12 (PA12)\",\"disabled\":true},{\"id\":\"polyamide-410--pa410-\",\"nodeId\":\"polyamide-410--pa410-\",\"humanReadableId\":\"Polyamide 410 (PA410)\",\"label\":\"Polyamide 410 (PA410)\",\"disabled\":true},{\"id\":\"polyamide-46--pa46-\",\"nodeId\":\"polyamide-46--pa46-\",\"humanReadableId\":\"Polyamide 46 (PA46)\",\"label\":\"Polyamide 46 (PA46)\",\"disabled\":true},{\"id\":\"polyamide-6--pa6-\",\"nodeId\":\"polyamide-6--pa6-\",\"humanReadableId\":\"Polyamide 6 (PA6)\",\"label\":\"Polyamide 6 (PA6)\",\"disabled\":true,\"children\":[{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t-\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true}]},{\"id\":\"polyamide-6-66--pa6-66-\",\"nodeId\":\"polyamide-6-66--pa6-66-\",\"humanReadableId\":\"Polyamide 6/66 (PA6/66)\",\"label\":\"Polyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"polyamide-610--pa610-\",\"nodeId\":\"polyamide-610--pa610-\",\"humanReadableId\":\"Polyamide 610 (PA610)\",\"label\":\"Polyamide 610 (PA610)\",\"disabled\":true},{\"id\":\"polyamide-612--pa612-\",\"nodeId\":\"polyamide-612--pa612-\",\"humanReadableId\":\"Polyamide 612 (PA612)\",\"label\":\"Polyamide 612 (PA612)\",\"disabled\":true},{\"id\":\"polyamide-66--pa66-\",\"nodeId\":\"polyamide-66--pa66-\",\"humanReadableId\":\"Polyamide 66 (PA66)\",\"label\":\"Polyamide 66 (PA66)\",\"disabled\":true},{\"id\":\"polyphthalamide--ppa-\",\"nodeId\":\"polyphthalamide--ppa-\",\"humanReadableId\":\"Polyphthalamide (PPA)\",\"label\":\"Polyphthalamide (PPA)\",\"disabled\":true,\"children\":[{\"id\":\"copolyamide-66-6i--pa66-6i-\",\"nodeId\":\"copolyamide-66-6i--pa66-6i-\",\"humanReadableId\":\"Copolyamide 66/6I (PA66/6I)\",\"label\":\"Copolyamide 66/6I (PA66/6I)\",\"disabled\":true},{\"id\":\"copolyamide-6t-66--pa6t-66-\",\"nodeId\":\"copolyamide-6t-66--pa6t-66-\",\"humanReadableId\":\"Copolyamide 6T/66 (PA6T/66)\",\"label\":\"Copolyamide 6T/66 (PA6T/66)\",\"disabled\":true},{\"id\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"nodeId\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"humanReadableId\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"label\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"disabled\":true},{\"id\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"nodeId\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"humanReadableId\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"label\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"disabled\":true},{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t--\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true},{\"id\":\"polyamide-6t--pa6t-\",\"nodeId\":\"polyamide-6t--pa6t-\",\"humanReadableId\":\"Polyamide 6T (PA6T)\",\"label\":\"Polyamide 6T (PA6T)\",\"disabled\":true},{\"id\":\"polyamide-mxd6--pamxd6-\",\"nodeId\":\"polyamide-mxd6--pamxd6-\",\"humanReadableId\":\"Polyamide MXD6 (PAMXD6)\",\"label\":\"Polyamide MXD6 (PAMXD6)\",\"disabled\":true},{\"id\":\"polyamide-pa6-6t--pa6-6t-\",\"nodeId\":\"polyamide-pa6-6t--pa6-6t-\",\"humanReadableId\":\"Polyamide PA6/6T (PA6/6T)\",\"label\":\"Polyamide PA6/6T (PA6/6T)\",\"disabled\":true}]}]},{\"id\":\"polyaryletherketone--paek-\",\"nodeId\":\"polyaryletherketone--paek-\",\"humanReadableId\":\"Polyaryletherketone (PAEK)\",\"label\":\"Polyaryletherketone (PAEK)\",\"disabled\":true,\"children\":[{\"id\":\"polyether-ketone--pek-\",\"nodeId\":\"polyether-ketone--pek-\",\"humanReadableId\":\"Polyether Ketone (PEK)\",\"label\":\"Polyether Ketone (PEK)\",\"disabled\":true},{\"id\":\"polyetherether-ketone--peek-\",\"nodeId\":\"polyetherether-ketone--peek-\",\"humanReadableId\":\"Polyetherether Ketone (PEEK)\",\"label\":\"Polyetherether Ketone (PEEK)\",\"disabled\":true},{\"id\":\"polyetherketoneketone--pekk-\",\"nodeId\":\"polyetherketoneketone--pekk-\",\"humanReadableId\":\"Polyetherketoneketone (PEKK)\",\"label\":\"Polyetherketoneketone (PEKK)\",\"disabled\":true}]},{\"id\":\"polycarbonate--pc-\",\"nodeId\":\"polycarbonate--pc-\",\"humanReadableId\":\"Polycarbonate (PC)\",\"label\":\"Polycarbonate (PC)\",\"disabled\":true},{\"id\":\"polyester\",\"nodeId\":\"polyester\",\"humanReadableId\":\"Polyester\",\"label\":\"Polyester\",\"disabled\":true,\"children\":[{\"id\":\"polybutylene-terephthalate--pbt-\",\"nodeId\":\"polybutylene-terephthalate--pbt-\",\"humanReadableId\":\"Polybutylene Terephthalate (PBT)\",\"label\":\"Polybutylene Terephthalate (PBT)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate--pet-\",\"nodeId\":\"polyethylene-terephthalate--pet-\",\"humanReadableId\":\"Polyethylene Terephthalate (PET)\",\"label\":\"Polyethylene Terephthalate (PET)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate-glycol--petg-\",\"nodeId\":\"polyethylene-terephthalate-glycol--petg-\",\"humanReadableId\":\"Polyethylene Terephthalate Glycol (PETG)\",\"label\":\"Polyethylene Terephthalate Glycol (PETG)\",\"disabled\":true},{\"id\":\"polyglycolicide--pga-\",\"nodeId\":\"polyglycolicide--pga-\",\"humanReadableId\":\"Polyglycolicide (PGA)\",\"label\":\"Polyglycolicide (PGA)\",\"disabled\":true},{\"id\":\"polytrimethylene-terephthalate--ptt-\",\"nodeId\":\"polytrimethylene-terephthalate--ptt-\",\"humanReadableId\":\"Polytrimethylene Terephthalate (PTT)\",\"label\":\"Polytrimethylene Terephthalate (PTT)\",\"disabled\":true}]},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe-\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true},{\"id\":\"polyimide--pi-\",\"nodeId\":\"polyimide--pi-\",\"humanReadableId\":\"Polyimide (PI)\",\"label\":\"Polyimide (PI)\",\"disabled\":true,\"children\":[{\"id\":\"polyamidimide--pai-\",\"nodeId\":\"polyamidimide--pai-\",\"humanReadableId\":\"Polyamidimide (PAI)\",\"label\":\"Polyamidimide (PAI)\",\"disabled\":true},{\"id\":\"polybenzimidazole--pbi-\",\"nodeId\":\"polybenzimidazole--pbi-\",\"humanReadableId\":\"Polybenzimidazole (PBI)\",\"label\":\"Polybenzimidazole (PBI)\",\"disabled\":true},{\"id\":\"polyetherimide--pei-\",\"nodeId\":\"polyetherimide--pei-\",\"humanReadableId\":\"Polyetherimide (PEI)\",\"label\":\"Polyetherimide (PEI)\",\"disabled\":true}]},{\"id\":\"polyketone--pk-\",\"nodeId\":\"polyketone--pk-\",\"humanReadableId\":\"Polyketone (PK)\",\"label\":\"Polyketone (PK)\",\"disabled\":true},{\"id\":\"polylactic-acid--pla-\",\"nodeId\":\"polylactic-acid--pla-\",\"humanReadableId\":\"Polylactic Acid (PLA)\",\"label\":\"Polylactic Acid (PLA)\",\"disabled\":true},{\"id\":\"polymer-blend\",\"nodeId\":\"polymer-blend\",\"humanReadableId\":\"Polymer Blend\",\"label\":\"Polymer Blend\",\"disabled\":true},{\"id\":\"polyolefin--po-\",\"nodeId\":\"polyolefin--po-\",\"humanReadableId\":\"Polyolefin (PO)\",\"label\":\"Polyolefin (PO)\",\"disabled\":true,\"children\":[{\"id\":\"polybutene--pb-\",\"nodeId\":\"polybutene--pb-\",\"humanReadableId\":\"Polybutene (PB)\",\"label\":\"Polybutene (PB)\",\"disabled\":true},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe--\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"children\":[{\"id\":\"high-density-polyethylene--pe-hd-\",\"nodeId\":\"high-density-polyethylene--pe-hd-\",\"humanReadableId\":\"High Density Polyethylene (PE-HD)\",\"label\":\"High Density Polyethylene (PE-HD)\",\"disabled\":true},{\"id\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"nodeId\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"humanReadableId\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"label\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"disabled\":true},{\"id\":\"linear-low-density-polyethylene--pe-lld-\",\"nodeId\":\"linear-low-density-polyethylene--pe-lld-\",\"humanReadableId\":\"Linear Low Density Polyethylene (PE-LLD)\",\"label\":\"Linear Low Density Polyethylene (PE-LLD)\",\"disabled\":true},{\"id\":\"low-density-polyethylene--pe-ld-\",\"nodeId\":\"low-density-polyethylene--pe-ld-\",\"humanReadableId\":\"Low Density Polyethylene (PE-LD)\",\"label\":\"Low Density Polyethylene (PE-LD)\",\"disabled\":true},{\"id\":\"medium-density-polyethylene--pe-md-\",\"nodeId\":\"medium-density-polyethylene--pe-md-\",\"humanReadableId\":\"Medium Density Polyethylene (PE-MD)\",\"label\":\"Medium Density Polyethylene (PE-MD)\",\"disabled\":true},{\"id\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"nodeId\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"humanReadableId\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"label\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"disabled\":true},{\"id\":\"very-low-density-polyethylene--pe-vld-\",\"nodeId\":\"very-low-density-polyethylene--pe-vld-\",\"humanReadableId\":\"Very Low Density Polyethylene (PE-VLD)\",\"label\":\"Very Low Density Polyethylene (PE-VLD)\",\"disabled\":true}]},{\"id\":\"polymethylpentene--pmp-\",\"nodeId\":\"polymethylpentene--pmp-\",\"humanReadableId\":\"Polymethylpentene (PMP)\",\"label\":\"Polymethylpentene (PMP)\",\"disabled\":true},{\"id\":\"polypropylene--pp-\",\"nodeId\":\"polypropylene--pp-\",\"humanReadableId\":\"Polypropylene (PP)\",\"label\":\"Polypropylene (PP)\",\"disabled\":true}]},{\"id\":\"polyoxymethylene--pom-\",\"nodeId\":\"polyoxymethylene--pom-\",\"humanReadableId\":\"Polyoxymethylene (POM)\",\"label\":\"Polyoxymethylene (POM)\",\"disabled\":true},{\"id\":\"polyphenyl\",\"nodeId\":\"polyphenyl\",\"humanReadableId\":\"Polyphenyl\",\"label\":\"Polyphenyl\",\"disabled\":true,\"children\":[{\"id\":\"polyphenyl-ether--ppe-\",\"nodeId\":\"polyphenyl-ether--ppe-\",\"humanReadableId\":\"Polyphenyl Ether (PPE)\",\"label\":\"Polyphenyl Ether (PPE)\",\"disabled\":true},{\"id\":\"polyphenylene-oxide--ppo-\",\"nodeId\":\"polyphenylene-oxide--ppo-\",\"humanReadableId\":\"Polyphenylene Oxide (PPO)\",\"label\":\"Polyphenylene Oxide (PPO)\",\"disabled\":true},{\"id\":\"polyphenylene-sulfide--pps-\",\"nodeId\":\"polyphenylene-sulfide--pps-\",\"humanReadableId\":\"Polyphenylene Sulfide (PPS)\",\"label\":\"Polyphenylene Sulfide (PPS)\",\"disabled\":true}]},{\"id\":\"polysaccharide\",\"nodeId\":\"polysaccharide\",\"humanReadableId\":\"Polysaccharide\",\"label\":\"Polysaccharide\",\"disabled\":true},{\"id\":\"polysulphones\",\"nodeId\":\"polysulphones\",\"humanReadableId\":\"Polysulphones\",\"label\":\"Polysulphones\",\"disabled\":true,\"children\":[{\"id\":\"polyether-sulfone--pes-\",\"nodeId\":\"polyether-sulfone--pes-\",\"humanReadableId\":\"Polyether Sulfone (PES)\",\"label\":\"Polyether Sulfone (PES)\",\"disabled\":true},{\"id\":\"polyphenylsulphone--ppsu-\",\"nodeId\":\"polyphenylsulphone--ppsu-\",\"humanReadableId\":\"Polyphenylsulphone (PPSU)\",\"label\":\"Polyphenylsulphone (PPSU)\",\"disabled\":true},{\"id\":\"polysulphone--psu-\",\"nodeId\":\"polysulphone--psu-\",\"humanReadableId\":\"Polysulphone (PSU)\",\"label\":\"Polysulphone (PSU)\",\"disabled\":true},{\"id\":\"polysulphone-general--psu-\",\"nodeId\":\"polysulphone-general--psu-\",\"humanReadableId\":\"Polysulphone General (PSU)\",\"label\":\"Polysulphone General (PSU)\",\"disabled\":true}]},{\"id\":\"styrene\",\"nodeId\":\"styrene\",\"humanReadableId\":\"Styrene\",\"label\":\"Styrene\",\"disabled\":true,\"children\":[{\"id\":\"acrylonitrile-butadiene-styrene--abs-\",\"nodeId\":\"acrylonitrile-butadiene-styrene--abs-\",\"humanReadableId\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"label\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"disabled\":true},{\"id\":\"acrylonitrile-styrene-acrylate--asa-\",\"nodeId\":\"acrylonitrile-styrene-acrylate--asa-\",\"humanReadableId\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"label\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"disabled\":true},{\"id\":\"high-impact-polystyrene--hips-\",\"nodeId\":\"high-impact-polystyrene--hips-\",\"humanReadableId\":\"High Impact Polystyrene (HIPS)\",\"label\":\"High Impact Polystyrene (HIPS)\",\"disabled\":true},{\"id\":\"methacrylate-butadiene-styrene--mbs-\",\"nodeId\":\"methacrylate-butadiene-styrene--mbs-\",\"humanReadableId\":\"Methacrylate Butadiene Styrene (MBS)\",\"label\":\"Methacrylate Butadiene Styrene (MBS)\",\"disabled\":true},{\"id\":\"polystyrene--ps-\",\"nodeId\":\"polystyrene--ps-\",\"humanReadableId\":\"Polystyrene (PS)\",\"label\":\"Polystyrene (PS)\",\"disabled\":true},{\"id\":\"styrene-acrylonitrile--san-\",\"nodeId\":\"styrene-acrylonitrile--san-\",\"humanReadableId\":\"Styrene Acrylonitrile (SAN)\",\"label\":\"Styrene Acrylonitrile (SAN)\",\"disabled\":true}]},{\"id\":\"vinyl\",\"nodeId\":\"vinyl\",\"humanReadableId\":\"Vinyl\",\"label\":\"Vinyl\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-vinyl-acetate--evac-\",\"nodeId\":\"ethylene-vinyl-acetate--evac-\",\"humanReadableId\":\"Ethylene Vinyl Acetate (EVAC)\",\"label\":\"Ethylene Vinyl Acetate (EVAC)\",\"disabled\":true},{\"id\":\"polyvinyl-chloride--pvc-\",\"nodeId\":\"polyvinyl-chloride--pvc-\",\"humanReadableId\":\"Polyvinyl Chloride (PVC)\",\"label\":\"Polyvinyl Chloride (PVC)\",\"disabled\":true}]}]},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"humanReadableId\":\"Thermosetting\",\"label\":\"Thermosetting\",\"disabled\":true,\"children\":[{\"id\":\"amino-resin\",\"nodeId\":\"amino-resin\",\"humanReadableId\":\"Amino Resin\",\"label\":\"Amino Resin\",\"disabled\":true,\"children\":[{\"id\":\"bismaleimide--bmi-\",\"nodeId\":\"bismaleimide--bmi-\",\"humanReadableId\":\"Bismaleimide (BMI)\",\"label\":\"Bismaleimide (BMI)\",\"disabled\":true},{\"id\":\"melamine-formaldehyde--mf-\",\"nodeId\":\"melamine-formaldehyde--mf-\",\"humanReadableId\":\"Melamine formaldehyde (MF)\",\"label\":\"Melamine formaldehyde (MF)\",\"disabled\":true}]},{\"id\":\"epoxy-resin--ep-\",\"nodeId\":\"epoxy-resin--ep-\",\"humanReadableId\":\"Epoxy Resin (EP)\",\"label\":\"Epoxy Resin (EP)\",\"disabled\":true},{\"id\":\"phenol-formaldehyde-resin--pf-\",\"nodeId\":\"phenol-formaldehyde-resin--pf-\",\"humanReadableId\":\"Phenol Formaldehyde Resin (PF)\",\"label\":\"Phenol Formaldehyde Resin (PF)\",\"disabled\":true},{\"id\":\"phthalonitrile--pn-\",\"nodeId\":\"phthalonitrile--pn-\",\"humanReadableId\":\"Phthalonitrile (PN)\",\"label\":\"Phthalonitrile (PN)\",\"disabled\":true},{\"id\":\"polyester-resin--up-\",\"nodeId\":\"polyester-resin--up-\",\"humanReadableId\":\"Polyester Resin (UP)\",\"label\":\"Polyester Resin (UP)\",\"disabled\":true},{\"id\":\"vinyl-ester-resin--ve-\",\"nodeId\":\"vinyl-ester-resin--ve-\",\"humanReadableId\":\"Vinyl Ester Resin (VE)\",\"label\":\"Vinyl Ester Resin (VE)\",\"disabled\":true}]}]}],\"propertySections\":[],\"suppliers\":[{\"id\":\"dest\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"materialsCount\":93},{\"id\":\"ugit\",\"label\":\"Ugitech\",\"materialsCount\":50},{\"id\":\"sver\",\"label\":\"Sverdrup Steel AS\",\"materialsCount\":20},{\"id\":\"salo\",\"label\":\"Salomon's Metalen\",\"materialsCount\":16},{\"id\":\"hemp\",\"label\":\"Hempel Special Metals\",\"materialsCount\":4},{\"id\":\"vdmm\",\"label\":\"VDM Metals\",\"materialsCount\":1},{\"id\":\"song\",\"label\":\"Dongguan songshun mould steel Co., Ltd.\",\"materialsCount\":13},{\"id\":\"ambi\",\"label\":\"Ambica Steels Limited\",\"materialsCount\":10}],\"supplierMaterialsOnly\":false,\"text\":\"\",\"results\":{\"materials\":{\"data\":[{\"id\":\"DESTB19\",\"label\":\"Acidur 4529\",\"url\":\"/materials/destb19-acidur-4529\",\"category\":{\"id\":\"superaustenitic-stainless-steel\",\"label\":\"Superaustenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS11\",\"label\":\"Acidur 4401 +AT \",\"url\":\"/materials/dests11-acidur-4401-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS12\",\"label\":\"Acidur 4435 +AT \",\"url\":\"/materials/dests12-acidur-4435-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS13\",\"label\":\"Acidur 4541 +AT \",\"url\":\"/materials/dests13-acidur-4541-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS14\",\"label\":\"Acidur 4571 +AT \",\"url\":\"/materials/dests14-acidur-4571-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS11A\",\"label\":\"Acidur 4404 +AT \",\"url\":\"/materials/dests11a-acidur-4404-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS9\",\"label\":\"Acidur 4301 +AT \",\"url\":\"/materials/dests9-acidur-4301-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS9A\",\"label\":\"Acidur 4307 +AT \",\"url\":\"/materials/dests9a-acidur-4307-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS10\",\"label\":\"Acidur 4305 +AT \",\"url\":\"/materials/dests10-acidur-4305-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"VDMM023\",\"label\":\"VDM® Alloy 926\",\"url\":\"/materials/vdmm023-vdm-alloy-926\",\"category\":{\"id\":\"superaustenitic-stainless-steel\",\"label\":\"Superaustenitic Stainless Steel\"},\"supplier\":{\"id\":\"VDMM\",\"label\":\"VDM Metals\",\"url\":\"/suppliers/vdmm-vdm-metals\"}},{\"id\":\"DESTS7\",\"label\":\"Acidur 4418 QT900 \",\"url\":\"/materials/dests7-acidur-4418-qt900-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS15\",\"label\":\"Acidur 4462 +AT \",\"url\":\"/materials/dests15-acidur-4462-at-\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS7A\",\"label\":\"Acidur 4418 QT760 \",\"url\":\"/materials/dests7a-acidur-4418-qt760-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"UGIT0076\",\"label\":\"UGIMA® 4460 Cold Finished\",\"url\":\"/materials/ugit0076-ugima-4460-cold-finished\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"UGIT0077\",\"label\":\"UGIMA® 4460 Cold Finished and Drawn\",\"url\":\"/materials/ugit0077-ugima-4460-cold-finished-and-drawn\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"UGIT0129\",\"label\":\"UGI® 4545 AIR H1025\",\"url\":\"/materials/ugit0129-ugi-4545-air-h1025\",\"category\":{\"id\":\"precipitation-hardening-stainless-steel\",\"label\":\"Precipitation Hardening Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"DESTS1\",\"label\":\"Corrodur 4021 QT800 \",\"url\":\"/materials/dests1-corrodur-4021-qt800-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS3\",\"label\":\"Corrodur 4034 Annealed \",\"url\":\"/materials/dests3-corrodur-4034-annealed-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS4\",\"label\":\"Acidur 4057 QT800 \",\"url\":\"/materials/dests4-acidur-4057-qt800-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS8\",\"label\":\"Acidur 4542 P800 \",\"url\":\"/materials/dests8-acidur-4542-p800-\",\"category\":{\"id\":\"precipitation-hardening-stainless-steel\",\"label\":\"Precipitation Hardening Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}}],\"materialsCount\":2214,\"page\":1}},\"alerts\":[\"advanced-search-alert-compare-hint\"],\"context\":{\"unitsSystem\":\"metric\",\"categories\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"humanReadableId\":\"Biological Material\",\"label\":\"Biological Material\",\"disabled\":true,\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"humanReadableId\":\"Wood\",\"label\":\"Wood\",\"disabled\":true,\"ancestors\":[\"biological-material\"],\"rootNode\":\"biological-material\"}],\"rootNode\":\"biological-material\",\"childrenNr\":1,\"checked\":false},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"humanReadableId\":\"Ceramic\",\"label\":\"Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"humanReadableId\":\"Carbon\",\"label\":\"Carbon\",\"disabled\":true,\"children\":[{\"id\":\"carbon-nanotube\",\"nodeId\":\"carbon-nanotube\",\"humanReadableId\":\"Carbon Nanotube\",\"label\":\"Carbon Nanotube\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\"],\"rootNode\":\"ceramic\"},{\"id\":\"diamond\",\"nodeId\":\"diamond\",\"humanReadableId\":\"Diamond\",\"label\":\"Diamond\",\"disabled\":true,\"children\":[{\"id\":\"natural-diamond\",\"nodeId\":\"natural-diamond\",\"humanReadableId\":\"Natural Diamond\",\"label\":\"Natural Diamond\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\",\"diamond\"],\"rootNode\":\"ceramic\"},{\"id\":\"synthetic-diamond\",\"nodeId\":\"synthetic-diamond\",\"humanReadableId\":\"Synthetic Diamond\",\"label\":\"Synthetic Diamond\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\",\"diamond\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"carbon\"],\"rootNode\":\"ceramic\",\"childrenNr\":2},{\"id\":\"graphene\",\"nodeId\":\"graphene\",\"humanReadableId\":\"Graphene\",\"label\":\"Graphene\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\"],\"rootNode\":\"ceramic\"},{\"id\":\"graphite\",\"nodeId\":\"graphite\",\"humanReadableId\":\"Graphite\",\"label\":\"Graphite\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":4},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"humanReadableId\":\"Engineering Ceramic\",\"label\":\"Engineering Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"non-oxide-based\",\"nodeId\":\"non-oxide-based\",\"humanReadableId\":\"Non Oxide Based\",\"label\":\"Non Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"boride-based\",\"nodeId\":\"boride-based\",\"humanReadableId\":\"Boride Based\",\"label\":\"Boride Based\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"carbide-based\",\"nodeId\":\"carbide-based\",\"humanReadableId\":\"Carbide Based\",\"label\":\"Carbide Based\",\"disabled\":true,\"children\":[{\"id\":\"boron-carbide\",\"nodeId\":\"boron-carbide\",\"humanReadableId\":\"Boron Carbide\",\"label\":\"Boron Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"silicon-carbide\",\"nodeId\":\"silicon-carbide\",\"humanReadableId\":\"Silicon Carbide\",\"label\":\"Silicon Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"tantalum-carbide\",\"nodeId\":\"tantalum-carbide\",\"humanReadableId\":\"Tantalum Carbide\",\"label\":\"Tantalum Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"titanium-carbide\",\"nodeId\":\"titanium-carbide\",\"humanReadableId\":\"Titanium Carbide\",\"label\":\"Titanium Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"tungsten-carbide\",\"nodeId\":\"tungsten-carbide\",\"humanReadableId\":\"Tungsten Carbide\",\"label\":\"Tungsten Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"zirconium-carbide\",\"nodeId\":\"zirconium-carbide\",\"humanReadableId\":\"Zirconium Carbide\",\"label\":\"Zirconium Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\",\"childrenNr\":6},{\"id\":\"nitride-based\",\"nodeId\":\"nitride-based\",\"humanReadableId\":\"Nitride Based\",\"label\":\"Nitride Based\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nitirde\",\"nodeId\":\"aluminium-nitirde\",\"humanReadableId\":\"Aluminium Nitirde\",\"label\":\"Aluminium Nitirde\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"nitride-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"boron-nitride\",\"nodeId\":\"boron-nitride\",\"humanReadableId\":\"Boron Nitride\",\"label\":\"Boron Nitride\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"nitride-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"silicon-nitride\",\"nodeId\":\"silicon-nitride\",\"humanReadableId\":\"Silicon Nitride\",\"label\":\"Silicon Nitride\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"nitride-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"titanium-nitride\",\"nodeId\":\"titanium-nitride\",\"humanReadableId\":\"Titanium Nitride\",\"label\":\"Titanium Nitride\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"nitride-based\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\",\"childrenNr\":4},{\"id\":\"silicate-based\",\"nodeId\":\"silicate-based\",\"humanReadableId\":\"Silicate Based\",\"label\":\"Silicate Based\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"sulfide-based\",\"nodeId\":\"sulfide-based\",\"humanReadableId\":\"Sulfide Based\",\"label\":\"Sulfide Based\",\"disabled\":true,\"children\":[{\"id\":\"bismuth-sulfide\",\"nodeId\":\"bismuth-sulfide\",\"humanReadableId\":\"Bismuth Sulfide\",\"label\":\"Bismuth Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"copper-sulfide\",\"nodeId\":\"copper-sulfide\",\"humanReadableId\":\"Copper Sulfide\",\"label\":\"Copper Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"iron-sulfide\",\"nodeId\":\"iron-sulfide\",\"humanReadableId\":\"Iron Sulfide\",\"label\":\"Iron Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"manganese-sulfide\",\"nodeId\":\"manganese-sulfide\",\"humanReadableId\":\"Manganese Sulfide\",\"label\":\"Manganese Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"molybdenum-disulfide\",\"nodeId\":\"molybdenum-disulfide\",\"humanReadableId\":\"Molybdenum Disulfide\",\"label\":\"Molybdenum Disulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"multiphase-metal-sulfide\",\"nodeId\":\"multiphase-metal-sulfide\",\"humanReadableId\":\"Multiphase Metal Sulfide\",\"label\":\"Multiphase Metal Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"tin-sulfide\",\"nodeId\":\"tin-sulfide\",\"humanReadableId\":\"Tin Sulfide\",\"label\":\"Tin Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"tungsten-disulfide\",\"nodeId\":\"tungsten-disulfide\",\"humanReadableId\":\"Tungsten Disulfide\",\"label\":\"Tungsten Disulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"zinc-sulfide\",\"nodeId\":\"zinc-sulfide\",\"humanReadableId\":\"Zinc Sulfide\",\"label\":\"Zinc Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\",\"childrenNr\":9}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":5},{\"id\":\"oxide-based\",\"nodeId\":\"oxide-based\",\"humanReadableId\":\"Oxide Based\",\"label\":\"Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"advanced-ceramic-oxides\",\"nodeId\":\"advanced-ceramic-oxides\",\"humanReadableId\":\"Advanced Ceramic Oxides\",\"label\":\"Advanced Ceramic Oxides\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"aluminium-oxide\",\"nodeId\":\"aluminium-oxide\",\"humanReadableId\":\"Aluminium Oxide\",\"label\":\"Aluminium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"beryllium-oxide\",\"nodeId\":\"beryllium-oxide\",\"humanReadableId\":\"Beryllium Oxide\",\"label\":\"Beryllium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"ferrite\",\"nodeId\":\"ferrite\",\"humanReadableId\":\"Ferrite\",\"label\":\"Ferrite\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-silicate\",\"nodeId\":\"aluminium-silicate\",\"humanReadableId\":\"Aluminium Silicate\",\"label\":\"Aluminium Silicate\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\",\"silicon-oxide\"],\"rootNode\":\"ceramic\"},{\"id\":\"magnesium-silicate\",\"nodeId\":\"magnesium-silicate\",\"humanReadableId\":\"Magnesium Silicate\",\"label\":\"Magnesium Silicate\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\",\"silicon-oxide\"],\"rootNode\":\"ceramic\"},{\"id\":\"zirconium-silicate\",\"nodeId\":\"zirconium-silicate\",\"humanReadableId\":\"Zirconium Silicate\",\"label\":\"Zirconium Silicate\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\",\"silicon-oxide\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\",\"childrenNr\":3},{\"id\":\"titanium-oxide\",\"nodeId\":\"titanium-oxide\",\"humanReadableId\":\"Titanium Oxide\",\"label\":\"Titanium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"zirconium-oxide\",\"nodeId\":\"zirconium-oxide\",\"humanReadableId\":\"Zirconium Oxide\",\"label\":\"Zirconium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":7},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"multi-oxide-ceramics\",\"nodeId\":\"multi-oxide-ceramics\",\"humanReadableId\":\"Multi-Oxide Ceramics\",\"label\":\"Multi-Oxide Ceramics\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based-ceramic-matrix-composite\"],\"rootNode\":\"ceramic\"},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide-\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based-ceramic-matrix-composite\"],\"rootNode\":\"ceramic\"},{\"id\":\"ytterbium-oxide\",\"nodeId\":\"ytterbium-oxide\",\"humanReadableId\":\"Ytterbium Oxide\",\"label\":\"Ytterbium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based-ceramic-matrix-composite\"],\"rootNode\":\"ceramic\"},{\"id\":\"yttrium-oxide\",\"nodeId\":\"yttrium-oxide\",\"humanReadableId\":\"Yttrium Oxide\",\"label\":\"Yttrium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based-ceramic-matrix-composite\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":4}],\"ancestors\":[\"ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":3},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"humanReadableId\":\"Natural Ceramic\",\"label\":\"Natural Ceramic\",\"disabled\":true,\"ancestors\":[\"ceramic\"],\"rootNode\":\"ceramic\"}],\"rootNode\":\"ceramic\",\"childrenNr\":3,\"checked\":false},{\"id\":\"composite\",\"nodeId\":\"composite\",\"humanReadableId\":\"Composite\",\"label\":\"Composite\",\"disabled\":true,\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"humanReadableId\":\"Ceramic Matrix Composite\",\"label\":\"Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"carbide-based-ceramic-matrix-composite\",\"nodeId\":\"carbide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Carbide Based Ceramic Matrix Composite\",\"label\":\"Carbide Based Ceramic Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"ceramic-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite-\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"ceramic-matrix-composite\"],\"rootNode\":\"composite\"}],\"ancestors\":[\"composite\"],\"rootNode\":\"composite\",\"childrenNr\":2},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"humanReadableId\":\"Metal Matrix Composite\",\"label\":\"Metal Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-matrix-composite\",\"nodeId\":\"aluminium-matrix-composite\",\"humanReadableId\":\"Aluminium Matrix Composite\",\"label\":\"Aluminium Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"beryllium-matrix-composite\",\"nodeId\":\"beryllium-matrix-composite\",\"humanReadableId\":\"Beryllium Matrix Composite\",\"label\":\"Beryllium Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"cobalt-matrix-composite\",\"nodeId\":\"cobalt-matrix-composite\",\"humanReadableId\":\"Cobalt Matrix Composite\",\"label\":\"Cobalt Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"cobalt-and-nickel-matrix-composite\",\"nodeId\":\"cobalt-and-nickel-matrix-composite\",\"humanReadableId\":\"Cobalt and Nickel Matrix Composite\",\"label\":\"Cobalt and Nickel Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"iron-matrix-composite\",\"nodeId\":\"iron-matrix-composite\",\"humanReadableId\":\"Iron Matrix Composite\",\"label\":\"Iron Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"nickel-matrix-composite\",\"nodeId\":\"nickel-matrix-composite\",\"humanReadableId\":\"Nickel Matrix Composite\",\"label\":\"Nickel Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"}],\"ancestors\":[\"composite\"],\"rootNode\":\"composite\",\"childrenNr\":6},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"humanReadableId\":\"Polymer Matrix Composite\",\"label\":\"Polymer Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"thermoset-polymer-matrix-composite\",\"nodeId\":\"thermoset-polymer-matrix-composite\",\"humanReadableId\":\"Thermoset Polymer Matrix Composite\",\"label\":\"Thermoset Polymer Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"polymer-matrix-composite\"],\"rootNode\":\"composite\"}],\"ancestors\":[\"composite\"],\"rootNode\":\"composite\",\"childrenNr\":1}],\"rootNode\":\"composite\",\"childrenNr\":3,\"checked\":false},{\"id\":\"glass\",\"nodeId\":\"glass\",\"humanReadableId\":\"Glass\",\"label\":\"Glass\",\"disabled\":true,\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"humanReadableId\":\"Glass Ceramic\",\"label\":\"Glass Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"las-glass-ceramic\",\"nodeId\":\"las-glass-ceramic\",\"humanReadableId\":\"LAS Glass Ceramic\",\"label\":\"LAS Glass Ceramic\",\"disabled\":true,\"ancestors\":[\"glass\",\"glass-ceramic\"],\"rootNode\":\"glass\"}],\"ancestors\":[\"glass\"],\"rootNode\":\"glass\",\"childrenNr\":1},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"humanReadableId\":\"Lead Glass\",\"label\":\"Lead Glass\",\"disabled\":true,\"ancestors\":[\"glass\"],\"rootNode\":\"glass\"},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"humanReadableId\":\"Silicate Glass\",\"label\":\"Silicate Glass\",\"disabled\":true,\"children\":[{\"id\":\"aluminosilicate\",\"nodeId\":\"aluminosilicate\",\"humanReadableId\":\"Aluminosilicate\",\"label\":\"Aluminosilicate\",\"disabled\":true,\"ancestors\":[\"glass\",\"silicate-glass\"],\"rootNode\":\"glass\"},{\"id\":\"borosilicate\",\"nodeId\":\"borosilicate\",\"humanReadableId\":\"Borosilicate\",\"label\":\"Borosilicate\",\"disabled\":true,\"ancestors\":[\"glass\",\"silicate-glass\"],\"rootNode\":\"glass\"},{\"id\":\"fused-quartz\",\"nodeId\":\"fused-quartz\",\"humanReadableId\":\"Fused Quartz\",\"label\":\"Fused Quartz\",\"disabled\":true,\"ancestors\":[\"glass\",\"silicate-glass\"],\"rootNode\":\"glass\"},{\"id\":\"soda-lime-silicate\",\"nodeId\":\"soda-lime-silicate\",\"humanReadableId\":\"Soda Lime Silicate\",\"label\":\"Soda Lime Silicate\",\"disabled\":true,\"ancestors\":[\"glass\",\"silicate-glass\"],\"rootNode\":\"glass\"}],\"ancestors\":[\"glass\"],\"rootNode\":\"glass\",\"childrenNr\":4}],\"rootNode\":\"glass\",\"childrenNr\":3,\"checked\":false},{\"id\":\"metal\",\"nodeId\":\"metal\",\"humanReadableId\":\"Metal\",\"label\":\"Metal\",\"partiallyChecked\":true,\"materialsCount\":2214,\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"humanReadableId\":\"Aluminium\",\"label\":\"Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-master-alloy\",\"nodeId\":\"aluminium-master-alloy\",\"humanReadableId\":\"Aluminium Master Alloy\",\"label\":\"Aluminium Master Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-aluminium\",\"nodeId\":\"cast-aluminium\",\"humanReadableId\":\"Cast Aluminium\",\"label\":\"Cast Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1xx-x\",\"nodeId\":\"1xx-x\",\"humanReadableId\":\"1xx.x\",\"label\":\"1xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"2xx-x\",\"nodeId\":\"2xx-x\",\"humanReadableId\":\"2xx.x\",\"label\":\"2xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"3xx-x\",\"nodeId\":\"3xx-x\",\"humanReadableId\":\"3xx.x\",\"label\":\"3xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"4xx-x\",\"nodeId\":\"4xx-x\",\"humanReadableId\":\"4xx.x\",\"label\":\"4xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"5xx-x\",\"nodeId\":\"5xx-x\",\"humanReadableId\":\"5xx.x\",\"label\":\"5xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"7xx-x\",\"nodeId\":\"7xx-x\",\"humanReadableId\":\"7xx.x\",\"label\":\"7xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"8xx-x\",\"nodeId\":\"8xx-x\",\"humanReadableId\":\"8xx.x\",\"label\":\"8xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"aluminium\"],\"rootNode\":\"metal\",\"childrenNr\":7},{\"id\":\"wrought-aluminium\",\"nodeId\":\"wrought-aluminium\",\"humanReadableId\":\"Wrought Aluminium\",\"label\":\"Wrought Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1000-series\",\"nodeId\":\"1000-series\",\"humanReadableId\":\"1000 Series\",\"label\":\"1000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"2000-series\",\"nodeId\":\"2000-series\",\"humanReadableId\":\"2000 Series\",\"label\":\"2000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"3000-series\",\"nodeId\":\"3000-series\",\"humanReadableId\":\"3000 Series\",\"label\":\"3000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"4000-series\",\"nodeId\":\"4000-series\",\"humanReadableId\":\"4000 Series\",\"label\":\"4000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"5000-series\",\"nodeId\":\"5000-series\",\"humanReadableId\":\"5000 Series\",\"label\":\"5000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"6000-series\",\"nodeId\":\"6000-series\",\"humanReadableId\":\"6000 Series\",\"label\":\"6000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"7000-series\",\"nodeId\":\"7000-series\",\"humanReadableId\":\"7000 Series\",\"label\":\"7000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"8000-series\",\"nodeId\":\"8000-series\",\"humanReadableId\":\"8000 Series\",\"label\":\"8000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"aluminium\"],\"rootNode\":\"metal\",\"childrenNr\":8}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":3},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"humanReadableId\":\"Clad / Bimetal\",\"label\":\"Clad / Bimetal\",\"disabled\":true,\"ancestors\":[\"metal\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"humanReadableId\":\"Cobalt\",\"label\":\"Cobalt\",\"disabled\":true,\"children\":[{\"id\":\"cobalt-chromium\",\"nodeId\":\"cobalt-chromium\",\"humanReadableId\":\"Cobalt Chromium\",\"label\":\"Cobalt Chromium\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-chromium-molybdenum\",\"nodeId\":\"cobalt-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Chromium Molybdenum\",\"label\":\"Cobalt Chromium Molybdenum\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-chromium-nickel-tungsten\",\"nodeId\":\"cobalt-chromium-nickel-tungsten\",\"humanReadableId\":\"Cobalt Chromium Nickel Tungsten\",\"label\":\"Cobalt Chromium Nickel Tungsten\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-chromium-tungsten\",\"nodeId\":\"cobalt-chromium-tungsten\",\"humanReadableId\":\"Cobalt Chromium Tungsten\",\"label\":\"Cobalt Chromium Tungsten\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-nickel-chromium-molybdenum\",\"nodeId\":\"cobalt-nickel-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Nickel Chromium Molybdenum\",\"label\":\"Cobalt Nickel Chromium Molybdenum\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-superalloy\",\"nodeId\":\"cobalt-superalloy\",\"humanReadableId\":\"Cobalt Superalloy\",\"label\":\"Cobalt Superalloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-cobalt-alloy\",\"nodeId\":\"unclassified-cobalt-alloy\",\"humanReadableId\":\"Unclassified Cobalt Alloy\",\"label\":\"Unclassified Cobalt Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":7},{\"id\":\"copper\",\"nodeId\":\"copper\",\"humanReadableId\":\"Copper\",\"label\":\"Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper\",\"nodeId\":\"cast-copper\",\"humanReadableId\":\"Cast Copper\",\"label\":\"Cast Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass\",\"nodeId\":\"cast-copper-brass\",\"humanReadableId\":\"Cast Copper Brass\",\"label\":\"Cast Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass-yellow-brass\",\"nodeId\":\"cast-copper-brass-yellow-brass\",\"humanReadableId\":\"Cast Copper Brass Yellow Brass\",\"label\":\"Cast Copper Brass Yellow Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"cast-copper-silicon-brass\",\"nodeId\":\"cast-copper-silicon-brass\",\"humanReadableId\":\"Cast Copper Silicon Brass\",\"label\":\"Cast Copper Silicon Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"copper-bismuth-alloy\",\"nodeId\":\"copper-bismuth-alloy\",\"humanReadableId\":\"Copper Bismuth Alloy\",\"label\":\"Copper Bismuth Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"red-brass\",\"nodeId\":\"red-brass\",\"humanReadableId\":\"Red Brass\",\"label\":\"Red Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-brass\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\",\"childrenNr\":4},{\"id\":\"cast-copper-bronze\",\"nodeId\":\"cast-copper-bronze\",\"humanReadableId\":\"Cast Copper Bronze\",\"label\":\"Cast Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-bronze-aluminium-bronze\",\"nodeId\":\"cast-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Cast Copper Bronze Aluminium Bronze\",\"label\":\"Cast Copper Bronze Aluminium Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"leaded-tin-bronze\",\"nodeId\":\"leaded-tin-bronze\",\"humanReadableId\":\"Leaded Tin Bronze\",\"label\":\"Leaded Tin Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-tin-bronze\",\"nodeId\":\"nickel-tin-bronze\",\"humanReadableId\":\"Nickel Tin Bronze\",\"label\":\"Nickel Tin Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"tin-bronze\",\"nodeId\":\"tin-bronze\",\"humanReadableId\":\"Tin Bronze\",\"label\":\"Tin Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-bronze\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\",\"childrenNr\":4},{\"id\":\"cast-copper-high-copper-alloy\",\"nodeId\":\"cast-copper-high-copper-alloy\",\"humanReadableId\":\"Cast Copper High Copper Alloy\",\"label\":\"Cast Copper High Copper Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"cast-copper-nickel-grade\",\"nodeId\":\"cast-copper-nickel-grade\",\"humanReadableId\":\"Cast Copper Nickel Grade\",\"label\":\"Cast Copper Nickel Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"cast-copper-nickel-silver-grade\",\"nodeId\":\"cast-copper-nickel-silver-grade\",\"humanReadableId\":\"Cast Copper Nickel Silver Grade\",\"label\":\"Cast Copper Nickel Silver Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"cast-copper-pure---low-alloyed-copper\",\"nodeId\":\"cast-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Cast Copper Pure / Low Alloyed Copper\",\"label\":\"Cast Copper Pure / Low Alloyed Copper\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"copper-lead-alloy\",\"nodeId\":\"copper-lead-alloy\",\"humanReadableId\":\"Copper-Lead Alloy\",\"label\":\"Copper-Lead Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"special-alloy\",\"nodeId\":\"special-alloy\",\"humanReadableId\":\"Special Alloy\",\"label\":\"Special Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\"],\"rootNode\":\"metal\",\"childrenNr\":8},{\"id\":\"welding\",\"nodeId\":\"welding\",\"humanReadableId\":\"Welding\",\"label\":\"Welding\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper\",\"nodeId\":\"wrought-copper\",\"humanReadableId\":\"Wrought Copper\",\"label\":\"Wrought Copper\",\"disabled\":true,\"children\":[{\"id\":\"unclassified-wrought-copper\",\"nodeId\":\"unclassified-wrought-copper\",\"humanReadableId\":\"Unclassified Wrought Copper\",\"label\":\"Unclassified Wrought Copper\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-brass\",\"nodeId\":\"wrought-copper-brass\",\"humanReadableId\":\"Wrought Copper Brass\",\"label\":\"Wrought Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"leaded-brass\",\"nodeId\":\"leaded-brass\",\"humanReadableId\":\"Leaded Brass\",\"label\":\"Leaded Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"tin-brass\",\"nodeId\":\"tin-brass\",\"humanReadableId\":\"Tin Brass\",\"label\":\"Tin Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-brass-yellow-brass\",\"nodeId\":\"wrought-copper-brass-yellow-brass\",\"humanReadableId\":\"Wrought Copper Brass Yellow Brass\",\"label\":\"Wrought Copper Brass Yellow Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"yellow-wrought-brass\",\"nodeId\":\"yellow-wrought-brass\",\"humanReadableId\":\"Yellow Wrought Brass\",\"label\":\"Yellow Wrought Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\",\"childrenNr\":5},{\"id\":\"wrought-copper-bronze\",\"nodeId\":\"wrought-copper-bronze\",\"humanReadableId\":\"Wrought Copper Bronze\",\"label\":\"Wrought Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"copper-silver-zinc-alloy\",\"nodeId\":\"copper-silver-zinc-alloy\",\"humanReadableId\":\"Copper Silver Zinc Alloy\",\"label\":\"Copper Silver Zinc Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"leaded-phosphor-bronze\",\"nodeId\":\"leaded-phosphor-bronze\",\"humanReadableId\":\"Leaded Phosphor Bronze\",\"label\":\"Leaded Phosphor Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy-\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"phosphor-bronze\",\"nodeId\":\"phosphor-bronze\",\"humanReadableId\":\"Phosphor Bronze\",\"label\":\"Phosphor Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-bronze-aluminium-bronze\",\"nodeId\":\"wrought-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Aluminium Bronze\",\"label\":\"Wrought Copper Bronze Aluminium Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-bronze-silicon-bronze\",\"nodeId\":\"wrought-copper-bronze-silicon-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Silicon Bronze\",\"label\":\"Wrought Copper Bronze Silicon Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\",\"childrenNr\":6},{\"id\":\"wrought-copper-high-copper-alloy\",\"nodeId\":\"wrought-copper-high-copper-alloy\",\"humanReadableId\":\"Wrought Copper High Copper Alloy\",\"label\":\"Wrought Copper High Copper Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-nickel-grade\",\"nodeId\":\"wrought-copper-nickel-grade\",\"humanReadableId\":\"Wrought Copper Nickel Grade\",\"label\":\"Wrought Copper Nickel Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-nickel-silver-grade\",\"nodeId\":\"wrought-copper-nickel-silver-grade\",\"humanReadableId\":\"Wrought Copper Nickel Silver Grade\",\"label\":\"Wrought Copper Nickel Silver Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-pure---low-alloyed-copper\",\"nodeId\":\"wrought-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Wrought Copper Pure / Low Alloyed Copper\",\"label\":\"Wrought Copper Pure / Low Alloyed Copper\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\"],\"rootNode\":\"metal\",\"childrenNr\":7}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":3},{\"id\":\"iron\",\"nodeId\":\"iron\",\"humanReadableId\":\"Iron\",\"label\":\"Iron\",\"disabled\":true,\"children\":[{\"id\":\"alloy-iron\",\"nodeId\":\"alloy-iron\",\"humanReadableId\":\"Alloy Iron\",\"label\":\"Alloy Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"},{\"id\":\"cast-iron\",\"nodeId\":\"cast-iron\",\"humanReadableId\":\"Cast Iron\",\"label\":\"Cast Iron\",\"disabled\":true,\"children\":[{\"id\":\"ductile--nodular--cast-iron\",\"nodeId\":\"ductile--nodular--cast-iron\",\"humanReadableId\":\"Ductile (Nodular) Cast Iron\",\"label\":\"Ductile (Nodular) Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"},{\"id\":\"grey-cast-iron\",\"nodeId\":\"grey-cast-iron\",\"humanReadableId\":\"Grey Cast Iron\",\"label\":\"Grey Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"},{\"id\":\"other-cast-iron-alloy\",\"nodeId\":\"other-cast-iron-alloy\",\"humanReadableId\":\"Other Cast Iron Alloy\",\"label\":\"Other Cast Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"},{\"id\":\"white-cast-iron\",\"nodeId\":\"white-cast-iron\",\"humanReadableId\":\"White Cast Iron\",\"label\":\"White Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\",\"childrenNr\":5},{\"id\":\"ferromolybdenum\",\"nodeId\":\"ferromolybdenum\",\"humanReadableId\":\"Ferromolybdenum\",\"label\":\"Ferromolybdenum\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"},{\"id\":\"ferrosilicon\",\"nodeId\":\"ferrosilicon\",\"humanReadableId\":\"Ferrosilicon\",\"label\":\"Ferrosilicon\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"},{\"id\":\"ferrovanadium\",\"nodeId\":\"ferrovanadium\",\"humanReadableId\":\"Ferrovanadium\",\"label\":\"Ferrovanadium\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"},{\"id\":\"iron-alloy\",\"nodeId\":\"iron-alloy\",\"humanReadableId\":\"Iron Alloy\",\"label\":\"Iron Alloy\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nickel-cobalt-iron-alloy\",\"nodeId\":\"aluminium-nickel-cobalt-iron-alloy\",\"humanReadableId\":\"Aluminium Nickel Cobalt Iron Alloy\",\"label\":\"Aluminium Nickel Cobalt Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"iron-alloy\"],\"rootNode\":\"metal\"},{\"id\":\"miscellaneous-iron-alloy\",\"nodeId\":\"miscellaneous-iron-alloy\",\"humanReadableId\":\"Miscellaneous Iron Alloy\",\"label\":\"Miscellaneous Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"iron-alloy\"],\"rootNode\":\"metal\"},{\"id\":\"soft-magnetic-iron\",\"nodeId\":\"soft-magnetic-iron\",\"humanReadableId\":\"Soft Magnetic Iron\",\"label\":\"Soft Magnetic Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"iron-alloy\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\",\"childrenNr\":3},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron-\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":7},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"humanReadableId\":\"Magnesium\",\"label\":\"Magnesium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-grade\",\"nodeId\":\"aluminium-grade\",\"humanReadableId\":\"Aluminium Grade\",\"label\":\"Aluminium Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-aluminium-manganese-grade\",\"nodeId\":\"cast-aluminium-manganese-grade\",\"humanReadableId\":\"Cast Aluminium Manganese Grade\",\"label\":\"Cast Aluminium Manganese Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-rare-earth-grade\",\"nodeId\":\"cast-rare-earth-grade\",\"humanReadableId\":\"Cast Rare Earth Grade\",\"label\":\"Cast Rare Earth Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-wrought-aluminium-zinc-grade\",\"nodeId\":\"cast-wrought-aluminium-zinc-grade\",\"humanReadableId\":\"Cast/Wrought Aluminium Zinc Grade\",\"label\":\"Cast/Wrought Aluminium Zinc Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-wrought-unclassified-grade\",\"nodeId\":\"cast-wrought-unclassified-grade\",\"humanReadableId\":\"Cast/Wrought Unclassified Grade\",\"label\":\"Cast/Wrought Unclassified Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"pure-magnesium\",\"nodeId\":\"pure-magnesium\",\"humanReadableId\":\"Pure Magnesium\",\"label\":\"Pure Magnesium\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"rare-earth-grade\",\"nodeId\":\"rare-earth-grade\",\"humanReadableId\":\"Rare Earth Grade\",\"label\":\"Rare Earth Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-zinc-grade\",\"nodeId\":\"wrought-zinc-grade\",\"humanReadableId\":\"Wrought Zinc Grade\",\"label\":\"Wrought Zinc Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"yttrium-grade\",\"nodeId\":\"yttrium-grade\",\"humanReadableId\":\"Yttrium Grade\",\"label\":\"Yttrium Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"zinc-grade\",\"nodeId\":\"zinc-grade\",\"humanReadableId\":\"Zinc Grade\",\"label\":\"Zinc Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":10},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"humanReadableId\":\"Manganese\",\"label\":\"Manganese\",\"disabled\":true,\"ancestors\":[\"metal\"],\"rootNode\":\"metal\"},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"humanReadableId\":\"Nickel\",\"label\":\"Nickel\",\"disabled\":true,\"children\":[{\"id\":\"nickel-chromium-alloy\",\"nodeId\":\"nickel-chromium-alloy\",\"humanReadableId\":\"Nickel Chromium Alloy\",\"label\":\"Nickel Chromium Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-cobalt-alloy\",\"nodeId\":\"nickel-chromium-cobalt-alloy\",\"humanReadableId\":\"Nickel Chromium Cobalt Alloy\",\"label\":\"Nickel Chromium Cobalt Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-iron-alloy\",\"nodeId\":\"nickel-chromium-iron-alloy\",\"humanReadableId\":\"Nickel Chromium Iron Alloy\",\"label\":\"Nickel Chromium Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-molybdenum-alloy\",\"nodeId\":\"nickel-chromium-molybdenum-alloy\",\"humanReadableId\":\"Nickel Chromium Molybdenum Alloy\",\"label\":\"Nickel Chromium Molybdenum Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-cobalt-alloy\",\"nodeId\":\"nickel-cobalt-alloy\",\"humanReadableId\":\"Nickel Cobalt Alloy\",\"label\":\"Nickel Cobalt Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-copper-alloy\",\"nodeId\":\"nickel-copper-alloy\",\"humanReadableId\":\"Nickel Copper Alloy\",\"label\":\"Nickel Copper Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-iron-alloy\",\"nodeId\":\"nickel-iron-alloy\",\"humanReadableId\":\"Nickel Iron Alloy\",\"label\":\"Nickel Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-molybdenum-alloy\",\"nodeId\":\"nickel-molybdenum-alloy\",\"humanReadableId\":\"Nickel Molybdenum Alloy\",\"label\":\"Nickel Molybdenum Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-superalloy\",\"nodeId\":\"nickel-superalloy\",\"humanReadableId\":\"Nickel Superalloy\",\"label\":\"Nickel Superalloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-welding-filler\",\"nodeId\":\"nickel-welding-filler\",\"humanReadableId\":\"Nickel Welding Filler\",\"label\":\"Nickel Welding Filler\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"other-nickel-alloy\",\"nodeId\":\"other-nickel-alloy\",\"humanReadableId\":\"Other Nickel Alloy\",\"label\":\"Other Nickel Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"pure-low-nickel-alloy\",\"nodeId\":\"pure-low-nickel-alloy\",\"humanReadableId\":\"Pure/Low Nickel Alloy\",\"label\":\"Pure/Low Nickel Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":12},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"humanReadableId\":\"Noble Metal\",\"label\":\"Noble Metal\",\"disabled\":true,\"children\":[{\"id\":\"gold\",\"nodeId\":\"gold\",\"humanReadableId\":\"Gold\",\"label\":\"Gold\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"iridium\",\"nodeId\":\"iridium\",\"humanReadableId\":\"Iridium\",\"label\":\"Iridium\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"palladium\",\"nodeId\":\"palladium\",\"humanReadableId\":\"Palladium\",\"label\":\"Palladium\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"platinum\",\"nodeId\":\"platinum\",\"humanReadableId\":\"Platinum\",\"label\":\"Platinum\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"rhodium\",\"nodeId\":\"rhodium\",\"humanReadableId\":\"Rhodium\",\"label\":\"Rhodium\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"silver\",\"nodeId\":\"silver\",\"humanReadableId\":\"Silver\",\"label\":\"Silver\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":6},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"humanReadableId\":\"Other Metal\",\"label\":\"Other Metal\",\"disabled\":true,\"children\":[{\"id\":\"beryllium\",\"nodeId\":\"beryllium\",\"humanReadableId\":\"Beryllium\",\"label\":\"Beryllium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\"},{\"id\":\"cadmium\",\"nodeId\":\"cadmium\",\"humanReadableId\":\"Cadmium\",\"label\":\"Cadmium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\"},{\"id\":\"chromium\",\"nodeId\":\"chromium\",\"humanReadableId\":\"Chromium\",\"label\":\"Chromium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\"},{\"id\":\"lead\",\"nodeId\":\"lead\",\"humanReadableId\":\"Lead\",\"label\":\"Lead\",\"disabled\":true,\"children\":[{\"id\":\"lead-antimony\",\"nodeId\":\"lead-antimony\",\"humanReadableId\":\"Lead Antimony\",\"label\":\"Lead Antimony\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"lead\"],\"rootNode\":\"metal\"},{\"id\":\"lead-tin\",\"nodeId\":\"lead-tin\",\"humanReadableId\":\"Lead Tin\",\"label\":\"Lead Tin\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"lead\"],\"rootNode\":\"metal\"},{\"id\":\"pure-low-alloyed-lead\",\"nodeId\":\"pure-low-alloyed-lead\",\"humanReadableId\":\"Pure/Low Alloyed Lead\",\"label\":\"Pure/Low Alloyed Lead\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"lead\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":3},{\"id\":\"lithium\",\"nodeId\":\"lithium\",\"humanReadableId\":\"Lithium\",\"label\":\"Lithium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\"},{\"id\":\"neodymium\",\"nodeId\":\"neodymium\",\"humanReadableId\":\"Neodymium\",\"label\":\"Neodymium\",\"disabled\":true,\"children\":[{\"id\":\"neodymium-iron-boron-alloy\",\"nodeId\":\"neodymium-iron-boron-alloy\",\"humanReadableId\":\"Neodymium Iron Boron Alloy\",\"label\":\"Neodymium Iron Boron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"neodymium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":1},{\"id\":\"samarium\",\"nodeId\":\"samarium\",\"humanReadableId\":\"Samarium\",\"label\":\"Samarium\",\"disabled\":true,\"children\":[{\"id\":\"samarium-cobalt-alloy\",\"nodeId\":\"samarium-cobalt-alloy\",\"humanReadableId\":\"Samarium Cobalt Alloy\",\"label\":\"Samarium Cobalt Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"samarium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":1},{\"id\":\"tin\",\"nodeId\":\"tin\",\"humanReadableId\":\"Tin\",\"label\":\"Tin\",\"disabled\":true,\"children\":[{\"id\":\"pure-low-alloyed-tin\",\"nodeId\":\"pure-low-alloyed-tin\",\"humanReadableId\":\"Pure/Low Alloyed Tin\",\"label\":\"Pure/Low Alloyed Tin\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"tin\"],\"rootNode\":\"metal\"},{\"id\":\"tin-antimony\",\"nodeId\":\"tin-antimony\",\"humanReadableId\":\"Tin Antimony\",\"label\":\"Tin Antimony\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"tin\"],\"rootNode\":\"metal\"},{\"id\":\"tin-lead\",\"nodeId\":\"tin-lead\",\"humanReadableId\":\"Tin Lead\",\"label\":\"Tin Lead\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"tin\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-tin\",\"nodeId\":\"unclassified-tin\",\"humanReadableId\":\"Unclassified Tin\",\"label\":\"Unclassified Tin\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"tin\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":4},{\"id\":\"zinc\",\"nodeId\":\"zinc\",\"humanReadableId\":\"Zinc\",\"label\":\"Zinc\",\"disabled\":true,\"children\":[{\"id\":\"unalloyed-zinc\",\"nodeId\":\"unalloyed-zinc\",\"humanReadableId\":\"Unalloyed Zinc\",\"label\":\"Unalloyed Zinc\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"zinc\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-zinc\",\"nodeId\":\"unclassified-zinc\",\"humanReadableId\":\"Unclassified Zinc\",\"label\":\"Unclassified Zinc\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"zinc\"],\"rootNode\":\"metal\"},{\"id\":\"zinc-aluminium\",\"nodeId\":\"zinc-aluminium\",\"humanReadableId\":\"Zinc Aluminium\",\"label\":\"Zinc Aluminium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"zinc\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":3}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":9},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"humanReadableId\":\"Refractory Metal\",\"label\":\"Refractory Metal\",\"disabled\":true,\"children\":[{\"id\":\"hafnium\",\"nodeId\":\"hafnium\",\"humanReadableId\":\"Hafnium\",\"label\":\"Hafnium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"molybdenum\",\"nodeId\":\"molybdenum\",\"humanReadableId\":\"Molybdenum\",\"label\":\"Molybdenum\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"niobium\",\"nodeId\":\"niobium\",\"humanReadableId\":\"Niobium\",\"label\":\"Niobium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"rhenium\",\"nodeId\":\"rhenium\",\"humanReadableId\":\"Rhenium\",\"label\":\"Rhenium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"tantalum\",\"nodeId\":\"tantalum\",\"humanReadableId\":\"Tantalum\",\"label\":\"Tantalum\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"tungsten\",\"nodeId\":\"tungsten\",\"humanReadableId\":\"Tungsten\",\"label\":\"Tungsten\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"vanadium\",\"nodeId\":\"vanadium\",\"humanReadableId\":\"Vanadium\",\"label\":\"Vanadium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"zirconium\",\"nodeId\":\"zirconium\",\"humanReadableId\":\"Zirconium\",\"label\":\"Zirconium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":8},{\"id\":\"steel\",\"nodeId\":\"steel\",\"humanReadableId\":\"Steel\",\"label\":\"Steel\",\"checked\":true,\"children\":[{\"id\":\"alloy-steel\",\"nodeId\":\"alloy-steel\",\"humanReadableId\":\"Alloy Steel\",\"label\":\"Alloy Steel\",\"checked\":true,\"children\":[{\"id\":\"chromium-molybdenum-steel\",\"nodeId\":\"chromium-molybdenum-steel\",\"humanReadableId\":\"Chromium Molybdenum Steel\",\"label\":\"Chromium Molybdenum Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"chromium-molybdenum-vanadium-steel\",\"nodeId\":\"chromium-molybdenum-vanadium-steel\",\"humanReadableId\":\"Chromium Molybdenum Vanadium Steel\",\"label\":\"Chromium Molybdenum Vanadium Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"chromium-steel\",\"nodeId\":\"chromium-steel\",\"humanReadableId\":\"Chromium Steel\",\"label\":\"Chromium Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"chromium-vanadium-steel\",\"nodeId\":\"chromium-vanadium-steel\",\"humanReadableId\":\"Chromium Vanadium Steel\",\"label\":\"Chromium Vanadium Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"manganese-steel\",\"nodeId\":\"manganese-steel\",\"humanReadableId\":\"Manganese Steel\",\"label\":\"Manganese Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"molybdenum-steel\",\"nodeId\":\"molybdenum-steel\",\"humanReadableId\":\"Molybdenum Steel\",\"label\":\"Molybdenum Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-molybdenum-steel\",\"nodeId\":\"nickel-chromium-molybdenum-steel\",\"humanReadableId\":\"Nickel Chromium Molybdenum Steel\",\"label\":\"Nickel Chromium Molybdenum Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-steel\",\"nodeId\":\"nickel-chromium-steel\",\"humanReadableId\":\"Nickel Chromium Steel\",\"label\":\"Nickel Chromium Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-molybdenum-steel\",\"nodeId\":\"nickel-molybdenum-steel\",\"humanReadableId\":\"Nickel Molybdenum Steel\",\"label\":\"Nickel Molybdenum Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-steel\",\"nodeId\":\"nickel-steel\",\"humanReadableId\":\"Nickel Steel\",\"label\":\"Nickel Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nitriding-steel\",\"nodeId\":\"nitriding-steel\",\"humanReadableId\":\"Nitriding Steel\",\"label\":\"Nitriding Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"silicon-manganese-steel\",\"nodeId\":\"silicon-manganese-steel\",\"humanReadableId\":\"Silicon Manganese Steel\",\"label\":\"Silicon Manganese Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"silicon-steel\",\"nodeId\":\"silicon-steel\",\"humanReadableId\":\"Silicon Steel\",\"label\":\"Silicon Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-low-alloy-steel\",\"nodeId\":\"unclassified-low-alloy-steel\",\"humanReadableId\":\"Unclassified Low Alloy Steel\",\"label\":\"Unclassified Low Alloy Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\",\"childrenNr\":14},{\"id\":\"carbon-steel\",\"nodeId\":\"carbon-steel\",\"humanReadableId\":\"Carbon Steel\",\"label\":\"Carbon Steel\",\"checked\":true,\"children\":[{\"id\":\"high-carbon-steel\",\"nodeId\":\"high-carbon-steel\",\"humanReadableId\":\"High Carbon Steel\",\"label\":\"High Carbon Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"carbon-steel\"],\"rootNode\":\"metal\"},{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"carbon-steel\"],\"rootNode\":\"metal\"},{\"id\":\"medium-carbon-steel\",\"nodeId\":\"medium-carbon-steel\",\"humanReadableId\":\"Medium Carbon Steel\",\"label\":\"Medium Carbon Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"carbon-steel\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-carbon-steel\",\"nodeId\":\"unclassified-carbon-steel\",\"humanReadableId\":\"Unclassified Carbon Steel\",\"label\":\"Unclassified Carbon Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"carbon-steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\",\"childrenNr\":4},{\"id\":\"low-alloy-steel\",\"nodeId\":\"low-alloy-steel\",\"humanReadableId\":\"Low Alloy Steel\",\"label\":\"Low Alloy Steel\",\"checked\":true,\"disabled\":true,\"children\":[{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel-\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\",\"low-alloy-steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\",\"childrenNr\":1},{\"id\":\"maraging-steel\",\"nodeId\":\"maraging-steel\",\"humanReadableId\":\"Maraging Steel\",\"label\":\"Maraging Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\"},{\"id\":\"stainless-steel\",\"nodeId\":\"stainless-steel\",\"humanReadableId\":\"Stainless Steel\",\"label\":\"Stainless Steel\",\"checked\":true,\"children\":[{\"id\":\"austenitic-stainless-steel\",\"nodeId\":\"austenitic-stainless-steel\",\"humanReadableId\":\"Austenitic Stainless Steel\",\"label\":\"Austenitic Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"duplex-stainless-steel\",\"nodeId\":\"duplex-stainless-steel\",\"humanReadableId\":\"Duplex Stainless Steel\",\"label\":\"Duplex Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"ferritic-stainless-steel\",\"nodeId\":\"ferritic-stainless-steel\",\"humanReadableId\":\"Ferritic Stainless Steel\",\"label\":\"Ferritic Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"martensitic-stainless-steel\",\"nodeId\":\"martensitic-stainless-steel\",\"humanReadableId\":\"Martensitic Stainless Steel\",\"label\":\"Martensitic Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"precipitation-hardening-stainless-steel\",\"nodeId\":\"precipitation-hardening-stainless-steel\",\"humanReadableId\":\"Precipitation Hardening Stainless Steel\",\"label\":\"Precipitation Hardening Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"superaustenitic-stainless-steel\",\"nodeId\":\"superaustenitic-stainless-steel\",\"humanReadableId\":\"Superaustenitic Stainless Steel\",\"label\":\"Superaustenitic Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-stainless-steel\",\"nodeId\":\"unclassified-stainless-steel\",\"humanReadableId\":\"Unclassified Stainless Steel\",\"label\":\"Unclassified Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\",\"childrenNr\":7},{\"id\":\"tool-and-machining-steel\",\"nodeId\":\"tool-and-machining-steel\",\"humanReadableId\":\"Tool And Machining Steel\",\"label\":\"Tool And Machining Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":6},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"humanReadableId\":\"Titanium\",\"label\":\"Titanium\",\"disabled\":true,\"children\":[{\"id\":\"alpha-alloy\",\"nodeId\":\"alpha-alloy\",\"humanReadableId\":\"Alpha Alloy\",\"label\":\"Alpha Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"alpha-beta-alloy\",\"nodeId\":\"alpha-beta-alloy\",\"humanReadableId\":\"Alpha Beta Alloy\",\"label\":\"Alpha Beta Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"beta-alloy\",\"nodeId\":\"beta-alloy\",\"humanReadableId\":\"Beta Alloy\",\"label\":\"Beta Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"low-alloy-titanium\",\"nodeId\":\"low-alloy-titanium\",\"humanReadableId\":\"Low Alloy Titanium\",\"label\":\"Low Alloy Titanium\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"near-alpha-alloy\",\"nodeId\":\"near-alpha-alloy\",\"humanReadableId\":\"Near Alpha Alloy\",\"label\":\"Near Alpha Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"pure-titanium\",\"nodeId\":\"pure-titanium\",\"humanReadableId\":\"Pure Titanium\",\"label\":\"Pure Titanium\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":6}],\"rootNode\":\"metal\",\"childrenNr\":13,\"checked\":false},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"humanReadableId\":\"Polymer\",\"label\":\"Polymer\",\"disabled\":true,\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"humanReadableId\":\"Elastomer\",\"label\":\"Elastomer\",\"disabled\":true,\"children\":[{\"id\":\"butadiene-rubber--br-\",\"nodeId\":\"butadiene-rubber--br-\",\"humanReadableId\":\"Butadiene Rubber (BR)\",\"label\":\"Butadiene Rubber (BR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"chloroprene-rubber--cr-\",\"nodeId\":\"chloroprene-rubber--cr-\",\"humanReadableId\":\"Chloroprene Rubber (CR)\",\"label\":\"Chloroprene Rubber (CR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"ethylene-propylene-diene-rubber--epdm-\",\"nodeId\":\"ethylene-propylene-diene-rubber--epdm-\",\"humanReadableId\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"label\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"ethylene-propylene-rubber--epr-\",\"nodeId\":\"ethylene-propylene-rubber--epr-\",\"humanReadableId\":\"Ethylene Propylene Rubber (EPR)\",\"label\":\"Ethylene Propylene Rubber (EPR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"fluorosilicone-rubber--fvmq-\",\"nodeId\":\"fluorosilicone-rubber--fvmq-\",\"humanReadableId\":\"Fluorosilicone Rubber (FVMQ)\",\"label\":\"Fluorosilicone Rubber (FVMQ)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"natural-rubber--nr-\",\"nodeId\":\"natural-rubber--nr-\",\"humanReadableId\":\"Natural Rubber (NR)\",\"label\":\"Natural Rubber (NR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"nitrile-rubber--nbr-\",\"nodeId\":\"nitrile-rubber--nbr-\",\"humanReadableId\":\"Nitrile Rubber (NBR)\",\"label\":\"Nitrile Rubber (NBR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"styrene-butadiene-rubber--sbr-\",\"nodeId\":\"styrene-butadiene-rubber--sbr-\",\"humanReadableId\":\"Styrene Butadiene Rubber (SBR)\",\"label\":\"Styrene Butadiene Rubber (SBR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-elastomer--tpe-\",\"nodeId\":\"thermoplastic-elastomer--tpe-\",\"humanReadableId\":\"Thermoplastic Elastomer (TPE)\",\"label\":\"Thermoplastic Elastomer (TPE)\",\"disabled\":true,\"children\":[{\"id\":\"elastomeric-alloy--tpv-\",\"nodeId\":\"elastomeric-alloy--tpv-\",\"humanReadableId\":\"Elastomeric Alloy (TPV)\",\"label\":\"Elastomeric Alloy (TPV)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"styrene-butadiene-styrene--sbs-\",\"nodeId\":\"styrene-butadiene-styrene--sbs-\",\"humanReadableId\":\"Styrene Butadiene Styrene (SBS)\",\"label\":\"Styrene Butadiene Styrene (SBS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-copolyester--tpc-\",\"nodeId\":\"thermoplastic-copolyester--tpc-\",\"humanReadableId\":\"Thermoplastic Copolyester (TPC)\",\"label\":\"Thermoplastic Copolyester (TPC)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-polyamide--tpa-\",\"nodeId\":\"thermoplastic-polyamide--tpa-\",\"humanReadableId\":\"Thermoplastic Polyamide (TPA)\",\"label\":\"Thermoplastic Polyamide (TPA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-polyester-elastomer--tpee-\",\"nodeId\":\"thermoplastic-polyester-elastomer--tpee-\",\"humanReadableId\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"label\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-polyolefin--tpo-\",\"nodeId\":\"thermoplastic-polyolefin--tpo-\",\"humanReadableId\":\"Thermoplastic Polyolefin (TPO)\",\"label\":\"Thermoplastic Polyolefin (TPO)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-polyurethane--tpu-\",\"nodeId\":\"thermoplastic-polyurethane--tpu-\",\"humanReadableId\":\"Thermoplastic Polyurethane (TPU)\",\"label\":\"Thermoplastic Polyurethane (TPU)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"nodeId\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"humanReadableId\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"label\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\",\"childrenNr\":8}],\"ancestors\":[\"polymer\"],\"rootNode\":\"polymer\",\"childrenNr\":9},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"humanReadableId\":\"Thermoplastic\",\"label\":\"Thermoplastic\",\"disabled\":true,\"children\":[{\"id\":\"acrylic\",\"nodeId\":\"acrylic\",\"humanReadableId\":\"Acrylic\",\"label\":\"Acrylic\",\"disabled\":true,\"children\":[{\"id\":\"polyacrylonitrile--pan-\",\"nodeId\":\"polyacrylonitrile--pan-\",\"humanReadableId\":\"Polyacrylonitrile (PAN)\",\"label\":\"Polyacrylonitrile (PAN)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"acrylic\"],\"rootNode\":\"polymer\"},{\"id\":\"polymethyl-methacrylate--pmma-\",\"nodeId\":\"polymethyl-methacrylate--pmma-\",\"humanReadableId\":\"Polymethyl methacrylate (PMMA)\",\"label\":\"Polymethyl methacrylate (PMMA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"acrylic\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":2},{\"id\":\"fluoropolymer\",\"nodeId\":\"fluoropolymer\",\"humanReadableId\":\"Fluoropolymer\",\"label\":\"Fluoropolymer\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"nodeId\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"humanReadableId\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"label\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"fluoropolymer\"],\"rootNode\":\"polymer\"},{\"id\":\"fluorinated-ethylene-propylene--fep-\",\"nodeId\":\"fluorinated-ethylene-propylene--fep-\",\"humanReadableId\":\"Fluorinated ethylene propylene (FEP)\",\"label\":\"Fluorinated ethylene propylene (FEP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"fluoropolymer\"],\"rootNode\":\"polymer\"},{\"id\":\"polytetrafluoroethylene--ptfe-\",\"nodeId\":\"polytetrafluoroethylene--ptfe-\",\"humanReadableId\":\"Polytetrafluoroethylene (PTFE)\",\"label\":\"Polytetrafluoroethylene (PTFE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"fluoropolymer\"],\"rootNode\":\"polymer\"},{\"id\":\"polyvinylidenefluoride--pvdf-\",\"nodeId\":\"polyvinylidenefluoride--pvdf-\",\"humanReadableId\":\"Polyvinylidenefluoride (PVDF)\",\"label\":\"Polyvinylidenefluoride (PVDF)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"fluoropolymer\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":4},{\"id\":\"liquid-crystal-polymers--lcp-\",\"nodeId\":\"liquid-crystal-polymers--lcp-\",\"humanReadableId\":\"Liquid Crystal Polymers (LCP)\",\"label\":\"Liquid Crystal Polymers (LCP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide--pa-\",\"nodeId\":\"polyamide--pa-\",\"humanReadableId\":\"Polyamide (PA)\",\"label\":\"Polyamide (PA)\",\"disabled\":true,\"children\":[{\"id\":\"aramide\",\"nodeId\":\"aramide\",\"humanReadableId\":\"Aramide\",\"label\":\"Aramide\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"copolyamide-6-66--pa6-66-\",\"nodeId\":\"copolyamide-6-66--pa6-66-\",\"humanReadableId\":\"Copolyamide 6/66 (PA6/66)\",\"label\":\"Copolyamide 6/66 (PA6/66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"other-polyamide--pa-\",\"nodeId\":\"other-polyamide--pa-\",\"humanReadableId\":\"Other Polyamide (PA)\",\"label\":\"Other Polyamide (PA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-1010--pa1010-\",\"nodeId\":\"polyamide-1010--pa1010-\",\"humanReadableId\":\"Polyamide 1010 (PA1010)\",\"label\":\"Polyamide 1010 (PA1010)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-1012--pa1012-\",\"nodeId\":\"polyamide-1012--pa1012-\",\"humanReadableId\":\"Polyamide 1012 (PA1012)\",\"label\":\"Polyamide 1012 (PA1012)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-11--pa11-\",\"nodeId\":\"polyamide-11--pa11-\",\"humanReadableId\":\"Polyamide 11 (PA11)\",\"label\":\"Polyamide 11 (PA11)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-12--pa12-\",\"nodeId\":\"polyamide-12--pa12-\",\"humanReadableId\":\"Polyamide 12 (PA12)\",\"label\":\"Polyamide 12 (PA12)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-410--pa410-\",\"nodeId\":\"polyamide-410--pa410-\",\"humanReadableId\":\"Polyamide 410 (PA410)\",\"label\":\"Polyamide 410 (PA410)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-46--pa46-\",\"nodeId\":\"polyamide-46--pa46-\",\"humanReadableId\":\"Polyamide 46 (PA46)\",\"label\":\"Polyamide 46 (PA46)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-6--pa6-\",\"nodeId\":\"polyamide-6--pa6-\",\"humanReadableId\":\"Polyamide 6 (PA6)\",\"label\":\"Polyamide 6 (PA6)\",\"disabled\":true,\"children\":[{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t-\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyamide-6--pa6-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\",\"childrenNr\":1},{\"id\":\"polyamide-6-66--pa6-66-\",\"nodeId\":\"polyamide-6-66--pa6-66-\",\"humanReadableId\":\"Polyamide 6/66 (PA6/66)\",\"label\":\"Polyamide 6/66 (PA6/66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-610--pa610-\",\"nodeId\":\"polyamide-610--pa610-\",\"humanReadableId\":\"Polyamide 610 (PA610)\",\"label\":\"Polyamide 610 (PA610)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-612--pa612-\",\"nodeId\":\"polyamide-612--pa612-\",\"humanReadableId\":\"Polyamide 612 (PA612)\",\"label\":\"Polyamide 612 (PA612)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-66--pa66-\",\"nodeId\":\"polyamide-66--pa66-\",\"humanReadableId\":\"Polyamide 66 (PA66)\",\"label\":\"Polyamide 66 (PA66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphthalamide--ppa-\",\"nodeId\":\"polyphthalamide--ppa-\",\"humanReadableId\":\"Polyphthalamide (PPA)\",\"label\":\"Polyphthalamide (PPA)\",\"disabled\":true,\"children\":[{\"id\":\"copolyamide-66-6i--pa66-6i-\",\"nodeId\":\"copolyamide-66-6i--pa66-6i-\",\"humanReadableId\":\"Copolyamide 66/6I (PA66/6I)\",\"label\":\"Copolyamide 66/6I (PA66/6I)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"copolyamide-6t-66--pa6t-66-\",\"nodeId\":\"copolyamide-6t-66--pa6t-66-\",\"humanReadableId\":\"Copolyamide 6T/66 (PA6T/66)\",\"label\":\"Copolyamide 6T/66 (PA6T/66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"nodeId\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"humanReadableId\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"label\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"nodeId\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"humanReadableId\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"label\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t--\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-6t--pa6t-\",\"nodeId\":\"polyamide-6t--pa6t-\",\"humanReadableId\":\"Polyamide 6T (PA6T)\",\"label\":\"Polyamide 6T (PA6T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-mxd6--pamxd6-\",\"nodeId\":\"polyamide-mxd6--pamxd6-\",\"humanReadableId\":\"Polyamide MXD6 (PAMXD6)\",\"label\":\"Polyamide MXD6 (PAMXD6)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-pa6-6t--pa6-6t-\",\"nodeId\":\"polyamide-pa6-6t--pa6-6t-\",\"humanReadableId\":\"Polyamide PA6/6T (PA6/6T)\",\"label\":\"Polyamide PA6/6T (PA6/6T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\",\"childrenNr\":8}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":15},{\"id\":\"polyaryletherketone--paek-\",\"nodeId\":\"polyaryletherketone--paek-\",\"humanReadableId\":\"Polyaryletherketone (PAEK)\",\"label\":\"Polyaryletherketone (PAEK)\",\"disabled\":true,\"children\":[{\"id\":\"polyether-ketone--pek-\",\"nodeId\":\"polyether-ketone--pek-\",\"humanReadableId\":\"Polyether Ketone (PEK)\",\"label\":\"Polyether Ketone (PEK)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyaryletherketone--paek-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyetherether-ketone--peek-\",\"nodeId\":\"polyetherether-ketone--peek-\",\"humanReadableId\":\"Polyetherether Ketone (PEEK)\",\"label\":\"Polyetherether Ketone (PEEK)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyaryletherketone--paek-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyetherketoneketone--pekk-\",\"nodeId\":\"polyetherketoneketone--pekk-\",\"humanReadableId\":\"Polyetherketoneketone (PEKK)\",\"label\":\"Polyetherketoneketone (PEKK)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyaryletherketone--paek-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":3},{\"id\":\"polycarbonate--pc-\",\"nodeId\":\"polycarbonate--pc-\",\"humanReadableId\":\"Polycarbonate (PC)\",\"label\":\"Polycarbonate (PC)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyester\",\"nodeId\":\"polyester\",\"humanReadableId\":\"Polyester\",\"label\":\"Polyester\",\"disabled\":true,\"children\":[{\"id\":\"polybutylene-terephthalate--pbt-\",\"nodeId\":\"polybutylene-terephthalate--pbt-\",\"humanReadableId\":\"Polybutylene Terephthalate (PBT)\",\"label\":\"Polybutylene Terephthalate (PBT)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"},{\"id\":\"polyethylene-terephthalate--pet-\",\"nodeId\":\"polyethylene-terephthalate--pet-\",\"humanReadableId\":\"Polyethylene Terephthalate (PET)\",\"label\":\"Polyethylene Terephthalate (PET)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"},{\"id\":\"polyethylene-terephthalate-glycol--petg-\",\"nodeId\":\"polyethylene-terephthalate-glycol--petg-\",\"humanReadableId\":\"Polyethylene Terephthalate Glycol (PETG)\",\"label\":\"Polyethylene Terephthalate Glycol (PETG)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"},{\"id\":\"polyglycolicide--pga-\",\"nodeId\":\"polyglycolicide--pga-\",\"humanReadableId\":\"Polyglycolicide (PGA)\",\"label\":\"Polyglycolicide (PGA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"},{\"id\":\"polytrimethylene-terephthalate--ptt-\",\"nodeId\":\"polytrimethylene-terephthalate--ptt-\",\"humanReadableId\":\"Polytrimethylene Terephthalate (PTT)\",\"label\":\"Polytrimethylene Terephthalate (PTT)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":5},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe-\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyimide--pi-\",\"nodeId\":\"polyimide--pi-\",\"humanReadableId\":\"Polyimide (PI)\",\"label\":\"Polyimide (PI)\",\"disabled\":true,\"children\":[{\"id\":\"polyamidimide--pai-\",\"nodeId\":\"polyamidimide--pai-\",\"humanReadableId\":\"Polyamidimide (PAI)\",\"label\":\"Polyamidimide (PAI)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyimide--pi-\"],\"rootNode\":\"polymer\"},{\"id\":\"polybenzimidazole--pbi-\",\"nodeId\":\"polybenzimidazole--pbi-\",\"humanReadableId\":\"Polybenzimidazole (PBI)\",\"label\":\"Polybenzimidazole (PBI)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyimide--pi-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyetherimide--pei-\",\"nodeId\":\"polyetherimide--pei-\",\"humanReadableId\":\"Polyetherimide (PEI)\",\"label\":\"Polyetherimide (PEI)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyimide--pi-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":3},{\"id\":\"polyketone--pk-\",\"nodeId\":\"polyketone--pk-\",\"humanReadableId\":\"Polyketone (PK)\",\"label\":\"Polyketone (PK)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polylactic-acid--pla-\",\"nodeId\":\"polylactic-acid--pla-\",\"humanReadableId\":\"Polylactic Acid (PLA)\",\"label\":\"Polylactic Acid (PLA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polymer-blend\",\"nodeId\":\"polymer-blend\",\"humanReadableId\":\"Polymer Blend\",\"label\":\"Polymer Blend\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyolefin--po-\",\"nodeId\":\"polyolefin--po-\",\"humanReadableId\":\"Polyolefin (PO)\",\"label\":\"Polyolefin (PO)\",\"disabled\":true,\"children\":[{\"id\":\"polybutene--pb-\",\"nodeId\":\"polybutene--pb-\",\"humanReadableId\":\"Polybutene (PB)\",\"label\":\"Polybutene (PB)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe--\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"children\":[{\"id\":\"high-density-polyethylene--pe-hd-\",\"nodeId\":\"high-density-polyethylene--pe-hd-\",\"humanReadableId\":\"High Density Polyethylene (PE-HD)\",\"label\":\"High Density Polyethylene (PE-HD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"nodeId\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"humanReadableId\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"label\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"linear-low-density-polyethylene--pe-lld-\",\"nodeId\":\"linear-low-density-polyethylene--pe-lld-\",\"humanReadableId\":\"Linear Low Density Polyethylene (PE-LLD)\",\"label\":\"Linear Low Density Polyethylene (PE-LLD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"low-density-polyethylene--pe-ld-\",\"nodeId\":\"low-density-polyethylene--pe-ld-\",\"humanReadableId\":\"Low Density Polyethylene (PE-LD)\",\"label\":\"Low Density Polyethylene (PE-LD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"medium-density-polyethylene--pe-md-\",\"nodeId\":\"medium-density-polyethylene--pe-md-\",\"humanReadableId\":\"Medium Density Polyethylene (PE-MD)\",\"label\":\"Medium Density Polyethylene (PE-MD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"nodeId\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"humanReadableId\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"label\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"very-low-density-polyethylene--pe-vld-\",\"nodeId\":\"very-low-density-polyethylene--pe-vld-\",\"humanReadableId\":\"Very Low Density Polyethylene (PE-VLD)\",\"label\":\"Very Low Density Polyethylene (PE-VLD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\"],\"rootNode\":\"polymer\",\"childrenNr\":7},{\"id\":\"polymethylpentene--pmp-\",\"nodeId\":\"polymethylpentene--pmp-\",\"humanReadableId\":\"Polymethylpentene (PMP)\",\"label\":\"Polymethylpentene (PMP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\"],\"rootNode\":\"polymer\"},{\"id\":\"polypropylene--pp-\",\"nodeId\":\"polypropylene--pp-\",\"humanReadableId\":\"Polypropylene (PP)\",\"label\":\"Polypropylene (PP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":4},{\"id\":\"polyoxymethylene--pom-\",\"nodeId\":\"polyoxymethylene--pom-\",\"humanReadableId\":\"Polyoxymethylene (POM)\",\"label\":\"Polyoxymethylene (POM)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphenyl\",\"nodeId\":\"polyphenyl\",\"humanReadableId\":\"Polyphenyl\",\"label\":\"Polyphenyl\",\"disabled\":true,\"children\":[{\"id\":\"polyphenyl-ether--ppe-\",\"nodeId\":\"polyphenyl-ether--ppe-\",\"humanReadableId\":\"Polyphenyl Ether (PPE)\",\"label\":\"Polyphenyl Ether (PPE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyphenyl\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphenylene-oxide--ppo-\",\"nodeId\":\"polyphenylene-oxide--ppo-\",\"humanReadableId\":\"Polyphenylene Oxide (PPO)\",\"label\":\"Polyphenylene Oxide (PPO)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyphenyl\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphenylene-sulfide--pps-\",\"nodeId\":\"polyphenylene-sulfide--pps-\",\"humanReadableId\":\"Polyphenylene Sulfide (PPS)\",\"label\":\"Polyphenylene Sulfide (PPS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyphenyl\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":3},{\"id\":\"polysaccharide\",\"nodeId\":\"polysaccharide\",\"humanReadableId\":\"Polysaccharide\",\"label\":\"Polysaccharide\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polysulphones\",\"nodeId\":\"polysulphones\",\"humanReadableId\":\"Polysulphones\",\"label\":\"Polysulphones\",\"disabled\":true,\"children\":[{\"id\":\"polyether-sulfone--pes-\",\"nodeId\":\"polyether-sulfone--pes-\",\"humanReadableId\":\"Polyether Sulfone (PES)\",\"label\":\"Polyether Sulfone (PES)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polysulphones\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphenylsulphone--ppsu-\",\"nodeId\":\"polyphenylsulphone--ppsu-\",\"humanReadableId\":\"Polyphenylsulphone (PPSU)\",\"label\":\"Polyphenylsulphone (PPSU)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polysulphones\"],\"rootNode\":\"polymer\"},{\"id\":\"polysulphone--psu-\",\"nodeId\":\"polysulphone--psu-\",\"humanReadableId\":\"Polysulphone (PSU)\",\"label\":\"Polysulphone (PSU)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polysulphones\"],\"rootNode\":\"polymer\"},{\"id\":\"polysulphone-general--psu-\",\"nodeId\":\"polysulphone-general--psu-\",\"humanReadableId\":\"Polysulphone General (PSU)\",\"label\":\"Polysulphone General (PSU)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polysulphones\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":4},{\"id\":\"styrene\",\"nodeId\":\"styrene\",\"humanReadableId\":\"Styrene\",\"label\":\"Styrene\",\"disabled\":true,\"children\":[{\"id\":\"acrylonitrile-butadiene-styrene--abs-\",\"nodeId\":\"acrylonitrile-butadiene-styrene--abs-\",\"humanReadableId\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"label\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"acrylonitrile-styrene-acrylate--asa-\",\"nodeId\":\"acrylonitrile-styrene-acrylate--asa-\",\"humanReadableId\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"label\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"high-impact-polystyrene--hips-\",\"nodeId\":\"high-impact-polystyrene--hips-\",\"humanReadableId\":\"High Impact Polystyrene (HIPS)\",\"label\":\"High Impact Polystyrene (HIPS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"methacrylate-butadiene-styrene--mbs-\",\"nodeId\":\"methacrylate-butadiene-styrene--mbs-\",\"humanReadableId\":\"Methacrylate Butadiene Styrene (MBS)\",\"label\":\"Methacrylate Butadiene Styrene (MBS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"polystyrene--ps-\",\"nodeId\":\"polystyrene--ps-\",\"humanReadableId\":\"Polystyrene (PS)\",\"label\":\"Polystyrene (PS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"styrene-acrylonitrile--san-\",\"nodeId\":\"styrene-acrylonitrile--san-\",\"humanReadableId\":\"Styrene Acrylonitrile (SAN)\",\"label\":\"Styrene Acrylonitrile (SAN)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":6},{\"id\":\"vinyl\",\"nodeId\":\"vinyl\",\"humanReadableId\":\"Vinyl\",\"label\":\"Vinyl\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-vinyl-acetate--evac-\",\"nodeId\":\"ethylene-vinyl-acetate--evac-\",\"humanReadableId\":\"Ethylene Vinyl Acetate (EVAC)\",\"label\":\"Ethylene Vinyl Acetate (EVAC)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"vinyl\"],\"rootNode\":\"polymer\"},{\"id\":\"polyvinyl-chloride--pvc-\",\"nodeId\":\"polyvinyl-chloride--pvc-\",\"humanReadableId\":\"Polyvinyl Chloride (PVC)\",\"label\":\"Polyvinyl Chloride (PVC)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"vinyl\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":2}],\"ancestors\":[\"polymer\"],\"rootNode\":\"polymer\",\"childrenNr\":19},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"humanReadableId\":\"Thermosetting\",\"label\":\"Thermosetting\",\"disabled\":true,\"children\":[{\"id\":\"amino-resin\",\"nodeId\":\"amino-resin\",\"humanReadableId\":\"Amino Resin\",\"label\":\"Amino Resin\",\"disabled\":true,\"children\":[{\"id\":\"bismaleimide--bmi-\",\"nodeId\":\"bismaleimide--bmi-\",\"humanReadableId\":\"Bismaleimide (BMI)\",\"label\":\"Bismaleimide (BMI)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\",\"amino-resin\"],\"rootNode\":\"polymer\"},{\"id\":\"melamine-formaldehyde--mf-\",\"nodeId\":\"melamine-formaldehyde--mf-\",\"humanReadableId\":\"Melamine formaldehyde (MF)\",\"label\":\"Melamine formaldehyde (MF)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\",\"amino-resin\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\",\"childrenNr\":2},{\"id\":\"epoxy-resin--ep-\",\"nodeId\":\"epoxy-resin--ep-\",\"humanReadableId\":\"Epoxy Resin (EP)\",\"label\":\"Epoxy Resin (EP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"},{\"id\":\"phenol-formaldehyde-resin--pf-\",\"nodeId\":\"phenol-formaldehyde-resin--pf-\",\"humanReadableId\":\"Phenol Formaldehyde Resin (PF)\",\"label\":\"Phenol Formaldehyde Resin (PF)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"},{\"id\":\"phthalonitrile--pn-\",\"nodeId\":\"phthalonitrile--pn-\",\"humanReadableId\":\"Phthalonitrile (PN)\",\"label\":\"Phthalonitrile (PN)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"},{\"id\":\"polyester-resin--up-\",\"nodeId\":\"polyester-resin--up-\",\"humanReadableId\":\"Polyester Resin (UP)\",\"label\":\"Polyester Resin (UP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"},{\"id\":\"vinyl-ester-resin--ve-\",\"nodeId\":\"vinyl-ester-resin--ve-\",\"humanReadableId\":\"Vinyl Ester Resin (VE)\",\"label\":\"Vinyl Ester Resin (VE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\"],\"rootNode\":\"polymer\",\"childrenNr\":6}],\"rootNode\":\"polymer\",\"childrenNr\":3,\"checked\":false}],\"categorySpecificFilter\":{\"name\":\"metal\",\"disabled\":false,\"forms\":[{\"id\":\"bar\",\"label\":\"Bar\",\"checked\":true},{\"id\":\"billet\",\"label\":\"Billet\"},{\"id\":\"casting\",\"label\":\"Casting\",\"disabled\":true},{\"id\":\"coil\",\"label\":\"Coil\"},{\"id\":\"disc\",\"label\":\"Disc\",\"disabled\":true},{\"id\":\"flat\",\"label\":\"Flat\"},{\"id\":\"flat-bar\",\"label\":\"Flat Bar\"},{\"id\":\"foil\",\"label\":\"Foil\"},{\"id\":\"forging\",\"label\":\"Forging\"},{\"id\":\"full-section\",\"label\":\"Full Section\",\"disabled\":true},{\"id\":\"half-round-bar\",\"label\":\"Half Round Bar\",\"disabled\":true},{\"id\":\"hexagonal-bar\",\"label\":\"Hexagonal Bar\"},{\"id\":\"hexagonal-bright-bar\",\"label\":\"Hexagonal Bright Bar\",\"disabled\":true},{\"id\":\"hexagonal-rod\",\"label\":\"Hexagonal Rod\"},{\"id\":\"hexagonal-wire\",\"label\":\"Hexagonal Wire\"},{\"id\":\"hollow-bar\",\"label\":\"Hollow Bar\",\"disabled\":true},{\"id\":\"ingot\",\"label\":\"Ingot\",\"disabled\":true},{\"id\":\"pipe\",\"label\":\"Pipe\",\"disabled\":true},{\"id\":\"plate\",\"label\":\"Plate\"},{\"id\":\"powder\",\"label\":\"Powder\",\"disabled\":true},{\"id\":\"profile\",\"label\":\"Profile\"},{\"id\":\"profile-wire\",\"label\":\"Profile Wire\",\"disabled\":true},{\"id\":\"rod\",\"label\":\"Rod\"},{\"id\":\"round-bar\",\"label\":\"Round Bar\"},{\"id\":\"round-bright-bar\",\"label\":\"Round Bright Bar\",\"disabled\":true},{\"id\":\"round-rod\",\"label\":\"Round Rod\"},{\"id\":\"round-wire\",\"label\":\"Round Wire\"},{\"id\":\"seamless-tube\",\"label\":\"Seamless Tube\"},{\"id\":\"sheet\",\"label\":\"Sheet\"},{\"id\":\"spring\",\"label\":\"Spring\",\"disabled\":true},{\"id\":\"squar-bar\",\"label\":\"Squar Bar\",\"disabled\":true},{\"id\":\"square-bar\",\"label\":\"Square Bar\"},{\"id\":\"strip\",\"label\":\"Strip\"},{\"id\":\"tube\",\"label\":\"Tube\"},{\"id\":\"welded-tube\",\"label\":\"Welded Tube\",\"disabled\":true},{\"id\":\"wire\",\"label\":\"Wire\"}],\"fillers\":[],\"modifications\":[],\"processing\":[],\"certifications\":[],\"primaryPhase\":[],\"secondaryPhase\":[]},\"tags\":[{\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}],\"suppliers\":[{\"id\":\"dest\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"materialsCount\":93},{\"id\":\"ugit\",\"label\":\"Ugitech\",\"materialsCount\":50},{\"id\":\"sver\",\"label\":\"Sverdrup Steel AS\",\"materialsCount\":20},{\"id\":\"salo\",\"label\":\"Salomon's Metalen\",\"materialsCount\":16},{\"id\":\"hemp\",\"label\":\"Hempel Special Metals\",\"materialsCount\":4},{\"id\":\"vdmm\",\"label\":\"VDM Metals\",\"materialsCount\":1},{\"id\":\"song\",\"label\":\"Dongguan songshun mould steel Co., Ltd.\",\"materialsCount\":13},{\"id\":\"ambi\",\"label\":\"Ambica Steels Limited\",\"materialsCount\":10}]},\"collapsed\":{\"categories\":[]},\"specification\":{\"queryParams\":\"categories=steel\\u0026tags=form:bar\",\"clauses\":[{\"type\":\"tags\",\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}]},\"tags\":[{\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}],\"view\":\"result-list\",\"sidebarCollapsed\":false,\"unitsSystem\":\"metric\",\"polymerFilter\":{\"disabled\":true}},\"supplierSearch\":{\"specification\":{\"grade\":{\"value\":\"\",\"touched\":false},\"form\":{\"value\":\"\",\"touched\":false},\"country\":{\"value\":[]},\"certification\":{\"value\":[]}},\"grades\":[],\"forms\":[],\"countries\":[],\"certifications\":[],\"results\":{\"companies\":{\"data\":[],\"companiesCount\":20,\"equivalentsCount\":20,\"page\":1}},\"view\":\"result-list\",\"map\":{\"selectedLocation\":{\"id\":\"Location 1\",\"companyCode\":\"Supplier A\"},\"locations\":[{\"companyCode\":\"Supplier A\",\"id\":\"Location 1\",\"position\":{\"lat\":41.3954,\"lng\":20.162}},{\"companyCode\":\"Supplier A\",\"id\":\"Location 2\",\"position\":{\"lat\":41.3917,\"lng\":25.1649}},{\"companyCode\":\"Supplier A\",\"id\":\"Location 3\",\"isEquivalent\":true,\"position\":{\"lat\":49.3773,\"lng\":28.1585}},{\"companyCode\":\"Supplier A\",\"id\":\"Location 4\",\"position\":{\"lat\":45.3797,\"lng\":12.1682}},{\"companyCode\":\"Supplier A\",\"id\":\"Location 5\",\"isEquivalent\":true,\"position\":{\"lat\":38.3773,\"lng\":37.1915}}]}},\"categoriesTree\":{\"list\":[],\"selected\":{},\"recommended\":{}},\"messages\":{\"conversationsList\":[],\"currentConversation\":null,\"selectedConversationId\":\"\"},\"messagesAdmin\":{\"adminConversationsList\":[],\"adminCurrentConversation\":\"\",\"adminCurrentRecommendedSuppliers\":[],\"adminCurrentLinkedSuppliers\":[],\"selectedAdminConversationId\":\"\",\"filterType\":\"code\",\"filterValue\":\"\",\"resolution\":\"\",\"sort\":\"desc\",\"sortingField\":\"createdDate\",\"size\":10,\"page\":0,\"conversationsCount\":0,\"pagesCount\":0,\"suppliers\":[]},\"suppliersFilter\":{\"suppliersTree\":null,\"selectedSuppliers\":null},\"undo\":{},\"propertiesTree\":{\"list\":[],\"selected\":{}},\"retargeting\":{\"title\":\"\",\"data\":[],\"selectedUsersIds\":[],\"singleUserId\":\"\"},\"formData\":{\"materialId\":\"\",\"companyCodes\":[],\"categories\":[],\"formName\":\"\",\"verifiedDistributors\":[]},\"supplierDashboard\":{\"currentDashboardView\":\"\",\"currentDashboardMenuSubItem\":null,\"dashboardInfo\":{}},\"applicationsFilter\":{\"applications\":[],\"selectedApplications\":[]},\"unseen\":{\"unseenConversationsCount\":0},\"ashbyChart\":{\"data\":{},\"zoomedViewData\":{\"supplierMaterials\":[],\"context\":{}},\"clickedClusters\":[],\"suppliers\":[]},\"campaigns\":{\"categoryCampaigns\":[],\"defaultCampaigns\":[{\"name\":\"Default Ad\",\"category\":\"matmatch\",\"supplierId\":\"Default\",\"slots\":[\"Top\"],\"targetUrl\":\"https://go.matmatch.com/advertise\",\"targetWindow\":\"_blank\",\"banners\":[{\"size\":\"728x90\",\"imageId\":\"d792d789-c5c3-4a70-808b-3ec5ff2d9d33\"}]}]},\"searchBar\":{\"show\":true},\"advancedSearchPlotMaterials\":{\"ashbyChartSettings\":{\"propertyX\":\"density\",\"propertyY\":\"elastic-modulus\"}}}},\"page\":\"/advanced-search\",\"query\":{\"categories\":\"steel\",\"tags\":\"form:bar\"},\"buildId\":\"d4287122\",\"runtimeConfig\":{\"NODE_ENV\":\"production\",\"MATMATCH_CONFIG_ENV\":\"production\",\"SENTRY_DSN\":\"https://adb8811c666c47d48ea65639f264583b@sentry.io/189857\",\"RECAPTCHA_KEY\":\"6LcKSOAUAAAAALB76MApsk-XoTTzEBY2-oqMwwLm\",\"GA_ENABLED\":true,\"GA_ENABLE_LOG_TO_CONSOLE\":false,\"LEADFEEDER_ENABLED\":true,\"LEADFEEDER_TRACKING_ID\":\"Yn8J1xYRVZwgW0Rk\",\"HUBSPOT_ENABLED\":true,\"HUBSPOT_TRACKING_ID\":\"4597184\",\"HUBSPOT_SUBSCRIPTION_ID\":\"7207954\",\"HUBSPOT_NEWSLETTER_FORM_ID\":\"406d64d3-90e0-4174-902c-5fb4e72743ee\",\"HUBSPOT_CONTACT_FORM_ID\":\"1d836df6-1a29-42af-b067-822ad3021c1f\",\"HUBSPOT_SUSTAINABILITY_FORM_ID\":\"ac183d3d-8966-4086-b781-2d843b345377\",\"HUBSPOT_REQUEST_BOARD_FORM_ID\":\"0726b812-0d7c-4b9a-848b-ee6797c92db0\",\"HUBSPOT_CONTACT_FORM_ID_FIELD_NAMES\":{\"supplyMaterialsFieldName\":\"is_materials_supplier__c\"},\"HUBSPOT_REQUEST_MATERIAL_DATA_FORM_ID\":\"bce2daac-e6e7-41cb-ba4c-b4e27c7fec37\",\"HUBSPOT_REQUEST_BOOK_A_DEMO\":\"ed5d8d19-d961-48cf-b58c-f192500e6eb7\",\"HUBSPOT_REQUEST_BOOK_A_DEMO_FORM_LINK\":\"https://share.hsforms.com/17V2NGdlhSM-1jPGSUA5utw2qj7k\",\"HUBSPOT_REQUEST_BOOK_A_DEMO_FIELD_NAMES\":{\"supplierTypesFieldName\":\"plsuppliertype__c\"},\"HUBSPOT_REQUEST_BOOK_A_MEETING\":\"b4b7750c-75f8-4741-8fe6-daec03c1454b\",\"HUBSPOT_GET_IT_NOW\":\"818cf677-3f93-4f86-83dc-43996c9c8b2d\",\"ADBUTLER_ENABLED\":true,\"ADBUTLER_ACCOUNT_ID\":181075,\"ADBUTLER_ADVANCED_SEARCH_ZONE_ID\":470439,\"ADBUTLER_MATERIAL_PAGE_ZONE_ID\":470587,\"ADBUTLER_CONTENT_HUB_ZONE_ID\":473203,\"GA_TRACKING_ID\":\"UA-85033665-5\",\"GA_OPTIMIZE_ID\":\"GTM-KQK3NFF\",\"GTM_ID\":\"GTM-PV6RPFJ\"},\"isFallback\":false,\"customServer\":true,\"gip\":true,\"appGip\":true,\"scriptLoader\":[]}</script></body></html>\n\n\nUsing the ‘find_all’ function of soup we can find all these blocks by specifying the details of the block, i.e. <div class=”job_seen_beacon>\nThe length of jobs_soup should be the number of job panels on the page, and each should be for a specific job. The output for the first is shown below (different search criteria).\n\n#collapse-output\njobs_soup=soup.find_all(name=\"div\", attrs={\"class\":\"job_seen_beacon\"})\n\njobs_soup[0]\n\nWe now need to pick out the details of the job from these blocks. To do this we go back to Chrome.\n\nClicking on one of the job titles displays the job title is given as:\n<span title=\"Data Analyst\">Data Analyst</span>\nThere are a few ways we can extract this. What we want is a “span” with a feature called “title”. One way is to scroll through all “div” and find one with a title, using the except to help if it doesn’t have a title.\n\ndiv=jobs_soup[0]\nfor ab in div.find_all(name=\"span\"):\n            \n   try:                            \n      aJob=ab['title']   \n          \n   except:\n      pass\n        \naJob\n\n'Electricians Mate / Electrical Improver'\n\n\nEach category we want to extract is slightly different so requires a slightly different approach. Although, the same procedure of using the developer tools in chrome and then modifying how the soup is searched is used.\nFor the company name it is within <span class=”companyName”><a>Company X…\nSo can be accessed from the string within the span with class= companyName .\n\naaa=div.find_all(name=\"span\", attrs={\"class\":\"companyName\"})\naaa[0].string\n\n'Electrical Avenue'\n\n\n\n\nFunction to scrape\nThis can be done for other details we might want from the other job details as below in a single function\n\ndef extract_title(soup): \n    #initialse\n    jobs = []\n    company=[]\n    pay=[]\n    descr=[]\n    \n    #\"job_seen_beacon\" is the div for each job panel \n          # would be better to use <a> tag with \n    for div in soup.find_all(name=\"div\", attrs={\"class\":\"job_seen_beacon\"}):\n\n        #for the company name is in span tag with class=companyName\n        aComp=\"-\"\n        for a in div.find_all(name=\"span\", attrs={\"class\":\"companyName\"}):\n            try:\n                aComp=a.string\n            except:\n                print('exception comp')\n                pass \n        company.append(a.string)\n        \n        aJob='-'\n        for ab in div.find_all(name=\"span\"):\n            try:\n                aJob=ab['title']              \n            except: #Exception\n                pass\n        jobs.append(aJob)\n        \n        aPay=\"0\"\n        for abc in div.find_all(name=\"span\", attrs={\"class\":\"salary-snippet\"}):\n            try:\n                aPay=abc.string\n            except:\n                print('exception pay')\n                pass\n        pay.append(aPay)\n\n        \n        aDescr=''\n        abc = div.find_all(name='div',attrs={\"class\":\"job-snippet\"})\n        for abcd in abc[0].find_all(name='li'):\n            try:\n                aDescr=aDescr+abcd.getText()+'-'\n            except:\n                print('exception decr')\n                pass\n        \n        descr.append(aDescr)\n        \n    sa=soup.find_all(name='a',attrs={\"target\":\"_blank\"})\n    urlss=[]\n    \n    strURLstart='https://www.indeed.co.uk'\n    for aSect in sa:\n        li=[]\n        try:\n            aCheck=aSect['id']\n            li.append(aCheck)\n            urlss.append(strURLstart+aSect['href'])\n        except:\n            pass\n            \n    return jobs, company, pay, descr, urlss\n\nBut there may be more than the first page, so creating a function that can just take:\n\nJob details\nLocation\nMaximum number of returned results.\n\nWe get the following:\n\n## Cycle through pages and call inner function 'extract_title'\ndef extract_outer(jobtype,location,max_results):\n    import requests\n    import bs4\n    from bs4 import BeautifulSoup\n    import pandas as pd\n    import numpy as np\n    import copy as copy\n    import time\n    \n    #Split job into two string with plus - i.e. \"road sweeper\"->\"road + sweeper\"\n    jobtype=jobtype.replace(' ',' + ')\n    \n    #initialise values\n    df=pd.DataFrame(columns=['Company','Job Title','Pay','Details','URL'])\n    \n    #Scroll through pages i.e. 0-9 in page1 --10-19 in page2 (in theory!)\n    i=0\n    for start in range(0, max_results, 10):#Add 10 on till a max\n        \n        #initialise values\n        num = (len(df) + 1)\n        jobs_, company_, pay_, descr_, urlss_ = [], [] , [], [], []\n        num=str(start)\n        \n        #add a pause\n        time.sleep(1)\n        \n        #get URL\n        URL=\"https://uk.indeed.com/jobs?q=\"+jobtype+\"&l=\"+location+\"&start=\"+num#conducting a request of the stated URL above:\n        page = requests.get(URL)#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n        soup = BeautifulSoup(page.text, \"html.parser\")#printing soup in a more structured tree format that makes for easier reading\n        \n        #call the inner function\n        jobs_, company_, pay_, descr_, urlss_=extract_title(soup)\n        \n        # append the lists\n        if i==0:          ## on 1st go assign df values\n            df['Company']=company_\n            df['Job Title']=jobs_\n            df['Pay']=pay_\n            df['Details']=descr_\n            df['URL']=urlss_\n        else:            ## on next ones concat df with a new df \n            df_=pd.DataFrame(columns=['Company','Job Title','Pay','Details','URL'])\n            df_['Company']=company_\n            df_['Job Title']=jobs_\n            df_['Pay']=pay_\n            df_['Details']=descr_\n            df_['URL']=urlss_\n            \n            df=pd.concat(\n                [df,df_ \n                \n                ]\n                        )\n            del df_\n        i=i+1\n    \n        df=df.reset_index(drop=True)#reset index- drop stops index becoming a column\n    return df\n\nWhich can be called to return a pandas DataFrame with:\n\nCompany\nJob Title\nPay\nJob Details\nURL for more details\n\nThe function is called like this:\n\njobtitle='data analyst'\nmaxRes=50\nlocat=\"Swansea%2C+Swansea\"\nfname=\"indeed_\"+jobtitle+'_'+locat+'_maxRes='+str(maxRes)+'.csv'\ndf=extract_outer(jobtitle,locat,maxRes)\ndf.head(10)\n\n\n\n\n\n  \n    \n      \n      Company\n      Job Title\n      Pay\n      Details\n      URL\n    \n  \n  \n    \n      0\n      CAIS\n      Data / BI Analyst & Developer\n      0\n      This role will be instrumental in developing a...\n      https://www.indeed.co.uk/company/CAIS/jobs/Dat...\n    \n    \n      1\n      Jisc\n      Scholarly Communications Data Analyst\n      0\n      The Data analyst will be responsible for colle...\n      https://www.indeed.co.uk/pagead/clk?mo=r&ad=-6...\n    \n    \n      2\n      Digital Health and Care Wales\n      Support and Business Analyst\n      0\n      Until recently this type of information was he...\n      https://www.indeed.co.uk/rc/clk?jk=c95fc84ef57...\n    \n    \n      3\n      ERS Administration Services\n      Senior Risk Analyst\n      0\n      Are you an experienced Risk Analyst looking fo...\n      https://www.indeed.co.uk/rc/clk?jk=c239d92f7fa...\n    \n    \n      4\n      IQUW\n      Senior Risk Analyst\n      0\n      Are you an experienced Risk Analyst looking fo...\n      https://www.indeed.co.uk/rc/clk?jk=fd313f82db9...\n    \n    \n      5\n      Momentum Security Recruitment\n      Business Analyst\n      0\n      Collection and analysis of data to support man...\n      https://www.indeed.co.uk/company/Momentum-Secu...\n    \n    \n      6\n      Public Health Wales NHS Trust\n      Principal Information Analyst / Finance Delive...\n      0\n      The ideal candidate will be enthusiastic about...\n      https://www.indeed.co.uk/rc/clk?jk=2cbca7681eb...\n    \n    \n      7\n      IQUW Group\n      Senior Risk Analyst\n      0\n      As a key member of the Risk Management Team, t...\n      https://www.indeed.co.uk/company/IQUW-Group/jo...\n    \n    \n      8\n      Momentum Security Recruitment\n      Business Test Analyst\n      0\n      Understanding of data creation and manipulatio...\n      https://www.indeed.co.uk/company/Momentum-Secu...\n    \n    \n      9\n      Public Health Wales NHS Trust\n      Senior Business Analyst - Finance Delivery Unit\n      0\n      You will work within the Analytics Centre of E...\n      https://www.indeed.co.uk/rc/clk?jk=d354ad34b6a...\n    \n  \n\n\n\n\n\n\nLooking inside the individual pages\nSo far the data frame just has details available on the main search page. The information is limited (see details tab below).\nMore details can be found on the individual pages\n\ndf.iloc[0].Details\n\n'This role will be instrumental in developing a new infrastructure of data development and insights.-As part of this we are introducing new tools, technology and…-'\n\n\nFor each job the same webscraping procedure can be used to get information from the job page.\nBelow is how to get the full description\n\nURL=df.URL[0]\npage = requests.get(URL)#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\nsoup = BeautifulSoup(page.text, \"html.parser\")#printing soup in a more structured tree format that makes for easier reading\nasoup=soup.find(name=\"div\", attrs={\"id\":\"jobDescriptionText\"})\nasoup2=asoup.text\nasoup2\n\n'An opportunity has arisen for an enthusiastic and self-motivated individual to join our newly formed Data and Evaluation Department. Adferiad are embarking on a new Data, Insight and CRM Delivery Plan to maximise our data as an asset, create an insight driven culture and modernise our ways of working. As part of this we are introducing new tools, technology and processes to continually improve our data and CRM capabilities; and empower a digital-first approachThis is a new and exciting role and is based in our busy Office in Llansamlet, Swansea; however, as Adferiad provide services across all counties in Wales, some travel may be required. Working within a team of Data and IT colleagues, this role is an exciting opportunity for those interested in a career within the analytic field. This role will be instrumental in developing a new infrastructure of data development and insights.Reference ID: H69Job Type: PermanentSalary: £29,226.00 per yearBenefits:On-site parkingSchedule:Monday to Friday'\n\n\nDetails of this could then be extracted to look for key words, salary etc. Using Natural Language Processing.\n\n\nIndeed overview\nAt this stage one might think “I can do this in my web browser“. Which is obviously true.\nBut this data can now be processed further to find other things. Maybe we want to compare pay in different regions, look for where there are more jobs of a certain type, interrogate the jobs details for specific information."
  },
  {
    "objectID": "posts/PYTHON/others_python/Web_scraping.html#example-using-selenium",
    "href": "posts/PYTHON/others_python/Web_scraping.html#example-using-selenium",
    "title": "Web scraping",
    "section": "Example using selenium",
    "text": "Example using selenium\n\nThis uses the same methodology as above but instead uses Selenium which controls a web browser.\nThis means links can be clicked, or other boxes can be okayed (e.g. accept cookie box).\nSince this was done it appears the website has slightly changed as the code does not work.\n\n# Some imports\n\nimport requests\nimport bs4\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium import webdriver\nimport time\nimport os\n\nGet web driver for chrome from https://chromedriver.chromium.org/downloads\nThen use it to open the website.\n\n#hide\nURLweb = \"https://matmatch.com/advanced-search?categories=steel&tags=form:bar\"\nbrowser_loc='C:/Users/44781/pyproj/chromedriver.exe'\n\n\n#import chrome webdriver\n\nURL = URLweb\nbrowser = webdriver.Chrome(browser_loc)\nbrowser.get(URL)\n\nChrome is now controlled from this notebook\n\n\n#get rid of cookie q\nelem2=browser.find_element_by_tag_name('button')\nbrowser.execute_script(\"arguments[0].click();\", elem2)\n\n\nThe functions\n\n1. innerPage\nthis scrolls through each search page\nand calls OneSearchPage\n\n\n2. OneSearchPage\nOne of the search pages\nFor each link calls gothrough_A_Link\n\n\n3. gothrough_A_Link\nThis looks on a materials page\nThis then calls getTableData function to extract table data\n\n\n4. getTableData\ngetTableData\n\ndef innerPage(browser):\n    import time\n    f=0\n    ii=0\n    #first time through\n    dfAll=OneSearchPage(browser)\n    foutname='steel_bar_'+str(ii)\n    dfAll.to_csv(foutname)\n    print('ii ',ii)\n    while f==0:\n        if ii<200:\n            \n            #find Next page button and click it\n            elemNext=browser.find_elements_by_xpath(\"//button[contains(@data-test-item,'next-page')]\")\n            try:\n                elemNext[0].click()#this should fail if last page\n            except:\n                f=1\n                print('failed',elemNext[0].text)\n                break\n            time.sleep(1)\n            #next timeS through\n            dfAll=OneSearchPage(browser)\n            \n            ii=ii+1\n            foutname='steel_bar_'+str(ii)\n            dfAll.to_csv(foutname)\n            print('ii ',ii)\n            \n        else:\n            break\n            \n        \n        \n    return dfAll\n\n\ndef OneSearchPage(browser,*dfnew):\n    #find each element with <a> and contain materials\n    elem2=browser.find_elements_by_xpath(\"//a[contains(@href,'/materials/')]\")\n\n    if 'df' in locals():\n        del df\n    if 'df_' in locals():\n        del df_\n\n\n    i=0\n    for eel in elem2:\n        if i<200:\n            print(eel.text)\n            time.sleep(1)\n\n            if len(dfnew)>0:##if we give dfnew as input\n                \n                df_=gothrough_A_Link(eel,browser)\n                if i==0:\n                    dfOne=dfnew[0].append(df_)\n                else:\n                    dfOne=dfOne.append(df_)\n            else:#if don't give input dfnew\n                if i==0:#on 1st call create dfOne\n                    dfOne=gothrough_A_Link(eel,browser)\n                else:#on 2nd call append\n                    df_=gothrough_A_Link(eel,browser)\n                    dfOne=dfOne.append(df_)\n\n            i=i+1\n            time.sleep(1)\n            print('i ',i)\n        else:\n            break\n    return dfOne\n\n\ndef gothrough_A_Link(pageElement,browser):\n    import time\n    from selenium.webdriver.common.keys import Keys \n    #give like gothrough_A_Link(elem2[ii],browser)\n    time.sleep(.6)\n#     print(pageElement)\n    #open element- but in new tab\n    try:\n        pageElement.click()#send_keys(Keys.RETURN)\n    except:\n        time.sleep(0.9)\n        time.sleep(0.9)\n    #switch to new window\n\n    #get current window\n    p = browser.current_window_handle\n    #get windows\n    chwd=browser.window_handles\n    for w in chwd:\n    #switch focus to child window\n        if(w!=p):\n            browser.switch_to.window(w)\n            break\n    time.sleep(0.9)\n    \n    \n    #get current url\n    url_current=browser.current_url\n    \n    #get table details\n    \n    df=getTableData(url_current)\n    \n    \n    #close new window\n    time.sleep(0.9)\n    browser.close()\n    browser.switch_to.window(browser.window_handles[0])\n\n    return df\n\n############################################################################################\n\n############################################################################################\n\n\n    \n\n\ndef getTableData(URL):\n    import requests\n    import bs4\n    from bs4 import BeautifulSoup\n    import pandas as pd\n    \n    \n    res = requests.get(URL)\n    soup = BeautifulSoup(res.content,'lxml')\n\n    # get alloy name\n    titla=soup.find('h1').text\n\n#     print(titla)\n    #get alloy description\n    descripta=soup.find('div',{'class':'common__SubSectionWrapper-sc-3st4qy-0 lbsGSv'}).getText()\n    descripta=descripta.replace('Description','Description: ')\n    descripta=descripta.split('More technical information')[0]#sometimes occurs\n\n\n    #get table\n    table = soup.find_all('table')\n\n    tdAll=[]\n    nomsAll=[]\n    accepted_strings={'Density','Elastic modulus','Elongation','Tensile strength','Yield strength'}\n    for ta in table:\n    #     print('-------------------\\n',ta.text[0:30])\n        tatr=ta.find_all('tr')\n        textdegC=\"°C\"\n        for trr in tatr:\n    #         print(trr.text[0:30])\n            tatrtd=trr.find_all('td')\n            try:\n                textaStartRow=tatrtd[0].text\n                \n                if textaStartRow==\"Density\":\n                    nomsAll.append(textaStartRow)\n                    \n                    if 'g/cm' in tatrtd[1].p.text:\n                        tdAll.append(tatrtd[1].p.text)\n                    elif 'g/cm' in tatrtd[2].p.text:\n                        tdAll.append(tatrtd[2].p.text)\n                        \n                elif textaStartRow==\"Elastic modulus\":\n                    nomsAll.append(textaStartRow)\n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n                    \n                elif textaStartRow==\"Elongation\":\n                    nomsAll.append(textaStartRow)\n                    \n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n                    \n                elif textaStartRow==\"Charpy impact energy, V-notch\":\n                    nomsAll.append(textaStartRow)\n                    \n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n                        \n                elif textaStartRow==\"Tensile strength\":\n                    nomsAll.append(textaStartRow)\n                   \n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n                        \n                elif textaStartRow==\"Yield strength\":\n                    nomsAll.append(textaStartRow)\n                    \n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n        \n            except:\n                \n                pass\n            \n     #Chemical composition\n    tableComp=soup.find('p',text='Chemical properties')#know it is below a paragraph with title Chemical Properties \n    try:\n        taatta=tableComp.next_sibling\n        trComp=taatta.find_all('tr')\n        compPC=[]\n        compID=[]\n        for trr in trComp:\n            try:\n                tdd=trr.find_all('td')\n                nomsAll.append(tdd[0].text)\n                tdAll.append(tdd[1].p.text)\n            except:\n                pass\n    except:\n        pass\n    \n     #if we want to\n    dff=pd.DataFrame(tdAll).transpose()\n    print(nomsAll,tdAll)\n    dff.columns=nomsAll\n    \n    dff['Description']=descripta\n    dff.insert(0, 'Alloy', titla)\n    \n    return dff\n\n\ndfOUT=innerPage(browser)\n\n#and do some cleaning of data\ndf = cleanDFdatFunc(dfOUT)\n\n\n\n\nLook at the data\n\n#hide\ndf = pd.read_csv(\"C:/Users/44781/pyproj/JobScraping/steel_sheet_Comb_Clean\")\ndf.drop(columns=['Unnamed: 0'],inplace=True)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Alloy\n      Description\n      Elastic modulus\n      Elongation\n      Charpy impact energy, V-notch\n      Tensile strength\n      Yield strength\n      Carbon\n      Chromium\n      Copper\n      ...\n      Zirconium\n      Cobalt\n      Tungsten\n      Antimony\n      Arsenic\n      Bismuth\n      Calcium\n      Lead\n      Tin\n      Iron\n    \n  \n  \n    \n      0\n      VDM® Alloy 926\n      Description: 1.4529 (X1NiCrMoCuN25-20-7) is an...\n      193.0\n      0.0\n      0\n      650.0\n      0.0\n      0.020\n      20.5\n      1.00\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      45.240\n    \n    \n      1\n      1.4507 / X2CrNiMoCuN25-6-3\n      Description: The material 1.4507 is a duplex s...\n      200.0\n      0.0\n      0\n      800.0\n      0.0\n      0.030\n      25.0\n      1.75\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      59.715\n    \n    \n      2\n      1.4529 / X1NiCrMoCuN25-20-7\n      Description: The material 1.4529 is an austeni...\n      195.0\n      0.0\n      0\n      750.0\n      0.0\n      0.020\n      20.0\n      1.00\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      45.740\n    \n    \n      3\n      1.4521 / X2CrMoTi18-2\n      Description: The material 1.4521 is a ferritic...\n      220.0\n      0.0\n      0\n      550.0\n      0.0\n      0.025\n      18.5\n      0.00\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      76.440\n    \n    \n      4\n      DIN 17103 Grade TStE 285 normalized or normali...\n      Description: The fine grained steel TStE 285 i...\n      217.0\n      24.0\n      0\n      420.0\n      255.0\n      0.160\n      0.3\n      0.20\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      97.485\n    \n  \n\n5 rows × 32 columns\n\n\n\n\nimport matplotlib.pyplot as plt\ncoluse='Tensile strength'\ncoluse2='Elongation'\n\ndf_=df[df[coluse]>0]\ndf_=df_[df_[coluse2]>0]\nplt.scatter(x=df_[coluse2],y=df_[coluse])\n\nplt.xlabel(coluse2 +'%')\nplt.ylabel(coluse +' MPa')\nplt.grid('on')\n\n\n\n\n\n\nDo some Quick Machine Learning\n\nX=composition to predict Y=Elongation or Yield strength or Tensile strength\nUsed RandomForestRegressor from scikit learn https://scikit-learn.org/stable/\n\n30% test 70% to train\n\nResults from test data when trained on train data\n\nMAE: 2.7%\nTensile strength MAE: 74 Mpa\nYield strength MAE: 84 MPa"
  },
  {
    "objectID": "posts/PYTHON/others_python/Working_with_videos.html#intoduction",
    "href": "posts/PYTHON/others_python/Working_with_videos.html#intoduction",
    "title": "Working with videos",
    "section": "Intoduction",
    "text": "Intoduction\nSome bits of python code to use videos\n\n#hide\nloca='C:\\\\Users\\\\44781\\\\Documents\\\\GitHub\\\\GolfSwingTSimm\\\\data\\\\golfDB.pkl'"
  },
  {
    "objectID": "posts/PYTHON/others_python/Working_with_videos.html#some-imports",
    "href": "posts/PYTHON/others_python/Working_with_videos.html#some-imports",
    "title": "Working with videos",
    "section": "Some imports",
    "text": "Some imports\n\nimport pandas as pd\nimport os\nimport cv2\nimport numpy as np\n\ndf = pd.read_pickle(loca)\n\nidUSE = 6\n\ndf1=df.loc[idUSE]"
  },
  {
    "objectID": "posts/PYTHON/others_python/Working_with_videos.html#youtube-videos",
    "href": "posts/PYTHON/others_python/Working_with_videos.html#youtube-videos",
    "title": "Working with videos",
    "section": "Youtube videos",
    "text": "Youtube videos\nCan have various issues so check https://pytube.io/en/latest/user/install.html if issues in use.\nI used !pip install pytube then after a week I was getting errors. So in terminal I did\n!pip install pytube then clone directory\ngit clone git://github.com/pytube/pytube.git and finally install\ncd pytube python -m pip install .\nImport the module, and here I’ll use the golf dataset from another post\n\nfrom pytube import YouTube\n\nytID=df1['youtube_id']\nyt = YouTube('http://youtube.com/watch?v='+ytID)\n\nThe youtube object contains several videos in different formats.\n\n#collapse-output\nyt.streams\n\n[<Stream: itag=\"17\" mime_type=\"video/3gpp\" res=\"144p\" fps=\"7fps\" vcodec=\"mp4v.20.3\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">, <Stream: itag=\"248\" mime_type=\"video/webm\" res=\"1080p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"247\" mime_type=\"video/webm\" res=\"720p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"244\" mime_type=\"video/webm\" res=\"480p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"243\" mime_type=\"video/webm\" res=\"360p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"242\" mime_type=\"video/webm\" res=\"240p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"278\" mime_type=\"video/webm\" res=\"144p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">]\n\n\nWe can then filter the results based on criteria. By running yt.streams.filter?? we can see more on the code, as shown below\n\nSignature:\nyt.streams.filter(\n    fps=None,\n    res=None,\n    resolution=None,\n    mime_type=None,\n    type=None,\n    subtype=None,\n    file_extension=None,\n    abr=None,\n    bitrate=None,\n    video_codec=None,\n    audio_codec=None,\n    only_audio=None,\n    only_video=None,\n    progressive=None,\n    adaptive=None,\n    is_dash=None,\n    custom_filter_functions=None,\n)\n\n\nstreams= yt.streams.filter(file_extension='mp4',res='360p')\nstreams\n\n[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">]\n\n\nDownload the stream\n\nstreams.first().download(filename=ytID+'.mp4')\n\n'C:\\\\Users\\\\44781\\\\Documents\\\\GitHub\\\\THS_website\\\\_notebooks\\\\iPuVhnI8pJU.mp4'"
  },
  {
    "objectID": "posts/PYTHON/others_python/Working_with_videos.html#video-player",
    "href": "posts/PYTHON/others_python/Working_with_videos.html#video-player",
    "title": "Working with videos",
    "section": "Video Player",
    "text": "Video Player\nTo play the videos I’ll be using VLC. There can be some issues with installing so I used the exe file from here https://get.videolan.org/vlc/3.0.11/win64/vlc-3.0.11-win64.exe\nAnother fix to install issues is inserting a line like os.add_dll_directory(\"Location\\anaconda3\\\\Lib\\\\site-packages\") into the script\nMore details of using VLC with Python can be found here https://bigl.es/tooling-tuesday-using-vlc-with-python/\nImporting vlc and creating a media object and then playing it.\n\nimport vlc\n\nvidLoc=ytID+'.mp4'\n\nmedia = vlc.MediaPlayer(vidLoc)\n\nmedia.play()\n\n0\n\n\n\n.play opens a player as shown above. Note there is no pause/play/rewind buttons and the player cannot be closed. The only way to close is to use the command media.stop() or restart the kernel\n\nmedia.stop()\n\nTo make it more like a standard video player the following can be used:\n\nmedia.play() to play\nmedia.pause() to pause\nmedia.set_rate(3) to increase speed of video\nmedia.get_time() and media.set_time(5) to get and set the time of video\nmedia.stop() to close the video\n\nIntsead of doing these on the command line it makes sense to have them as button presses.\nI’ll use easygui here as it’s quite easy and I’m not too bothered about the aesthetics or functionality. Because easygui is a bit clunky. https://bigl.es/tooling-tuesday-easygui/\nSo to use create a easygui buttonbox with different features to control the video. Once clicked the button will then close (can’t keep same button open with this) and open again.\n\nimport easygui \n\n\nwhile True:\n    choice = easygui.buttonbox(title=\"@Golf Media Player\",\n       choices=[\"Play\",\"<<\",\"<<<\",\">>\",\">>>\",\"Pause\",\"Stop\"])\n\n    if choice == \"Play\":\n        media.set_rate(1)\n        media.play()\n    elif choice == \"Pause\":\n        media.pause()\n    elif choice ==\">>\":\n        media.set_rate(2)\n    elif choice==\">>>\":\n        media.set_rate(4)\n    elif choice==\"<<\":\n        timo=media.get_time()\n        timo=timo-2.5*1000\n        if timo<0:\n            timo=0\n        media.set_time(timo)\n    elif choice==\"<<<\":\n        timo=media.get_time()\n        timo=timo-5*1000\n        if timo<0:\n            timo=0\n        media.set_time(timo)\n    else:\n        time_use = media.get_time()/1000\n        print('the time is {}'.format(time_use))\n        media.stop()\n        break\n\nthe time is 15.652"
  },
  {
    "objectID": "posts/PYTHON/others_python/Working_with_videos.html#extracting-images-from-the-video",
    "href": "posts/PYTHON/others_python/Working_with_videos.html#extracting-images-from-the-video",
    "title": "Working with videos",
    "section": "Extracting images from the video",
    "text": "Extracting images from the video\nTo work with a video it is most often easier to convert it to an image.\nTo do this I’ll use cv2 https://pypi.org/project/opencv-python/\nFirst we create a cv2 object of the video with cap = cv2.VideoCapture(vidLoc) then success, image = cap.read() to get images as we scroll through the frames, as shown below.\n\n#collapse-output\ncap = cv2.VideoCapture(vidLoc)\n\nsuccess, image = cap.read()\nwhile success:\n    success, image = cap.read()\n    print(success)\n\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nFalse\n\n\nSome useful features of the cap object that will be used are:\n\ncap.get(cv2.CAP_PROP_POS_MSEC) the duration of the video\ncap.get(cv2.CAP_PROP_FRAME_COUNT) the frame count\nframe_count / fps the duration in seconds (the previous two divided)\ncv2.CAP_PROP_FRAME_WIDTH) frame width\ncv2.CAP_PROP_FRAME_HEIGHT) frame height\ncv2.copyMakeBorder() to create an image object to save and select which area of the video to save\ncv2.imwrite(fnom, img) to save the frame as an image\n\nWe could instead use other ways as shown https://learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/ to extract images but I’ll use the above\nThe below is modified from https://github.com/wmcnally/golfdb\nIt creates images at a given frame where the video is cropped based on the variable bbox (which is between 0 and 1)\nNote also dim=600 which adjusts the size of the output image\n\n         \ndef getImages(cap,bbox,frame_use):\n    \n    x = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) * bbox[0])\n    y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * bbox[1])\n    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) * bbox[2])\n    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * bbox[3])\n    \n    count = 0\n    success, image = cap.read()\n    while success:\n        count += 1\n        \n        if abs(count-frame_use)==0:\n                dim=600\n                crop_img = image[y:y + h, x:x + w]\n                crop_size = crop_img.shape[:2]\n                ratio = dim / max(crop_size)\n                new_size = tuple([int(x*ratio) for x in crop_size])\n                resized = cv2.resize(crop_img, (new_size[1], new_size[0]))\n                delta_w = dim - new_size[1]\n                delta_h = dim - new_size[0]\n                top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n                left, right = delta_w // 2, delta_w - (delta_w // 2)\n                b_img = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT,\n                                           value=[0.406*255, 0.456*255, 0.485*255])  # ImageNet means (BGR)\n                cv2.imwrite(os.path.join(ytID+str(count)+\".jpg\"),b_img)\n                \n        elif count > frame_use:\n            break\n        success, image = cap.read()\n\n        \n\nAnd to run the above function\n\ncap = cv2.VideoCapture(vidLoc)\ngetImages(cap,df1['bbox'],100)\n\n\nevent_names = {\n    0: 'Address',\n    1: 'Toe-up',\n    2: 'Mid-backswing (arm parallel)',\n    3: 'Top',\n    4: 'Mid-downswing (arm parallel)',\n    5: 'Impact',\n    6: 'Mid-follow-through (shaft parallel)',\n    7: 'Finish'\n}\n_, img = cap.read()\n# cv2.imshow(event_names[0], img)\n\n\nimport matplotlib.pyplot as plt\n\nplt.imshow(img)\n\n<matplotlib.image.AxesImage at 0x23f1d3cc7f0>\n\n\n\n\n\n\nbbox\n\narray([0.1453125 , 0.00138889, 0.46796875, 0.99930556])"
  }
]