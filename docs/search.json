[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html#communicating-code-and-data",
    "href": "index.html#communicating-code-and-data",
    "title": "TH Simm Python Pages",
    "section": "Communicating code and data",
    "text": "Communicating code and data\n\nPresentation"
  },
  {
    "objectID": "index.html#links",
    "href": "index.html#links",
    "title": "TH Simm Python Pages",
    "section": "Links",
    "text": "Links\nWebsite built with Quarto visit for more info https://quarto.org/docs/websites."
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#content",
    "href": "posts/Communicating_Code/CommCodePres.html#content",
    "title": "Overview: Communicating code and data",
    "section": "Content",
    "text": "Content\n\nNotebooks overview\nConverting Notebooks\nExample useage of notebooks"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#jupyter-notebooks",
    "href": "posts/Communicating_Code/CommCodePres.html#jupyter-notebooks",
    "title": "Overview: Communicating code and data",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nFrom TalkPython: Awesome Jupyter Libraries and Extensions\n\nJupyter is an amazing environment for exploring data and generating executable reports with Python. But there are many external tools, extensions, and libraries to make it so much better and make you more productive.\n\n\nA notebook consists of two parts\n\nmarkdown part where we can:\n\nwrite text, add images, links, html, LaTeX etc\n\ncode part which runs and displays output of code\n\n\nSome links:\n\nJupyter Book\nA curated list of awesome Jupyter projects\nCode Documentation QA of Code\nFastAI guide for better blogs"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#example-of-a-notebook",
    "href": "posts/Communicating_Code/CommCodePres.html#example-of-a-notebook",
    "title": "Overview: Communicating code and data",
    "section": "Example of a notebook",
    "text": "Example of a notebook\nAn example notebook"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#example-of-a-notebook-output",
    "href": "posts/Communicating_Code/CommCodePres.html#example-of-a-notebook-output",
    "title": "Overview: Communicating code and data",
    "section": "Example of a notebook: output",
    "text": "Example of a notebook: output\n\nimport matplotlib.pyplot as plt\nplt.plot(df2['date_of_sampling'])"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#example-of-a-notebook-output-2",
    "href": "posts/Communicating_Code/CommCodePres.html#example-of-a-notebook-output-2",
    "title": "Overview: Communicating code and data",
    "section": "Example of a notebook: output 2",
    "text": "Example of a notebook: output 2\n\nimport altair as alt\nfrom vega_datasets import data\n\nmovies = alt.UrlData(\n    data.movies.url,\n    format=alt.DataFormat(parse={\"Release_Date\":\"date\"})\n)\nratings = ['G', 'NC-17', 'PG', 'PG-13', 'R']\ngenres = ['Action', 'Adventure', 'Black Comedy', 'Comedy',\n       'Concert/Performance', 'Documentary', 'Drama', 'Horror', 'Musical',\n       'Romantic Comedy', 'Thriller/Suspense', 'Western']\n\nbase = alt.Chart(movies, width=200, height=200).mark_point(filled=True).transform_calculate(\n    Rounded_IMDB_Rating = \"floor(datum.IMDB_Rating)\",\n    Hundred_Million_Production =  \"datum.Production_Budget > 100000000.0 ? 100 : 10\",\n    Release_Year = \"year(datum.Release_Date)\"\n).transform_filter(\n    alt.datum.IMDB_Rating > 0\n).transform_filter(\n    alt.FieldOneOfPredicate(field='MPAA_Rating', oneOf=ratings)\n).encode(\n    x=alt.X('Worldwide_Gross:Q', scale=alt.Scale(domain=(100000,10**9), clamp=True)),\n    y='IMDB_Rating:Q',\n    tooltip=\"Title:N\"\n)\n\n# A slider filter\nyear_slider = alt.binding_range(min=1969, max=2018, step=1)\nslider_selection = alt.selection_single(bind=year_slider, fields=['Release_Year'], name=\"Release Year_\")\n\n\nfilter_year = base.add_selection(\n    slider_selection\n).transform_filter(\n    slider_selection\n).properties(title=\"Slider Filtering\")\n\n# A dropdown filter\ngenre_dropdown = alt.binding_select(options=genres)\ngenre_select = alt.selection_single(fields=['Major_Genre'], bind=genre_dropdown, name=\"Genre\")\n\nfilter_genres = base.add_selection(\n    genre_select\n).transform_filter(\n    genre_select\n).properties(title=\"Dropdown Filtering\")\n\n#color changing marks\nrating_radio = alt.binding_radio(options=ratings)\n\nrating_select = alt.selection_single(fields=['MPAA_Rating'], bind=rating_radio, name=\"Rating\")\nrating_color_condition = alt.condition(rating_select,\n                      alt.Color('MPAA_Rating:N', legend=None),\n                      alt.value('lightgray'))\n\nhighlight_ratings = base.add_selection(\n    rating_select\n).encode(\n    color=rating_color_condition\n).properties(title=\"Radio Button Highlighting\")\n\n# Boolean selection for format changes\ninput_checkbox = alt.binding_checkbox()\ncheckbox_selection = alt.selection_single(bind=input_checkbox, name=\"Big Budget Films\")\n\nsize_checkbox_condition = alt.condition(checkbox_selection,\n                                        alt.SizeValue(25),\n                                        alt.Size('Hundred_Million_Production:Q')\n                                       )\n\nbudget_sizing = base.add_selection(\n    checkbox_selection\n).encode(\n    size=size_checkbox_condition\n).properties(title=\"Checkbox Formatting\")\n\n( filter_year | filter_genres) &  (highlight_ratings | budget_sizing  )"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#communicating-when-code-is-a-large-element-of-what-is-being-presented",
    "href": "posts/Communicating_Code/CommCodePres.html#communicating-when-code-is-a-large-element-of-what-is-being-presented",
    "title": "Overview: Communicating code and data",
    "section": "Communicating when code is a large element of what is being presented",
    "text": "Communicating when code is a large element of what is being presented\n\nMicrosoft Word/ppt- type methods aren’t set-up well to include code\nProgramming files (e.g. .py) aren’t set-up well to share\nVideoing code with outputs is an option, but don’t translate to other formats (i.e. we may also need to do a written format of this)\nApps (e.g. streamlit) can be good.\n\nBut the code is hidden\n\nProgramming notebooks (e.g..ipynb) offer a good and easy to share code but with some limitations\n\nAn easier way is to convert the notebooks to html\n\ne.g. maybe someone doesn’t have python installed"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#notebook-benefits",
    "href": "posts/Communicating_Code/CommCodePres.html#notebook-benefits",
    "title": "Overview: Communicating code and data",
    "section": "Notebook Benefits",
    "text": "Notebook Benefits\n\nNotebooks are intuitive\n\nYou have the code then the result of the code\nPlus can add details of how code works\nAnd it’s linear\n\nCan get things up and working quickly\nAid with communicating code\nEncourages Writing\n\nand writing things down aids thinking in the now and understanding what you did and why in the future\n\n\nCan use shell commands e.g. !pip install pandas\nCan use magic commands e.g. %%time to time a cell\n\nWith the ONS moving towards Python/R from Excel and a varied level of skills. The first of these is particularly important to aid communicating code"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#what-i-have-used-to-convert-notebooks",
    "href": "posts/Communicating_Code/CommCodePres.html#what-i-have-used-to-convert-notebooks",
    "title": "Overview: Communicating code and data",
    "section": "What I have used to convert notebooks",
    "text": "What I have used to convert notebooks\n\nfastpages\n\nPreviously I converted notebooks to html via fastpages but this is now deprecated and they are recommending the use of quarto.\n\nquarto\n\nSo far I have found quarto really good and flexible (N.B. R works too)\nEasy to convert a notebook to multiple formats, including html, powerpoint, pdf, word doc\nBUT Quarto is not possible within ONS (as far as I can tell currently)\n\nnbconvert is another option I tried\n\nbut it doesn’t seem to have the functionality of fastpages or quarto.\n\nJupyter Books seems to be the best option within ONS\n\nMaybe not as good as quarto but it works!"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#others",
    "href": "posts/Communicating_Code/CommCodePres.html#others",
    "title": "Overview: Communicating code and data",
    "section": "Others",
    "text": "Others\n\nI know some people use Sphinx,\n\nis recommended by QA\nFrom what I can tell sphinx on it’s own is not as easy to use as notebooks\nBut there is a jupyter extension nbsphinx\nJupyter Books uses Sphinx heavily under the hood\n\nnbdev\n\nI think is connected to quarto\n\nVoila\n\nVoilà turns Jupyter notebooks into standalone web applications.\nLooks good, bit like streamlit\nbut seems to interfere with other libraries and not checked whether works in ONS\nmercury seems similar\n\nAnything else people use and recommend?"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#quarto-outputs",
    "href": "posts/Communicating_Code/CommCodePres.html#quarto-outputs",
    "title": "Overview: Communicating code and data",
    "section": "Quarto Outputs",
    "text": "Quarto Outputs\nWe can then create different files from this .ipynb Jupyter notebook using the following code:\n\nquarto render testPres.ipynb --to pptx\nquarto render testPres.ipynb --to pdf\nquarto render testPres.ipynb --to html\nquarto render testPres.ipynb --to revealjs\n\nor for Jupyter Books - jupyter-book build .\\PesticideDocs\\"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#creating-a-webpage-from-this",
    "href": "posts/Communicating_Code/CommCodePres.html#creating-a-webpage-from-this",
    "title": "Overview: Communicating code and data",
    "section": "Creating a webpage from this",
    "text": "Creating a webpage from this\nTakes about 30 mins including installing chosen converter. (But can be done much quicker)\n\ncreate a Github repo for your website\nchoose the converter (e.g. Jupyter Books)\n\nAnd follow their instructions\n\ngo to settings -> Pages within the repo\n\nfew options to do\n\nOptional: add your own website url to it\n\nLink how to do this here"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#example-documenting-code",
    "href": "posts/Communicating_Code/CommCodePres.html#example-documenting-code",
    "title": "Overview: Communicating code and data",
    "section": "Example: Documenting Code",
    "text": "Example: Documenting Code\n\nHere is my website for my research project on pesticides in UK food.\nThis is not the same as documentation for a package but there are parallels\n\nThis does a few things:\n\nDocuments the analysis steps I have taken including the code and outputs\n\nUseful for data transparency, useability of the code if needs modifiying/adapting, and why I did XYZ\n\nProvides a way to present the data\n\nThere is a streamlit app, but sometimes I like to be able to see the code"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#example-discussing-code",
    "href": "posts/Communicating_Code/CommCodePres.html#example-discussing-code",
    "title": "Overview: Communicating code and data",
    "section": "Example: Discussing Code",
    "text": "Example: Discussing Code\n\nGP Tables example"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#example-tool-to-aid-learning",
    "href": "posts/Communicating_Code/CommCodePres.html#example-tool-to-aid-learning",
    "title": "Overview: Communicating code and data",
    "section": "Example: Tool to aid learning",
    "text": "Example: Tool to aid learning\nA big area I have been using Jupyter Notebooks for is to aid learning\n\nIf you want to understand something it helps to write it down\nHaving the code next to it is a big advantage\nAnd if stored on github you can access it anywhere\n\nTensoflow cheat sheet"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#example-debugging-code",
    "href": "posts/Communicating_Code/CommCodePres.html#example-debugging-code",
    "title": "Overview: Communicating code and data",
    "section": "Example: Debugging Code",
    "text": "Example: Debugging Code\n\nSince starting at ONS I have been working with understanding an existing project and latterly adding code to it\nThe project consists of multiple python files across several folders\n\nMy Python was good but lots of the functions and their useage weren’t immediately obvious to me\n\nbreak-points in VS Studio is really good to step through the code and work out what happens in the code.\n\nI had not used before with Python (but had lots with MATLAB), and it’s really useful\n\nBut it can be limited what you can do\n\ndifficult to probe code if want to write more than 1 line of code\nthe experience/knowledge exists as you go through it but no documentation to refer to later, e.g. function X does this when I give it Y etc\n\nBy copying and pasting code into Jupyter cells I could see and document how they worked (e.g. changing inputs)\n\nThis (copying and pasting) would get around code changes too (which would be an issue if modules were just imported)\nbecause this was all done in Jupyter notebook I can have a ipynb code file and a html file showing how the code works\nI could even save a pickle file of the variables at a particularly point to understand how the code would work from this point"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#presenting-in-multiple-formats",
    "href": "posts/Communicating_Code/CommCodePres.html#presenting-in-multiple-formats",
    "title": "Overview: Communicating code and data",
    "section": "Presenting in multiple formats",
    "text": "Presenting in multiple formats\n\nJupyter notebooks can be used on their own or as html\nBut can also be used to create presentations, pdf/word documentation or even books\nThis presentation was done with Quarto using the revealjs format\n\nSo it is a presentation format but with a html file\n\nSome of these file types can be difficult within ONS framework to do\n\nI hit a wall when trying to go beyond html and docs with Jupyter books due to dependencies"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#presenting-in-multiple-formats-video",
    "href": "posts/Communicating_Code/CommCodePres.html#presenting-in-multiple-formats-video",
    "title": "Overview: Communicating code and data",
    "section": "Presenting in multiple formats: video",
    "text": "Presenting in multiple formats: video\nVideo"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres.html#questions-comments",
    "href": "posts/Communicating_Code/CommCodePres.html#questions-comments",
    "title": "Overview: Communicating code and data",
    "section": "Questions/ Comments",
    "text": "Questions/ Comments\n\nThoughts on:\n\nusing notebooks\ndocumenting code\nencouraging communication of code across ONS areas and experiences\n\nCan we share html files? Or do we have to work within the current framework?\nAnything else?"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_html.html#what-i-have-used-to-convert-notebooks-to-html",
    "href": "posts/Communicating_Code/CommCodePres_html.html#what-i-have-used-to-convert-notebooks-to-html",
    "title": "Communicating code: Website",
    "section": "What I have used to convert notebooks to html",
    "text": "What I have used to convert notebooks to html\n\nfastpages\n\nPreviously I converted notebooks to html via fastpages but this is now deprecated and they are recommending the use of quarto.\n\nquarto\n\nSo far I have found quarto really good and flexible (N.B. R works too)\nEasy to convert a notebook to multiple formats, including html, powerpoint, pdf, word doc\nBUT Quarto is not possible if installing from non pip sources is an issue (as far as I can tell currently)\n\nnbconvert is another option I tried\n\nbut it doesn’t seem to have the functionality of fastpages or quarto.\n\nJupyter Books seems to be the best option within companies with installation issues\n\nMaybe not as good as quarto but it works!"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_html.html#others",
    "href": "posts/Communicating_Code/CommCodePres_html.html#others",
    "title": "Communicating code: Website",
    "section": "Others",
    "text": "Others\n\nI know some people use Sphinx,\n\nis recommended by QA\nFrom what I can tell sphinx on it’s own is not as easy to use as notebooks\nBut there is a jupyter extension nbsphinx\nJupyter Books uses Sphinx heavily under the hood\n\nnbdev\n\nI think is connected to quarto\n\nVoila\n\nVoilà turns Jupyter notebooks into standalone web applications.\nLooks good, bit like streamlit\nbut seems to interfere with other libraries\nmercury seems similar"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_html.html#creating-html-other-formats",
    "href": "posts/Communicating_Code/CommCodePres_html.html#creating-html-other-formats",
    "title": "Communicating code: Website",
    "section": "Creating html (& other formats)",
    "text": "Creating html (& other formats)\n\nQuarto\nInstallation is via a package i.e. .msi for Windows or .pkg for Mac. Which can cause issues.\nWorks with both ipynb and qmd files, which are both a mixture of markdown and executable code.\nThe only thing that needs to be done with the notebook is add a YAML block at the start of the notebook, like the following (raq not markdown was used):\n---\ntitle: \"Communicating code: Website\"\nsubtitle: \"Using the notebook format for a website\"\nauthor: \"Thomas H. Simm\"\nformat:\n  html:\n    toc: true\ntitle-slide-attributes:\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\njupyter: python3\n---\nWe can create different files from this .ipynb Jupyter notebook using the following code:\n\nquarto render testPres.ipynb --to pptx\nquarto render testPres.ipynb --to pdf\nquarto render testPres.ipynb --to html\nquarto render testPres.ipynb --to revealjs\n\nFurther, formatting for projects (i.e. for website) can be done within the configuration file _quarto.yml\nproject:\n  type: website\n  output-dir: _site\n\nwebsite:\n  title: \"ThomasHSimm\"\n  favicon: /posts/Picture3.png\n  body-header: <img src=\"/posts/header2.png\" height=200>\n\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/ThomasHSimm\n      - icon: mortarboard-fill\n        href: https://scholar.google.com/citations?hl=en&user=HdPDn1sAAAAJ\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_html.html#jupyter-books",
    "href": "posts/Communicating_Code/CommCodePres_html.html#jupyter-books",
    "title": "Communicating code: Website",
    "section": "Jupyter Books",
    "text": "Jupyter Books\nWe can create different files from this .ipynb Jupyter notebook using the following code:\n\njupyter-book build .\\PesticideDocs\\\njupyter-book build <path-to-book>\njupyter-book build <path-to-book> --builder pdfhtml\njupyter-book build <path-to-book> --builder singlehtml\n\nThe only difference in notebook is that it needs to have One header in a markdown cell for the table of contents, e.g. \n# Title of page\n\nConfiguration file\nA seperate files _config.yml is used to define how the html (or other) files will look\n# Book settings\n# Learn more at https://jupyterbook.org/customize/config.html\n\ntitle: Defra Pesticide Testing, Data Analysis\nauthor: Thomas Simm\nlogo: ONS-logo.png\nexclude_patterns: [_build, Thumbs.db, .DS_Store, \"**.ipynb_checkpoints\"]\n\n\n# Force re-execution of notebooks on each build.\n# See https://jupyterbook.org/content/execute.html\nexecute:\n  execute_notebooks: force\n\n# Define the name of the latex output file for PDF builds\nlatex:\n  latex_documents:\n    targetname: book.tex\n\n# Add a bibtex file so that we can create citations\nbibtex_bibfiles:\n  - references.bib\n\n# Information about where the book exists on the web\nrepository:\n  url: https://github.com/ThomasHSimm/Pesticide  # Online location of your book\n  path_to_book: docs  # Optional path to your book, relative to the repository root\n  branch: master  # Which branch of the repository should be used when creating links (optional)\n\n# Add GitHub buttons to your book\n# See https://jupyterbook.org/customize/config.html#add-a-link-to-your-repository\n# HTML-specific settings\nhtml:\n  favicon                   : \"_images/favicon.jpg\"  # A path to a favicon image\n  use_edit_page_button      : false  # Whether to add an \"edit this page\" button to pages. If `true`, repository information in repository: must be filled in\n  use_repository_button     : false  # Whether to add a link to your repository button\n  use_issues_button         : false  # Whether to add an \"open an issue\" button\n  use_multitoc_numbering    : true   # Continuous numbering across parts/chapters\n  extra_navbar              : Powered by <a href=\"https://jupyterbook.org\">Jupyter Book</a>\n                              <br>Home website <a href=\"https://thomashsimm.com/\">thomashsimm.com</a> # Will be displayed underneath the left navbar.\n  extra_footer              : \"\"  # Will be displayed underneath the footer.\n  google_analytics_id       : \"\"  # A GA id that can be used to track book views.\n  home_page_in_navbar       : true  # Whether to include your home page in the left Navigation Bar\n  baseurl                   : \"\"  # The base URL where your book will be hosted. Used for creating image previews and social links. e.g.: https://mypage.com/mybook/\n  comments:\n    hypothesis              : false\n    utterances              : false\n  announcement              : \"\" # A banner announcement at the top of the site.\n\nAnd in addition to the config file a table of contents file is required _toc.yml:\n# Table of contents\n# Learn more at https://jupyterbook.org/customize/toc.html\n\nformat: jb-book\nroot: intro\nchapters:\n- file: Pesticide_Plots\n- file: References\n- file: UK_areas\n- file: using_jupyter_books"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_html.html#creating-a-webpage-from-this",
    "href": "posts/Communicating_Code/CommCodePres_html.html#creating-a-webpage-from-this",
    "title": "Communicating code: Website",
    "section": "Creating a webpage from this",
    "text": "Creating a webpage from this\nTakes about 30 mins including installing the chosen converter. (But can be done much quicker)\n\ncreate a Github repo for your website\nchoose the converter (e.g. Jupyter Books)\n\nAnd follow their instructions\n\ngo to settings -> Pages within the repo\n\nfew options to do\n\nOptional: add your own website url to it\n\nLink how to do this here\nIn Quarto a command from your PC in the repo, publishes the website:\nquarto publish quarto-pub\nOr equivalently with Jupyter Books:\nghp-import -n -p -f _build/html"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_html.html#creating-directly-from-the-repo",
    "href": "posts/Communicating_Code/CommCodePres_html.html#creating-directly-from-the-repo",
    "title": "Communicating code: Website",
    "section": "Creating directly from the repo",
    "text": "Creating directly from the repo\nIf we instead want to convert notebook files directly from a repo to create a website then this can be done with Netlify.\nThis is useful if using Gitlab (i.e. not Github) or don’t want all the extra html files cluttering the repo.\n\nSteps:\nhttps://jupyterbook.org/en/stable/publish/netlify.html\n\nSign up and connect Github/Gitlab\nAdd a requirements.txt file and also toc.yml to directory\nOn netlify -> Add new site -> import from an existing repo\nInsert something like below\n\nN.B. the command:\npip install -r requirements.txt && jupyter-book build .\nand folder location \n\n\nExample:\n\nGitlab repo\nResulting website https://thomashsimm.netlify.app/intro.html\n\nAnd from the inner folder"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#jupyter-notebooks",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#jupyter-notebooks",
    "title": "Communicating code: Notebooks",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nFrom TalkPython: Awesome Jupyter Libraries and Extensions\n\nJupyter is an amazing environment for exploring data and generating executable reports with Python. But there are many external tools, extensions, and libraries to make it so much better and make you more productive.\n\n\nA notebook consists of two parts\n\nmarkdown part where we can:\n\nwrite text, add images, links, html, LaTeX etc\n\ncode part which runs and displays output of code\n\n\nSome links:\n\nJupyter Book\nA curated list of awesome Jupyter projects\nCode Documentation QA of Code\nFastAI guide for better blogs"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#example-of-a-notebook",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#example-of-a-notebook",
    "title": "Communicating code: Notebooks",
    "section": "Example of a notebook",
    "text": "Example of a notebook\nAn example notebook"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#markdown-in-a-notebook",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#markdown-in-a-notebook",
    "title": "Communicating code: Notebooks",
    "section": "Markdown in a notebook",
    "text": "Markdown in a notebook\nSome useful commands:\n\n# Notebooks Markdown and Code and ## Markdown in a notebook\n![](ghtop_images/pest.png) looks like this\n\n\n\nAnd the same with a mp4 file ![](ghtop_images/revealjs.mp4)\n\nVideo\n\n> If we want text like this\n\n\nIf we want text like this\n\n\nOr if we want code use `a = b + c`\n\nor:\n```\na = b\na = a + c\n```\na = b + c\n\nHTML works too\n\n<img src=\"ghtop_images/pest.png\"></img>"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#code-in-a-notebook",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#code-in-a-notebook",
    "title": "Communicating code: Notebooks",
    "section": "Code in a notebook",
    "text": "Code in a notebook\nExample interactive format using altair:\n\nimport altair as alt\nfrom vega_datasets import data\n\nmovies = alt.UrlData(\n    data.movies.url,\n    format=alt.DataFormat(parse={\"Release_Date\":\"date\"})\n)\nratings = ['G', 'NC-17', 'PG', 'PG-13', 'R']\ngenres = ['Action', 'Adventure', 'Black Comedy', 'Comedy',\n       'Concert/Performance', 'Documentary', 'Drama', 'Horror', 'Musical',\n       'Romantic Comedy', 'Thriller/Suspense', 'Western']\n\nbase = alt.Chart(movies, width=200, height=200).mark_point(filled=True).transform_calculate(\n    Rounded_IMDB_Rating = \"floor(datum.IMDB_Rating)\",\n    Hundred_Million_Production =  \"datum.Production_Budget > 100000000.0 ? 100 : 10\",\n    Release_Year = \"year(datum.Release_Date)\"\n).transform_filter(\n    alt.datum.IMDB_Rating > 0\n).transform_filter(\n    alt.FieldOneOfPredicate(field='MPAA_Rating', oneOf=ratings)\n).encode(\n    x=alt.X('Worldwide_Gross:Q', scale=alt.Scale(domain=(100000,10**9), clamp=True)),\n    y='IMDB_Rating:Q',\n    tooltip=\"Title:N\"\n)\n\n# A slider filter\nyear_slider = alt.binding_range(min=1969, max=2018, step=1)\nslider_selection = alt.selection_single(bind=year_slider, fields=['Release_Year'], name=\"Release Year_\")\n\n\nfilter_year = base.add_selection(\n    slider_selection\n).transform_filter(\n    slider_selection\n).properties(title=\"Slider Filtering\")\n\n# A dropdown filter\ngenre_dropdown = alt.binding_select(options=genres)\ngenre_select = alt.selection_single(fields=['Major_Genre'], bind=genre_dropdown, name=\"Genre\")\n\nfilter_genres = base.add_selection(\n    genre_select\n).transform_filter(\n    genre_select\n).properties(title=\"Dropdown Filtering\")\n\n#color changing marks\nrating_radio = alt.binding_radio(options=ratings)\n\nrating_select = alt.selection_single(fields=['MPAA_Rating'], bind=rating_radio, name=\"Rating\")\nrating_color_condition = alt.condition(rating_select,\n                      alt.Color('MPAA_Rating:N', legend=None),\n                      alt.value('lightgray'))\n\nhighlight_ratings = base.add_selection(\n    rating_select\n).encode(\n    color=rating_color_condition\n).properties(title=\"Radio Button Highlighting\")\n\n# Boolean selection for format changes\ninput_checkbox = alt.binding_checkbox()\ncheckbox_selection = alt.selection_single(bind=input_checkbox, name=\"Big Budget Films\")\n\nsize_checkbox_condition = alt.condition(checkbox_selection,\n                                        alt.SizeValue(25),\n                                        alt.Size('Hundred_Million_Production:Q')\n                                       )\n\nbudget_sizing = base.add_selection(\n    checkbox_selection\n).encode(\n    size=size_checkbox_condition\n).properties(title=\"Checkbox Formatting\")\n\n( filter_year | filter_genres) &  (highlight_ratings | budget_sizing  )"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#simpler-code-output",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#simpler-code-output",
    "title": "Communicating code: Notebooks",
    "section": "Simpler code output",
    "text": "Simpler code output\nx = np.arange(0,np.pi,.01)\ny = np.sin(x)\nplt.plot(x,y)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.arange(0,np.pi,.01)\ny = np.sin(x)\nplt.plot(x,y)"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#notebooks-my-view",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#notebooks-my-view",
    "title": "Communicating code: Notebooks",
    "section": "Notebooks: my view",
    "text": "Notebooks: my view\nAlthough notebooks have their validish detractors I don’t like notebooks.- Joel Grus Youtube I think if you approach them in the right way they are a super powerful tool.\nThe negatives seem to be:\n\nencourage bad practice in code (a genuine problem)\nissues around order of what cell is run (easily got around with good practice)\nissues around lack of auto complete (I don’t see the issue, use in visual studio autocomplete is there)\nno grammar/spelling correction\nissues with using git and version control\n\nthere are ways around this though"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#notebook-benefits",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#notebook-benefits",
    "title": "Communicating code: Notebooks",
    "section": "Notebook Benefits",
    "text": "Notebook Benefits\n\nNotebooks are intuitive\n\nYou have the code then the result of the code\nPlus can add details of how code works\nAnd it’s linear\n\nCan get things up and working quickly\nAid with communicating code\nEncourages Writing\n\nand writing things down aids thinking in the now and understanding what you did and why in the future\n\nFastAI guide for better blogs\n\nCan use shell commands e.g. !pip install pandas\nCan use magic commands e.g. %%time to time a cell\nEasy to convert code to a pipeline\n\nWith many companies moving towards Python/R from Excel and a varied level of skills. The first of these is particularly important to aid communicating code"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#communicating-when-code-is-a-large-element-of-what-is-being-presented",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#communicating-when-code-is-a-large-element-of-what-is-being-presented",
    "title": "Communicating code: Notebooks",
    "section": "Communicating when code is a large element of what is being presented",
    "text": "Communicating when code is a large element of what is being presented\n\nMicrosoft Word/ppt- type methods aren’t set-up well to include code\nProgramming files (e.g. .py) aren’t set-up well to share\nVideoing code with outputs is an option, but don’t translate to other formats (i.e. we may also need to do a written format of this)\nApps (e.g. streamlit) can be good.\n\nBut the code is hidden\n\nProgramming notebooks (e.g..ipynb) offer a good and easy to share code but with some limitations\n\nAn easier way is to convert the notebooks to html\n\ne.g. maybe someone doesn’t have python installed"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#example-documenting-code",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#example-documenting-code",
    "title": "Communicating code: Notebooks",
    "section": "Example: Documenting Code",
    "text": "Example: Documenting Code\n\nHere is my website for my research project on pesticides in UK food.\nThis is not the same as documentation for a package but there are parallels\n\nThis does a few things:\n\nDocuments the analysis steps I have taken including the code and outputs\n\nUseful for data transparency, useability of the code if needs modifiying/adapting, and why I did XYZ\n\nProvides a way to present the data\n\nThere is a streamlit app, but sometimes I like to be able to see the code"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#example-tool-to-aid-learning",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#example-tool-to-aid-learning",
    "title": "Communicating code: Notebooks",
    "section": "Example: Tool to aid learning",
    "text": "Example: Tool to aid learning\nA big area I have been using Jupyter Notebooks for is to aid learning\n\nIf you want to understand something it helps to write it down\nHaving the code next to it is a big advantage\nAnd if stored on github you can access it anywhere\n\nTensoflow cheat sheet"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_notebooks.html#example-debugging-code",
    "href": "posts/Communicating_Code/CommCodePres_notebooks.html#example-debugging-code",
    "title": "Communicating code: Notebooks",
    "section": "Example: Debugging Code",
    "text": "Example: Debugging Code\n\nSince starting at ONS I have been working with understanding an existing project and latterly adding code to it\nThe project consists of multiple python files across several folders\n\nMy Python was good but lots of the functions and their useage weren’t immediately obvious to me\n\nbreak-points in VS Studio is really good to step through the code and work out what happens in the code.\n\nI had not used before with Python (but had lots with MATLAB), and it’s really useful\n\nBut it can be limited what you can do\n\ndifficult to probe code if want to write more than 1 line of code\nthe experience/knowledge exists as you go through it but no documentation to refer to later, e.g. function X does this when I give it Y etc\n\nBy copying and pasting code into Jupyter cells I could see and document how they worked (e.g. changing inputs)\n\nThis (copying and pasting) would get around code changes too (which would be an issue if modules were just imported)\nbecause this was all done in Jupyter notebook I can have a ipynb code file and a html file showing how the code works\nI could even save a pickle file of the variables at a particularly point to understand how the code would work from this point"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#content",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#content",
    "title": "Communicating code: Presentations",
    "section": "Content",
    "text": "Content\n\nQuarto\n\npowerpoint https://quarto.org/docs/presentations/\nhtml\n\nJupyter books\nStreamlit"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#creating-the-template",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#creating-the-template",
    "title": "Communicating code: Presentations",
    "section": "Creating the template",
    "text": "Creating the template\n(Office info correct for Office 365 Feb 2023, Version 2301 Build 16.0.16026.20002)\nIf your workplace has a custom template or you have one you always use, you can incorporate this into quarto.\nHowever, quarto is quite specific on the form this template takes, and requires the following elements - Title Slide - Title and Content - Section Header - Two Content - Comparison - Content with Caption - Blank\nBy selecting Layout from the Home tab in powerpoint the different layouts can be seen\n\nThey can then be modified by going to View tab - Slide Master.\nIf using your own template you will need to match the names of the slides given above. These can be found by hovering over the slides on the left or right clicking on one and selecting “Rename Layout”\n\nAlternatively, create a custom template using quarto and then modify this. The following command creates the template:\nquarto pandoc -o template.pptx --print-default-data-file reference.pptx\nThen go to View tab - Slide Master and modify each slide layout.\nNote if you are trying to match a template, some tips: - go to Design -> Slide Size and match this to your template - when View tab - Slide Master is selected go to first tab (see above it will be left indented) on one you are copying from and select all on this then paste to the new template - these will be background images and other things that want to be passed to all slides - Check other slides for images and font-styles etc to match to the new template"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#load-the-template",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#load-the-template",
    "title": "Communicating code: Presentations",
    "section": "Load the template",
    "text": "Load the template\nTo load the template the first cell in the notebook needs to be modified as follows to reference the template.pptx file.\nformat:\n  pptx:\n    reference-doc: template.pptx\n    slide-level: 2\nIn addition, we can also specify here the rule by which a new slide is defined. If slide-level: 2 is used a new slide is defined by “##’ and a new section header by ‘#’. So if we used ‘###’ this would be a heading within the slide.\nIf slide-level: 1 is used a new slide is defined by “#’ and ‘##’ this would be a heading within the slide (this is normally the default)."
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#check-the-slides",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#check-the-slides",
    "title": "Communicating code: Presentations",
    "section": "Check the slides",
    "text": "Check the slides\nI have found creation of slides to powerpoint more prone to strange results than if .doc/.pdf/.html are used.\nSo check the slides, see if interactive content or code has been included (probably not) and if the slide content goes outside the slide.\n\nIn the example above - There is overlap of text on a slide - Strange ouput of a slide - Code output not displayed"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#adding-style-to-revealjs",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#adding-style-to-revealjs",
    "title": "Communicating code: Presentations",
    "section": "Adding style to revealjs",
    "text": "Adding style to revealjs\nA simple way to add template like details to a revealjs file is to add a style.css sheet.\nIn the example below, the style sheet adds logo.png to the bottom right of each sheet\nThe file style.css looks like this:\n.reveal .slide-logo {\n  display: block;\n  position: fixed;\n  top: unset !important;\n  left: unset !important;\n  bottom: 50px;\n  right: 12px;\n  height: 100px !important;\n  width: 100x !important;\n  max-width: unset !important;\n  max-height: unset !important;\n}\nAnd the revealjs part at the top of the jupyter notebook looks like this\nrevealjs:\n    slide-number: true\n    height: 1080\n    width: 1920\n    logo: logo.png\n    css: style.css\nSo this would then look like the following, with the logo (logo.png) in the bottom right, and size and positioning given by the css file"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#what-the-revealjs-file-looks-like",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#what-the-revealjs-file-looks-like",
    "title": "Communicating code: Presentations",
    "section": "What the revealjs file looks like",
    "text": "What the revealjs file looks like\nVideo"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-overview",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-overview",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: overview",
    "text": "Streamlit Functionality: overview\nStreamlit allows various functionality:\n\ntextbox\nimages/videos\ncharts/tables\nmenus/buttons\netc"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-streamlit_layout",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-streamlit_layout",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: streamlit_layout",
    "text": "Streamlit Functionality: streamlit_layout\nBut unlike some apps (am thinking MATLAB GUIs) you can’t create the look and functionality separately. So if you want something in a certain position it can be tricky. HTML can be used with st.markdown to give more control but it isn’t recommended to use by streamlit.\nInstead, to create the layout as you would like they have the following features:"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-columns-and-sidebar",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-columns-and-sidebar",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: columns and sidebar",
    "text": "Streamlit Functionality: columns and sidebar\nThe most useable are the first two: columns and sidebar\nColumns allows us to split the app vertically. The code is fairly simple:\nEither colL, colM, colR = st.columns(3) for 3 equal columns or to split columns with different sizes:\ncolL, _, colR = st.columns((10, 5, 20))\nwith colL:\n    st.write('On the left')\nwith colR:\n    st.write('On the right twice as big as left')\nst.sidebar just adds a sidebar to the app that can be hidden or shown.\nAnything in the sidebar is just prefixed by st.sidebar so:\nst.sidebar.write('I am in the sidebar')\nst.write('I am in the main app')\nst.sidebar.write('I am back in the sidebar')"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-html",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-html",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: html",
    "text": "Streamlit Functionality: html\nIt is possible to add various additional personalisations using html. BUT it does come with security risks and so is [not recommended]](https://github.com/streamlit/streamlit/issues/152)\n\nBut it does allow much more control over the layout of the app that can be useful for a presentation: - Can add a background image - Can add background color to a textbox - Control over positioning of widgets - lots more\nHTML is implementated using st.markdown with unsafe_allow_html=True inside the former"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-html-examples",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-html-examples",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: html examples",
    "text": "Streamlit Functionality: html examples\nadd background to a text box\ntext = \"Code Examples\"\n        st.markdown(f'<center><p style=font-family:\"Calibri\";background-color:#FFFFFF;color:#000000;font-size:42px;border-radius:10%><b>{text}</b></p></center>', unsafe_allow_html=True)\n\nOr to add a background image\nimport streamlit as st\nimport base64\n\n@st.cache(allow_output_mutation=True)\ndef get_base64_of_bin_file(bin_file):\n    with open(bin_file, 'rb') as f:\n        data = f.read()\n    return base64.b64encode(data).decode()\n\ndef set_png_as_page_bg(png_file):\n    bin_str = get_base64_of_bin_file(png_file) \n    page_bg_img = '''\n    <style>\n    .stApp {\n    background-image: url(\"data:image/png;base64,%s\");\n    background-size: contain;\n    background-repeat: no-repeat;\n    background-attachment: scroll; # doesn't work\n    }\n    </style>\n    ''' % bin_str\n    st.markdown(page_bg_img, unsafe_allow_html=True)\n    return"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-echo",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-echo",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: echo",
    "text": "Streamlit Functionality: echo\n\nSometimes you want your Streamlit app to contain both your usual Streamlit graphic elements and the code that generated those elements. That’s where st.echo() comes in\n\nEasier to display this by an example:\n\nIn the example above the right of the image is given below (st.columns is used, where the input for the function is found from the left column).\n\nst.echo is used with the with statement.\neverything within the with is printed to the screen and executed\n\nwith st.echo():\n    # Everything inside this block will be both printed to the screen\n    # and executed.\n\n    def do_pd_replace(text, text_search, text_sub):\n        col_name = \"Start string\"\n        df = pd.DataFrame(data=[text], columns=[col_name])\n\n        df[\"Final String\"] = df[col_name].replace(\n            text_search, text_sub, regex=True\n        )\n\n        st.dataframe(df)\n        st.write(f\"text_search = '{text_search}' and text_sub = '{text_sub}'\")\n        st.write(f\"Input string = '{text}'\")\n        st.write(f\"Output string = '{df['Final String'].values[0]}'\")\n\n    do_pd_replace(text, text_search, text_sub)"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-pages",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#streamlit-functionality-pages",
    "title": "Communicating code: Presentations",
    "section": "Streamlit Functionality: pages",
    "text": "Streamlit Functionality: pages\nBy simply creating a folder called pages and putting other streamlit .py files in the folder they can then be accessed in the sidebar.\n\nA main file needs to be outside the pages folder\nThe .py files in pages behave as if they were outside the folder (i.e. when loading files/functions)"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_pres.html#example-streamlit-presentation",
    "href": "posts/Communicating_Code/CommCodePres_pres.html#example-streamlit-presentation",
    "title": "Communicating code: Presentations",
    "section": "Example Streamlit Presentation",
    "text": "Example Streamlit Presentation\nVideo"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#excel-files",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#excel-files",
    "title": "Communicating code: Tables",
    "section": "Excel files",
    "text": "Excel files\n\nChatGPT: What are the problems of Excel and xlsx files?\n\n\nLimited scalability: Excel has a limit on the number of rows and columns it can handle effectively.\nInaccurate data: The manual nature of data entry in Excel can lead to errors and inaccuracies.\nFragility: Complex Excel spreadsheets can break easily if any formula or cell reference is altered.\nLack of security: Excel files are vulnerable to unauthorized access and malicious attacks.\nSlow performance: Large and complex Excel files can become slow to open and use, leading to decreased productivity.\nCompatibility issues: XLSX files may not be compatible with older versions of Excel, or with other software applications.\nLimited collaboration: Sharing Excel files and making changes to them can be difficult, especially when multiple people are involved.\n\nFor me it is the Slow performance alongside: (a) we are doing the data manipulation outside Excel anyway and (b) having to have another application open\n\nods with Excel\nAbout 10 s to open 3 ods files with Excel\n\n\n.ods converted to html in firefox browser\nAbout 6 s to open 3 converted ods files in a browser\n\n\n.ods converted to html firefox browser no new tabs\nAlmost instant when open converted ods files in same browser"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#what-aspect-of-tables-i-am-considering",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#what-aspect-of-tables-i-am-considering",
    "title": "Communicating code: Tables",
    "section": "What aspect of tables I am considering",
    "text": "What aspect of tables I am considering"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#convert-xlsx-to-html",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#convert-xlsx-to-html",
    "title": "Communicating code: Tables",
    "section": "Convert xlsx to html?",
    "text": "Convert xlsx to html?\n\nOpening xlsx files in Excel is slow\nConverting to html if we don’t want to edit could be an option\nIf we are moving to Python/R aren’t non-Excel options worth considering??\n\nConverting xlsx files to html\n\nSeems the most obvious course\nBut it doesn’t seem that easy with code\n\nbut easy within Excel"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#what-does-chatgpt-say-to-convert-excel-file",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#what-does-chatgpt-say-to-convert-excel-file",
    "title": "Communicating code: Tables",
    "section": "What does chatgpt say to convert excel file?",
    "text": "What does chatgpt say to convert excel file?\n\nConvert an excel file to html with python"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#what-does-chatgpt-say-without-pandas",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#what-does-chatgpt-say-without-pandas",
    "title": "Communicating code: Tables",
    "section": "What does chatgpt say without pandas?",
    "text": "What does chatgpt say without pandas?\n\nconvert excel file to html in python without pandas include the excel formatting such as column width\n\n\n\nimport pandas as pd\n\nimport os\nfrom pathlib import Path\nimport sys\n\nmodule_path = Path( os.getcwd() )\nmodule_path = module_path.parent.parent.parent.__str__() + '\\\\Pesticide'\n\ncwd = module_path\n\nfolder_path = os.path.join(cwd,'data')\n\nsys.path.insert(0, module_path)\n\ndf2 = pd.read_csv(os.path.join(folder_path,'combined_df.csv') ,index_col=0 )\n# change data type of columns\ndf2['date_of_sampling'] = pd.to_datetime(df2['date_of_sampling'])"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#pandas",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#pandas",
    "title": "Communicating code: Tables",
    "section": "pandas",
    "text": "pandas\n\nSince (in Python) we are mainly working with pandas. Let’s consider how pandas outputs can be modified.\npandas options\n\nSome code functionality\n# precision of all columns\npd.set_option(\"display.precision\", 2)\n# Or map as a string\ndf2['amount_pc_str'] = df2['amount_pc'].map(lambda x: '%.3f' % x)\n# some other options\npd.set_option('max_colwidth', 20)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', 0)"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#pandas-basic",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#pandas-basic",
    "title": "Communicating code: Tables",
    "section": "pandas basic",
    "text": "pandas basic\n\ndf2\n\n\n\n\n\n  \n    \n      \n      sample_id\n      date_of_sampling\n      description\n      country_of_origin\n      retail_outlet\n      address\n      brand_name\n      packer_/_manufacturer_/_importer\n      product\n      address_postcode\n      packer_postcode\n      address_area\n      packer_area\n      chem_name\n      amount_detected\n      mrl\n      amount_pc\n    \n  \n  \n    \n      0\n      1958/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Asda\n      Creechbarrow Road, Taunton TA1 2AN\n      Asda\n      Asda Stores Ltd Leeds, UK LS11 5AD\n      Apple\n      TA1 2AN\n      LS11 5AD\n      Somerset\n      West Yorkshire\n      boscalid\n      0.03\n      2.0\n      0.015\n    \n    \n      1\n      1958/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Asda\n      Creechbarrow Road, Taunton TA1 2AN\n      Asda\n      Asda Stores Ltd Leeds, UK LS11 5AD\n      Apple\n      TA1 2AN\n      LS11 5AD\n      Somerset\n      West Yorkshire\n      pyraclostrobin\n      0.01\n      0.5\n      0.020\n    \n    \n      2\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      boscalid\n      0.05\n      2.0\n      0.025\n    \n    \n      3\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      flonicamid (sum)\n      0.02\n      0.2\n      0.100\n    \n    \n      4\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      pyraclostrobin\n      0.03\n      0.5\n      0.060\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      35155\n      2858/2020 Organic\n      2020-10-20\n      Organic Sweet Potatoes\n      Spain\n      Tesco\n      300 Beverley Way, New Malden KT3 4PJ\n      Tesco\n      Tesco Stores Ltd Welwyn Garden City AL7 1GA\n      Sweet_Potatoes_Q4_(BNA)\n      KT3 4PJ\n      AL7 1GA\n      Greater London\n      Hertfordshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35156\n      0562/2020 Organic\n      2020-10-05\n      Organic Duchy Sweet Potatoes\n      Egypt\n      Waitrose\n      Mill Lane, Swindon SN1 7BX\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      SN1 7BX\n      RG12 8YA\n      Wiltshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35157\n      0563/2020\n      2020-10-05\n      Sweet Potatoes\n      USA\n      Waitrose\n      Mill Lane, Swindon SN1 7BX\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      SN1 7BX\n      RG12 8YA\n      Wiltshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35158\n      2601/2020\n      2020-10-14\n      Sweet Potatoes\n      USA\n      Waitrose\n      Ossington Way, Newark NG24 1FF\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      NG24 1FF\n      RG12 8YA\n      Nottinghamshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35159\n      2601/2020\n      2020-10-14\n      Sweet Potatoes\n      USA\n      Waitrose\n      Ossington Way, Newark NG24 1FF\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      NG24 1FF\n      RG12 8YA\n      Nottinghamshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n  \n\n35160 rows × 17 columns"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#pandas-overview",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#pandas-overview",
    "title": "Communicating code: Tables",
    "section": "pandas overview",
    "text": "pandas overview\n\nUsing pandas we can control various outputs\nBut these still need a format to display within\nAnd display functionality is not easy\n\nOr convert to a html file\ndf2.iloc[:500].to_html('df2_500.html')\nBut using a style sheet as shown in stack overflow by Parfait\n\ndf_out = df2.iloc[:500].copy()\n\npd.set_option('colheader_justify', 'center')   # FOR TABLE <th>\n\nhtml_string = '''\n<html>\n  <head><title>HTML Pandas Dataframe with CSS</title></head>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"df_style.css\"/>\n  <body>\n    {table}\n  </body>\n</html>.\n'''\n\n# OUTPUT AN HTML FILE\nwith open('df2_500.html', 'w') as f:\n    f.write(html_string.format(table=df_out.to_html(classes='mystyle')))"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#section",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#section",
    "title": "Communicating code: Tables",
    "section": "",
    "text": "https://www.python-excel.org/"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#ipydatagrid",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#ipydatagrid",
    "title": "Communicating code: Tables",
    "section": "ipydatagrid",
    "text": "ipydatagrid\nhttps://github.com/bloomberg/ipydatagrid\n\n\nfrom ipydatagrid import DataGrid, TextRenderer, VegaExpr\nimport ipydatagrid\ndatagrid = DataGrid(df2, selection_mode=\"cell\", editable=True,\n                   base_row_size=32, base_column_size=150)\n\ndatagrid = DataGrid(df2, base_row_size=30, base_column_size=150)\ndatagrid"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#itables-code",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#itables-code",
    "title": "Communicating code: Tables",
    "section": "itables code",
    "text": "itables code\nfrom itables import init_notebook_mode\n\nimport itables\ninit_notebook_mode(all_interactive=True)\n\nitables.show(df2)\n\nfrom itables import init_notebook_mode\n\nimport itables\ninit_notebook_mode(all_interactive=True)\n\nitables.show(df2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      sample_id\n      date_of_sampling\n      description\n      country_of_origin\n      retail_outlet\n      address\n      brand_name\n      packer_/_manufacturer_/_importer\n      product\n      address_postcode\n      packer_postcode\n      address_area\n      packer_area\n      chem_name\n      amount_detected\n      mrl\n      amount_pc\n    \n  Loading... (need help?)"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#dash",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#dash",
    "title": "Communicating code: Tables",
    "section": "Dash",
    "text": "Dash\nhttps://dash.plotly.com/datatable\n\nDownloaded 800,000 times per month, Dash is the original low-code framework for rapidly building data apps in Python, R, Julia, and F# (experimental).\n\nhttps://medium.com/plotly/introducing-jupyterdash-811f1f57c02e\n\nimport plotly.express as px\nfrom jupyter_dash import JupyterDash\nimport dash_core_components as dcc\nimport dash_html_components as html\nfrom dash.dependencies import Input, Output# Load Data\ndf = px.data.tips()# Build App\napp = JupyterDash(__name__)\napp.layout = html.Div([\n    html.H1(\"JupyterDash Demo\"),\n    dcc.Graph(id='graph'),\n    html.Label([\n        \"colorscale\",\n        dcc.Dropdown(\n            id='colorscale-dropdown', clearable=False,\n            value='plasma', options=[\n                {'label': c, 'value': c}\n                for c in px.colors.named_colorscales()\n            ])\n    ]),\n])# Define callback to update graph\n@app.callback(\n    Output('graph', 'figure'),\n    [Input(\"colorscale-dropdown\", \"value\")]\n)\ndef update_figure(colorscale):\n    return px.scatter(\n        df, x=\"total_bill\", y=\"tip\", color=\"size\",\n        color_continuous_scale=colorscale,\n        render_mode=\"webgl\", title=\"Tips\"\n    )# Run app and display result inline in the notebook\napp.run_server(mode='inline')\n\nC:\\Users\\44781\\AppData\\Local\\Temp\\ipykernel_15260\\3294666565.py:3: UserWarning: \nThe dash_core_components package is deprecated. Please replace\n`import dash_core_components as dcc` with `from dash import dcc`\n  import dash_core_components as dcc\nC:\\Users\\44781\\AppData\\Local\\Temp\\ipykernel_15260\\3294666565.py:4: UserWarning: \nThe dash_html_components package is deprecated. Please replace\n`import dash_html_components as html` with `from dash import html`\n  import dash_html_components as html"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#streamlit",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#streamlit",
    "title": "Communicating code: Tables",
    "section": "Streamlit",
    "text": "Streamlit\n\nA faster way to build and share data apps\n\n\nDash can be run within a notebook but is principally an app.\nStreamlit is a similar app.\nBut much easier to code.\n\nimport pandas as pd\nimport streamlit as st\nall_dfs = pd.read_csv(\"./data/combined_df.csv\")\nst.dataframe(all_dfs.head())"
  },
  {
    "objectID": "posts/Communicating_Code/CommCodePres_tables.html#and-more",
    "href": "posts/Communicating_Code/CommCodePres_tables.html#and-more",
    "title": "Communicating code: Tables",
    "section": "And more",
    "text": "And more\n\nDataTables\n\nDataTables is a plug-in for the jQuery Javascript library. It is a highly flexible tool, built upon the foundations of progressive enhancement, that adds all of these advanced features to any HTML table.\n\n\n\nJupyter widgets\nIf you are looking for Jupyter widgets, have a look at (taken from https://mwouts.github.io/itables/references.html) - QGrid by Quantopian - IPyaggrid by Louis Raison and Olivier Borderies - IPySheet by QuantStack."
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#content",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#content",
    "title": "Presentation: Communicating code and data",
    "section": "Content",
    "text": "Content\n\nNotebooks\n\nWhat are they?\nExamples\nPros and cons\n\nApps\n\nVoila\nStreamlit\n\nWebsites and HTML\n\nConverting notebooks to HTML and websites\n\nPresentations\n\nUsing notebooks for presentations\n\nTabular Data\n\nComments on Excel\nThoughts on code alternatives"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#jupyter-notebooks",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#jupyter-notebooks",
    "title": "Presentation: Communicating code and data",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nFrom TalkPython: Awesome Jupyter Libraries and Extensions\n\nJupyter is an amazing environment for exploring data and generating executable reports with Python. But there are many external tools, extensions, and libraries to make it so much better and make you more productive.\n\n\nA notebook consists of two parts\n\nmarkdown part where we can:\n\nwrite text, add images, links, html, LaTeX etc\n\ncode part which runs and displays output of code\n\n\nSome links:\n\nJupyter Book\nA curated list of awesome Jupyter projects\nCode Documentation QA of Code\nFastAI guide for better blogs"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-of-a-notebook",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-of-a-notebook",
    "title": "Presentation: Communicating code and data",
    "section": "Example of a notebook",
    "text": "Example of a notebook\nAn example notebook"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-1",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-1",
    "title": "Presentation: Communicating code and data",
    "section": "Markdown in a notebook 1",
    "text": "Markdown in a notebook 1\nSome useful commands:\n\n# Notebooks General and ## Markdown in a notebook 1\n![](ghtop_images/pest.png) looks like this"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-2",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-2",
    "title": "Presentation: Communicating code and data",
    "section": "Markdown in a notebook 2",
    "text": "Markdown in a notebook 2\n\nAnd the same with a mp4 file ![](ghtop_images/revealjs.mp4)\nOr a youtube video \"\""
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-3",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-3",
    "title": "Presentation: Communicating code and data",
    "section": "Markdown in a notebook 3",
    "text": "Markdown in a notebook 3\n\n> If we want text like this\n\n\nIf we want text like this\n\n\nOr if we want code use `a = b + c`\n\nor:\n```\na = b\na = a + c\n```\n\na = b\n\na = a + c"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-4",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#markdown-in-a-notebook-4",
    "title": "Presentation: Communicating code and data",
    "section": "Markdown in a notebook 4",
    "text": "Markdown in a notebook 4\n\nHTML works too\n\n<img src=\"ghtop_images/pest.png\"></img>"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#code-in-a-notebook",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#code-in-a-notebook",
    "title": "Presentation: Communicating code and data",
    "section": "Code in a notebook",
    "text": "Code in a notebook\nExample interactive format using altair:"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#simpler-code-output",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#simpler-code-output",
    "title": "Presentation: Communicating code and data",
    "section": "Simpler code output",
    "text": "Simpler code output\nx = np.arange(0,np.pi,.01)\ny = np.sin(x)\nplt.plot(x,y)"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#other-code-stuff",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#other-code-stuff",
    "title": "Presentation: Communicating code and data",
    "section": "Other code stuff",
    "text": "Other code stuff\n\nCan use shell commands e.g. !pip install pandas\nCan use magic commands e.g. %%time to time a cell\n\n%%time\ny=0\nfor x in range(0,100):\n    y+=x\nprint(f\"y is {y}\")\n\n\ny is 4950\nCPU times: total: 0 ns\nWall time: 0 ns"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#but-not-everyone-loves-notebooks",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#but-not-everyone-loves-notebooks",
    "title": "Presentation: Communicating code and data",
    "section": "But Not everyone loves notebooks :(",
    "text": "But Not everyone loves notebooks :(\nNotebooks have their validish detractors I don’t like notebooks.- Joel Grus Youtube"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#notebooks-opinion",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#notebooks-opinion",
    "title": "Presentation: Communicating code and data",
    "section": "Notebooks Opinion",
    "text": "Notebooks Opinion\nAlthough notebooks have their validish detractors I don’t like notebooks.- Joel Grus Youtube I think if you approach them in the right way they are a super powerful tool.\nThe negatives seem to be:\n\nencourage bad practice in code (a genuine problem)\nissues around order of what cell is run (easily got around with good practice)\nissues around lack of auto complete (I don’t see the issue, use in visual studio autocomplete is there)\nno grammar/spelling correction\nissues with using git and version control\n\nthere are ways around this though\n\nanything else?"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#notebook-benefits",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#notebook-benefits",
    "title": "Presentation: Communicating code and data",
    "section": "Notebook Benefits",
    "text": "Notebook Benefits\n\nNotebooks are intuitive\n\nYou have the code then the result of the code\nCan add text or images\nAnd it’s linear\n\nCan get things up and working quickly\nAid with communicating code\nEncourages Writing\n\nand writing things down aids thinking in the now and understanding what you did and why in the future\n\nFastAI guide for better blogs\n\nEasy to convert code to a pipeline\nTreat it as a notebook\n\nin the same way an artist would have a sketchbook to help make final piece\n\nWith many companies moving towards Python/R from Excel and a varied level of skills.\n\n“Aid with communicating code” is particularly important"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-documenting-code",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-documenting-code",
    "title": "Presentation: Communicating code and data",
    "section": "Example: Documenting Code",
    "text": "Example: Documenting Code\n\nHere is my website for my research project on pesticides in UK food\nThis is not the same as documentation for a package but there are parallels\n\nThis does a few things:\n\nDocuments the analysis steps I have taken including the code and outputs\n\nUseful for data transparency, useability of the code if needs modifiying/adapting, and why I did XYZ\n\nProvides a way to present the data\n\nThere is a streamlit app, but sometimes I like to be able to see the code"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-tool-to-aid-learning",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-tool-to-aid-learning",
    "title": "Presentation: Communicating code and data",
    "section": "Example: Tool to aid learning",
    "text": "Example: Tool to aid learning\nA big area I have been using Jupyter Notebooks for is to aid learning\n\nIf you want to understand something it helps to write it down\nHaving the code next to it is a big advantage\nAnd if stored on github you can access it anywhere\n\nTensoflow cheat sheet"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-debugging-code",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-debugging-code",
    "title": "Presentation: Communicating code and data",
    "section": "Example: Debugging Code",
    "text": "Example: Debugging Code\n\nSince starting at ONS I have been working with understanding an existing project and latterly adding code to it\nThe project consists of multiple python files across several folders\n\nMy Python was good but lots of the functions and their useage weren’t immediately obvious to me\n\nbreak-points in VS Studio is really good to step through the code and work out what happens in the code.\n\nI had not used before with Python (but had lots with MATLAB), and it’s really useful\n\nBut it can be limited what you can do\n\ndifficult to probe code if want to write more than 1 line of code\nthe experience/knowledge exists as you go through it but no documentation to refer to later, e.g. function X does this when I give it Y etc"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-debugging-code-2",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-debugging-code-2",
    "title": "Presentation: Communicating code and data",
    "section": "Example: Debugging Code 2",
    "text": "Example: Debugging Code 2\n\nBy copying and pasting code into Jupyter cells I could see and document how they worked (e.g. changing inputs)\n\nThis (copying and pasting) would get around code changes too (which would be an issue if modules were just imported)\nbecause this was all done in Jupyter notebook I can have a ipynb code file and a html file showing how the code works\nI could even save a pickle file of the variables at a particularly point to understand how the code would work from this point"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#apps-overview",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#apps-overview",
    "title": "Presentation: Communicating code and data",
    "section": "Apps Overview",
    "text": "Apps Overview\nThere are many packages that can be used to convert python code to an app\nUsing Notebooks directly\n\nVoila\nmercury\n\nApps without notebooks\n\nPySimpleGUI\n\nSimple and useful but not the best for displaying data\n\nDash\n\nLooks really good, but also super complicated\n\nStreamlit\n\nEasy and looks good"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#voila",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#voila",
    "title": "Presentation: Communicating code and data",
    "section": "Voila",
    "text": "Voila\n\nVoila is relatively simple to use\nrun with something like voila .\\Excel_Voila.ipynb\nconverts notebook to an app\ncan use things like ipywidgets for interactivity\nthe reason I’m interested in it’s use is streamlit doesn’t seem to give flexibility to modify table output I’d like"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-overview",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-overview",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Overview",
    "text": "Streamlit Overview\n\nStreamlit is an open-source Python library that makes it easy to create and share beautiful, custom web apps for machine learning and data science. In just a few minutes you can build and deploy powerful data apps. So let’s get started!\n\nPrincipally used to create apps, but some of the functionality works well for code/data presentations"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-overview",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-overview",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: overview",
    "text": "Streamlit Functionality: overview\nStreamlit allows various functionality:\n\ntextbox\nimages/videos\ncharts/tables\nmenus/buttons\netc"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-streamlit_layout",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-streamlit_layout",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: streamlit_layout",
    "text": "Streamlit Functionality: streamlit_layout\nBut unlike some apps (am thinking MATLAB GUIs) you can’t create the look and functionality separately. So if you want something in a certain position it can be tricky. HTML can be used with st.markdown to give more control but it isn’t recommended to use by streamlit.\nInstead, to create the layout as you would like they have the following features:"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-columns-and-sidebar",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-columns-and-sidebar",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: columns and sidebar",
    "text": "Streamlit Functionality: columns and sidebar\nThe most useable are the first two: columns and sidebar\nColumns allows us to split the app vertically. The code is fairly simple:\nEither colL, colM, colR = st.columns(3) for 3 equal columns or to split columns with different sizes:\ncolL, _, colR = st.columns((10, 5, 20))\nwith colL:\n    st.write('On the left')\nwith colR:\n    st.write('On the right twice as big as left')\nst.sidebar just adds a sidebar to the app that can be hidden or shown.\nAnything in the sidebar is just prefixed by st.sidebar so:\nst.sidebar.write('I am in the sidebar')\nst.write('I am in the main app')\nst.sidebar.write('I am back in the sidebar')"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-html",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-html",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: html",
    "text": "Streamlit Functionality: html\nIt is possible to add various additional personalisations using html. - BUT it does come with security risks and so is [not recommended]](https://github.com/streamlit/streamlit/issues/152)\n\nAllows much more control over the layout of the app that can be useful for a presentation: - Can add a background image - Can add background color to a textbox - Control over positioning of widgets - lots more\nHTML is implementated using st.markdown with unsafe_allow_html=True inside the former"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-html-examples",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-html-examples",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: html examples",
    "text": "Streamlit Functionality: html examples\nadd background to a text box\ntext = \"Code Examples\"\n        st.markdown(f'<center><p style=font-family:\"Calibri\";background-color:#FFFFFF;color:#000000;font-size:42px;border-radius:10%><b>{text}</b></p></center>', unsafe_allow_html=True)\n\nOr to add a background image\nimport streamlit as st\nimport base64\n\n@st.cache(allow_output_mutation=True)\ndef get_base64_of_bin_file(bin_file):\n    with open(bin_file, 'rb') as f:\n        data = f.read()\n    return base64.b64encode(data).decode()\n\ndef set_png_as_page_bg(png_file):\n    bin_str = get_base64_of_bin_file(png_file) \n    page_bg_img = '''\n    <style>\n    .stApp {\n    background-image: url(\"data:image/png;base64,%s\");\n    background-size: contain;\n    background-repeat: no-repeat;\n    background-attachment: scroll; # doesn't work\n    }\n    </style>\n    ''' % bin_str\n    st.markdown(page_bg_img, unsafe_allow_html=True)\n    return"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-echo",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-echo",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: echo",
    "text": "Streamlit Functionality: echo\n\nSometimes you want your Streamlit app to contain both your usual Streamlit graphic elements and the code that generated those elements. That’s where st.echo() comes in\n\nEasier to display this by an example:\n\nIn the example above the right of the image is given below (st.columns is used, where the input for the function is found from the left column).\n\nst.echo is used with the with statement.\neverything within the with is printed to the screen and executed\n\nwith st.echo():\n    # Everything inside this block will be both printed to the screen\n    # and executed.\n\n    def do_pd_replace(text, text_search, text_sub):\n        col_name = \"Start string\"\n        df = pd.DataFrame(data=[text], columns=[col_name])\n\n        df[\"Final String\"] = df[col_name].replace(\n            text_search, text_sub, regex=True\n        )\n\n        st.dataframe(df)\n        st.write(f\"text_search = '{text_search}' and text_sub = '{text_sub}'\")\n        st.write(f\"Input string = '{text}'\")\n        st.write(f\"Output string = '{df['Final String'].values[0]}'\")\n\n    do_pd_replace(text, text_search, text_sub)"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-pages",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit-functionality-pages",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit Functionality: pages",
    "text": "Streamlit Functionality: pages\nBy simply creating a folder called pages and putting other streamlit .py files in the folder they can then be accessed in the sidebar.\n\nA main file needs to be outside the pages folder\nThe .py files in pages behave as if they were outside the folder (i.e. when loading files/functions)"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-streamlit-presentation",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#example-streamlit-presentation",
    "title": "Presentation: Communicating code and data",
    "section": "Example Streamlit Presentation",
    "text": "Example Streamlit Presentation\nVideo"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#what-i-have-used-to-convert-notebooks-to-html",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#what-i-have-used-to-convert-notebooks-to-html",
    "title": "Presentation: Communicating code and data",
    "section": "What I have used to convert notebooks to html",
    "text": "What I have used to convert notebooks to html\n\nfastpages\n\nI have used fastpages, but this is now deprecated and they are recommending the use of quarto\n\nquarto\n\nSo far I have found quarto really good and flexible (N.B. R works too)\nEasy to convert a notebook to multiple formats, including html, powerpoint, pdf, word doc\nBUT Quarto is not possible if installing from non pip sources is an issue (as far as I can tell currently)\n\nnbconvert is another option I tried\n\nbut it doesn’t seem to have the functionality of fastpages or quarto\n\nJupyter Books seems to be the best option within companies with installation issues\n\nMaybe not as good as quarto but it works!"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#others",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#others",
    "title": "Presentation: Communicating code and data",
    "section": "Others",
    "text": "Others\n\nI know some people use Sphinx,\n\nis recommended by QA\nFrom what I can tell sphinx on it’s own is not as easy to use as notebooks\nBut there is a jupyter extension nbsphinx\nJupyter Books uses Sphinx heavily under the hood\n\nnbdev\n\nI think is connected to quarto\n\nVoila\n\nVoilà turns Jupyter notebooks into standalone web applications.\nLooks good, bit like streamlit\nbut seems to interfere with other libraries\nmercury seems similar"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-html-other-formats",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-html-other-formats",
    "title": "Presentation: Communicating code and data",
    "section": "Creating html (& other formats)",
    "text": "Creating html (& other formats)\nQuarto\nInstallation is via a package i.e. .msi for Windows or .pkg for Mac. Which can cause issues.\nWorks with both ipynb and qmd files, which are both a mixture of markdown and executable code.\nThe only thing that needs to be done with the notebook is add a YAML block at the start of the notebook, like the following (raq not markdown was used):\n---\ntitle: \"Communicating code: Website\"\nsubtitle: \"Using the notebook format for a website\"\nauthor: \"Thomas H. Simm\"\nformat:\n  html:\n    toc: true\ntitle-slide-attributes:\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\njupyter: python3\n---\nWe can create different files from this .ipynb Jupyter notebook using the following code:\n\nquarto render testPres.ipynb --to pptx\nquarto render testPres.ipynb --to pdf\nquarto render testPres.ipynb --to html\nquarto render testPres.ipynb --to revealjs"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-1",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-1",
    "title": "Presentation: Communicating code and data",
    "section": "Quarto",
    "text": "Quarto\nFurther, formatting for projects (i.e. for website) can be done within the configuration file _quarto.yml\nproject:\n  type: website\n  output-dir: _site\n\nwebsite:\n  title: \"ThomasHSimm\"\n  favicon: /posts/Picture3.png\n  body-header: <img src=\"/posts/header2.png\" height=200>\n\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/ThomasHSimm\n      - icon: mortarboard-fill\n        href: https://scholar.google.com/citations?hl=en&user=HdPDn1sAAAAJ\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#jupyter-books",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#jupyter-books",
    "title": "Presentation: Communicating code and data",
    "section": "Jupyter Books",
    "text": "Jupyter Books\nWe can create different files from this .ipynb Jupyter notebook using the following code:\n\njupyter-book build .\\PesticideDocs\\\njupyter-book build <path-to-book>\njupyter-book build <path-to-book> --builder pdfhtml\njupyter-book build <path-to-book> --builder singlehtml\n\nThe only difference in notebook is that it needs to have One header in a markdown cell for the table of contents, e.g. \n# Title of page"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#configuration-file",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#configuration-file",
    "title": "Presentation: Communicating code and data",
    "section": "Configuration file",
    "text": "Configuration file\nA seperate files _config.yml is used to define how the html (or other) files will look\n# Book settings\n# Learn more at https://jupyterbook.org/customize/config.html\n\ntitle: Defra Pesticide Testing, Data Analysis\nauthor: Thomas Simm\nlogo: ONS-logo.png\nexclude_patterns: [_build, Thumbs.db, .DS_Store, \"**.ipynb_checkpoints\"]\n\n\n# Force re-execution of notebooks on each build.\n# See https://jupyterbook.org/content/execute.html\nexecute:\n  execute_notebooks: force\n\n# Define the name of the latex output file for PDF builds\nlatex:\n  latex_documents:\n    targetname: book.tex\n\n# Add a bibtex file so that we can create citations\nbibtex_bibfiles:\n  - references.bib\n\n# Information about where the book exists on the web\nrepository:\n  url: https://github.com/ThomasHSimm/Pesticide  # Online location of your book\n  path_to_book: docs  # Optional path to your book, relative to the repository root\n  branch: master  # Which branch of the repository should be used when creating links (optional)\n\n# Add GitHub buttons to your book\n# See https://jupyterbook.org/customize/config.html#add-a-link-to-your-repository\n# HTML-specific settings\nhtml:\n  favicon                   : \"_images/favicon.jpg\"  # A path to a favicon image\n  use_edit_page_button      : false  # Whether to add an \"edit this page\" button to pages. If `true`, repository information in repository: must be filled in\n  use_repository_button     : false  # Whether to add a link to your repository button\n  use_issues_button         : false  # Whether to add an \"open an issue\" button\n  use_multitoc_numbering    : true   # Continuous numbering across parts/chapters\n  extra_navbar              : Powered by <a href=\"https://jupyterbook.org\">Jupyter Book</a>\n                              <br>Home website <a href=\"https://thomashsimm.com/\">thomashsimm.com</a> # Will be displayed underneath the left navbar.\n  extra_footer              : \"\"  # Will be displayed underneath the footer.\n  google_analytics_id       : \"\"  # A GA id that can be used to track book views.\n  home_page_in_navbar       : true  # Whether to include your home page in the left Navigation Bar\n  baseurl                   : \"\"  # The base URL where your book will be hosted. Used for creating image previews and social links. e.g.: https://mypage.com/mybook/\n  comments:\n    hypothesis              : false\n    utterances              : false\n  announcement              : \"\" # A banner announcement at the top of the site."
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#table-of-content",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#table-of-content",
    "title": "Presentation: Communicating code and data",
    "section": "Table of content",
    "text": "Table of content\nAnd in addition to the config file a table of contents file is required _toc.yml:\n# Table of contents\n# Learn more at https://jupyterbook.org/customize/toc.html\n\nformat: jb-book\nroot: intro\nchapters:\n- file: Pesticide_Plots\n- file: References\n- file: UK_areas\n- file: using_jupyter_books"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-webpage-from-this",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-webpage-from-this",
    "title": "Presentation: Communicating code and data",
    "section": "Creating a webpage from this",
    "text": "Creating a webpage from this\nTakes about 30 mins including installing the chosen converter. (But can be done much quicker)\n\ncreate a Github repo for your website\nchoose the converter (e.g. Jupyter Books)\n\nAnd follow their instructions\n\ngo to settings -> Pages within the repo\n\nfew options to do\n\nOptional: add your own website url to it\n\nLink how to do this here\nIn Quarto a command from your PC in the repo, publishes the website:\nquarto publish quarto-pub\nOr equivalently with Jupyter Books:\nghp-import -n -p -f _build/html"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-directly-from-the-repo",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-directly-from-the-repo",
    "title": "Presentation: Communicating code and data",
    "section": "Creating directly from the repo",
    "text": "Creating directly from the repo\nIf we instead want to convert notebook files directly from a repo to create a website then this can be done with Netlify.\nThis is useful if using Gitlab (i.e. not Github) or don’t want all the extra html files cluttering the repo.\nSteps:\nhttps://jupyterbook.org/en/stable/publish/netlify.html\n\nSign up and connect Github/Gitlab\nAdd a requirements.txt file and also toc.yml to directory\nOn netlify -> Add new site -> import from an existing repo\nInsert something like below\n\nN.B. the command:\npip install -r requirements.txt && jupyter-book build .\nand folder location"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#on-netlify",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#on-netlify",
    "title": "Presentation: Communicating code and data",
    "section": "On netlify",
    "text": "On netlify\n\nExample:\n\nGitlab repo\nResulting website https://thomashsimm.netlify.app/intro.html"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-presentations",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-presentations",
    "title": "Presentation: Communicating code and data",
    "section": "Quarto Presentations",
    "text": "Quarto Presentations\nQuarto supports a variety of formats for creating presentations, including:\n\nrevealjs — reveal.js (HTML)\npptx — PowerPoint (MS Office)\nbeamer — Beamer (LaTeX/PDF)\n\nI’ll consider the first two"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-powerpoint-overview",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#quarto-powerpoint-overview",
    "title": "Presentation: Communicating code and data",
    "section": "Quarto PowerPoint overview",
    "text": "Quarto PowerPoint overview\nThe steps to make a PowerPoint presentation from a notebook:\n\nCreate the inbuilt template.pptx file\nAdjust it to match your own template\nAt the top of the notebook insert format for pptx including the template file\nChoose how you will define a new page\nYou will probably need to manually check the slides and adjust as required\n\nespecially for interactive content and code"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-the-template",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-the-template",
    "title": "Presentation: Communicating code and data",
    "section": "Creating the template",
    "text": "Creating the template\n(Office info correct for Office 365 Feb 2023, Version 2301 Build 16.0.16026.20002)\nIf your workplace has a custom template or you have one you always use, you can incorporate this into quarto.\nHowever, quarto is quite specific on the form this template takes, and requires the following elements\n\nTitle Slide\nTitle and Content\nSection Header\nTwo Content\nComparison\nContent with Caption\nBlank"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template",
    "title": "Presentation: Communicating code and data",
    "section": "Creating a ppt template",
    "text": "Creating a ppt template\nBy selecting Layout from the Home tab in powerpoint the different layouts can be seen\n\nThey can then be modified by going to View tab - Slide Master."
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template-2",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template-2",
    "title": "Presentation: Communicating code and data",
    "section": "Creating a ppt template 2",
    "text": "Creating a ppt template 2\nIf using your own template you will need to match the names of the slides given above. These can be found by hovering over the slides on the left or right clicking on one and selecting “Rename Layout”"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template-3",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#creating-a-ppt-template-3",
    "title": "Presentation: Communicating code and data",
    "section": "Creating a ppt template 3",
    "text": "Creating a ppt template 3\nAlternatively, create a custom template using quarto and then modify this. The following command creates the template:\nquarto pandoc -o template.pptx --print-default-data-file reference.pptx\nThen go to View tab - Slide Master and modify each slide layout.\nNote if you are trying to match a template, some tips: - go to Design -> Slide Size and match this to your template - when View tab - Slide Master is selected go to first tab (see above it will be left indented) on one you are copying from and select all on this then paste to the new template - these will be background images and other things that want to be passed to all slides - Check other slides for images and font-styles etc to match to the new template"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#load-the-template",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#load-the-template",
    "title": "Presentation: Communicating code and data",
    "section": "Load the template",
    "text": "Load the template\nTo load the template the first cell in the notebook needs to be modified as follows to reference the template.pptx file.\nformat:\n  pptx:\n    reference-doc: template.pptx\n    slide-level: 2\nIn addition, we can also specify here the rule by which a new slide is defined. If slide-level: 2 is used a new slide is defined by “##’ and a new section header by ‘#’. So if we used ‘###’ this would be a heading within the slide.\nIf slide-level: 1 is used a new slide is defined by “#’ and ‘##’ this would be a heading within the slide (this is normally the default)."
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#check-the-slides",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#check-the-slides",
    "title": "Presentation: Communicating code and data",
    "section": "Check the slides",
    "text": "Check the slides\nI have found creation of slides to powerpoint more prone to strange results than if .doc/.pdf/.html are used.\nSo check the slides, see if interactive content or code has been included (probably not) and if the slide content goes outside the slide.\n\nIn the example above - There is overlap of text on a slide - Strange ouput of a slide - Code output not displayed"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#adding-style-to-revealjs",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#adding-style-to-revealjs",
    "title": "Presentation: Communicating code and data",
    "section": "Adding style to revealjs",
    "text": "Adding style to revealjs\nA simple way to add template like details to a revealjs file is to add a style.css sheet.\nIn the example below, the style sheet adds logo.png to the bottom right of each sheet\nThe file style.css looks like this:\n.reveal .slide-logo {\n  display: block;\n  position: fixed;\n  top: unset !important;\n  left: unset !important;\n  bottom: 50px;\n  right: 12px;\n  height: 100px !important;\n  width: 100x !important;\n  max-width: unset !important;\n  max-height: unset !important;\n}"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#adding-style-to-revealjs-1",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#adding-style-to-revealjs-1",
    "title": "Presentation: Communicating code and data",
    "section": "Adding style to revealjs",
    "text": "Adding style to revealjs\nAnd the revealjs part at the top of the jupyter notebook looks like this\nrevealjs:\n    slide-number: true\n    height: 1080\n    width: 1920\n    logo: logo.png\n    css: style.css\nSo this would then look like the following, with the logo (logo.png) in the bottom right, and size and positioning given by the css file"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#what-the-revealjs-file-looks-like",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#what-the-revealjs-file-looks-like",
    "title": "Presentation: Communicating code and data",
    "section": "What the revealjs file looks like",
    "text": "What the revealjs file looks like\nVideo"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#excel-files",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#excel-files",
    "title": "Presentation: Communicating code and data",
    "section": "Excel files",
    "text": "Excel files\n\nChatGPT: What are the problems of Excel and xlsx files?\n\n\nLimited scalability: Excel has a limit on the number of rows and columns it can handle effectively.\nInaccurate data: The manual nature of data entry in Excel can lead to errors and inaccuracies.\nFragility: Complex Excel spreadsheets can break easily if any formula or cell reference is altered.\nLack of security: Excel files are vulnerable to unauthorized access and malicious attacks.\nSlow performance: Large and complex Excel files can become slow to open and use, leading to decreased productivity.\nCompatibility issues: XLSX files may not be compatible with older versions of Excel, or with other software applications.\nLimited collaboration: Sharing Excel files and making changes to them can be difficult, especially when multiple people are involved.\n\nFor me it is the Slow performance alongside: (a) we are doing the data manipulation outside Excel anyway and (b) having to have another application open"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#what-aspect-of-tables-i-am-considering",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#what-aspect-of-tables-i-am-considering",
    "title": "Presentation: Communicating code and data",
    "section": "What aspect of tables I am considering",
    "text": "What aspect of tables I am considering"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#loading-data",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#loading-data",
    "title": "Presentation: Communicating code and data",
    "section": "Loading data",
    "text": "Loading data\n.ods with Excel\nAbout 10 s to open 3 ods files with Excel\n.ods converted to html in firefox browser\nAbout 6 s to open 3 converted ods files in a browser\n.ods converted to html firefox browser no new tabs\nAlmost instant when open converted ods files in same browser"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#convert-xlsx-to-html",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#convert-xlsx-to-html",
    "title": "Presentation: Communicating code and data",
    "section": "Convert xlsx to html?",
    "text": "Convert xlsx to html?\n\nOpening xlsx files in Excel is slow\nConverting to html if we don’t want to edit could be an option\nIf we are moving to Python/R aren’t non-Excel options worth considering??\n\nConverting xlsx files to html\n\nSeems the most obvious course\nBut it doesn’t seem that easy with code\n\nbut easy within Excel"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#pandas",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#pandas",
    "title": "Presentation: Communicating code and data",
    "section": "pandas",
    "text": "pandas\n\nSince (in Python) we are mainly working with pandas. Let’s consider how pandas outputs can be modified.\npandas options\n\nSome code functionality\n# precision of all columns\npd.set_option(\"display.precision\", 2)\n# Or map as a string\ndf2['amount_pc_str'] = df2['amount_pc'].map(lambda x: '%.3f' % x)\n# some other options\npd.set_option('max_colwidth', 20)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', 0)"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#pandas-basic",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#pandas-basic",
    "title": "Presentation: Communicating code and data",
    "section": "pandas basic",
    "text": "pandas basic\n\n\n\n\n\n\n  \n    \n      \n      sample_id\n      date_of_sampling\n      description\n      country_of_origin\n      retail_outlet\n      address\n      brand_name\n      packer_/_manufacturer_/_importer\n      product\n      address_postcode\n      packer_postcode\n      address_area\n      packer_area\n      chem_name\n      amount_detected\n      mrl\n      amount_pc\n    \n  \n  \n    \n      0\n      1958/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Asda\n      Creechbarrow Road, Taunton TA1 2AN\n      Asda\n      Asda Stores Ltd Leeds, UK LS11 5AD\n      Apple\n      TA1 2AN\n      LS11 5AD\n      Somerset\n      West Yorkshire\n      boscalid\n      0.03\n      2.0\n      0.015\n    \n    \n      1\n      1958/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Asda\n      Creechbarrow Road, Taunton TA1 2AN\n      Asda\n      Asda Stores Ltd Leeds, UK LS11 5AD\n      Apple\n      TA1 2AN\n      LS11 5AD\n      Somerset\n      West Yorkshire\n      pyraclostrobin\n      0.01\n      0.5\n      0.020\n    \n    \n      2\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      boscalid\n      0.05\n      2.0\n      0.025\n    \n    \n      3\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      flonicamid (sum)\n      0.02\n      0.2\n      0.100\n    \n    \n      4\n      0230/2016\n      2016-08-08\n      Bramley Apples\n      UK\n      Co-op\n      Northgate, Louth LN11 0LT\n      Co-op\n      Co-operative Group Ltd Manchester M60 0AG\n      Apple\n      LN11 0LT\n      M60 0AG\n      Lincolnshire\n      Greater Manchester\n      pyraclostrobin\n      0.03\n      0.5\n      0.060\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      35155\n      2858/2020 Organic\n      2020-10-20\n      Organic Sweet Potatoes\n      Spain\n      Tesco\n      300 Beverley Way, New Malden KT3 4PJ\n      Tesco\n      Tesco Stores Ltd Welwyn Garden City AL7 1GA\n      Sweet_Potatoes_Q4_(BNA)\n      KT3 4PJ\n      AL7 1GA\n      Greater London\n      Hertfordshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35156\n      0562/2020 Organic\n      2020-10-05\n      Organic Duchy Sweet Potatoes\n      Egypt\n      Waitrose\n      Mill Lane, Swindon SN1 7BX\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      SN1 7BX\n      RG12 8YA\n      Wiltshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35157\n      0563/2020\n      2020-10-05\n      Sweet Potatoes\n      USA\n      Waitrose\n      Mill Lane, Swindon SN1 7BX\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      SN1 7BX\n      RG12 8YA\n      Wiltshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35158\n      2601/2020\n      2020-10-14\n      Sweet Potatoes\n      USA\n      Waitrose\n      Ossington Way, Newark NG24 1FF\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      NG24 1FF\n      RG12 8YA\n      Nottinghamshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n    \n      35159\n      2601/2020\n      2020-10-14\n      Sweet Potatoes\n      USA\n      Waitrose\n      Ossington Way, Newark NG24 1FF\n      Waitrose\n      Waitrose Ltd Doncastle Road, Bracknell, Berksh...\n      Sweet_Potatoes_Q4_(BNA)\n      NG24 1FF\n      RG12 8YA\n      Nottinghamshire\n      Berkshire\n      0\n      0.00\n      0.0\n      0.000\n    \n  \n\n35160 rows × 17 columns"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#pandas-overview",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#pandas-overview",
    "title": "Presentation: Communicating code and data",
    "section": "pandas overview",
    "text": "pandas overview\n\nUsing pandas we can control various outputs\nBut these still need a format to display within\nAnd display functionality is not easy\n\nOr convert to a html file\ndf2.iloc[:500].to_html('df2_500.html')\nBut using a style sheet as shown in stack overflow by Parfait"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#ipydatagrid",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#ipydatagrid",
    "title": "Presentation: Communicating code and data",
    "section": "ipydatagrid",
    "text": "ipydatagrid\nhttps://github.com/bloomberg/ipydatagrid"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code",
    "title": "Presentation: Communicating code and data",
    "section": "itables code",
    "text": "itables code\nfrom itables import init_notebook_mode\n\nimport itables\ninit_notebook_mode(all_interactive=True)\n\nitables.show(df2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      sample_id\n      date_of_sampling\n      description\n      country_of_origin\n      retail_outlet\n      address\n      brand_name\n      packer_/_manufacturer_/_importer\n      product\n      address_postcode\n      packer_postcode\n      address_area\n      packer_area\n      chem_name\n      amount_detected\n      mrl\n      amount_pc\n    \n  Loading... (need help?)"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#dash",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#dash",
    "title": "Presentation: Communicating code and data",
    "section": "Dash",
    "text": "Dash\nhttps://dash.plotly.com/datatable\n\nDownloaded 800,000 times per month, Dash is the original low-code framework for rapidly building data apps in Python, R, Julia, and F# (experimental).\n\nhttps://medium.com/plotly/introducing-jupyterdash-811f1f57c02e\n\n\nOSError: Address 'http://127.0.0.1:8050' already in use.\n    Try passing a different port to run_server."
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#streamlit",
    "title": "Presentation: Communicating code and data",
    "section": "Streamlit",
    "text": "Streamlit\n\nA faster way to build and share data apps\n\n\nDash can be run within a notebook but is principally an app.\nStreamlit is a similar app.\nBut much easier to code.\n\nimport pandas as pd\nimport streamlit as st\nall_dfs = pd.read_csv(\"./data/combined_df.csv\")\nst.dataframe(all_dfs.head())\n# Or\nst.tables(all_dfs)"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#and-more",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#and-more",
    "title": "Presentation: Communicating code and data",
    "section": "And more",
    "text": "And more\nDataTables\n\nDataTables is a plug-in for the jQuery Javascript library. It is a highly flexible tool, built upon the foundations of progressive enhancement, that adds all of these advanced features to any HTML table.\n\nJupyter widgets\nIf you are looking for Jupyter widgets, have a look at (taken from https://mwouts.github.io/itables/references.html) - QGrid by Quantopian - IPyaggrid by Louis Raison and Olivier Borderies - IPySheet by QuantStack."
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#more-details-on-itables",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#more-details-on-itables",
    "title": "Presentation: Communicating code and data",
    "section": "More details on itables",
    "text": "More details on itables\nFrom my brief review I found itables the best package\n\nIt works\nIt gives lots of control of table output to be consistent with good-practice\n\nColumn width\nNumber formatting\nColumn alignment\n\nAlongside\n\nSearch\nColumn ordering\nHow many rows are shown\nScrolling options\netc"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code1",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code1",
    "title": "Presentation: Communicating code and data",
    "section": "itables code1",
    "text": "itables code1\ndef _indi_columnDefs(cols, format,col_width):\n    if 'num_format' in format:\n        if format['num_format'] == \"#,##0\":\n            format_str = \"',', '.', 0, ''\"\n        elif format['num_format'] ==  '0.0':\n            format_str = \"',', '.', 1, ''\"\n        else: \n            format_str = \"',', '.', 3, ''\"\n    else:\n        format_str = \"',', '.', 3, ''\"\n    columnDefs= {\n            \"targets\": cols,\n            \"className\":f\"dt-{format['align']}\",\n            \"render\": JavascriptCode(f\"$.fn.dataTable.render.number({format_str})\"),\n            \"width\": f\"{col_width}px\",\n        }\n    return columnDefs"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code2",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code2",
    "title": "Presentation: Communicating code and data",
    "section": "itables code2",
    "text": "itables code2\nstyle = {\n    \"general\": {\n        \"table_output\" :{\n            \"pct_cols\" : {\n                \"regex_defined\": [\"%\" , \"[Pp]ercentage\"],\n                \"format\": {\"num_format\": \"0.0\", \"align\": \"right\"}\n            },\n            \"total_cols\" : {\n                    \"regex_defined\": [\"[Tt]otal\" ],\n                    \"format\": { \"num_format\": \"0.0\", \"align\": \"center\"}\n            },\n            \"code_cols\" : {\n                \"regex_defined\": [\"[Cc]ode\"],\n                \"format\": { \"align\": \"left\"}\n            },\n            \"_else\" : {\n                \"regex_defined\": [],\n                \"format\": {\"num_format\": \"#,##0\", \"align\": \"right\"}\n            }\n        \n        },\n        \"col_width\": 130.0\n    }\n}"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code3",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code3",
    "title": "Presentation: Communicating code and data",
    "section": "itables code3",
    "text": "itables code3\n\ndef _create_style_col(style: dict, df: pd.DataFrame):\n    style_col = {}\n    colsAll=[]\n    for keys in style['general']['table_output'].keys():\n        if keys !='_else':\n            # print(\">>\",keys)\n            cols=[]\n            for i,column in enumerate(df.columns):\n                # print(column)\n                if [True for reg in style['general']['table_output'][keys]['regex_defined'] if re.search(reg,column)]:\n                    # print(i,column)\n                    cols.append(i)\n            # print(cols)\n            colsAll = colsAll + cols\n            style_col[keys]=cols\n\n    style_col['_else'] = [ i for i,column in enumerate(df.columns) if i not in colsAll]\n\n    return style_col"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code4",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code4",
    "title": "Presentation: Communicating code and data",
    "section": "itables code4",
    "text": "itables code4\ndef create_columnDefs(style: dict, df: pd.DataFrame):\n    \n    style_col = _create_style_col(style, df)\n    columnDefs = []\n    for keys in style['general']['table_output'].keys():\n        columnDefs.append( _indi_columnDefs(style_col[keys],\n                                            style['general']['table_output'][keys]['format'],\n                                            style['general']['col_width']) )\n    return columnDefs"
  },
  {
    "objectID": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code5",
    "href": "posts/Communicating_Code/PresentationOfCommunicatingCode.html#itables-code5",
    "title": "Presentation: Communicating code and data",
    "section": "itables code5",
    "text": "itables code5\n\ncolumnDefs= create_columnDefs(style, data)\nshow(\n    data,\n    # style=\"table-layout:auto;width:80%;float:left\",\n    classes=\"display\",\n    \n    # specify how many rows\n    lengthMenu = [25,100,-1],\n    # or to scroll through data\n    scrollX=True,\n    # scrollY=\"800px\", \n    scrollCollapse=True, \n    # paging=False,\n\n    style=f\"width:{style['general']['col_width']*10}px\",\n    autoWidth=False,\n\n    # add footer\n    # footer=True,\n    \n    columnDefs=columnDefs,\n    tags =f'<caption style=\"caption-side: Bottom\">File: {files[0]} and Tab: {ansa.value}</caption>'\n)"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#general",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#general",
    "title": "TensorFlow cheat sheet",
    "section": "General",
    "text": "General\nLibrary websites:\nkeras.io\ntensorflow.org"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#courses",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#courses",
    "title": "TensorFlow cheat sheet",
    "section": "Courses",
    "text": "Courses\nI have tried both of the following courses: DeepLearning.AI TensorFlow Developer Professional Certificate and TensorFlow 2 for Deep Learning Specialization.\n\nDeepLearning.AI TensorFlow Developer Professional Certificate\nTensorFlow 2 for Deep Learning Specialization\n\nThe Tensorflow2 course is a bit longer and goes into more depth, although there are additional extended courses for the deeplearning one. The deeplearning one can be done within the current 7 days trail period of coursera. The Tensorflow2 course is tricky to do in this timeframe. This is due to more material, the harder coursework, and waiting for capstone projects to be marked.\nIn the end I only did the first course of Tensorflow2 as I found the tests had material that wasn’t explained within the course and I found the lectures lacking in detail and the instructors became increasingly boring. I gave up after getting to the capstone in course 2 (of 3) when they asked a question about an NLP network that was never explained anywhere. However, the coursework is a good challenge, so it may be worth doing the course for this alone and learning from other sources in addition to this one.\nI prefered the DeepLearning courses as they were more in depth and didn’t assume as much prior knowledge, and the presentation was better. I am currently working through the follow-up course TensorFlow: Advanced Techniques Specialization and given time will do the NLP and MLOps courses.\nSome Others:\nOne by Udacity Intro to TensorFlow for Deep Learning is being offered for free and looks okay too.\nTensorFlow example tutorials written as Jupyter notebooks and run directly in Google Colab—a hosted notebook environment that requires no setup. Click the Run in Google Colab button. Part of the TensorFlow resources."
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#resources",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#resources",
    "title": "TensorFlow cheat sheet",
    "section": "Resources",
    "text": "Resources\n\nTensorFlow’s website recommendations\nFrançois Chollet\n\nHis book Deep Learning with Python, Second Edition can be read online.\n\nDeep learning book by Ian Goodfellow and Yoshua Bengio and Aaron Courville\n\navailable free online\n\nProbabilistic Programming & Bayesian Methods for Hackers\n\navailable online"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#model-creations",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#model-creations",
    "title": "TensorFlow cheat sheet",
    "section": "Model creations",
    "text": "Model creations\nThe easiest way to create a model in Keras is through keras.Sequential, which creates a neural network as a stack of layers.\nSo in the examplel below - the 1st layer has units = 4 and input_shape=2 with a relu activation function - the 2nd layer has units = 3 with a relu activation function - the 3rd layer has units = 1\nThe 3rd layer is the output layer. Since there is no activation function this would be a regression problem to predict one value.\n\nFor non sequential models or with multiple inputs/outputs see functional API\n\nTabular Data\nhttps://www.kaggle.com/code/thomassimm/premier-league-predictions-using-tensorflow\n\nmodel = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(512//8,activation='relu'),\n        tf.keras.layers.Dense(1,activation='sigmoid')        \n    ])\n\n\n\nImage Data\n\nmodel = tf.keras.models.Sequential([ \n          tf.keras.layers.Convolution2D( 64,(3,3),activation='relu',input_shape=(28,28,1) ),\n          tf.keras.layers.MaxPool2D(2,2),\n          tf.keras.layers.Flatten(),\n          tf.keras.layers.Dense(256//2,activation='relu'),\n          tf.keras.layers.Dense(1,activation='sigmoid') ])\n\n\n\nLanguage Data\nThe standard language model starts with an embedding layer, this then needs to be flattened to a vector, then we can add a dense layer before an output layer.\nThe Embedding layer creates a vector-space for the text data. So for example, the words beautiful and ugly may be in opposite directions. And words such as cat and kitten may be close together in vector space.\nGlobalAveragePooling1Dcan be replaced by Flatten()\n\nmodel = tf.keras.Sequential([ \n    tf.keras.layers.Embedding(num_words,embedding_dim,input_length=maxlen),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(5,'softmax')\n])\n\nThe model above does not take account for the order of words,\nIf we want to do this we can insert an additional layer after the embedding layer. For example, by using the LSTM model as below\n\nmodel_lstm= tf.keras.Sequential([\n    tf.keras.layers.Embedding(VOCAB_SIZE,EMBEDDING_DIM,input_length=MAXLEN),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')   \n])\n\nWe can even insert a conolution layer after the embedding instead\ntf.keras.layers.Conv1D(128,5,activation='relu')\nFor two consecutive layers of RNNs use return_sequences=True\n\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#compile-the-model",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#compile-the-model",
    "title": "TensorFlow cheat sheet",
    "section": "Compile the model",
    "text": "Compile the model\nTo compile the model, need to define the following:\n\nthe optimizer to use, i.e. how to update the parameters to improve model during fitting\nthe loss, i.e. what defines the goodness of the fit\nany metrics to record\n\n\nopt = keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(\n    optimizer=opt,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#evaluate-predict-the-model",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#evaluate-predict-the-model",
    "title": "TensorFlow cheat sheet",
    "section": "Evaluate / Predict the model",
    "text": "Evaluate / Predict the model\ntest_loss, test_accuracy = model.evaluate(scaled_test_images,\ntf.keras.utils.to_categorical(test_labels),\nverbose=0)\nand more or less outputs depending on metrics used\npred = model.predict(X_sample)"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#saving-and-loading",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#saving-and-loading",
    "title": "TensorFlow cheat sheet",
    "section": "Saving and Loading",
    "text": "Saving and Loading\n\nSaving / Loading weights\n\nmodel_weights_file='my_file'\n\nmodel.save_weights(model_weights_file)\n\nmodel.load_weights(model_weights_file)\n\n\n# All the model\n\nmodel.save('saved_model/my_model')\n\nnew_model = tf.keras.models.load_model('saved_model/my_model')"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#callbacks",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#callbacks",
    "title": "TensorFlow cheat sheet",
    "section": "Callbacks",
    "text": "Callbacks\nwithin model.fit(....)\ncallbacks=[callback_function]\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n\nEarlyStopping\n\nto stop the model early if some conditions are met\n\nModelCheckpoint\n\nsave the model/model weights (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)\nmain data stored similar to ‘.data-00000-of-00001’\nhttps://www.tensorflow.org/tutorials/keras/save_and_load#what_are_these_files\nCan give file names with variables using {}\n\nval_loss\nval_accuracy\nbatch\nepoch\n\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    min_delta=0.0001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n    monitor='val_binary_accuracy',\n)\n\nfilepath = os.path.join(cwd,'checkpoints_every_epoch/checkpoint.{epoch}.{batch}')\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n        save_weights_only=True,\n        save_best_only=True,\n        filepath=filepath,\n    )"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#overfitting-strategies",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#overfitting-strategies",
    "title": "TensorFlow cheat sheet",
    "section": "Overfitting strategies",
    "text": "Overfitting strategies\n\nDropout\nThe idea behind dropout is to randomly drop out some fraction of a layer’s input units every step of training, making it much harder for the network to learn those spurious patterns in the training data that leads to overfitting.\nInstead, it has to search for broad, general patterns, whose weight patterns tend to be more robust.\nYou could also think about dropout as creating a kind of ensemble of networks like with RandomForests.\nExample useage, apply 30% dropout to the next layer\nlayers.Dropout(rate=0.3),\nlayers.Dense(16)\nExample taken from kaggle https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization\n\n\n\nBatch Normalization\nNormalization is important in neural networks, it can really significantly improve the results of the values of the input and output are between 0 and 1.\nIn contrast, it is not important in other models such as random forests. Hence, the input data is often normalised such as train_datagen = ImageDataGenerator(rescale=1./255.) in image models.\nSo if it is good to normalize the input data it can also be good to normalize the layers of the network. This can be done with a BatchNormalization layer.A batch normalization layer looks at each batch as it comes in, first normalizing the batch with its own mean and standard deviation, and then also putting the data on a new scale with two trainable rescaling parameters. Batchnorm, in effect, performs a kind of coordinated rescaling of its inputs.\nAs stated in https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization batchnorm: - batchnorm is most often added as an aid to the optimization process - but it can sometimes also help prediction performance - Models with batchnorm tend to need fewer epochs to complete training. - And can fix various problems that can cause the training to get “stuck”. - it can be used at almost any point in a network.\nlayers.Dense(16, activation='relu'),\nlayers.BatchNormalization(),\n… or between a layer and its activation function:\nlayers.Dense(16),\nlayers.BatchNormalization(),\nlayers.Activation('relu'),\n… Or if you add it as the first layer of your network it can act as a kind of adaptive preprocessor like Sci-Kit Learn’s StandardScaler."
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#multiple-inputs-and-outputs",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#multiple-inputs-and-outputs",
    "title": "TensorFlow cheat sheet",
    "section": "Multiple inputs and outputs",
    "text": "Multiple inputs and outputs\n3 inputs and 2 outputs. Simple model\nInputs: - temp_train - nocc_train - lumbp_train\nOutputs: - out1_train - out2_train\nThings to note: - inputs in the model is a list of the Input() parts - concatentate is used with the input list to provide input to the next layers of the model - outputs in the model is a list of the output layers - When compiling use dictionary to set loss and metrics to each output - or lists ['binary_crossentropy','binary_crossentropy'] - When fitting, for the inputs/outputs either: - provide a list of the inputs [temp_train,nocc_train, lumbp_train] - give as a dict {'layer_name':variable_name}\n\n## Functional: multiple inputs\n# N.B. lowercase 'c' concatenate\nimport tensorflow as tf \nfrom tensorflow.keras.layers import Input, Dense, concatenate\ninput_shape=(1,)\n\n# get individual inputs\ninputs_temp = Input(shape=input_shape,name='temp')\ninputs_nocc = Input(shape=input_shape,name='nocc')\ninputs_lumbp = Input(shape=input_shape,name='lumbp')\n\n# combine them\ninput_list = [inputs_temp,inputs_nocc,inputs_lumbp]\ninput_layer =concatenate(input_list)\n\n# add inputs to the model for two outputs\noutput_pred1  = Dense(2,activation='sigmoid',name='out_1')(input_layer)\noutput_pred2 = Dense(2,activation='sigmoid',name='out_2')(input_layer)\n\n# output layer\noutput_list = [output_pred1, output_pred2]\n\n# create the model object\nmodel = tf.keras.Model(inputs=input_list, outputs=output_list )\n\n# show the model\nmodel.summary()\n\n# Compile\nmodel.compile(\n        optimizer='SGD',\n        loss={'out_1':'binary_crossentropy',\n              'out_2':'binary_crossentropy'},\n        metrics={'out_1':['accuracy'],\n                 'out_2':['accuracy']},\n        loss_weights=[1,0.2]\n        )\n\ntf.keras.utils.plot_model(model)\n\n\n# Define training inputs and outputs\ninputs_train = {'temp': temp_train, 'nocc': nocc_train, 'lumbp': lumbp_train}\noutputs_train = {'out_1': out1_train, 'out_2': out2_train}\n\n# fit the model\nmodel.fit(inputs_train,outputs_train)"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#inception-images",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#inception-images",
    "title": "TensorFlow cheat sheet",
    "section": "Inception (images)",
    "text": "Inception (images)\n\nLoad the model pre-trained weights\nImport the model architecture\nGive the model the input shape for data\nLoad the weights into the model\nFreeze all the layers\nPick out the front part of the model, as the layers to the end are more specialized\nAdd extra layers to the model that can be fitted to\n\n\n# 1- Download the inception v3 weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n# 2- Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# 3- create the model and load in the weights\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n                                  include_top = False, \n                                  weights = None) \n\n# 4- load weights into the model\npre_trained_model.load_weights(local_weights_file)\n\n# 5- Make all the layers in the pre-trained model non-trainable\nfor layers in pre_trained_model.layers:\n    layers.trainable = False\n    \n# 6- Pick out part of the model\nlast_desired_layer = pre_trained_model.get_layer('mixed7')    \nlast_output = last_desired_layer.output\n\n# 7- Add extra layers to the model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)  \n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024,activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1,activation='sigmoid')(x) \n\n# Create the complete model by using the Model class\nmodel = Model(inputs=pre_trained_model.input, outputs=x)\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001), \n            loss = 'binary_crossentropy',\n            metrics = ['accuracy'])"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#summary-info-of-model",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#summary-info-of-model",
    "title": "TensorFlow cheat sheet",
    "section": "Summary / info of model",
    "text": "Summary / info of model\nmodel.summary()\nGet summary of the model"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#class-or-function---metrics-and-losses",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#class-or-function---metrics-and-losses",
    "title": "TensorFlow cheat sheet",
    "section": "Class or Function - Metrics and Losses",
    "text": "Class or Function - Metrics and Losses\nIn general, classes use camel formatting CategoricalAccuracy whereas function use underscores and lower case categorical_accuracy and sometimes initials MAE\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#low-level-handling-of-metrics",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#low-level-handling-of-metrics",
    "title": "TensorFlow cheat sheet",
    "section": "Low level handling of metrics",
    "text": "Low level handling of metrics\n\nmetric.update_state() to accumulate metric stats after each batch\nmetric.result get current value of metric to display\nmetric.reset_state() to reset metric value typically at the end of epoch"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#categorical-binary-versus-multiple",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#categorical-binary-versus-multiple",
    "title": "TensorFlow cheat sheet",
    "section": "Categorical: Binary versus Multiple",
    "text": "Categorical: Binary versus Multiple\nFor categorical data there is a slight difference between if there are only 2 categories or more.\nGoing from binary to multiple: - We need to change activation in model from sigmoid to softmax in final Dense layer - Change loss function from binary_crossentropy to categorical_crossentropy in compile - Making data one-hot encoded, i.e. columns for each outcome - Or use SparseCategoricalCrossentropy\n\nmodel_binary = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(1,activation='sigmoid')        \n    ])\n\nmodel_multi = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(4,activation='softmax')        \n    ])\n\n\nmodel_binary.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n\nmodel_multi.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n\n\n# One-hot encoding method\n\ny_binary =[1,0,0,0,0,0,1,1,1,1,0,1,0,1]\n\ny_multi=[1,2,4,6,1,3,4,2,4,2,5,2,1,4,2,1]\ny_multi=tf.keras.utils.to_categorical(y_multi)\ny_multi\n\narray([[0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)\n\n\nAlternatively, with output data like [0, 1, 4, 0, 2, 3, 3, 0, …]\nuse: - SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(\n                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer='adam',\n                 metrics=['accuracy'])"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#learning-rate",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#learning-rate",
    "title": "TensorFlow cheat sheet",
    "section": "Learning rate",
    "text": "Learning rate\nFind the best learning rate by using callbacks\nThe learning rate to use on the data below would be where the loss is low (y-axis) but not too close to where it increases or is unstable.\nSo for this on the downward part of the curve between 10E-6 and 10E-5\n\n# Set the learning rate scheduler\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch / 20) )\n    \n# Set the training parameters\nmodel_tune.compile(loss=\"mse\", optimizer=optimizer)\n    \n# train the model\nhistory = model_tune.fit(dataset, epochs=100, callbacks=[lr_schedule])\n\n# plot the results\n# Define the learning rate array\nlrs = 1e-8 * (10 ** (np.arange(100) / 20))\n\n# Plot the loss in log scale\nplt.semilogx(lrs, history.history[\"loss\"])"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#lambda-functions",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#lambda-functions",
    "title": "TensorFlow cheat sheet",
    "section": "lambda functions",
    "text": "lambda functions\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda\ntf.keras.layers.Lambda(     function, output_shape=None, mask=None, arguments=None, **kwargs )\nAdd a function that works on the data within the model\n\n# expand the dimensions\ntf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n                      input_shape=[window_size])\n\n# make the output larger (can be useful if predicting to large values, but previous layer have activation function so values are close to 1)\ntf.keras.layers.Lambda(lambda x: x * 100.0)"
  },
  {
    "objectID": "posts/tensorflow/2022-09-28-Tensorflow.html#force-cpugpu",
    "href": "posts/tensorflow/2022-09-28-Tensorflow.html#force-cpugpu",
    "title": "TensorFlow cheat sheet",
    "section": "Force CPU/GPU",
    "text": "Force CPU/GPU\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\n\n# Check available CPU/GPU devices\n\nprint(tf.config.list_physical_devices('CPU'))\n\nprint(tf.config.list_physical_devices('GPU'))\n\nwith tf.device(\"CPU:0\"):\n    model.fit(....)\n    \nwith tf.device(\"GPU:0\"):\n    model.fit(....)"
  },
  {
    "objectID": "posts/tensorflow/2022-10-07-Tensorflow-2.html#dataset-generators",
    "href": "posts/tensorflow/2022-10-07-Tensorflow-2.html#dataset-generators",
    "title": "TensorFlow cheat sheet 2",
    "section": "Dataset generators",
    "text": "Dataset generators\nHave you ever had to work with a dataset so large that it overwhelmed your machine’s memory? Or maybe you have a complex function that needs to maintain an internal state every time it’s called, but the function is too small to justify creating its own class. In these cases and more, generators and the Python yield statement are here to help\nhttps://realpython.com/introduction-to-python-generators/\nHow yield works:\n\ndef do_yield():\n    for i in range(20):\n        yield i\n        \ngot_yield =  do_yield()\n\nprint(got_yield)\nprint(next(got_yield))\nprint(next(got_yield))\n\nnext(got_yield)\n\nprint(next(got_yield))\ngot_yield\nprint(next(got_yield))\n\nWhen datasets are large and won’t fit into memory, a way to handle this is to use detaset generators. Where data is fed into the model without loading it into memory at once.Each time we iterate the generator, it yields the next value in the series.\nAn example is below. The function takes a path to a file but returns a yield statement, or a data generator, and not a line of the data.\nAs above x,y = next(text_datagen) gets the next line of the text.\nThis can be used when fitting to the model using model.fit_generator(text_datagen)\nSee also load images.\n\ndef get_data(filepath):\n    with open(filepath,'r') as f:\n        for row in f:\n            x=row[0]\n            y=row[1]\n            yield (x,y)\n            \ntext_datagen = get_data('file.txt')\n\nmodel.fit_generator(text_datagen, steps_per_epoch=1000, epochs=5)\n\n\n# or something more practical:\ndef get_generator(features, labels, batch_size=1):\n    for n in range(int(len(features)/batch_size)):\n        x = features[n*batch_size: (n+1)*batch_size]\n        y = labels[n*batch_size: (n+1)*batch_size]\n        yield (x,y)"
  },
  {
    "objectID": "posts/tensorflow/2022-10-07-Tensorflow-2.html#the-dataset-class",
    "href": "posts/tensorflow/2022-10-07-Tensorflow-2.html#the-dataset-class",
    "title": "TensorFlow cheat sheet 2",
    "section": "The dataset Class",
    "text": "The dataset Class\n\nx=np.random.randint(0,255,(100,20,2,2))\ny=np.random.randint(0,4,size=(100,1))\n\ndataset_1 = tf.data.Dataset.from_tensor_slices(x)\n\nprint(\">>\",dataset_1.element_spec)\nprint('>> N.B. first dimension inetrpreted as batch size')\n\ndataset_2 = tf.data.Dataset.from_tensor_slices(y)\nprint(\">>\",dataset_2.element_spec)\n\ndataset_zipped = tf.data.Dataset.zip((dataset_1,dataset_2))\nprint(\">>\",dataset_zipped.element_spec)\n\ndataset_comb = tf.data.Dataset.from_tensor_slices((x,y))\nprint(\">>\",dataset_comb.element_spec)\n\n>> TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None)\n>> N.B. first dimension inetrpreted as batch size\n>> TensorSpec(shape=(1,), dtype=tf.int32, name=None)\n>> (TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(1,), dtype=tf.int32, name=None))\n>> (TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(1,), dtype=tf.int32, name=None))\n\n\nCan access the values by iterating\n\ndef check3s(dataset_comb):\n    dataset_iter = iter(dataset_comb)\n    for i,x in enumerate(dataset_iter):\n        if tf.squeeze(x[1])==3:\n            print('Has 3s')\n            return\n    return 'no 3s'\ncheck3s(dataset_comb)\n\nHas 3s\n\n\n\nFilter\nFilter certain values\n\ndef label_func(image,label):\n    return tf.squeeze(label) != 3\n\ndataset_comb = dataset_comb.filter(label_func)\n\ncheck3s(dataset_comb)\n\n'no 3s'\n\n\n\n\nMap\nModify values. Below creates one-hot encoding\n\ndef map_func(image, x):\n    return (image,tf.one_hot(x,depth=3) )\ndataset_comb_2=dataset_comb.map(map_func)\n\nfor i,x in enumerate(dataset_comb):\n    if i<5:\n        print(i,x[1].numpy())    \n    else:\n        break\n        \nfor i,x in enumerate(dataset_comb_2):\n    if i<5:\n        print(i,x[1].numpy())    \n    else:\n        break\n\n0 [0]\n1 [1]\n2 [2]\n3 [2]\n4 [2]\n0 [[1. 0. 0.]]\n1 [[0. 1. 0.]]\n2 [[0. 0. 1.]]\n3 [[0. 0. 1.]]\n4 [[0. 0. 1.]]\n\n\n\ndataset.batch(20), drop_remainder=True set batch size to 16 and remove any remaining samples if not divisible\ndataset.repeat(10) set the number of epochs. No value inside is indefinitely\ndataset.shuffle(100) shuffle the data, no of sample in the buffer\ndataset.filter(function_name) filter the values use lambda or a function that returns a boolean\ndataset.map(func_name) transform the values\n\ne.g. dataset.map(lambda x:x*2) doubles all values\n\ndataset.take(1) take a value from the dataset"
  },
  {
    "objectID": "posts/tensorflow/2022-10-07-Tensorflow-2.html#tensor-math",
    "href": "posts/tensorflow/2022-10-07-Tensorflow-2.html#tensor-math",
    "title": "TensorFlow cheat sheet 2",
    "section": "Tensor Math",
    "text": "Tensor Math\n\nimport tensorflow.keras.backend as K\n\nx = K.arange(0,10)\ny = K.square(x)\ny_mean = K.mean(y)\n\nprint(f\"x = {x},\\ny = {y},\\ny_mean = {y_mean}\")\n\nx = [0 1 2 3 4 5 6 7 8 9],\ny = [ 0  1  4  9 16 25 36 49 64 81],\ny_mean = 28\n\n\n\n#hide-input\nprint(f\"tf.add([1,2],[3,4]) = {tf.add([1,2],[3,4])}\\n\")\nprint(\"Or with operator overloading\")\nprint(f\"tf.Variable([1,2])+tf.Variable([3,4]) = {tf.Variable([1,2])+tf.Variable([3,4])}\\n\")\nprint(f\"x = tf.Variable([[1,2],[3,4]])\\n\")\nx=tf.Variable([[1,2],[3,4]])\nprint(f\"tf.square(x) = {tf.square(x)}\\n\")\nprint(\"Reduces dimension by adding up components\")\nprint(f\"tf.reduce_sum(x) = {tf.reduce_sum(x)}\\n\")\n      \n\ntf.add([1,2],[3,4]) = [4 6]\n\nOr with operator overloading\ntf.Variable([1,2])+tf.Variable([3,4]) = [4 6]\n\nx = tf.Variable([[1,2],[3,4]])\n\ntf.square(x) = [[ 1  4]\n [ 9 16]]\n\nReduces dimension by adding up components\ntf.reduce_sum(x) = 10"
  },
  {
    "objectID": "posts/tensorflow/2022-10-07-Tensorflow-2.html#tensor-operations",
    "href": "posts/tensorflow/2022-10-07-Tensorflow-2.html#tensor-operations",
    "title": "TensorFlow cheat sheet 2",
    "section": "Tensor Operations",
    "text": "Tensor Operations\n\nEvaluated immediately\nTensorFlow supports two types of code execution, graph-based where all of the data and ops are loaded into a graph before evaluating them within a session, or eager based where all of the code is executed line by line.\nIf eager mode was off, tensor would not be evaluated so\nx_sq = tf.square(2)\nprint(x_sq)\nthe print statement would just show details of the tensor object, such as its name, shape, data type and all that but it would not yet store the number 4 as a value.\nOtherwise values are evaluated immediately in custom eager mode = On\n\n\nBroadcasting\nBroadcasting is where adding or subtracting two tensors of different dimensions is handled in a way where the tensor with fewer dimensions is replicated to match the dimensions of the tensor with more dimensions.\na = tf.constant([[1,2],[3,4]])\n>>tf.add(a,1)\n=tf.Tensor([[2,3],[4,5]])\nOr overloading can utilise Python syntax such as\n>>a ** 2\n=tf.Tensor([[1,4],[9,16]])\nOr using numpy math operations. TensorFlow will convert the tensor objects a and b into ndarrays, and then pass those ndarrays to the np.cos function.\n>>np.cos(a)\n=array([[ 0.54030231, -0.41614684],        [-0.9899925 , -0.65364362]])\nDon’t need to preconvert from the ndarray data type into a tensor data type. TensorFlow handles this automatically.\nndarray = np.ones([3,3])\n=[[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]]\ntf.multiply(ndarray,3)\n=tf.Tensor( [[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]], shape=(3,3), dtype=float64)\nTensors can be easily converted back to numpy arrays using tensor.numpy()"
  },
  {
    "objectID": "posts/tensorflow/2022-10-07-Tensorflow-2.html#simple-example-of-using-gradient-tape-to-calculate-gradient-of-a-function",
    "href": "posts/tensorflow/2022-10-07-Tensorflow-2.html#simple-example-of-using-gradient-tape-to-calculate-gradient-of-a-function",
    "title": "TensorFlow cheat sheet 2",
    "section": "Simple example of using gradient tape to calculate gradient of a function",
    "text": "Simple example of using gradient tape to calculate gradient of a function\n\ndef myfunc(x):\n    return tf.math.sin(x) + tf.math.exp(x/3)\n\nw = tf.Variable(np.arange(0, np.pi*2,.2))\nwith tf.GradientTape() as tape:\n    loss = myfunc(w)\ngradient = tape.gradient(loss, w).numpy()\n\nplt.plot(w.numpy(), loss,'.-')\nplt.grid(True)\nplt.plot(w.numpy(), gradient,'x--');\nplt.legend(['Loss','Gradient of Loss']);"
  },
  {
    "objectID": "posts/tensorflow/2022-10-07-Tensorflow-2.html#using-watch",
    "href": "posts/tensorflow/2022-10-07-Tensorflow-2.html#using-watch",
    "title": "TensorFlow cheat sheet 2",
    "section": "Using watch",
    "text": "Using watch\nIf use watch on a variable the following variables referencing that variable are also watched\nBut the calls to new functions need to be within the with statement, but the gradient getting doesn’t\n\nx = tf.Variable(np.arange(0, np.pi*2,.2))\n\nwith tf.GradientTape() as t:\n    t.watch(x)\n    \n    y = tf.sin(x)\n    z = tf.exp(y)\ndz_dx = t.gradient(z,x)\n\nplt.plot(x.numpy(),z.numpy())\nplt.plot(x.numpy(),dz_dx.numpy(),'--')\nplt.legend(['z','dz/dx'])\nplt.grid(True)"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#coding-custom-layer",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#coding-custom-layer",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Coding custom layer",
    "text": "Coding custom layer\nA layer class is inherited from Kera’s Layer class. Hence, MyLayer(Layer):\n\ndef __init__(self, units=32):\n\nInitializes the class, accepts parameters and sets up internal variables.\nsuper().__init__() returns a temporary object of the superclass (proxy object) the Layer class. This allows us to acces methods of the base class. - make sure to pass class name and self in super() - or **kwargs\nThen build and call functions can be added to create the layer and when it is called. N.B. build can often be moved to __init__.\n\ndef build(self, input_shape):\n\nruns when instance is created\ncreates state of layers (weights)\n\ndef call(self, inputs):\n\ncall does the computation\n\n\nThe values for the parameters can be explicitly set using functions like tf.random_normal_initializer() and sepcifying a shape.\nThe key to call is defining how the parts in build and __init__ are put together to create the computation of the layer.\nAlso note that in the call the format is the same as for the functional API, where the previous layer is added at the end of the next layer.\nAll the variables (weights and biases) can also be accesed with layer_class.variables.\n\n# Create a custom layer\nfrom tensorflow.keras.layers import Layer\nimport tensorflow as tf\n\nclass SimpleDense(Layer):\n    \n    def __init__(self,units=32):\n        super(SimpleDense, self).__init__()\n        self.units = units\n        \n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.w = tf.Variable(\n                initial_value=w_init(shape=(input_shape[-1], self.units), dtype='float32'),\n                trainable=True,name='kernel',\n                                )\n        b_init = tf.zeros_initializer()\n        self.b = tf.Variable(\n                initial_value=b_init(shape=(self.units), dtype='float32'),\n                trainable=True, name='bias',\n                                )\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w)+self.b\n    \ndense_layer = SimpleDense(units=32)\n\nx = tf.ones((1,1))\n\nprint(dense_layer(x) )\nprint()\nprint(f\"Weights = {dense_layer.weights[0].numpy()} \\n\\nand biases {dense_layer.weights[1].numpy()}\")\nprint()\nprint([ var.numpy() for var in dense_layer.variables])\n\ntf.Tensor(\n[[-0.07436698 -0.02011585  0.05582675  0.05404044  0.02519816  0.02855827\n   0.00046192  0.01360966  0.04663334  0.04556176  0.04592257  0.04647708\n  -0.03950281 -0.00014847 -0.03248019  0.08354251  0.07218082 -0.01156685\n   0.04577427 -0.06801199 -0.02725383 -0.02071865  0.08600459 -0.00035707\n  -0.03410981  0.00493511 -0.05133317 -0.12937713 -0.13792662 -0.01709494\n  -0.05110807 -0.01718794]], shape=(1, 32), dtype=float32)\n\nWeights = [[-0.07436698 -0.02011585  0.05582675  0.05404044  0.02519816  0.02855827\n   0.00046192  0.01360966  0.04663334  0.04556176  0.04592257  0.04647708\n  -0.03950281 -0.00014847 -0.03248019  0.08354251  0.07218082 -0.01156685\n   0.04577427 -0.06801199 -0.02725383 -0.02071865  0.08600459 -0.00035707\n  -0.03410981  0.00493511 -0.05133317 -0.12937713 -0.13792662 -0.01709494\n  -0.05110807 -0.01718794]] \n\nand biases [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0.]\n\n[array([[-0.07436698, -0.02011585,  0.05582675,  0.05404044,  0.02519816,\n         0.02855827,  0.00046192,  0.01360966,  0.04663334,  0.04556176,\n         0.04592257,  0.04647708, -0.03950281, -0.00014847, -0.03248019,\n         0.08354251,  0.07218082, -0.01156685,  0.04577427, -0.06801199,\n        -0.02725383, -0.02071865,  0.08600459, -0.00035707, -0.03410981,\n         0.00493511, -0.05133317, -0.12937713, -0.13792662, -0.01709494,\n        -0.05110807, -0.01718794]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)]\n\n\nOr equivalently…\n\n# Create a custom layer\nfrom tensorflow.keras.layers import Layer\nimport tensorflow as tf\n\nclass MyLayer(Layer):\n    \n    def __init__(self,units,input_dim):\n        super(MyLayer, self).__init__()\n        self.w = self.add_weight(shape=(input_dim,units),\n                                initializer='random_normal',\n                                trainable=True)\n        self.b = self.add_weight(shape=(units,),\n                                 initializer='zeros',\n                                trainable=True)\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w)+self.b\n    \ndense_layer = MyLayer(3,5)\n\nx = tf.ones((1,5))\n\nprint(dense_layer(x) )\nprint()\nprint(f\"Weights = {dense_layer.weights[0].numpy()} \\n\\nand biases {dense_layer.weights[1].numpy()}\")"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#create-a-dropout-layer-as-a-custom-layer",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#create-a-dropout-layer-as-a-custom-layer",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Create a Dropout layer as a custom layer",
    "text": "Create a Dropout layer as a custom layer\nN.B. uses tf.nn primitive Neural Net (NN) Operations.\n\nclass MyDropout(Layer):\n\n    def __init__(self, rate):\n        super(MyDropout, self).__init__()\n        self.rate = rate\n        \n    def call(self, inputs):\n        # Define forward pass for dropout layer\n        return tf.nn.dropout(inputs, rate=self.rate)"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#add-activation-functions",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#add-activation-functions",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Add activation functions",
    "text": "Add activation functions\nTo add activation functions in the layer\n\nadd activation=None to the __init__ inputs so it accepts an activation but defaults to None if doesn’t recieve one\nadd the activation to the self variable\n\nuse self.activation = tf.keras.activations.get(activation)\ni.e. so we can pass a string or a function\n\ncall the activation function within the call\n\ni.e. return  self.activation(tf.matmul(inputs, self.w)+self.b)"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#custom-layers-in-a-model",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#custom-layers-in-a-model",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Custom layers in a model",
    "text": "Custom layers in a model\nCan create the model by passing the layer into keras.Sequential as a list. In the same way as done with other layer elements.\n\nxs = np.arange(-1,5,dtype=float)\nys = xs*2 -1\n\nmodel = tf.keras.Sequential([SimpleDense(units=1)])\n\nmodel.compile(optimizer='sgd',loss='mse')\nmodel.fit(xs,ys,epochs=500,verbose=0)\nprint(model.predict([10.]))\n\n[[18.981386]]"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#model-example-residual-networks",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-CustomLayersModels.html#model-example-residual-networks",
    "title": "TensorFlow Low-Level cheat sheet",
    "section": "Model example Residual Networks",
    "text": "Model example Residual Networks\n\n\nfrom tensorflow.keras.layers import Conv2D, Dense, Layer\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\n\nclass CNNResidual(Layer):\n    def __init__(self, layers, filters, **kwargs):\n        super(**kwargs).__init__()\n        self.hidden = [Conv2D(filters, (3,3), activation='relu') for _ in range(layers)]\n    def call(self, inputs):\n        x = inputs\n        for layer in self.hidden:\n            x = layer(x)\n        return inputs + x\n    \nclass DNNResidual(Layer):\n    def __init__(self, layers, neurons, **kwargs):\n        super(**kwargs).__init__()\n        self.hidden = [Dense(neurons, activation='relu') for _ in range(layers)]\n    def call(self, inputs):\n        x = inputs\n        for layer in self.hidden:\n            x = layer(x)\n        return inputs + x\n\nclass MyResidual(Model):\n    def __init(self, **kwargs):\n        self.hidden1 = Dense(30, activation='relu')\n        self.block1 = CNNResidual(2, 32)\n        self.block2 = DNNResidual(2, 64)\n        self.out = Dense(1)\n    def call(self, inputs):\n        x = self.hidden1(inputs)\n        x = self.block1(x)\n        for _ in range(1,4):\n            x = self.block2(x)\n        return self.out(x)"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#load-from-directory",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#load-from-directory",
    "title": "TensorFlow Images cheat sheet",
    "section": "Load from directory",
    "text": "Load from directory\nIf files are in folders can use flow_from_directory the files would need to be separated by class and training/validation as follows for a classification\ne.g. files in folders like this:\n\n/tmp/cats-v-dogs/validation/cats\n/tmp/cats-v-dogs/validation/dogs\n/tmp/cats-v-dogs/training/cats\n`/tmp/cats-v-dogs/training/dogs\n\n\ntrain_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n                                                      batch_size=256,\n                                                      class_mode='binary',\n                                                      target_size=(150, 150))\n# Test your generators\ntrain_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)\n\n# Put in the fit\nmodel.fit(train_generator,\n                    epochs=15,\n                    verbose=1,\n                    validation_data=validation_generator)"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#an-example-of-transfer-learning-on-images-with-inception",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#an-example-of-transfer-learning-on-images-with-inception",
    "title": "TensorFlow Images cheat sheet",
    "section": "An example of transfer learning on images with Inception",
    "text": "An example of transfer learning on images with Inception\n\nLoad the model pre-trained weights\nImport the model architecture\nGive the model the input shape for data\n\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),                                   include_top = False,                                    weights = None)\nBetter to keep the same shape as the model uses and change your data to match it than to change input_shape to match your data.\ninclude_top=False removes top most layer of the model- the output layer\nweights=None just uses the model architecture- note the weights are loaded on a later line\n\nLoad the weights into the model\nFreeze all the layers\nPick out the front part of the model, as the layers to the end are more specialized\nAdd extra layers to the model that can be fitted to\n\nNote this uses the functional API\n\nMatch the image size of our images to that needed by the model\n\nOur model expects 150X150X3 but our data is 50X50. So we need to multiply our image size by 3. This is done by the UpSampling2D layer\nmodel = tf.keras.layers.UpSampling2D(size=(3,3))(model)\nor use resize if image is bigger tf.image.resize(image, (150, 150,))\n\n# 1- Download the inception v3 weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n# 2- Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# 3- create the model and load in the weights\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n                                  include_top = False, \n                                  weights = None) \n\n# 4- load weights into the model\npre_trained_model.load_weights(local_weights_file)\n\n# 5- Make all the layers in the pre-trained model non-trainable\nfor layers in pre_trained_model.layers:\n    layers.trainable = False\n    \n# 6- Pick out part of the model\nlast_desired_layer = pre_trained_model.get_layer('mixed7')    \nlast_output = last_desired_layer.output\n\n# 7- Add extra layers to the model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)  \n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024,activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1,activation='sigmoid')(x) \n\n# 8. Increase input image sizes to match that needed by model using \n# a layer before the existing model starts\n\nmodel = tf.keras.layers.UpSampling2D(size=(3,3))(model)\n\n# Create the complete model by using the Model class\nmodel = Model(inputs=pre_trained_model.input, outputs=x)\n\n\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001), \n            loss = 'binary_crossentropy',\n            metrics = ['accuracy'])"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#r-cnn",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#r-cnn",
    "title": "TensorFlow Images cheat sheet",
    "section": "R-CNN",
    "text": "R-CNN\nR-CNN (R=region) a region based CNN to implement selective search with neural networks.\n\nTakes input images\nExtract regions using selective search method (~2k)\nExtract features using CNN from each region\n\nwarped to match AlexNet inputs\n\nClassify with support vector machine (SVM) instead of dense layers\nPlus regression to get bounding box of images\nVery slow & computationally expensive\n\n\nRoss Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik, “Rich feature hierarchies for accurate object detection and semantic segmentation” 2014"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#fast-r-cnn",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#fast-r-cnn",
    "title": "TensorFlow Images cheat sheet",
    "section": "Fast R-CNN",
    "text": "Fast R-CNN\nThe aim was to improve issues above with RCNN.\n\nEntire image is fed into the ConvNet\n\nno selective search- computationally expensive\nthis Convnet is trained on finding features\nproduces a feature map of the image\n\nEach feature map can then be fed into fully connected dense layer\n\nget feature vector of image\n\nFeature vector fed into layers to do regression and classification\n\n\nRoss Girshick, Fast R-CNN, 2015"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#faster-r-cnn",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#faster-r-cnn",
    "title": "TensorFlow Images cheat sheet",
    "section": "Faster R-CNN",
    "text": "Faster R-CNN\n\nentire image into Convnet\nsliding window to find areas of interest\nsomething called a Region Proposed Network is used with data to find and create anchor boxes on image\nThe cropped and passed to Dense layers for classification and regression.\n\n Deep Learning for Computer Vision with Python"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#object-detection-in-tensorflow",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#object-detection-in-tensorflow",
    "title": "TensorFlow Images cheat sheet",
    "section": "Object detection in TensorFlow",
    "text": "Object detection in TensorFlow\nhttps://www.tensorflow.org/hub\n\nTensorFlow Hub is a repository of trained machine learning models ready for fine-tuning and deployable anywhere. Reuse trained models like BERT and Faster R-CNN with just a few lines of code.\n\nCopy url from hub page https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1 page for faster rcnn. And copy url is “https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1”\n\nimport tensorflow as tf\nimport tensorflow-hub as hub\n\nmodule_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n\ndetector = hub.load(module_handle).signatures['default']\n\n\nAn example can be found here https://www.tensorflow.org/hub/tutorials/object_detection"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#object-detection-api",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-Images.html#object-detection-api",
    "title": "TensorFlow Images cheat sheet",
    "section": "Object Detection API",
    "text": "Object Detection API\nhttps://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md https://github.com/tensorflow/models/tree/master/research/object_detection https://www.tensorflow.org/guide/checkpoint"
  },
  {
    "objectID": "posts/tensorflow/2022-10-10-Tensorflow-NLP.html",
    "href": "posts/tensorflow/2022-10-10-Tensorflow-NLP.html",
    "title": "TensorFlow NLP cheat sheet",
    "section": "",
    "text": "Basic Implementation\nThe standard language model starts with an embedding layer, this then needs to be flattened to a vector, then we can add a dense layer before an output layer.\nThe Embedding layer creates a vector-space for the text data. So for example, the words beautiful and ugly may be in opposite directions. And words such as cat and kitten may be close together in vector space.\nGlobalAveragePooling1Dcan be replaced by Flatten()\n\nmodel = tf.keras.Sequential([ \n    tf.keras.layers.Embedding(num_words,embedding_dim,input_length=maxlen),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(5,'softmax')\n])\n\nThe model above does not take account for the order of words,\nIf we want to do this we can insert an additional layer after the embedding layer. For example, by using the LSTM model as below\n\nmodel_lstm= tf.keras.Sequential([\n    tf.keras.layers.Embedding(VOCAB_SIZE,EMBEDDING_DIM,input_length=MAXLEN),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')   \n])\n\nWe can even insert a conolution layer after the embedding instead\ntf.keras.layers.Conv1D(128,5,activation='relu')\nFor two consecutive layers of RNNs use return_sequences=True\n\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),\n\n\n\nText data Tokenizer\n\nCreate a Tokenizer instance\nFit tokenizer to text data with tokenizer.fit_on_texts(text_data)\nConvert text to sequences with sequences = tokenizer.texts_to_sequences(text_data)\n\nFor example, the following words have the indices: apple->1, brain->2, cat->3, that->4, is->5\nAnd a sequence of text within the data can be converted to a sequence: “that cat apple is brain” -> (4, 3, 1, 5, 2)\n\nGet the word index word_index = tokenizer.word_index\nGet the text back from the sequences text = tokenizer.sequences_to_texts(sequences)\n\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(oov_token=\"<OOV>\",num_words=10_000)\ntokenizer.fit_on_texts(text_data)\n\nsequences = label_tokenizer.texts_to_sequences(text_data)"
  }
]